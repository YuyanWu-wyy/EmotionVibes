nohup: ignoring input
[NbConvertApp] Converting notebook AdptivePrune_structure.ipynb to notebook
0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
2023-11-27 18:48:35.642897: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-27 18:49:09.804921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.816424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.816664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.820010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.820199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.820364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.891649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.891850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.892015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.892155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6
2023-11-27 18:49:09.892645: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2023-11-27 18:49:10.822157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.822447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.822633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.822851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.823027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.823167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6
2023-11-27 18:49:10.823199: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2023-11-27 18:49:10.846749: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled
2023-11-27 18:49:11.061077: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_16/lstm_cell_16/kernel/Assign' id:2656 op device:{requested: '', assigned: ''} def:{{{node lstm_16/lstm_cell_16/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_16/lstm_cell_16/kernel, lstm_16/lstm_cell_16/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 18:49:11.195138: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 18:49:11.228533: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 18:49:15.890905: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_28/lstm_cell_28/bias/v/Assign' id:17467 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_28/lstm_cell_28/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_28/lstm_cell_28/bias/v, training/Adam/lstm_28/lstm_cell_28/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 18:49:20.371191: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
2023-11-27 18:49:22.522801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-11-27 18:49:22.537186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902
2023-11-27 18:49:44.112175: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
Traceback (most recent call last):
  File "/usr/bin/jupyter-nbconvert", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/lib/python3.11/site-packages/jupyter_core/application.py", line 285, in launch_instance
    return super().launch_instance(argv=argv, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/traitlets/config/application.py", line 1043, in launch_instance
    app.start()
  File "/usr/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 410, in start
    self.convert_notebooks()
  File "/usr/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 585, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/usr/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 551, in convert_single_notebook
    output, resources = self.export_single_notebook(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 477, in export_single_notebook
    output, resources = self.exporter.from_filename(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 352, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py", line 100, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/usr/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py", line 121, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 166, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/usr/lib/python3.11/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import tensorflow as tf
from tensorflow.keras.callbacks import Callback
import numpy as np

import tensorflow as tf
from tensorflow.keras.callbacks import Callback
import numpy as np

class PruningCallback(tf.keras.callbacks.Callback):
    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):
        super(PruningCallback, self).__init__()
        self.initial_pruning_factor = initial_pruning_factor
        self.final_pruning_factor = final_pruning_factor
        self.start_epoch = start_epoch
        self.end_epoch = end_epoch if end_epoch is not None else np.inf
        self.frequency = frequency
        self.pruned_weights = {}
        self.layer_importance = {}

    def get_pruning_factor(self, epoch):
        if epoch < self.start_epoch:
            return 0
        if epoch > self.end_epoch:
            return self.final_pruning_factor
        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)

    def on_train_begin(self, logs=None):
        total_weight_magnitude = 0
        for layer in self.model.layers:
            if hasattr(layer, 'get_weights'):
                weights = layer.get_weights()
                layer_norm = sum(np.linalg.norm(w) for w in weights)
                total_weight_magnitude += layer_norm
                self.layer_importance[layer.name] = layer_norm
    
        # Normalize the layer importance values so they sum up to 1
        for layer_name in self.layer_importance:
            self.layer_importance[layer_name] /= total_weight_magnitude
    # def on_train_begin(self, logs=None):
    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])
    #     for layer in self.model.layers:
    #         if hasattr(layer, 'get_weights'):
    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude

    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):
        if layer_name in self.layer_importance:
            importance = self.layer_importance[layer_name]
            adjusted_pruning_factor = global_pruning_factor * (1 - importance)
            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1
        return global_pruning_factor
    def prune_weights(self, layer, global_pruning_factor):
        
        weights = layer.get_weights()
        layer_name = layer.name
        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)

        if layer_name not in self.pruned_weights:
            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]
        
        for i in range(len(weights)):
            weight = weights[i]
            # print(weight.shape)
            # print(weight.size)
            if weight.ndim > 1:  # Only prune dense or convolutional layers
                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])
                num_unpruned = np.sum(unpruned_weights)
                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))
                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])
                if num_pruning > 0:
                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)
                    abs_unpruned_weights = np.abs(weight[unpruned_weights])
                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]
                    
                    indices = np.unravel_index(pruning_flat_indices, weight.shape)
                    self.pruned_weights[layer_name][i][indices] = True

                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])
                
        layer.set_weights(weights)

    def on_epoch_end(self, epoch, logs=None):
        if (epoch - self.start_epoch) % self.frequency != 0:
            return

        pruning_factor = self.get_pruning_factor(epoch)
        for layer in self.model.layers:
            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):
                self.prune_weights(layer, pruning_factor)
model = individual_model(X_train_normalized)
model.compile(loss='mean_absolute_error', optimizer='adam')
num_epochs = 100
rates = [0.35]
idx = 0
for r in rates:
# Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.
    model_name = './checkpoints/Adaptive_structure_prune_model_'+str(idx)+'.h5'
    idx = idx+1
    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)
    pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=50, frequency=1)
    model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])
    for epoch in range(num_epochs):
        # Calculate the current pruning factor
        if epoch < start_epoch:
            current_pruning_factor = initial_pruning_factor
        elif epoch > end_epoch:
            current_pruning_factor = final_pruning_factor
        else:
            current_pruning_factor = initial_pruning_factor + (final_pruning_factor - initial_pruning_factor) * (epoch - start_epoch) / (end_epoch - start_epoch)
    
        # Initialize the structured pruning callback for the current epoch
        pruning_callback = StructuredPruningCallback(initial_pruning_factor=initial_pruning_factor,
                                                     final_pruning_factor=current_pruning_factor,
                                                     start_epoch=epoch,
                                                     end_epoch=epoch + 1,  # Apply pruning at the end of each epoch
                                                     frequency=1)
    
        # Train the model for one epoch
        model.fit(X_train_normalized_new, y_train, 
                  epochs=1,  # Train for one epoch at a time
                  batch_size=1024, 
                  validation_data=(X_val_normalized_new, y_val), 
                  callbacks=[pruning_callback])
    
        # Optionally, save the model at each stage
        model_name = './checkpoints/Structured_prune_model_epoch_{}.h5'.format(epoch)
        model.save(model_name)

------------------

----- stdout -----
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stderr -----
2023-11-27 18:49:09.804921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.816424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.816664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.820010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.820199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.820364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.891649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.891850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.892015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:09.892155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6
2023-11-27 18:49:09.892645: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
----- stdout -----
WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stderr -----
2023-11-27 18:49:10.822157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.822447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.822633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.822851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.823027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 18:49:10.823167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6
2023-11-27 18:49:10.823199: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2023-11-27 18:49:10.846749: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled
----- stderr -----
2023-11-27 18:49:11.061077: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_16/lstm_cell_16/kernel/Assign' id:2656 op device:{requested: '', assigned: ''} def:{{{node lstm_16/lstm_cell_16/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_16/lstm_cell_16/kernel, lstm_16/lstm_cell_16/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 18:49:11.195138: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 18:49:11.228533: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
----- stdout -----
WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
----- stdout -----
(29601, 95)
----- stdout -----
Train on 29601 samples, validate on 3694 samples
----- stderr -----
2023-11-27 18:49:15.890905: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_28/lstm_cell_28/bias/v/Assign' id:17467 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_28/lstm_cell_28/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_28/lstm_cell_28/bias/v, training/Adam/lstm_28/lstm_cell_28/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
----- stdout -----
Epoch 1/100
----- stderr -----
2023-11-27 18:49:20.371191: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
----- stderr -----
2023-11-27 18:49:22.522801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-11-27 18:49:22.537186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902
----- stdout -----
 1024/29601 [>.............................] - ETA: 2:12 - loss: 5.0393
----- stdout -----
 2048/29601 [=>............................] - ETA: 1:16 - loss: 5.0283
----- stdout -----
 3072/29601 [==>...........................] - ETA: 54s - loss: 4.9703
----- stdout -----
 4096/29601 [===>..........................] - ETA: 44s - loss: 4.9160
----- stdout -----
 5120/29601 [====>.........................] - ETA: 37s - loss: 4.8665
----- stdout -----
 6144/29601 [=====>........................] - ETA: 32s - loss: 4.8193
----- stdout -----
 7168/29601 [======>.......................] - ETA: 28s - loss: 4.7605
----- stdout -----
 8192/29601 [=======>......................] - ETA: 25s - loss: 4.7083
----- stdout -----
 9216/29601 [========>.....................] - ETA: 23s - loss: 4.6490
----- stdout -----
10240/29601 [=========>....................] - ETA: 21s - loss: 4.5908
----- stdout -----
11264/29601 [==========>...................] - ETA: 19s - loss: 4.5369
----- stdout -----
12288/29601 [===========>..................] - ETA: 17s - loss: 4.4825
----- stdout -----
13312/29601 [============>.................] - ETA: 16s - loss: 4.4231
----- stdout -----
14336/29601 [=============>................] - ETA: 15s - loss: 4.3612
----- stdout -----
15360/29601 [==============>...............] - ETA: 13s - loss: 4.2926
----- stdout -----
16384/29601 [===============>..............] - ETA: 12s - loss: 4.2261
----- stdout -----
17408/29601 [================>.............] - ETA: 11s - loss: 4.1627
----- stdout -----
18432/29601 [=================>............] - ETA: 10s - loss: 4.0937
----- stdout -----
19456/29601 [==================>...........] - ETA: 9s - loss: 4.0260
----- stdout -----
20480/29601 [===================>..........] - ETA: 8s - loss: 3.9558
----- stdout -----
21504/29601 [====================>.........] - ETA: 7s - loss: 3.8883
----- stdout -----
22528/29601 [=====================>........] - ETA: 6s - loss: 3.8224
----- stdout -----
23552/29601 [======================>.......] - ETA: 5s - loss: 3.7554
----- stdout -----
24576/29601 [=======================>......] - ETA: 4s - loss: 3.6920
----- stdout -----
25600/29601 [========================>.....] - ETA: 3s - loss: 3.6314
----- stdout -----
26624/29601 [=========================>....] - ETA: 2s - loss: 3.5784
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 3.5284
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 3.4791
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 3.4385
----- stderr -----
/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
2023-11-27 18:49:44.112175: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
----- stdout -----

Epoch 1: val_loss improved from inf to 2.05327, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 41s 1ms/sample - loss: 3.4385 - val_loss: 2.0533
----- stdout -----
Epoch 2/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 2.2201
----- stdout -----
 2048/29601 [=>............................] - ETA: 16s - loss: 2.2127
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 2.1587
----- stdout -----
 4096/29601 [===>..........................] - ETA: 15s - loss: 2.1351
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 2.0959
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 2.0711
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 2.0544
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 2.0401
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 2.0249
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 2.0094
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.9958
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.9852
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.9713
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.9608
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.9488
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.9384
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.9298
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.9201
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.9111
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.9017
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.8919
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.8854
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.8775
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.8693
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.8638
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.8578
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.8508
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.8441
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.8384
----- stdout -----

Epoch 2: val_loss improved from 2.05327 to 1.63451, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 611us/sample - loss: 1.8384 - val_loss: 1.6345
----- stdout -----
Epoch 3/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.7140
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.6629
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.6731
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.6678
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.6687
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.6697
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.6584
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.6513
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.6467
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.6459
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.6479
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.6510
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.6461
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.6427
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.6383
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.6382
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.6352
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.6305
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.6282
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.6244
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.6224
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.6203
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.6168
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.6171
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.6157
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.6157
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.6130
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.6127
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.6121
----- stdout -----

Epoch 3: val_loss improved from 1.63451 to 1.56232, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.6121 - val_loss: 1.5623
----- stdout -----
Epoch 4/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 15s - loss: 1.5835
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.5983
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.5684
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.5674
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.5661
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.5684
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.5676
----- stdout -----
 8192/29601 [=======>......................] - ETA: 11s - loss: 1.5655
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.5616
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.5563
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.5576
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.5569
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.5580
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.5571
----- stdout -----
15360/29601 [==============>...............] - ETA: 7s - loss: 1.5575
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.5545
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.5559
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.5556
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.5520
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.5521
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.5521
----- stdout -----
22528/29601 [=====================>........] - ETA: 3s - loss: 1.5529
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.5521
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.5533
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.5524
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.5542
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.5540
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.5532
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.5525
----- stdout -----

Epoch 4: val_loss improved from 1.56232 to 1.52938, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 596us/sample - loss: 1.5525 - val_loss: 1.5294
----- stdout -----
Epoch 5/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.5520
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.5486
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.5441
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.5315
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.5291
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.5214
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.5211
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.5197
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.5211
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.5229
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.5273
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.5266
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.5258
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.5233
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.5215
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.5204
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.5178
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.5183
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.5176
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.5208
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.5201
----- stdout -----
22528/29601 [=====================>........] - ETA: 3s - loss: 1.5206
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.5208
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.5222
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.5217
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.5237
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.5247
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.5248
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.5232
----- stdout -----

Epoch 5: val_loss improved from 1.52938 to 1.50502, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.5232 - val_loss: 1.5050
----- stdout -----
Epoch 6/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4890
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.5053
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.5177
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.5218
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.5136
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.5064
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.5100
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.5094
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.5101
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.5130
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.5103
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.5097
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.5090
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.5075
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.5090
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.5098
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.5086
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.5100
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.5098
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.5113
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.5105
----- stdout -----
22528/29601 [=====================>........] - ETA: 3s - loss: 1.5098
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.5099
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.5092
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.5074
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.5074
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.5076
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.5066
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.5066
----- stdout -----

Epoch 6: val_loss improved from 1.50502 to 1.48971, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 602us/sample - loss: 1.5066 - val_loss: 1.4897
----- stdout -----
Epoch 7/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4774
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4821
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.4821
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4932
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4870
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4955
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4913
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4875
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4922
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.4926
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4953
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4952
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4965
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4958
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4974
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4985
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4958
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4948
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4932
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4962
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4964
----- stdout -----
22528/29601 [=====================>........] - ETA: 3s - loss: 1.4972
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4967
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4961
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4969
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4945
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4942
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4950
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4953
----- stdout -----

Epoch 7: val_loss improved from 1.48971 to 1.47747, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4953 - val_loss: 1.4775
----- stdout -----
Epoch 8/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4936
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4854
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.4841
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4728
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4749
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4808
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4862
----- stdout -----
 8192/29601 [=======>......................] - ETA: 11s - loss: 1.4929
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4909
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.4906
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4895
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4915
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4899
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4864
----- stdout -----
15360/29601 [==============>...............] - ETA: 7s - loss: 1.4859
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4859
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4846
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4858
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4888
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4872
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4904
----- stdout -----
22528/29601 [=====================>........] - ETA: 3s - loss: 1.4899
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4900
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4904
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4900
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4882
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4883
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4855
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4852
----- stdout -----

Epoch 8: val_loss improved from 1.47747 to 1.46971, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 597us/sample - loss: 1.4852 - val_loss: 1.4697
----- stdout -----
Epoch 9/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 15s - loss: 1.4427
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4299
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.4444
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4575
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4610
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4705
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4754
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4780
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4798
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.4783
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4773
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4741
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4743
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4719
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4744
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4729
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4740
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4746
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4770
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4777
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4783
----- stdout -----
22528/29601 [=====================>........] - ETA: 3s - loss: 1.4790
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4802
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4801
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4807
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4796
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4790
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4795
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4783
----- stdout -----

Epoch 9: val_loss improved from 1.46971 to 1.45828, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4783 - val_loss: 1.4583
----- stdout -----
Epoch 10/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.5053
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4606
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.4590
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4621
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4675
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4635
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4646
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4648
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4670
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.4670
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4673
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4697
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4692
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4699
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4718
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4705
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4728
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4710
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4694
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4662
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4670
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4675
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4687
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4704
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4719
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4704
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4714
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4713
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4708
----- stdout -----

Epoch 10: val_loss improved from 1.45828 to 1.44990, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 603us/sample - loss: 1.4708 - val_loss: 1.4499
----- stdout -----
Epoch 11/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4423
----- stdout -----
 2048/29601 [=>............................] - ETA: 16s - loss: 1.4569
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4547
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4589
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4657
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4677
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.4658
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4667
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4657
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4616
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4598
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4647
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4656
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4683
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4672
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4694
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4709
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4711
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.4697
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4695
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4704
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4683
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4671
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.4694
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4702
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4712
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4704
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4693
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4672
----- stdout -----

Epoch 11: val_loss improved from 1.44990 to 1.44369, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 19s 654us/sample - loss: 1.4672 - val_loss: 1.4437
----- stdout -----
Epoch 12/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4881
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4910
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.4853
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.4853
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.4847
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.4807
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.4789
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.4749
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.4694
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.4694
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.4685
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.4671
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.4696
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.4709
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.4719
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.4699
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4682
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.4678
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.4701
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4705
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.4692
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4677
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4683
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.4681
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4664
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4660
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4655
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4655
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4651
----- stdout -----

Epoch 12: val_loss improved from 1.44369 to 1.43757, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 668us/sample - loss: 1.4651 - val_loss: 1.4376
----- stdout -----
Epoch 13/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4502
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4565
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4686
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4630
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4647
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4614
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4615
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4641
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4585
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4589
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4569
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4557
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4550
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4551
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4554
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4545
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4563
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4590
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4580
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4559
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4545
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4544
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4562
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4561
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4565
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4550
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4546
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4572
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4563
----- stdout -----

Epoch 13: val_loss did not improve from 1.43757
----- stdout -----
29601/29601 [==============================] - 18s 606us/sample - loss: 1.4563 - val_loss: 1.4385
----- stdout -----
Epoch 14/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4530
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4660
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4696
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4618
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4508
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4485
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4480
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4486
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4517
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4548
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4568
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4566
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4572
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4588
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4573
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4550
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4548
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4524
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4521
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4533
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4515
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4528
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4541
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4533
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4526
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4523
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4511
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4508
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4521
----- stdout -----

Epoch 14: val_loss improved from 1.43757 to 1.43345, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 611us/sample - loss: 1.4521 - val_loss: 1.4335
----- stdout -----
Epoch 15/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4921
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4828
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4577
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4579
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4673
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4765
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4775
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4760
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4715
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4711
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4692
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4730
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4681
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4664
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4647
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4637
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4644
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4651
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4658
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4641
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4627
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4623
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4607
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4605
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4603
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4592
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4588
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4590
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4593
----- stdout -----

Epoch 15: val_loss did not improve from 1.43345
----- stdout -----
29601/29601 [==============================] - 18s 606us/sample - loss: 1.4593 - val_loss: 1.4470
----- stdout -----
Epoch 16/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4890
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4607
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4718
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4490
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4492
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4583
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4568
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4557
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4511
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4517
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4548
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4542
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4507
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4508
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4525
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4478
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4494
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4496
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4500
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4486
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4472
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4461
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4451
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4454
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4453
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4453
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4444
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4428
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4422
----- stdout -----

Epoch 16: val_loss improved from 1.43345 to 1.42541, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 620us/sample - loss: 1.4422 - val_loss: 1.4254
----- stdout -----
Epoch 17/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4914
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4847
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4846
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4824
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4738
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4652
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4749
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4673
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4691
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4669
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4694
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4668
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4626
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4632
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4648
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4650
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4626
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4638
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4611
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4593
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4609
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4611
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4619
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4598
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4599
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4595
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4614
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4593
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4577
----- stdout -----

Epoch 17: val_loss did not improve from 1.42541
----- stdout -----
29601/29601 [==============================] - 18s 605us/sample - loss: 1.4577 - val_loss: 1.4273
----- stdout -----
Epoch 18/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4656
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4639
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4495
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4545
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4475
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4473
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4460
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4477
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4486
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4486
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4461
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4471
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4440
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4418
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4434
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4425
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4414
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4398
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4396
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4406
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4395
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4412
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4398
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4404
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4411
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4413
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4402
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4410
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4401
----- stdout -----

Epoch 18: val_loss improved from 1.42541 to 1.42213, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 607us/sample - loss: 1.4401 - val_loss: 1.4221
----- stdout -----
Epoch 19/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4480
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4714
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4531
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4522
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4413
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4363
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4339
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4360
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4400
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4420
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4419
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4398
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4391
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4406
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4386
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4372
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4364
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4379
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4356
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4363
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4375
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4380
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4399
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4388
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4391
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4376
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4366
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4379
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4384
----- stdout -----

Epoch 19: val_loss improved from 1.42213 to 1.41729, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.4384 - val_loss: 1.4173
----- stdout -----
Epoch 20/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4420
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4352
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4452
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4294
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4309
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4303
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4306
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4317
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4337
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4337
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4311
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4292
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4313
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4323
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4320
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4300
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4295
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4289
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4292
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4290
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4297
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4304
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4291
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4284
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4287
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4293
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4296
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4304
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4312
----- stdout -----

Epoch 20: val_loss did not improve from 1.41729
----- stdout -----
29601/29601 [==============================] - 18s 611us/sample - loss: 1.4312 - val_loss: 1.4198
----- stdout -----
Epoch 21/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4193
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4267
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4115
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4139
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4203
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4184
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4239
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4276
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4319
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4339
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4363
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4344
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4356
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4341
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4342
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4323
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4303
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4314
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4324
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4326
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4332
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4318
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4304
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4276
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4289
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4290
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4288
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4266
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4263
----- stdout -----

Epoch 21: val_loss improved from 1.41729 to 1.40833, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 613us/sample - loss: 1.4263 - val_loss: 1.4083
----- stdout -----
Epoch 22/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 17s - loss: 1.4195
----- stdout -----
 2048/29601 [=>............................] - ETA: 16s - loss: 1.4133
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4140
----- stdout -----
 4096/29601 [===>..........................] - ETA: 15s - loss: 1.4112
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4089
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4088
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.4111
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4115
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4128
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4159
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4187
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4202
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4194
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4199
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4214
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4223
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4208
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4207
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4203
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4219
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4222
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4220
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4219
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4228
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4222
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4217
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4220
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4232
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4235
----- stdout -----

Epoch 22: val_loss did not improve from 1.40833
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.4235 - val_loss: 1.4122
----- stdout -----
Epoch 23/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4470
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4227
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4295
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4294
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4191
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4264
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4234
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4208
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4235
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4185
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4191
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4208
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4202
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4237
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4259
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4264
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4260
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4269
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4272
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4278
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4261
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4267
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4266
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4265
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4252
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4247
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4255
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4244
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4239
----- stdout -----

Epoch 23: val_loss improved from 1.40833 to 1.40557, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 609us/sample - loss: 1.4239 - val_loss: 1.4056
----- stdout -----
Epoch 24/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3995
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4280
----- stdout -----
 3072/29601 [==>...........................] - ETA: 16s - loss: 1.4272
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.4177
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.4227
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.4213
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.4216
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.4247
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.4243
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.4234
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.4255
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.4285
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.4260
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.4242
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.4243
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.4232
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4207
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.4209
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.4218
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4228
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.4228
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4227
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4229
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.4220
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4218
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4216
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4202
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4195
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4198
----- stdout -----

Epoch 24: val_loss improved from 1.40557 to 1.40279, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 687us/sample - loss: 1.4198 - val_loss: 1.4028
----- stdout -----
Epoch 25/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4523
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4513
----- stdout -----
 3072/29601 [==>...........................] - ETA: 16s - loss: 1.4380
----- stdout -----
 4096/29601 [===>..........................] - ETA: 15s - loss: 1.4357
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4268
----- stdout -----
 6144/29601 [=====>........................] - ETA: 14s - loss: 1.4272
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.4227
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4183
----- stdout -----
 9216/29601 [========>.....................] - ETA: 12s - loss: 1.4159
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4139
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4174
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4171
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4205
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4190
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4147
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4137
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4149
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4136
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4157
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4167
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4174
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4162
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4139
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4155
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4157
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4158
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4167
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4165
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4159
----- stdout -----

Epoch 25: val_loss did not improve from 1.40279
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.4159 - val_loss: 1.4036
----- stdout -----
Epoch 26/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3974
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3963
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4200
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4123
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4108
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4106
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4116
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4088
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4137
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4175
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4180
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4163
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4178
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4182
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4160
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4170
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4189
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4182
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4181
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4173
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4187
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4203
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4205
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4204
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4187
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4159
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4155
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4158
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4165
----- stdout -----

Epoch 26: val_loss improved from 1.40279 to 1.39882, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 605us/sample - loss: 1.4165 - val_loss: 1.3988
----- stdout -----
Epoch 27/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.5718
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.5451
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.5088
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4998
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4972
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4942
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4878
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4768
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4682
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4590
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4595
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4567
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4537
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4509
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4518
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4489
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4450
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4432
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4431
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4416
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4410
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4407
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4419
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4419
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4406
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4382
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4361
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4346
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4354
----- stdout -----

Epoch 27: val_loss did not improve from 1.39882
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4354 - val_loss: 1.4000
----- stdout -----
Epoch 28/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4398
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4155
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4163
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4212
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4222
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4268
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4247
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4264
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4256
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4240
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4234
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4193
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4211
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4194
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4216
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4204
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4181
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4182
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4173
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4176
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4159
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4150
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4145
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4158
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4164
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4161
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4163
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4159
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4154
----- stdout -----

Epoch 28: val_loss did not improve from 1.39882
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4154 - val_loss: 1.3991
----- stdout -----
Epoch 29/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3604
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3842
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3922
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3909
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3936
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4009
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4041
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4048
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4065
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4043
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4049
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4078
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4088
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4120
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4129
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4113
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4110
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4105
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4103
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4104
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4117
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4113
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4101
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4106
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4114
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4122
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4121
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4128
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4121
----- stdout -----

Epoch 29: val_loss did not improve from 1.39882
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4121 - val_loss: 1.4016
----- stdout -----
Epoch 30/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4213
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4218
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.4324
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4262
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4158
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4139
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4118
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4134
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4128
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4120
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4128
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4135
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4119
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.4138
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4151
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.4141
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4141
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4132
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.4131
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4136
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4136
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4142
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4128
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.4120
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4118
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4122
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4118
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4110
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4107
----- stdout -----

Epoch 30: val_loss did not improve from 1.39882
----- stdout -----
29601/29601 [==============================] - 19s 628us/sample - loss: 1.4107 - val_loss: 1.3989
----- stdout -----
Epoch 31/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.7750
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.7303
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.7010
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.6498
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.6098
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.5770
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.5665
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.5655
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.5589
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.5500
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.5447
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.5348
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.5230
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.5191
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.5140
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.5076
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.5030
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4990
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4978
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4950
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4916
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4890
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4849
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4802
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4793
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4759
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4746
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4729
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4714
----- stdout -----

Epoch 31: val_loss did not improve from 1.39882
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4714 - val_loss: 1.4060
----- stdout -----
Epoch 32/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4248
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4209
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4134
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4046
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4133
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4122
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4124
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4107
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4101
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4121
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4150
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4127
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4155
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4189
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4179
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4200
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4211
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4209
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4205
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4210
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4190
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4186
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4167
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4171
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4157
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4139
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4147
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4150
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4159
----- stdout -----

Epoch 32: val_loss did not improve from 1.39882
----- stdout -----
29601/29601 [==============================] - 18s 601us/sample - loss: 1.4159 - val_loss: 1.4061
----- stdout -----
Epoch 33/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4222
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4097
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.4048
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3950
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3949
----- stdout -----
 6144/29601 [=====>........................] - ETA: 14s - loss: 1.3983
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.4030
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.4052
----- stdout -----
 9216/29601 [========>.....................] - ETA: 12s - loss: 1.4071
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.4081
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.4076
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4096
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.4111
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.4096
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4100
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.4105
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4128
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4125
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.4141
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4104
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4112
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4080
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4090
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.4102
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4103
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4096
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4097
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4105
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4082
----- stdout -----

Epoch 33: val_loss improved from 1.39882 to 1.39522, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 19s 630us/sample - loss: 1.4082 - val_loss: 1.3952
----- stdout -----
Epoch 34/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4219
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4193
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4179
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4130
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4125
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4096
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4077
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4040
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4071
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4040
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4050
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4037
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4044
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4060
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4060
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4069
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4073
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4053
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4053
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4066
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4064
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4063
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4054
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4068
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4061
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4063
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4067
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4077
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4066
----- stdout -----

Epoch 34: val_loss did not improve from 1.39522
----- stdout -----
29601/29601 [==============================] - 18s 601us/sample - loss: 1.4066 - val_loss: 1.3961
----- stdout -----
Epoch 35/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.5248
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.5095
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4820
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4650
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4622
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4637
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4612
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4566
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4511
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.4474
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4455
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4442
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4445
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4435
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4394
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4384
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4364
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4352
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4342
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4333
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4322
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4301
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4293
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4295
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4308
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4314
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4297
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4289
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4283
----- stdout -----

Epoch 35: val_loss did not improve from 1.39522
----- stdout -----
29601/29601 [==============================] - 18s 598us/sample - loss: 1.4283 - val_loss: 1.4124
----- stdout -----
Epoch 36/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3783
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3961
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4032
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4033
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4057
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4063
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.4103
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4083
----- stdout -----
 9216/29601 [========>.....................] - ETA: 12s - loss: 1.4072
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4035
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4038
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4044
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4041
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.4040
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4039
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.4071
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4072
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4089
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.4091
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4089
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.4053
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4051
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4042
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.4055
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4053
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4055
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4053
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4065
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4054
----- stdout -----

Epoch 36: val_loss did not improve from 1.39522
----- stdout -----
29601/29601 [==============================] - 19s 650us/sample - loss: 1.4054 - val_loss: 1.3966
----- stdout -----
Epoch 37/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4289
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4437
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4212
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4113
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4021
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3921
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4017
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3995
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3975
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3983
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3986
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3983
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3976
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3967
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3990
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4011
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4020
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4035
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4030
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4031
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4039
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4049
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4042
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4055
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4060
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4045
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4060
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4068
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4083
----- stdout -----

Epoch 37: val_loss improved from 1.39522 to 1.39171, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 606us/sample - loss: 1.4083 - val_loss: 1.3917
----- stdout -----
Epoch 38/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4202
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4040
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3980
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4040
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4012
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4024
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4023
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3997
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3977
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3964
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3964
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3977
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3969
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3947
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3938
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3955
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3962
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3969
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3976
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4000
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3999
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3999
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3982
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3995
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3989
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3995
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3998
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4021
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4031
----- stdout -----

Epoch 38: val_loss did not improve from 1.39171
----- stdout -----
29601/29601 [==============================] - 18s 602us/sample - loss: 1.4031 - val_loss: 1.3925
----- stdout -----
Epoch 39/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4058
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4244
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4280
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4257
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4224
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4268
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4174
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4217
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4212
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4203
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4169
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4165
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4153
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4158
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4152
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4143
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4140
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4141
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4160
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4167
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4153
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4153
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4145
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4138
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4141
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4130
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4136
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4122
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4110
----- stdout -----

Epoch 39: val_loss did not improve from 1.39171
----- stdout -----
29601/29601 [==============================] - 18s 602us/sample - loss: 1.4110 - val_loss: 1.3952
----- stdout -----
Epoch 40/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.7134
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.6888
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.6253
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.5786
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.5539
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.5537
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.5568
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.5495
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.5453
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.5396
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.5309
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.5281
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.5236
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.5191
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.5108
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.5065
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.5019
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4968
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4956
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4938
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4919
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4896
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4863
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4838
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4822
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4795
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4767
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4751
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4730
----- stdout -----

Epoch 40: val_loss did not improve from 1.39171
----- stdout -----
29601/29601 [==============================] - 18s 602us/sample - loss: 1.4730 - val_loss: 1.4038
----- stdout -----
Epoch 41/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4570
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4368
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4131
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4054
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4120
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4108
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4124
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4149
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4140
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4154
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4156
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4149
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4154
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4174
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4140
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4168
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4166
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4160
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4139
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4136
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4125
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4129
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4125
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4129
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4120
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4109
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4108
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4090
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4086
----- stdout -----

Epoch 41: val_loss improved from 1.39171 to 1.39157, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 605us/sample - loss: 1.4086 - val_loss: 1.3916
----- stdout -----
Epoch 42/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.6677
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.6475
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.5948
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.5595
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.5306
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.5178
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.5147
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.5094
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.5014
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4928
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4897
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4852
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4823
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4784
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4756
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4769
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4755
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4733
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4722
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4690
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4673
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4658
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4618
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4573
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4544
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4536
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4510
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4497
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4489
----- stdout -----

Epoch 42: val_loss did not improve from 1.39157
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.4489 - val_loss: 1.3960
----- stdout -----
Epoch 43/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3788
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4252
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4325
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4277
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4314
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4294
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4253
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4220
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4196
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4166
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4169
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4205
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4177
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4131
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4111
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4090
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4088
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4083
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4078
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4094
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4075
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4087
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4110
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4118
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4118
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4109
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4100
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4109
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4097
----- stdout -----

Epoch 43: val_loss did not improve from 1.39157
----- stdout -----
29601/29601 [==============================] - 18s 602us/sample - loss: 1.4097 - val_loss: 1.3953
----- stdout -----
Epoch 44/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4076
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3986
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3852
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3840
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3978
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3953
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3946
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3906
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3957
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3953
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3955
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3950
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3962
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3991
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4004
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4005
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4013
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4025
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4035
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4027
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4030
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4024
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4013
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4025
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4032
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4022
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4024
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4022
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4016
----- stdout -----

Epoch 44: val_loss improved from 1.39157 to 1.38856, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 610us/sample - loss: 1.4016 - val_loss: 1.3886
----- stdout -----
Epoch 45/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4290
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4123
----- stdout -----
 3072/29601 [==>...........................] - ETA: 16s - loss: 1.4109
----- stdout -----
 4096/29601 [===>..........................] - ETA: 15s - loss: 1.4054
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4031
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4036
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.3999
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4016
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4014
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3998
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4007
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4034
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4008
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4041
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4034
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4046
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.4030
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4032
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4055
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4059
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4050
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4029
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4025
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4010
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4009
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4012
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4024
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4026
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4018
----- stdout -----

Epoch 45: val_loss improved from 1.38856 to 1.38432, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 607us/sample - loss: 1.4018 - val_loss: 1.3843
----- stdout -----
Epoch 46/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4238
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4030
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3896
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3897
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4059
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4003
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4028
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4020
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4057
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4066
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4030
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4060
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4069
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4069
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4061
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4066
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4050
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4039
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4024
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4029
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4018
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3998
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4011
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4016
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4013
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4011
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4014
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4006
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4004
----- stdout -----

Epoch 46: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 603us/sample - loss: 1.4004 - val_loss: 1.3882
----- stdout -----
Epoch 47/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4162
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4114
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4101
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4052
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3996
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3991
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4021
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3963
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3987
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3991
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3986
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3949
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3974
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3981
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3984
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3974
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3952
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3943
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3953
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3963
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3951
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3947
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3970
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3964
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3969
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3962
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3958
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3963
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3955
----- stdout -----

Epoch 47: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 601us/sample - loss: 1.3955 - val_loss: 1.3869
----- stdout -----
Epoch 48/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3477
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3628
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3724
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3866
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3927
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3957
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.3967
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3966
----- stdout -----
 9216/29601 [========>.....................] - ETA: 12s - loss: 1.3953
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3966
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3983
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.4017
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4004
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3995
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3972
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3959
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3987
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3993
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3983
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3972
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3972
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3962
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3964
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3958
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3974
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3983
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3977
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3983
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3980
----- stdout -----

Epoch 48: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 612us/sample - loss: 1.3980 - val_loss: 1.3868
----- stdout -----
Epoch 49/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4353
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4229
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4110
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4223
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4188
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4193
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4159
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.4089
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4113
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.4128
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.4111
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.4068
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.4079
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.4099
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.4089
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.4059
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.4056
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.4043
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.4051
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.4039
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.4032
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.4036
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.4042
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.4057
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.4054
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.4040
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.4040
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.4042
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.4013
----- stdout -----

Epoch 49: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.4013 - val_loss: 1.3883
----- stdout -----
Epoch 50/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4142
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3999
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3986
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3967
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.4012
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3987
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3936
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3941
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3964
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.3971
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3933
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3933
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3965
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3958
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3960
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3941
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3959
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3970
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3967
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3961
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3970
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3970
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3977
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3984
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3982
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3961
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3962
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3953
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3961
----- stdout -----

Epoch 50: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.3961 - val_loss: 1.3846
----- stdout -----
Epoch 51/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3885
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.4021
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4113
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.4008
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3913
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3959
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3948
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3964
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3966
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3971
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3960
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3952
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3931
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3919
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3923
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3953
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3933
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3946
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3919
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3931
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3914
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3910
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3935
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3937
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3937
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3947
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3945
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3942
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3942
----- stdout -----

Epoch 51: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 604us/sample - loss: 1.3942 - val_loss: 1.3861
----- stdout -----
Epoch 52/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4150
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3963
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.4013
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3944
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.4029
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.4003
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.4068
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3981
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.4006
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3962
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3979
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3995
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3985
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3962
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3952
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3956
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3941
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3935
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3932
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3946
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3957
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3960
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3966
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3975
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3974
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3974
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3953
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3970
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3958
----- stdout -----

Epoch 52: val_loss did not improve from 1.38432
----- stdout -----
29601/29601 [==============================] - 18s 604us/sample - loss: 1.3958 - val_loss: 1.3853
----- stdout -----
Epoch 53/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4026
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3754
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3748
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3852
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3850
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3916
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3900
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3861
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3847
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3840
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3872
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3880
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3897
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3853
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3869
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3879
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3879
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3906
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3910
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3928
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3933
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3929
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3917
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3907
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3913
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3914
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3925
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3938
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3937
----- stdout -----

Epoch 53: val_loss improved from 1.38432 to 1.38294, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.3937 - val_loss: 1.3829
----- stdout -----
Epoch 54/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3994
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3903
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3775
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3853
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3935
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3977
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3994
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3992
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3921
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3935
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3901
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3886
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3901
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3900
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3903
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3915
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3923
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3933
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3929
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3916
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3933
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3943
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3935
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3931
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3925
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3935
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3928
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3930
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3928
----- stdout -----

Epoch 54: val_loss did not improve from 1.38294
----- stdout -----
29601/29601 [==============================] - 18s 603us/sample - loss: 1.3928 - val_loss: 1.3837
----- stdout -----
Epoch 55/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4240
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3916
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3875
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3861
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3855
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3913
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3860
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3831
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3868
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3938
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3982
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.3984
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3973
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3953
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3945
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3941
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3930
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3938
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3915
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3906
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3897
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3920
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3904
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3899
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3904
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3915
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3909
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3910
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3920
----- stdout -----

Epoch 55: val_loss improved from 1.38294 to 1.38215, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 19s 634us/sample - loss: 1.3920 - val_loss: 1.3821
----- stdout -----
Epoch 56/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4127
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4043
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3952
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3925
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3935
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3922
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3974
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3995
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.4042
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3987
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3981
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3948
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3977
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3969
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3986
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3975
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3955
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3954
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3936
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3934
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3937
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3936
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3925
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3925
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3930
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3920
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3909
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3915
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3907
----- stdout -----

Epoch 56: val_loss improved from 1.38215 to 1.38112, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 688us/sample - loss: 1.3907 - val_loss: 1.3811
----- stdout -----
Epoch 57/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4544
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.4142
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3980
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3941
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3910
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3855
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3847
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3812
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3831
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3840
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3844
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3841
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3871
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3872
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3879
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3868
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3870
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3883
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3913
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3910
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3900
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3906
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3891
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3903
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3903
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3896
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3886
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3884
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3868
----- stdout -----

Epoch 57: val_loss did not improve from 1.38112
----- stdout -----
29601/29601 [==============================] - 20s 686us/sample - loss: 1.3868 - val_loss: 1.3830
----- stdout -----
Epoch 58/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3677
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3891
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3906
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.4045
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.4056
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.4056
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3997
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3959
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3902
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3870
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3885
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.3893
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3882
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3848
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3824
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3836
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3836
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3837
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3838
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3825
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3826
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3829
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3855
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3859
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3847
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3865
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3861
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3864
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3850
----- stdout -----

Epoch 58: val_loss improved from 1.38112 to 1.37817, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 19s 631us/sample - loss: 1.3850 - val_loss: 1.3782
----- stdout -----
Epoch 59/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3644
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3933
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3784
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3786
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3775
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3790
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3802
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3811
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3817
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3764
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3777
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3788
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3763
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3754
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3739
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3753
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3738
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3761
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3772
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3777
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3797
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3822
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3817
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3835
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3829
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3824
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3813
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3816
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3826
----- stdout -----

Epoch 59: val_loss improved from 1.37817 to 1.37586, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 608us/sample - loss: 1.3826 - val_loss: 1.3759
----- stdout -----
Epoch 60/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3812
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3850
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3880
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3828
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3886
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3811
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3848
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3888
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3836
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3813
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3811
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3832
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3832
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3833
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3843
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3830
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3826
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3813
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3816
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3808
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3795
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3808
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3804
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3800
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3806
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3815
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3819
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3831
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3838
----- stdout -----

Epoch 60: val_loss did not improve from 1.37586
----- stdout -----
29601/29601 [==============================] - 19s 649us/sample - loss: 1.3838 - val_loss: 1.3771
----- stdout -----
Epoch 61/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3766
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3896
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3834
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3797
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3787
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3698
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3705
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3716
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3749
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3772
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3782
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3774
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3814
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3832
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3834
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3850
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3855
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3842
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3827
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3841
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3844
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3870
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3879
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3868
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3863
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3848
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3846
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3829
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3819
----- stdout -----

Epoch 61: val_loss did not improve from 1.37586
----- stdout -----
29601/29601 [==============================] - 19s 644us/sample - loss: 1.3819 - val_loss: 1.3792
----- stdout -----
Epoch 62/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3983
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3876
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3840
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3948
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3916
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3859
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3806
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3783
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3781
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3796
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3769
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3785
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3730
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3714
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3724
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3726
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3749
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3750
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3733
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3734
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3773
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3780
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3775
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3796
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3802
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3808
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3800
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3806
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3807
----- stdout -----

Epoch 62: val_loss improved from 1.37586 to 1.37467, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 612us/sample - loss: 1.3807 - val_loss: 1.3747
----- stdout -----
Epoch 63/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3395
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3575
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3638
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3737
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3749
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3783
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3784
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3821
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3799
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3810
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3819
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3839
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3862
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3836
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3825
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3833
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3824
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3830
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3813
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3822
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3814
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3804
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3809
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3825
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3824
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3822
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3826
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3809
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3792
----- stdout -----

Epoch 63: val_loss did not improve from 1.37467
----- stdout -----
29601/29601 [==============================] - 20s 685us/sample - loss: 1.3792 - val_loss: 1.3768
----- stdout -----
Epoch 64/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3901
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3927
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3934
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3890
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3939
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3931
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3958
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3887
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3891
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3894
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3863
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3873
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3891
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3844
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3814
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3837
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3842
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3845
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3831
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3842
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3866
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3859
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3828
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3807
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3813
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3801
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3796
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3776
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3774
----- stdout -----

Epoch 64: val_loss did not improve from 1.37467
----- stdout -----
29601/29601 [==============================] - 20s 685us/sample - loss: 1.3774 - val_loss: 1.3767
----- stdout -----
Epoch 65/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4178
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3971
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3903
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3791
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3786
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3798
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3820
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3799
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3756
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3782
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3767
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3706
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3768
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3779
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3764
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3782
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3778
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3787
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3789
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3782
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3795
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3757
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3777
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3769
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3761
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3778
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3764
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3758
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3768
----- stdout -----

Epoch 65: val_loss improved from 1.37467 to 1.37282, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 680us/sample - loss: 1.3768 - val_loss: 1.3728
----- stdout -----
Epoch 66/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3708
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3849
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3813
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3783
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3761
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3645
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3702
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3746
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3764
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3771
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3704
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3710
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3729
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3706
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3697
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3700
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3724
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3713
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3716
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3719
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3723
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3730
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3726
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3719
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3722
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3728
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3737
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3725
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3731
----- stdout -----

Epoch 66: val_loss improved from 1.37282 to 1.37148, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 690us/sample - loss: 1.3731 - val_loss: 1.3715
----- stdout -----
Epoch 67/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3700
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3758
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3836
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3752
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3685
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3659
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3686
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3684
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3680
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3709
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3734
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3712
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3717
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3702
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3696
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3688
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3695
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3702
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3716
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3706
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3706
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3683
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3685
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3698
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3705
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3713
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3718
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3720
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3741
----- stdout -----

Epoch 67: val_loss did not improve from 1.37148
----- stdout -----
29601/29601 [==============================] - 20s 685us/sample - loss: 1.3741 - val_loss: 1.3743
----- stdout -----
Epoch 68/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3975
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3730
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3657
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3617
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3654
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3656
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3680
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3710
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3695
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3681
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3685
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3703
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3691
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3713
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3703
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3719
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3729
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3715
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3704
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3716
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3706
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3712
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3718
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3724
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3719
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3723
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3728
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3728
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3738
----- stdout -----

Epoch 68: val_loss did not improve from 1.37148
----- stdout -----
29601/29601 [==============================] - 20s 685us/sample - loss: 1.3738 - val_loss: 1.3751
----- stdout -----
Epoch 69/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4190
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3831
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3611
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3756
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3784
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3739
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3689
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3720
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3700
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3696
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3707
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3697
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3724
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3731
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3725
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3712
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3728
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3725
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3719
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3713
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3705
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3701
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3701
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3705
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3688
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3697
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3704
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3703
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3707
----- stdout -----

Epoch 69: val_loss improved from 1.37148 to 1.37027, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 689us/sample - loss: 1.3707 - val_loss: 1.3703
----- stdout -----
Epoch 70/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.4074
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3702
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3658
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3776
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3746
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3649
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3619
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3647
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3727
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3738
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3738
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3731
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3718
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3698
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3721
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3727
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3731
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3733
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3713
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3707
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3701
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3705
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3703
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3718
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3713
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3713
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3706
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3707
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3717
----- stdout -----

Epoch 70: val_loss improved from 1.37027 to 1.36758, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 20s 691us/sample - loss: 1.3717 - val_loss: 1.3676
----- stdout -----
Epoch 71/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3633
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3732
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3783
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3689
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3619
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3659
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3745
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3673
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3693
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3699
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3718
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3714
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3716
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3730
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3733
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3708
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3713
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3731
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3699
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3676
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3661
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3662
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3664
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3670
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3688
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3689
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3685
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3690
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3686
----- stdout -----

Epoch 71: val_loss did not improve from 1.36758
----- stdout -----
29601/29601 [==============================] - 20s 686us/sample - loss: 1.3686 - val_loss: 1.3690
----- stdout -----
Epoch 72/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3766
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3657
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3663
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3795
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3821
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3794
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3777
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3752
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3733
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3706
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3721
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3710
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3686
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3676
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3658
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3680
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3668
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3674
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3657
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3643
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3661
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3670
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3677
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3674
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3682
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3685
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3678
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3680
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3686
----- stdout -----

Epoch 72: val_loss did not improve from 1.36758
----- stdout -----
29601/29601 [==============================] - 20s 687us/sample - loss: 1.3686 - val_loss: 1.3708
----- stdout -----
Epoch 73/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3757
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3614
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3761
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3713
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3751
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3748
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3731
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3716
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3696
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3677
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3679
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3655
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3678
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3665
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3673
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3685
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3691
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3712
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3716
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3741
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3747
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3741
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3735
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3733
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3721
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3722
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3704
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3699
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3696
----- stdout -----

Epoch 73: val_loss did not improve from 1.36758
----- stdout -----
29601/29601 [==============================] - 20s 670us/sample - loss: 1.3696 - val_loss: 1.3713
----- stdout -----
Epoch 74/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3807
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3573
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3482
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3483
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3554
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3562
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3577
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3602
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3580
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3593
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3621
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3617
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3623
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3638
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3637
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3661
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3674
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3670
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3660
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3677
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3707
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3696
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3676
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3677
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3680
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3694
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3681
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3684
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3689
----- stdout -----

Epoch 74: val_loss did not improve from 1.36758
----- stdout -----
29601/29601 [==============================] - 18s 607us/sample - loss: 1.3689 - val_loss: 1.3790
----- stdout -----
Epoch 75/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3879
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3845
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3769
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3755
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3773
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3784
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3739
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3664
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3695
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3699
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3691
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3666
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3675
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3673
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3670
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3652
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3628
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3632
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3617
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3628
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3639
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3644
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3659
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3667
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3670
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3672
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3680
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3673
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3679
----- stdout -----

Epoch 75: val_loss did not improve from 1.36758
----- stdout -----
29601/29601 [==============================] - 18s 606us/sample - loss: 1.3679 - val_loss: 1.3684
----- stdout -----
Epoch 76/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3677
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3662
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3699
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3660
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3658
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3632
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3698
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3717
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3715
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3706
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3679
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3662
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3653
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3655
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3680
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3708
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3716
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3726
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3723
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3696
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3670
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3672
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3666
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3671
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3665
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3638
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3637
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3649
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3661
----- stdout -----

Epoch 76: val_loss did not improve from 1.36758
----- stdout -----
29601/29601 [==============================] - 18s 614us/sample - loss: 1.3661 - val_loss: 1.3694
----- stdout -----
Epoch 77/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4209
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3650
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3719
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3687
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3686
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3694
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3688
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3676
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3655
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3637
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3628
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3640
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3645
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3667
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3655
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3663
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3671
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3676
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3672
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3666
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3657
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3635
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3635
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3635
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3621
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3625
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3650
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3658
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3655
----- stdout -----

Epoch 77: val_loss improved from 1.36758 to 1.36751, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 607us/sample - loss: 1.3655 - val_loss: 1.3675
----- stdout -----
Epoch 78/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3282
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3352
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3256
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3218
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3335
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3436
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3533
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3574
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3572
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3547
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3570
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3626
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3623
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3650
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3615
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3609
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3629
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3635
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3646
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3622
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3613
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3598
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3601
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3609
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3622
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3623
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3617
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3626
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3635
----- stdout -----

Epoch 78: val_loss did not improve from 1.36751
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.3635 - val_loss: 1.3682
----- stdout -----
Epoch 79/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3623
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3877
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3799
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3783
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3688
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3683
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3716
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3682
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3680
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3667
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3655
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3655
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3690
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3686
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3689
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3680
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3665
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3670
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3677
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3663
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3675
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3666
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3670
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3682
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3676
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3679
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3670
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3685
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3670
----- stdout -----

Epoch 79: val_loss improved from 1.36751 to 1.36648, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 19s 655us/sample - loss: 1.3670 - val_loss: 1.3665
----- stdout -----
Epoch 80/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3227
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3404
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3586
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3542
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3580
----- stdout -----
 6144/29601 [=====>........................] - ETA: 14s - loss: 1.3607
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.3624
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3593
----- stdout -----
 9216/29601 [========>.....................] - ETA: 12s - loss: 1.3566
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3565
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3573
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.3599
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3584
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3581
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3583
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3615
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3619
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3625
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3640
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3629
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3635
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3649
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3653
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3642
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3638
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3640
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3642
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3640
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3639
----- stdout -----

Epoch 80: val_loss did not improve from 1.36648
----- stdout -----
29601/29601 [==============================] - 18s 613us/sample - loss: 1.3639 - val_loss: 1.3746
----- stdout -----
Epoch 81/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3635
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3676
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3651
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3749
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3690
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3686
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3697
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3651
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3638
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3635
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3643
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3640
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3621
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3586
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3599
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3577
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3558
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3543
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3556
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3560
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3550
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3554
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3555
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3555
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3558
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3570
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3582
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3596
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3595
----- stdout -----

Epoch 81: val_loss improved from 1.36648 to 1.36634, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 604us/sample - loss: 1.3595 - val_loss: 1.3663
----- stdout -----
Epoch 82/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3719
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3497
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3470
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3541
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3575
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3571
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3649
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3645
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3611
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3614
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3608
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3612
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3625
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3642
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3644
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3644
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3636
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3634
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3645
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3630
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3645
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3632
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3643
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3630
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3630
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3625
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3608
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3609
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3617
----- stdout -----

Epoch 82: val_loss did not improve from 1.36634
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.3617 - val_loss: 1.3669
----- stdout -----
Epoch 83/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4065
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3913
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3762
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3658
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3686
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3751
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3738
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3680
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3679
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3677
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3675
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3683
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3673
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3653
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3652
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3655
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3666
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3653
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3632
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3611
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3613
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3600
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3589
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3596
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3599
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3595
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3592
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3595
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3599
----- stdout -----

Epoch 83: val_loss improved from 1.36634 to 1.36170, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 607us/sample - loss: 1.3599 - val_loss: 1.3617
----- stdout -----
Epoch 84/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3485
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3534
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3471
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3468
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3571
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3577
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3621
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3629
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3620
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3612
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3589
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3560
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3573
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3571
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3588
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3601
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3611
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3606
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3587
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3588
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3594
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3593
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3599
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3608
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3615
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3605
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3607
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3603
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3606
----- stdout -----

Epoch 84: val_loss did not improve from 1.36170
----- stdout -----
29601/29601 [==============================] - 18s 602us/sample - loss: 1.3606 - val_loss: 1.3673
----- stdout -----
Epoch 85/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3951
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3816
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3662
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3739
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3699
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3632
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3665
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3708
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3654
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3618
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3554
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3551
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3540
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3564
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3565
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3550
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3526
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3535
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3551
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3532
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3540
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3544
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3547
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3558
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3564
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3556
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3566
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3559
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3566
----- stdout -----

Epoch 85: val_loss improved from 1.36170 to 1.35892, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 18s 614us/sample - loss: 1.3566 - val_loss: 1.3589
----- stdout -----
Epoch 86/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3905
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3619
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3488
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3591
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3627
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3660
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3655
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3683
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3686
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3600
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3611
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3592
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3602
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3628
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3591
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3578
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3569
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3569
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3554
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3571
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3566
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3576
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3581
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3593
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3581
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3571
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3559
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3571
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3565
----- stdout -----

Epoch 86: val_loss did not improve from 1.35892
----- stdout -----
29601/29601 [==============================] - 18s 604us/sample - loss: 1.3565 - val_loss: 1.3683
----- stdout -----
Epoch 87/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3636
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3876
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3660
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3621
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3611
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3605
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3632
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3623
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3635
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3646
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3640
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3647
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3663
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3620
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3604
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3616
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3599
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3600
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3603
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3613
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3580
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3576
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3572
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3566
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3568
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3560
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3556
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3561
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3561
----- stdout -----

Epoch 87: val_loss did not improve from 1.35892
----- stdout -----
29601/29601 [==============================] - 18s 603us/sample - loss: 1.3561 - val_loss: 1.3638
----- stdout -----
Epoch 88/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3231
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3396
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3416
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3469
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3471
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3550
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3539
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3548
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3503
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3513
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3526
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3479
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3491
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3530
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3552
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3564
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3548
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3574
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3557
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3558
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3550
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3561
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3570
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3569
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3568
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3572
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3548
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3547
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3546
----- stdout -----

Epoch 88: val_loss did not improve from 1.35892
----- stdout -----
29601/29601 [==============================] - 18s 606us/sample - loss: 1.3546 - val_loss: 1.3616
----- stdout -----
Epoch 89/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3459
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3702
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3526
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3457
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3480
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3463
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3420
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3484
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3513
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3531
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3532
----- stdout -----
12288/29601 [===========>..................] - ETA: 10s - loss: 1.3481
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3499
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3502
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3533
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3535
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3567
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3576
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3587
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3604
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3605
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3600
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3581
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3585
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3589
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3581
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3569
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3571
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3568
----- stdout -----

Epoch 89: val_loss did not improve from 1.35892
----- stdout -----
29601/29601 [==============================] - 18s 607us/sample - loss: 1.3568 - val_loss: 1.3617
----- stdout -----
Epoch 90/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3925
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3651
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3828
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3780
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3670
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3647
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3588
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3583
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3626
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3617
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3578
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3592
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3600
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3592
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3583
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3601
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3580
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3570
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3573
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3575
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3566
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3564
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3551
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3565
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3561
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3560
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3552
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3550
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3561
----- stdout -----

Epoch 90: val_loss did not improve from 1.35892
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.3561 - val_loss: 1.3615
----- stdout -----
Epoch 91/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3209
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3313
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3306
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3381
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3389
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3371
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3379
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3354
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3364
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3378
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3434
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3416
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3443
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3449
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3468
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3456
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3447
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3449
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3474
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3485
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3502
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3512
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3515
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3523
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3524
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3523
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3522
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3520
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3534
----- stdout -----

Epoch 91: val_loss improved from 1.35892 to 1.35702, saving model to ./checkpoints/Adaptive_structure_prune_model_0.h5
----- stdout -----
29601/29601 [==============================] - 19s 642us/sample - loss: 1.3534 - val_loss: 1.3570
----- stdout -----
Epoch 92/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3459
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3388
----- stdout -----
 3072/29601 [==>...........................] - ETA: 16s - loss: 1.3464
----- stdout -----
 4096/29601 [===>..........................] - ETA: 15s - loss: 1.3664
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3628
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3664
----- stdout -----
 7168/29601 [======>.......................] - ETA: 13s - loss: 1.3741
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3686
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3657
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3622
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3628
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3662
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3632
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3619
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3583
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3553
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3535
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3526
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3520
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3542
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3523
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3531
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3522
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3528
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3534
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3538
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3536
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3528
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3527
----- stdout -----

Epoch 92: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 18s 603us/sample - loss: 1.3527 - val_loss: 1.3626
----- stdout -----
Epoch 93/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.4091
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3780
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3592
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3515
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3472
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3489
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3517
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3525
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3517
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3523
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3532
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3540
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3528
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3516
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3511
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3513
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3496
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3495
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3500
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3485
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3469
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3492
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3499
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3492
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3514
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3525
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3532
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3533
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3533
----- stdout -----

Epoch 93: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 18s 599us/sample - loss: 1.3533 - val_loss: 1.3604
----- stdout -----
Epoch 94/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3285
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3331
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3366
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3335
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3355
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3356
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3367
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3379
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3392
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3441
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3444
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3430
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3418
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3430
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3435
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3466
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3464
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3465
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3471
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3486
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3508
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3502
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3503
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3508
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3496
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3505
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3507
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3506
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3515
----- stdout -----

Epoch 94: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 18s 599us/sample - loss: 1.3515 - val_loss: 1.3622
----- stdout -----
Epoch 95/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3234
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3152
----- stdout -----
 3072/29601 [==>...........................] - ETA: 15s - loss: 1.3148
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3222
----- stdout -----
 5120/29601 [====>.........................] - ETA: 14s - loss: 1.3339
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3377
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3379
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3374
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3358
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3363
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3420
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3445
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3450
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3498
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3515
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3530
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3526
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3529
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3510
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3523
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3515
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3505
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3495
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3515
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3517
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3520
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3514
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3502
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3514
----- stdout -----

Epoch 95: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 18s 600us/sample - loss: 1.3514 - val_loss: 1.3614
----- stdout -----
Epoch 96/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3379
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3325
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.3519
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3491
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3516
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3561
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3539
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3549
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3547
----- stdout -----
10240/29601 [=========>....................] - ETA: 10s - loss: 1.3536
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3553
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3568
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3576
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3563
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3535
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3524
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3511
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3480
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3482
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3477
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3476
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3475
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3494
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3491
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3486
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3490
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3486
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3481
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3487
----- stdout -----

Epoch 96: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 18s 597us/sample - loss: 1.3487 - val_loss: 1.3618
----- stdout -----
Epoch 97/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 16s - loss: 1.3343
----- stdout -----
 2048/29601 [=>............................] - ETA: 15s - loss: 1.3347
----- stdout -----
 3072/29601 [==>...........................] - ETA: 14s - loss: 1.3371
----- stdout -----
 4096/29601 [===>..........................] - ETA: 14s - loss: 1.3347
----- stdout -----
 5120/29601 [====>.........................] - ETA: 13s - loss: 1.3372
----- stdout -----
 6144/29601 [=====>........................] - ETA: 13s - loss: 1.3397
----- stdout -----
 7168/29601 [======>.......................] - ETA: 12s - loss: 1.3417
----- stdout -----
 8192/29601 [=======>......................] - ETA: 12s - loss: 1.3401
----- stdout -----
 9216/29601 [========>.....................] - ETA: 11s - loss: 1.3422
----- stdout -----
10240/29601 [=========>....................] - ETA: 11s - loss: 1.3404
----- stdout -----
11264/29601 [==========>...................] - ETA: 10s - loss: 1.3430
----- stdout -----
12288/29601 [===========>..................] - ETA: 9s - loss: 1.3395
----- stdout -----
13312/29601 [============>.................] - ETA: 9s - loss: 1.3425
----- stdout -----
14336/29601 [=============>................] - ETA: 8s - loss: 1.3430
----- stdout -----
15360/29601 [==============>...............] - ETA: 8s - loss: 1.3422
----- stdout -----
16384/29601 [===============>..............] - ETA: 7s - loss: 1.3443
----- stdout -----
17408/29601 [================>.............] - ETA: 6s - loss: 1.3445
----- stdout -----
18432/29601 [=================>............] - ETA: 6s - loss: 1.3465
----- stdout -----
19456/29601 [==================>...........] - ETA: 5s - loss: 1.3450
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3448
----- stdout -----
21504/29601 [====================>.........] - ETA: 4s - loss: 1.3447
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3447
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3462
----- stdout -----
24576/29601 [=======================>......] - ETA: 2s - loss: 1.3472
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3472
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3476
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3486
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3473
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3479
----- stdout -----

Epoch 97: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 19s 636us/sample - loss: 1.3479 - val_loss: 1.3619
----- stdout -----
Epoch 98/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3387
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3340
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3580
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3428
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3506
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3472
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3477
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3492
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3516
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3505
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3497
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3508
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3510
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3509
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3503
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3533
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3533
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3543
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3527
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3522
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3521
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3509
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3500
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3487
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3475
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3492
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3487
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3487
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3489
----- stdout -----

Epoch 98: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 20s 682us/sample - loss: 1.3489 - val_loss: 1.3593
----- stdout -----
Epoch 99/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3887
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3572
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3408
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3512
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3509
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3460
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3360
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3354
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3382
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3391
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3380
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3403
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3381
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3382
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3401
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3384
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3399
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3406
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3433
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3457
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3445
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3453
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3455
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3462
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3460
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3465
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3458
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3450
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3449
----- stdout -----

Epoch 99: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 20s 685us/sample - loss: 1.3449 - val_loss: 1.3573
----- stdout -----
Epoch 100/100
----- stdout -----
 1024/29601 [>.............................] - ETA: 18s - loss: 1.3213
----- stdout -----
 2048/29601 [=>............................] - ETA: 17s - loss: 1.3369
----- stdout -----
 3072/29601 [==>...........................] - ETA: 17s - loss: 1.3446
----- stdout -----
 4096/29601 [===>..........................] - ETA: 16s - loss: 1.3474
----- stdout -----
 5120/29601 [====>.........................] - ETA: 15s - loss: 1.3500
----- stdout -----
 6144/29601 [=====>........................] - ETA: 15s - loss: 1.3475
----- stdout -----
 7168/29601 [======>.......................] - ETA: 14s - loss: 1.3539
----- stdout -----
 8192/29601 [=======>......................] - ETA: 13s - loss: 1.3524
----- stdout -----
 9216/29601 [========>.....................] - ETA: 13s - loss: 1.3504
----- stdout -----
10240/29601 [=========>....................] - ETA: 12s - loss: 1.3469
----- stdout -----
11264/29601 [==========>...................] - ETA: 11s - loss: 1.3443
----- stdout -----
12288/29601 [===========>..................] - ETA: 11s - loss: 1.3435
----- stdout -----
13312/29601 [============>.................] - ETA: 10s - loss: 1.3435
----- stdout -----
14336/29601 [=============>................] - ETA: 9s - loss: 1.3440
----- stdout -----
15360/29601 [==============>...............] - ETA: 9s - loss: 1.3454
----- stdout -----
16384/29601 [===============>..............] - ETA: 8s - loss: 1.3461
----- stdout -----
17408/29601 [================>.............] - ETA: 7s - loss: 1.3420
----- stdout -----
18432/29601 [=================>............] - ETA: 7s - loss: 1.3430
----- stdout -----
19456/29601 [==================>...........] - ETA: 6s - loss: 1.3441
----- stdout -----
20480/29601 [===================>..........] - ETA: 5s - loss: 1.3444
----- stdout -----
21504/29601 [====================>.........] - ETA: 5s - loss: 1.3436
----- stdout -----
22528/29601 [=====================>........] - ETA: 4s - loss: 1.3454
----- stdout -----
23552/29601 [======================>.......] - ETA: 3s - loss: 1.3469
----- stdout -----
24576/29601 [=======================>......] - ETA: 3s - loss: 1.3463
----- stdout -----
25600/29601 [========================>.....] - ETA: 2s - loss: 1.3446
----- stdout -----
26624/29601 [=========================>....] - ETA: 1s - loss: 1.3443
----- stdout -----
27648/29601 [===========================>..] - ETA: 1s - loss: 1.3453
----- stdout -----
28672/29601 [============================>.] - ETA: 0s - loss: 1.3453
----- stdout -----
29601/29601 [==============================] - ETA: 0s - loss: 1.3467
----- stdout -----

Epoch 100: val_loss did not improve from 1.35702
----- stdout -----
29601/29601 [==============================] - 20s 684us/sample - loss: 1.3467 - val_loss: 1.3583
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
Cell [0;32mIn[6], line 103[0m
[1;32m    100[0m model[38;5;241m.[39mfit(X_train_normalized_new, y_train, epochs[38;5;241m=[39mnum_epochs, batch_size[38;5;241m=[39m[38;5;241m1024[39m, validation_data[38;5;241m=[39m(X_val_normalized_new, y_val), callbacks[38;5;241m=[39m[pruning_callback, checkpoint])
[1;32m    101[0m [38;5;28;01mfor[39;00m epoch [38;5;129;01min[39;00m [38;5;28mrange[39m(num_epochs):
[1;32m    102[0m     [38;5;66;03m# Calculate the current pruning factor[39;00m
[0;32m--> 103[0m     [38;5;28;01mif[39;00m epoch [38;5;241m<[39m [43mstart_epoch[49m:
[1;32m    104[0m         current_pruning_factor [38;5;241m=[39m initial_pruning_factor
[1;32m    105[0m     [38;5;28;01melif[39;00m epoch [38;5;241m>[39m end_epoch:

[0;31mNameError[0m: name 'start_epoch' is not defined

nohup: ignoring input
[NbConvertApp] Converting notebook AdptivePrune_structure.ipynb to notebook
0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
2023-11-27 23:52:14.921482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-27 23:52:54.986589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:54.998382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.004911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.008371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.008565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.008855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.084889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.085095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.085259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:55.085473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6
2023-11-27 23:52:55.085850: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2023-11-27 23:52:56.003465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:56.003695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:56.003876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:56.004081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:56.004261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-27 23:52:56.004397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6
2023-11-27 23:52:56.004424: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2023-11-27 23:52:56.029388: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled
2023-11-27 23:52:56.289614: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_16/lstm_cell_16/recurrent_kernel/Assign' id:2676 op device:{requested: '', assigned: ''} def:{{{node lstm_16/lstm_cell_16/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_16/lstm_cell_16/recurrent_kernel, lstm_16/lstm_cell_16/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 23:52:56.424803: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 23:52:56.459965: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 23:53:00.921796: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm/lstm_cell/bias/m/Assign' id:16404 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm/lstm_cell/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm/lstm_cell/bias/m, training/Adam/lstm/lstm_cell/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2023-11-27 23:53:02.497874: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
2023-11-27 23:53:05.224877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-11-27 23:53:05.233680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902
2023-11-27 23:53:25.490599: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
[NbConvertApp] Writing 58844 bytes to AdptivePrune_structure.nbconvert.ipynb
