{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e4cd1e-14c8-4f76-8133-e8617bb62b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Baseline Method only use simple gait parameter feature, it only includes 2 dense layers\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## We delete people's data with low feedback score and remove people who kicked off the sensors during walking'\n",
    "## So 20 people in total.\n",
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "flag_tr_val_te = split_data(walk_nums_all, trace_nums_all, people_nums_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170353c1-fcb9-4e2b-9909-c3a263bf8bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:53:40.926348: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([fft_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168b9ce3-6991-48e6-93cf-edb4f8e8d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_label_gen(old_labels):\n",
    "    new_labels = np.zeros((old_labels.shape[0],))\n",
    "    \n",
    "    # Define classes based on conditions\n",
    "    new_labels[np.logical_and(old_labels[:, 0] <= 5, old_labels[:, 1] < 5)] = 0\n",
    "    new_labels[np.logical_and(old_labels[:, 0] > 5, old_labels[:, 1] < 5)] = 1\n",
    "    new_labels[np.logical_and(old_labels[:, 0] <= 5, old_labels[:, 1] >= 5)] = 2\n",
    "    new_labels[np.logical_and(old_labels[:, 0] > 5, old_labels[:, 1] >= 5)] = 3\n",
    "    \n",
    "    # If you need one-hot encoded labels for the classification output\n",
    "    one_hot_new_labels = np.eye(4)[new_labels.astype(int)]\n",
    "    return one_hot_new_labels\n",
    "y_train_class = new_label_gen(y_train)\n",
    "y_val_class = new_label_gen(y_val)\n",
    "y_test_class = new_label_gen(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e10b0d-fa00-4007-ad02-296357d1871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c990a1-41b3-4403-bcd9-3cc23f58da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def baseline_model(inputdim):\n",
    "    input_layer = Input(shape=(inputdim,))\n",
    "    h = Dense(64, activation='relu')(input_layer)\n",
    "    h = Dropout(0.2)(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    # h = Dense(16, activation='relu')(h)\n",
    "    output_layer_classification = Dense(4, activation='softmax', name='classification_output')(h)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer_classification)\n",
    "    \n",
    "    # compile the model with categorical_crossentropy loss function\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c8fb4a-5f62-4ff5-9d55-a5fd0197b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_new = np.hstack((X_train_normalized_new[0], X_train_normalized_new[1]))\n",
    "X_val_normalized_new = np.hstack((X_val_normalized_new[0], X_val_normalized_new[1]))\n",
    "X_test_normalized_new = np.hstack((X_test_normalized_new[0], X_test_normalized_new[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2683b708-6af7-41d5-a90d-6738f50c2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "# Compute class weights\n",
    "y_labels = np.argmax(y_train_class, axis=1)\n",
    "class_weights = class_weight.compute_class_weight(class_weight ='balanced', classes =np.unique(y_labels), y=y_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1acdad6-8e79-47f2-b3f6-9190d0bfad0f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29601 samples, validate on 3694 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:55:08.704268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.715360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.715597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.720783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.720976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.721146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.782571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.782854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.783042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 16:55:08.783198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1033 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-11-06 16:55:08.783619: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-06 16:55:08.791550: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-06 16:55:08.815301: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/dense_3/kernel/v/Assign' id:457 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_3/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_3/kernel/v, training/Adam/dense_3/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:55:08.904373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1024/29601 [>.............................] - ETA: 2s - loss: 1.4700 - acc: 0.2471\n",
      "Epoch 1: val_loss improved from inf to 1.32586, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 7us/sample - loss: 1.3800 - acc: 0.3282 - val_loss: 1.3259 - val_acc: 0.3763\n",
      "Epoch 2/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.3306 - acc: 0.3633\n",
      "Epoch 2: val_loss improved from 1.32586 to 1.29335, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.3117 - acc: 0.3783 - val_loss: 1.2934 - val_acc: 0.3933\n",
      "Epoch 3/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.3058 - acc: 0.3838\n",
      "Epoch 3: val_loss improved from 1.29335 to 1.27786, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2891 - acc: 0.3977 - val_loss: 1.2779 - val_acc: 0.4044\n",
      "Epoch 4/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2883 - acc: 0.3906\n",
      "Epoch 4: val_loss improved from 1.27786 to 1.27135, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2739 - acc: 0.4078 - val_loss: 1.2713 - val_acc: 0.4058\n",
      "Epoch 5/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2548 - acc: 0.4053\n",
      "Epoch 5: val_loss improved from 1.27135 to 1.26034, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2620 - acc: 0.4113 - val_loss: 1.2603 - val_acc: 0.4128\n",
      "Epoch 6/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2453 - acc: 0.4277\n",
      "Epoch 6: val_loss improved from 1.26034 to 1.25575, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2519 - acc: 0.4177 - val_loss: 1.2557 - val_acc: 0.4166\n",
      "Epoch 7/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2111 - acc: 0.4150\n",
      "Epoch 7: val_loss improved from 1.25575 to 1.24887, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2431 - acc: 0.4187 - val_loss: 1.2489 - val_acc: 0.4196\n",
      "Epoch 8/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2463 - acc: 0.4141\n",
      "Epoch 8: val_loss improved from 1.24887 to 1.24095, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2357 - acc: 0.4252 - val_loss: 1.2410 - val_acc: 0.4283\n",
      "Epoch 9/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2490 - acc: 0.4131\n",
      "Epoch 9: val_loss improved from 1.24095 to 1.23836, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2292 - acc: 0.4292 - val_loss: 1.2384 - val_acc: 0.4245\n",
      "Epoch 10/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2250 - acc: 0.4229\n",
      "Epoch 10: val_loss improved from 1.23836 to 1.23346, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2210 - acc: 0.4312 - val_loss: 1.2335 - val_acc: 0.4302\n",
      "Epoch 11/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1944 - acc: 0.4287\n",
      "Epoch 11: val_loss improved from 1.23346 to 1.23111, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2171 - acc: 0.4359 - val_loss: 1.2311 - val_acc: 0.4329\n",
      "Epoch 12/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2180 - acc: 0.4307\n",
      "Epoch 12: val_loss improved from 1.23111 to 1.23106, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2118 - acc: 0.4376 - val_loss: 1.2311 - val_acc: 0.4304\n",
      "Epoch 13/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2485 - acc: 0.4375\n",
      "Epoch 13: val_loss improved from 1.23106 to 1.22104, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2090 - acc: 0.4362 - val_loss: 1.2210 - val_acc: 0.4383\n",
      "Epoch 14/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1849 - acc: 0.4727\n",
      "Epoch 14: val_loss did not improve from 1.22104\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.2045 - acc: 0.4406 - val_loss: 1.2236 - val_acc: 0.4380\n",
      "Epoch 15/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1943 - acc: 0.4570\n",
      "Epoch 15: val_loss did not improve from 1.22104\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.2002 - acc: 0.4437 - val_loss: 1.2220 - val_acc: 0.4413\n",
      "Epoch 16/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2074 - acc: 0.4316\n",
      "Epoch 16: val_loss did not improve from 1.22104\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1974 - acc: 0.4430 - val_loss: 1.2213 - val_acc: 0.4383\n",
      "Epoch 17/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2280 - acc: 0.4209\n",
      "Epoch 17: val_loss did not improve from 1.22104\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1923 - acc: 0.4439 - val_loss: 1.2255 - val_acc: 0.4312\n",
      "Epoch 18/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1547 - acc: 0.4609\n",
      "Epoch 18: val_loss improved from 1.22104 to 1.21435, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1887 - acc: 0.4475 - val_loss: 1.2144 - val_acc: 0.4421\n",
      "Epoch 19/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1678 - acc: 0.4580\n",
      "Epoch 19: val_loss did not improve from 1.21435\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1845 - acc: 0.4508 - val_loss: 1.2232 - val_acc: 0.4337\n",
      "Epoch 20/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1984 - acc: 0.4365\n",
      "Epoch 20: val_loss did not improve from 1.21435\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1853 - acc: 0.4478 - val_loss: 1.2226 - val_acc: 0.4350\n",
      "Epoch 21/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2157 - acc: 0.4434\n",
      "Epoch 21: val_loss did not improve from 1.21435\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1807 - acc: 0.4516 - val_loss: 1.2191 - val_acc: 0.4312\n",
      "Epoch 22/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1604 - acc: 0.4736\n",
      "Epoch 22: val_loss did not improve from 1.21435\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1787 - acc: 0.4530 - val_loss: 1.2147 - val_acc: 0.4369\n",
      "Epoch 23/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1961 - acc: 0.4629\n",
      "Epoch 23: val_loss improved from 1.21435 to 1.20905, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1769 - acc: 0.4565 - val_loss: 1.2091 - val_acc: 0.4442\n",
      "Epoch 24/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1832 - acc: 0.4570\n",
      "Epoch 24: val_loss did not improve from 1.20905\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1757 - acc: 0.4570 - val_loss: 1.2143 - val_acc: 0.4394\n",
      "Epoch 25/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1751 - acc: 0.4453\n",
      "Epoch 25: val_loss did not improve from 1.20905\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1708 - acc: 0.4577 - val_loss: 1.2115 - val_acc: 0.4377\n",
      "Epoch 26/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1682 - acc: 0.4648\n",
      "Epoch 26: val_loss did not improve from 1.20905\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1699 - acc: 0.4562 - val_loss: 1.2175 - val_acc: 0.4318\n",
      "Epoch 27/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1574 - acc: 0.4482\n",
      "Epoch 27: val_loss did not improve from 1.20905\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1668 - acc: 0.4586 - val_loss: 1.2109 - val_acc: 0.4372\n",
      "Epoch 28/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1670 - acc: 0.4600\n",
      "Epoch 28: val_loss did not improve from 1.20905\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1635 - acc: 0.4629 - val_loss: 1.2157 - val_acc: 0.4285\n",
      "Epoch 29/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1120 - acc: 0.4678\n",
      "Epoch 29: val_loss improved from 1.20905 to 1.20846, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1616 - acc: 0.4607 - val_loss: 1.2085 - val_acc: 0.4361\n",
      "Epoch 30/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1573 - acc: 0.4795\n",
      "Epoch 30: val_loss improved from 1.20846 to 1.20612, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1587 - acc: 0.4627 - val_loss: 1.2061 - val_acc: 0.4421\n",
      "Epoch 31/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1565 - acc: 0.4795\n",
      "Epoch 31: val_loss improved from 1.20612 to 1.20438, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1545 - acc: 0.4641 - val_loss: 1.2044 - val_acc: 0.4383\n",
      "Epoch 32/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1853 - acc: 0.4365\n",
      "Epoch 32: val_loss did not improve from 1.20438\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1582 - acc: 0.4629 - val_loss: 1.2119 - val_acc: 0.4342\n",
      "Epoch 33/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1451 - acc: 0.4697\n",
      "Epoch 33: val_loss did not improve from 1.20438\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1538 - acc: 0.4650 - val_loss: 1.2104 - val_acc: 0.4350\n",
      "Epoch 34/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1602 - acc: 0.4395\n",
      "Epoch 34: val_loss improved from 1.20438 to 1.20415, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1521 - acc: 0.4691 - val_loss: 1.2041 - val_acc: 0.4418\n",
      "Epoch 35/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1595 - acc: 0.4873\n",
      "Epoch 35: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1488 - acc: 0.4661 - val_loss: 1.2137 - val_acc: 0.4293\n",
      "Epoch 36/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1551 - acc: 0.4453\n",
      "Epoch 36: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1493 - acc: 0.4680 - val_loss: 1.2098 - val_acc: 0.4348\n",
      "Epoch 37/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1575 - acc: 0.4580\n",
      "Epoch 37: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1490 - acc: 0.4682 - val_loss: 1.2091 - val_acc: 0.4334\n",
      "Epoch 38/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1503 - acc: 0.4688\n",
      "Epoch 38: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1411 - acc: 0.4740 - val_loss: 1.2073 - val_acc: 0.4388\n",
      "Epoch 39/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1236 - acc: 0.4834\n",
      "Epoch 39: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1430 - acc: 0.4691 - val_loss: 1.2071 - val_acc: 0.4388\n",
      "Epoch 40/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1038 - acc: 0.5107\n",
      "Epoch 40: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1394 - acc: 0.4740 - val_loss: 1.2080 - val_acc: 0.4391\n",
      "Epoch 41/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1764 - acc: 0.4688\n",
      "Epoch 41: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1395 - acc: 0.4742 - val_loss: 1.2070 - val_acc: 0.4402\n",
      "Epoch 42/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1616 - acc: 0.4521\n",
      "Epoch 42: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1382 - acc: 0.4747 - val_loss: 1.2107 - val_acc: 0.4356\n",
      "Epoch 43/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1519 - acc: 0.4600\n",
      "Epoch 43: val_loss did not improve from 1.20415\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1393 - acc: 0.4735 - val_loss: 1.2075 - val_acc: 0.4345\n",
      "Epoch 44/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1533 - acc: 0.4648\n",
      "Epoch 44: val_loss improved from 1.20415 to 1.20012, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1349 - acc: 0.4725 - val_loss: 1.2001 - val_acc: 0.4418\n",
      "Epoch 45/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1247 - acc: 0.4863\n",
      "Epoch 45: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1319 - acc: 0.4773 - val_loss: 1.2022 - val_acc: 0.4418\n",
      "Epoch 46/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1272 - acc: 0.5010\n",
      "Epoch 46: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1327 - acc: 0.4740 - val_loss: 1.2070 - val_acc: 0.4404\n",
      "Epoch 47/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1239 - acc: 0.4629\n",
      "Epoch 47: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1304 - acc: 0.4760 - val_loss: 1.2060 - val_acc: 0.4404\n",
      "Epoch 48/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0961 - acc: 0.4912\n",
      "Epoch 48: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1310 - acc: 0.4780 - val_loss: 1.2056 - val_acc: 0.4426\n",
      "Epoch 49/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1651 - acc: 0.4502\n",
      "Epoch 49: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1268 - acc: 0.4763 - val_loss: 1.2062 - val_acc: 0.4342\n",
      "Epoch 50/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1268 - acc: 0.4941\n",
      "Epoch 50: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1279 - acc: 0.4784 - val_loss: 1.2014 - val_acc: 0.4383\n",
      "Epoch 51/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0836 - acc: 0.4932\n",
      "Epoch 51: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1250 - acc: 0.4794 - val_loss: 1.2079 - val_acc: 0.4407\n",
      "Epoch 52/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1276 - acc: 0.4746\n",
      "Epoch 52: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1214 - acc: 0.4814 - val_loss: 1.2078 - val_acc: 0.4321\n",
      "Epoch 53/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1206 - acc: 0.4795\n",
      "Epoch 53: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1221 - acc: 0.4784 - val_loss: 1.2021 - val_acc: 0.4413\n",
      "Epoch 54/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1388 - acc: 0.4814\n",
      "Epoch 54: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1215 - acc: 0.4805 - val_loss: 1.2064 - val_acc: 0.4407\n",
      "Epoch 55/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1298 - acc: 0.4854\n",
      "Epoch 55: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1214 - acc: 0.4807 - val_loss: 1.2062 - val_acc: 0.4358\n",
      "Epoch 56/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1246 - acc: 0.4648\n",
      "Epoch 56: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1151 - acc: 0.4815 - val_loss: 1.2061 - val_acc: 0.4407\n",
      "Epoch 57/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1230 - acc: 0.4727\n",
      "Epoch 57: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1176 - acc: 0.4839 - val_loss: 1.2113 - val_acc: 0.4402\n",
      "Epoch 58/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1004 - acc: 0.4854\n",
      "Epoch 58: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1146 - acc: 0.4879 - val_loss: 1.2114 - val_acc: 0.4342\n",
      "Epoch 59/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0776 - acc: 0.5029\n",
      "Epoch 59: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1164 - acc: 0.4848 - val_loss: 1.2068 - val_acc: 0.4394\n",
      "Epoch 60/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0992 - acc: 0.4932\n",
      "Epoch 60: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1149 - acc: 0.4856 - val_loss: 1.2087 - val_acc: 0.4385\n",
      "Epoch 61/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1280 - acc: 0.5049\n",
      "Epoch 61: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1124 - acc: 0.4849 - val_loss: 1.2046 - val_acc: 0.4429\n",
      "Epoch 62/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1192 - acc: 0.4688\n",
      "Epoch 62: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1109 - acc: 0.4841 - val_loss: 1.2026 - val_acc: 0.4404\n",
      "Epoch 63/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1059 - acc: 0.4639\n",
      "Epoch 63: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1097 - acc: 0.4809 - val_loss: 1.2016 - val_acc: 0.4429\n",
      "Epoch 64/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0935 - acc: 0.4932\n",
      "Epoch 64: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1063 - acc: 0.4915 - val_loss: 1.2050 - val_acc: 0.4404\n",
      "Epoch 65/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1337 - acc: 0.4844\n",
      "Epoch 65: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1100 - acc: 0.4849 - val_loss: 1.2061 - val_acc: 0.4364\n",
      "Epoch 66/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0827 - acc: 0.4961\n",
      "Epoch 66: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1084 - acc: 0.4863 - val_loss: 1.2118 - val_acc: 0.4394\n",
      "Epoch 67/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1093 - acc: 0.4980\n",
      "Epoch 67: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1075 - acc: 0.4871 - val_loss: 1.2076 - val_acc: 0.4445\n",
      "Epoch 68/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1479 - acc: 0.4590\n",
      "Epoch 68: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1040 - acc: 0.4908 - val_loss: 1.2098 - val_acc: 0.4391\n",
      "Epoch 69/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0930 - acc: 0.5127\n",
      "Epoch 69: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1050 - acc: 0.4907 - val_loss: 1.2071 - val_acc: 0.4415\n",
      "Epoch 70/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1187 - acc: 0.4902\n",
      "Epoch 70: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1015 - acc: 0.4896 - val_loss: 1.2065 - val_acc: 0.4407\n",
      "Epoch 71/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0854 - acc: 0.4941\n",
      "Epoch 71: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1009 - acc: 0.4915 - val_loss: 1.2114 - val_acc: 0.4375\n",
      "Epoch 72/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0825 - acc: 0.5029\n",
      "Epoch 72: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1042 - acc: 0.4893 - val_loss: 1.2117 - val_acc: 0.4383\n",
      "Epoch 73/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1026 - acc: 0.4912\n",
      "Epoch 73: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1023 - acc: 0.4886 - val_loss: 1.2118 - val_acc: 0.4421\n",
      "Epoch 74/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1061 - acc: 0.4648\n",
      "Epoch 74: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1012 - acc: 0.4895 - val_loss: 1.2055 - val_acc: 0.4429\n",
      "Epoch 75/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0995 - acc: 0.5029\n",
      "Epoch 75: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0987 - acc: 0.4921 - val_loss: 1.2144 - val_acc: 0.4402\n",
      "Epoch 76/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0630 - acc: 0.4795\n",
      "Epoch 76: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0975 - acc: 0.4938 - val_loss: 1.2058 - val_acc: 0.4450\n",
      "Epoch 77/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1134 - acc: 0.4922\n",
      "Epoch 77: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0990 - acc: 0.4923 - val_loss: 1.2085 - val_acc: 0.4456\n",
      "Epoch 78/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1066 - acc: 0.4775\n",
      "Epoch 78: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0950 - acc: 0.4926 - val_loss: 1.2108 - val_acc: 0.4391\n",
      "Epoch 79/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0888 - acc: 0.5029\n",
      "Epoch 79: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0957 - acc: 0.4924 - val_loss: 1.2156 - val_acc: 0.4377\n",
      "Epoch 80/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1079 - acc: 0.4912\n",
      "Epoch 80: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0942 - acc: 0.4942 - val_loss: 1.2126 - val_acc: 0.4380\n",
      "Epoch 81/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1205 - acc: 0.4883\n",
      "Epoch 81: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0936 - acc: 0.4944 - val_loss: 1.2078 - val_acc: 0.4456\n",
      "Epoch 82/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0894 - acc: 0.4961\n",
      "Epoch 82: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0936 - acc: 0.4967 - val_loss: 1.2190 - val_acc: 0.4369\n",
      "Epoch 83/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1132 - acc: 0.4648\n",
      "Epoch 83: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0921 - acc: 0.4957 - val_loss: 1.2103 - val_acc: 0.4385\n",
      "Epoch 84/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0294 - acc: 0.5078\n",
      "Epoch 84: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0926 - acc: 0.4959 - val_loss: 1.2122 - val_acc: 0.4383\n",
      "Epoch 85/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1031 - acc: 0.4658\n",
      "Epoch 85: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0896 - acc: 0.4949 - val_loss: 1.2088 - val_acc: 0.4388\n",
      "Epoch 86/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1183 - acc: 0.4756\n",
      "Epoch 86: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0878 - acc: 0.4933 - val_loss: 1.2113 - val_acc: 0.4358\n",
      "Epoch 87/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0936 - acc: 0.5107\n",
      "Epoch 87: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0875 - acc: 0.4958 - val_loss: 1.2119 - val_acc: 0.4375\n",
      "Epoch 88/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0962 - acc: 0.5127\n",
      "Epoch 88: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0894 - acc: 0.4990 - val_loss: 1.2082 - val_acc: 0.4437\n",
      "Epoch 89/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0411 - acc: 0.5342\n",
      "Epoch 89: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0874 - acc: 0.4960 - val_loss: 1.2211 - val_acc: 0.4310\n",
      "Epoch 90/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0810 - acc: 0.4854\n",
      "Epoch 90: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0866 - acc: 0.4984 - val_loss: 1.2204 - val_acc: 0.4307\n",
      "Epoch 91/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0808 - acc: 0.4775\n",
      "Epoch 91: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0893 - acc: 0.4962 - val_loss: 1.2131 - val_acc: 0.4442\n",
      "Epoch 92/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0912 - acc: 0.4980\n",
      "Epoch 92: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0864 - acc: 0.4970 - val_loss: 1.2152 - val_acc: 0.4358\n",
      "Epoch 93/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1247 - acc: 0.4785\n",
      "Epoch 93: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0863 - acc: 0.4956 - val_loss: 1.2120 - val_acc: 0.4413\n",
      "Epoch 94/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0779 - acc: 0.5254\n",
      "Epoch 94: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0832 - acc: 0.5011 - val_loss: 1.2090 - val_acc: 0.4339\n",
      "Epoch 95/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0915 - acc: 0.4932\n",
      "Epoch 95: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0823 - acc: 0.4983 - val_loss: 1.2176 - val_acc: 0.4358\n",
      "Epoch 96/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0890 - acc: 0.5029\n",
      "Epoch 96: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0835 - acc: 0.4971 - val_loss: 1.2142 - val_acc: 0.4361\n",
      "Epoch 97/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0811 - acc: 0.5322\n",
      "Epoch 97: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0814 - acc: 0.5002 - val_loss: 1.2130 - val_acc: 0.4402\n",
      "Epoch 98/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0829 - acc: 0.5020\n",
      "Epoch 98: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0781 - acc: 0.4992 - val_loss: 1.2207 - val_acc: 0.4318\n",
      "Epoch 99/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0615 - acc: 0.5195\n",
      "Epoch 99: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0797 - acc: 0.5001 - val_loss: 1.2186 - val_acc: 0.4291\n",
      "Epoch 100/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1031 - acc: 0.4873\n",
      "Epoch 100: val_loss did not improve from 1.20012\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0785 - acc: 0.5005 - val_loss: 1.2139 - val_acc: 0.4380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f258f87bf10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "model = baseline_model(X_train_normalized_new.shape[1])\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "model_name = './checkpoints/Adaptive_prune_model_classify_baseline.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x=X_train_normalized_new, y=y_train_class, class_weight=class_weight_dict, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val_class), callbacks=[checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2569a9ab-e3c7-43cf-bb57-15f0e45b138c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.5787 - acc: 0.2275\n",
      "Epoch 1: val_loss improved from inf to 1.30339, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 5us/sample - loss: 1.3550 - acc: 0.3744 - val_loss: 1.3034 - val_acc: 0.4074\n",
      "Epoch 2/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2596 - acc: 0.4492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:55:45.508295: W tensorflow/c/c_api.cc:304] Operation '{name:'training_2/Adam/dense_4/bias/v/Assign' id:919 op device:{requested: '', assigned: ''} def:{{{node training_2/Adam/dense_4/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_2/Adam/dense_4/bias/v, training_2/Adam/dense_4/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-06 16:55:45.627464: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_3/mul' id:755 op device:{requested: '', assigned: ''} def:{{{node loss_3/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_3/mul/x, loss_3/classification_output_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.30339 to 1.26911, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2679 - acc: 0.4371 - val_loss: 1.2691 - val_acc: 0.4172\n",
      "Epoch 3/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2801 - acc: 0.4180\n",
      "Epoch 3: val_loss improved from 1.26911 to 1.25859, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2434 - acc: 0.4483 - val_loss: 1.2586 - val_acc: 0.4247\n",
      "Epoch 4/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2231 - acc: 0.4590\n",
      "Epoch 4: val_loss improved from 1.25859 to 1.24963, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2305 - acc: 0.4523 - val_loss: 1.2496 - val_acc: 0.4239\n",
      "Epoch 5/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1988 - acc: 0.4697\n",
      "Epoch 5: val_loss improved from 1.24963 to 1.24378, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2172 - acc: 0.4592 - val_loss: 1.2438 - val_acc: 0.4245\n",
      "Epoch 6/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1892 - acc: 0.4668\n",
      "Epoch 6: val_loss improved from 1.24378 to 1.23822, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2059 - acc: 0.4627 - val_loss: 1.2382 - val_acc: 0.4285\n",
      "Epoch 7/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1921 - acc: 0.4736\n",
      "Epoch 7: val_loss improved from 1.23822 to 1.23413, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.2036 - acc: 0.4622 - val_loss: 1.2341 - val_acc: 0.4310\n",
      "Epoch 8/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2008 - acc: 0.4814\n",
      "Epoch 8: val_loss improved from 1.23413 to 1.22946, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1963 - acc: 0.4660 - val_loss: 1.2295 - val_acc: 0.4358\n",
      "Epoch 9/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2291 - acc: 0.4346\n",
      "Epoch 9: val_loss improved from 1.22946 to 1.22426, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1915 - acc: 0.4648 - val_loss: 1.2243 - val_acc: 0.4350\n",
      "Epoch 10/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.2060 - acc: 0.4668\n",
      "Epoch 10: val_loss improved from 1.22426 to 1.22414, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1885 - acc: 0.4679 - val_loss: 1.2241 - val_acc: 0.4361\n",
      "Epoch 11/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1597 - acc: 0.4854\n",
      "Epoch 11: val_loss improved from 1.22414 to 1.22099, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1821 - acc: 0.4716 - val_loss: 1.2210 - val_acc: 0.4334\n",
      "Epoch 12/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1635 - acc: 0.4746\n",
      "Epoch 12: val_loss improved from 1.22099 to 1.21642, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1787 - acc: 0.4720 - val_loss: 1.2164 - val_acc: 0.4369\n",
      "Epoch 13/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1791 - acc: 0.4561\n",
      "Epoch 13: val_loss improved from 1.21642 to 1.21433, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1751 - acc: 0.4732 - val_loss: 1.2143 - val_acc: 0.4426\n",
      "Epoch 14/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1657 - acc: 0.4746\n",
      "Epoch 14: val_loss improved from 1.21433 to 1.21363, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1718 - acc: 0.4760 - val_loss: 1.2136 - val_acc: 0.4402\n",
      "Epoch 15/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1758 - acc: 0.4648\n",
      "Epoch 15: val_loss did not improve from 1.21363\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1668 - acc: 0.4782 - val_loss: 1.2160 - val_acc: 0.4423\n",
      "Epoch 16/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1653 - acc: 0.4912\n",
      "Epoch 16: val_loss improved from 1.21363 to 1.20745, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1666 - acc: 0.4793 - val_loss: 1.2074 - val_acc: 0.4445\n",
      "Epoch 17/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1631 - acc: 0.4805\n",
      "Epoch 17: val_loss improved from 1.20745 to 1.20604, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1635 - acc: 0.4791 - val_loss: 1.2060 - val_acc: 0.4445\n",
      "Epoch 18/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1559 - acc: 0.4775\n",
      "Epoch 18: val_loss improved from 1.20604 to 1.20524, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1600 - acc: 0.4816 - val_loss: 1.2052 - val_acc: 0.4472\n",
      "Epoch 19/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1510 - acc: 0.4805\n",
      "Epoch 19: val_loss improved from 1.20524 to 1.20252, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1581 - acc: 0.4833 - val_loss: 1.2025 - val_acc: 0.4483\n",
      "Epoch 20/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1788 - acc: 0.4805\n",
      "Epoch 20: val_loss improved from 1.20252 to 1.20158, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1554 - acc: 0.4848 - val_loss: 1.2016 - val_acc: 0.4499\n",
      "Epoch 21/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1870 - acc: 0.4854\n",
      "Epoch 21: val_loss improved from 1.20158 to 1.20106, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1513 - acc: 0.4853 - val_loss: 1.2011 - val_acc: 0.4532\n",
      "Epoch 22/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1715 - acc: 0.4688\n",
      "Epoch 22: val_loss did not improve from 1.20106\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1498 - acc: 0.4853 - val_loss: 1.2014 - val_acc: 0.4526\n",
      "Epoch 23/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1540 - acc: 0.4873\n",
      "Epoch 23: val_loss improved from 1.20106 to 1.19882, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1476 - acc: 0.4855 - val_loss: 1.1988 - val_acc: 0.4567\n",
      "Epoch 24/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1475 - acc: 0.4824\n",
      "Epoch 24: val_loss improved from 1.19882 to 1.19782, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1448 - acc: 0.4892 - val_loss: 1.1978 - val_acc: 0.4561\n",
      "Epoch 25/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1378 - acc: 0.4922\n",
      "Epoch 25: val_loss did not improve from 1.19782\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1428 - acc: 0.4890 - val_loss: 1.1981 - val_acc: 0.4561\n",
      "Epoch 26/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1327 - acc: 0.5020\n",
      "Epoch 26: val_loss improved from 1.19782 to 1.19778, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1422 - acc: 0.4915 - val_loss: 1.1978 - val_acc: 0.4513\n",
      "Epoch 27/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1507 - acc: 0.4922\n",
      "Epoch 27: val_loss did not improve from 1.19778\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1404 - acc: 0.4913 - val_loss: 1.2011 - val_acc: 0.4513\n",
      "Epoch 28/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1528 - acc: 0.4756\n",
      "Epoch 28: val_loss improved from 1.19778 to 1.19379, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1372 - acc: 0.4932 - val_loss: 1.1938 - val_acc: 0.4572\n",
      "Epoch 29/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1241 - acc: 0.5088\n",
      "Epoch 29: val_loss did not improve from 1.19379\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1364 - acc: 0.4924 - val_loss: 1.1938 - val_acc: 0.4589\n",
      "Epoch 30/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1173 - acc: 0.5068\n",
      "Epoch 30: val_loss improved from 1.19379 to 1.19161, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1341 - acc: 0.4947 - val_loss: 1.1916 - val_acc: 0.4567\n",
      "Epoch 31/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1326 - acc: 0.4727\n",
      "Epoch 31: val_loss did not improve from 1.19161\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1321 - acc: 0.4935 - val_loss: 1.1957 - val_acc: 0.4540\n",
      "Epoch 32/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1232 - acc: 0.4893\n",
      "Epoch 32: val_loss did not improve from 1.19161\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1293 - acc: 0.4960 - val_loss: 1.1957 - val_acc: 0.4510\n",
      "Epoch 33/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1220 - acc: 0.4961\n",
      "Epoch 33: val_loss did not improve from 1.19161\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1258 - acc: 0.4976 - val_loss: 1.1950 - val_acc: 0.4607\n",
      "Epoch 34/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1416 - acc: 0.5107\n",
      "Epoch 34: val_loss improved from 1.19161 to 1.18821, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1265 - acc: 0.4974 - val_loss: 1.1882 - val_acc: 0.4618\n",
      "Epoch 35/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1324 - acc: 0.4971\n",
      "Epoch 35: val_loss improved from 1.18821 to 1.18740, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1250 - acc: 0.4981 - val_loss: 1.1874 - val_acc: 0.4575\n",
      "Epoch 36/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1125 - acc: 0.5010\n",
      "Epoch 36: val_loss did not improve from 1.18740\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1210 - acc: 0.4974 - val_loss: 1.1875 - val_acc: 0.4624\n",
      "Epoch 37/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1290 - acc: 0.4980\n",
      "Epoch 37: val_loss did not improve from 1.18740\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1217 - acc: 0.4987 - val_loss: 1.1885 - val_acc: 0.4578\n",
      "Epoch 38/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1488 - acc: 0.4922\n",
      "Epoch 38: val_loss did not improve from 1.18740\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1205 - acc: 0.5012 - val_loss: 1.1896 - val_acc: 0.4616\n",
      "Epoch 39/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1309 - acc: 0.4961\n",
      "Epoch 39: val_loss did not improve from 1.18740\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1147 - acc: 0.5043 - val_loss: 1.1876 - val_acc: 0.4629\n",
      "Epoch 40/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0819 - acc: 0.5264\n",
      "Epoch 40: val_loss improved from 1.18740 to 1.18560, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1169 - acc: 0.4992 - val_loss: 1.1856 - val_acc: 0.4632\n",
      "Epoch 41/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1256 - acc: 0.4707\n",
      "Epoch 41: val_loss did not improve from 1.18560\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1119 - acc: 0.5031 - val_loss: 1.1890 - val_acc: 0.4683\n",
      "Epoch 42/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0948 - acc: 0.5225\n",
      "Epoch 42: val_loss did not improve from 1.18560\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1116 - acc: 0.5056 - val_loss: 1.1875 - val_acc: 0.4605\n",
      "Epoch 43/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0818 - acc: 0.5332\n",
      "Epoch 43: val_loss improved from 1.18560 to 1.18427, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1113 - acc: 0.5049 - val_loss: 1.1843 - val_acc: 0.4653\n",
      "Epoch 44/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1048 - acc: 0.5254\n",
      "Epoch 44: val_loss did not improve from 1.18427\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1106 - acc: 0.5061 - val_loss: 1.1863 - val_acc: 0.4672\n",
      "Epoch 45/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0729 - acc: 0.5244\n",
      "Epoch 45: val_loss did not improve from 1.18427\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1075 - acc: 0.5051 - val_loss: 1.1869 - val_acc: 0.4645\n",
      "Epoch 46/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0889 - acc: 0.5254\n",
      "Epoch 46: val_loss improved from 1.18427 to 1.18410, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1075 - acc: 0.5046 - val_loss: 1.1841 - val_acc: 0.4629\n",
      "Epoch 47/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0885 - acc: 0.5254\n",
      "Epoch 47: val_loss did not improve from 1.18410\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1077 - acc: 0.5064 - val_loss: 1.1918 - val_acc: 0.4626\n",
      "Epoch 48/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1048 - acc: 0.5039\n",
      "Epoch 48: val_loss did not improve from 1.18410\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1051 - acc: 0.5071 - val_loss: 1.1851 - val_acc: 0.4626\n",
      "Epoch 49/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1083 - acc: 0.5049\n",
      "Epoch 49: val_loss did not improve from 1.18410\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.1014 - acc: 0.5082 - val_loss: 1.1864 - val_acc: 0.4659\n",
      "Epoch 50/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0768 - acc: 0.5195\n",
      "Epoch 50: val_loss did not improve from 1.18410\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.1028 - acc: 0.5093 - val_loss: 1.1843 - val_acc: 0.4683\n",
      "Epoch 51/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1110 - acc: 0.5078\n",
      "Epoch 51: val_loss did not improve from 1.18410\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0995 - acc: 0.5090 - val_loss: 1.1842 - val_acc: 0.4702\n",
      "Epoch 52/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0685 - acc: 0.5205\n",
      "Epoch 52: val_loss did not improve from 1.18410\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0993 - acc: 0.5118 - val_loss: 1.1844 - val_acc: 0.4691\n",
      "Epoch 53/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0715 - acc: 0.5293\n",
      "Epoch 53: val_loss improved from 1.18410 to 1.18362, saving model to ./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0979 - acc: 0.5127 - val_loss: 1.1836 - val_acc: 0.4691\n",
      "Epoch 54/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1035 - acc: 0.5225\n",
      "Epoch 54: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0979 - acc: 0.5114 - val_loss: 1.1878 - val_acc: 0.4667\n",
      "Epoch 55/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0935 - acc: 0.5371\n",
      "Epoch 55: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0937 - acc: 0.5149 - val_loss: 1.1836 - val_acc: 0.4664\n",
      "Epoch 56/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1087 - acc: 0.5137\n",
      "Epoch 56: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0963 - acc: 0.5132 - val_loss: 1.1874 - val_acc: 0.4653\n",
      "Epoch 57/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0754 - acc: 0.5244\n",
      "Epoch 57: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0921 - acc: 0.5126 - val_loss: 1.1851 - val_acc: 0.4653\n",
      "Epoch 58/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0699 - acc: 0.5381\n",
      "Epoch 58: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0911 - acc: 0.5141 - val_loss: 1.1874 - val_acc: 0.4637\n",
      "Epoch 59/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0736 - acc: 0.5361\n",
      "Epoch 59: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0884 - acc: 0.5159 - val_loss: 1.1904 - val_acc: 0.4651\n",
      "Epoch 60/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1067 - acc: 0.5225\n",
      "Epoch 60: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0884 - acc: 0.5188 - val_loss: 1.1855 - val_acc: 0.4626\n",
      "Epoch 61/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1197 - acc: 0.4932\n",
      "Epoch 61: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0884 - acc: 0.5168 - val_loss: 1.1866 - val_acc: 0.4629\n",
      "Epoch 62/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0772 - acc: 0.5254\n",
      "Epoch 62: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0854 - acc: 0.5196 - val_loss: 1.1877 - val_acc: 0.4659\n",
      "Epoch 63/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0749 - acc: 0.5205\n",
      "Epoch 63: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0874 - acc: 0.5167 - val_loss: 1.1845 - val_acc: 0.4648\n",
      "Epoch 64/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1177 - acc: 0.4932\n",
      "Epoch 64: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0846 - acc: 0.5183 - val_loss: 1.1842 - val_acc: 0.4675\n",
      "Epoch 65/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1093 - acc: 0.4902\n",
      "Epoch 65: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0847 - acc: 0.5177 - val_loss: 1.1848 - val_acc: 0.4645\n",
      "Epoch 66/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0788 - acc: 0.5244\n",
      "Epoch 66: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0829 - acc: 0.5172 - val_loss: 1.1841 - val_acc: 0.4675\n",
      "Epoch 67/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0871 - acc: 0.5107\n",
      "Epoch 67: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0835 - acc: 0.5194 - val_loss: 1.1871 - val_acc: 0.4618\n",
      "Epoch 68/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0868 - acc: 0.5078\n",
      "Epoch 68: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0797 - acc: 0.5196 - val_loss: 1.1844 - val_acc: 0.4694\n",
      "Epoch 69/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.1328 - acc: 0.4824\n",
      "Epoch 69: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0794 - acc: 0.5178 - val_loss: 1.1895 - val_acc: 0.4597\n",
      "Epoch 70/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0827 - acc: 0.5254\n",
      "Epoch 70: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0805 - acc: 0.5202 - val_loss: 1.1867 - val_acc: 0.4675\n",
      "Epoch 71/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0880 - acc: 0.5156\n",
      "Epoch 71: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0772 - acc: 0.5205 - val_loss: 1.1869 - val_acc: 0.4626\n",
      "Epoch 72/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0580 - acc: 0.5312\n",
      "Epoch 72: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0752 - acc: 0.5252 - val_loss: 1.1858 - val_acc: 0.4645\n",
      "Epoch 73/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0392 - acc: 0.5449\n",
      "Epoch 73: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0779 - acc: 0.5249 - val_loss: 1.1842 - val_acc: 0.4694\n",
      "Epoch 74/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0762 - acc: 0.5127\n",
      "Epoch 74: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0784 - acc: 0.5229 - val_loss: 1.1847 - val_acc: 0.4689\n",
      "Epoch 75/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0908 - acc: 0.5088\n",
      "Epoch 75: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0731 - acc: 0.5265 - val_loss: 1.1904 - val_acc: 0.4672\n",
      "Epoch 76/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0744 - acc: 0.5449\n",
      "Epoch 76: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0746 - acc: 0.5236 - val_loss: 1.1893 - val_acc: 0.4664\n",
      "Epoch 77/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0643 - acc: 0.5176\n",
      "Epoch 77: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0729 - acc: 0.5210 - val_loss: 1.1839 - val_acc: 0.4702\n",
      "Epoch 78/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0651 - acc: 0.5283\n",
      "Epoch 78: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0713 - acc: 0.5275 - val_loss: 1.1885 - val_acc: 0.4708\n",
      "Epoch 79/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0509 - acc: 0.5127\n",
      "Epoch 79: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0726 - acc: 0.5223 - val_loss: 1.1842 - val_acc: 0.4664\n",
      "Epoch 80/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0631 - acc: 0.5215\n",
      "Epoch 80: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0707 - acc: 0.5247 - val_loss: 1.1857 - val_acc: 0.4637\n",
      "Epoch 81/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0763 - acc: 0.5312\n",
      "Epoch 81: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0695 - acc: 0.5246 - val_loss: 1.1879 - val_acc: 0.4659\n",
      "Epoch 82/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0595 - acc: 0.5244\n",
      "Epoch 82: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0676 - acc: 0.5275 - val_loss: 1.1848 - val_acc: 0.4702\n",
      "Epoch 83/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0801 - acc: 0.5078\n",
      "Epoch 83: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0688 - acc: 0.5258 - val_loss: 1.1838 - val_acc: 0.4651\n",
      "Epoch 84/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0027 - acc: 0.5820\n",
      "Epoch 84: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0672 - acc: 0.5272 - val_loss: 1.1896 - val_acc: 0.4662\n",
      "Epoch 85/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0476 - acc: 0.5352\n",
      "Epoch 85: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0661 - acc: 0.5257 - val_loss: 1.1930 - val_acc: 0.4594\n",
      "Epoch 86/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0727 - acc: 0.5283\n",
      "Epoch 86: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0640 - acc: 0.5291 - val_loss: 1.1877 - val_acc: 0.4702\n",
      "Epoch 87/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0637 - acc: 0.5254\n",
      "Epoch 87: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0643 - acc: 0.5291 - val_loss: 1.1869 - val_acc: 0.4681\n",
      "Epoch 88/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0527 - acc: 0.5312\n",
      "Epoch 88: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0594 - acc: 0.5292 - val_loss: 1.1901 - val_acc: 0.4632\n",
      "Epoch 89/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0351 - acc: 0.5332\n",
      "Epoch 89: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0593 - acc: 0.5316 - val_loss: 1.1888 - val_acc: 0.4648\n",
      "Epoch 90/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0663 - acc: 0.5244\n",
      "Epoch 90: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0626 - acc: 0.5309 - val_loss: 1.1882 - val_acc: 0.4710\n",
      "Epoch 91/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0309 - acc: 0.5430\n",
      "Epoch 91: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0600 - acc: 0.5320 - val_loss: 1.1927 - val_acc: 0.4700\n",
      "Epoch 92/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0979 - acc: 0.5117\n",
      "Epoch 92: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 2us/sample - loss: 1.0621 - acc: 0.5284 - val_loss: 1.1862 - val_acc: 0.4683\n",
      "Epoch 93/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0857 - acc: 0.5068\n",
      "Epoch 93: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0579 - acc: 0.5343 - val_loss: 1.1906 - val_acc: 0.4637\n",
      "Epoch 94/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0377 - acc: 0.5488\n",
      "Epoch 94: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0558 - acc: 0.5330 - val_loss: 1.1898 - val_acc: 0.4659\n",
      "Epoch 95/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0436 - acc: 0.5361\n",
      "Epoch 95: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0557 - acc: 0.5338 - val_loss: 1.1901 - val_acc: 0.4686\n",
      "Epoch 96/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0615 - acc: 0.5244\n",
      "Epoch 96: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0577 - acc: 0.5304 - val_loss: 1.1874 - val_acc: 0.4681\n",
      "Epoch 97/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0965 - acc: 0.4990\n",
      "Epoch 97: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0558 - acc: 0.5317 - val_loss: 1.1884 - val_acc: 0.4653\n",
      "Epoch 98/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0524 - acc: 0.5264\n",
      "Epoch 98: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0555 - acc: 0.5337 - val_loss: 1.1918 - val_acc: 0.4653\n",
      "Epoch 99/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0668 - acc: 0.5410\n",
      "Epoch 99: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0575 - acc: 0.5322 - val_loss: 1.1919 - val_acc: 0.4694\n",
      "Epoch 100/100\n",
      " 1024/29601 [>.............................] - ETA: 0s - loss: 1.0384 - acc: 0.5469\n",
      "Epoch 100: val_loss did not improve from 1.18362\n",
      "29601/29601 [==============================] - 0s 1us/sample - loss: 1.0549 - acc: 0.5334 - val_loss: 1.1900 - val_acc: 0.4624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f258f87ba50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "model = baseline_model(X_train_normalized_new.shape[1])\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "model_name = './checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x=X_train_normalized_new, y=y_train_class, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val_class), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e067b8a2-8d03-45e7-a576-37c706a4faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:57:49.235099: W tensorflow/c/c_api.cc:304] Operation '{name:'classification_output_4/kernel/Assign' id:1419 op device:{requested: '', assigned: ''} def:{{{node classification_output_4/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](classification_output_4/kernel, classification_output_4/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-06 16:57:49.354195: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3_2/kernel/m/Assign' id:1574 op device:{requested: '', assigned: ''} def:{{{node dense_3_2/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_3_2/kernel/m, dense_3_2/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-06 16:57:49.423771: W tensorflow/c/c_api.cc:304] Operation '{name:'classification_output_4/Softmax' id:1430 op device:{requested: '', assigned: ''} def:{{{node classification_output_4/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](classification_output_4/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.66%\n",
      "Confusion Matrix:\n",
      "[[43  4  7  5]\n",
      " [37 56 15  8]\n",
      " [11 13 47  4]\n",
      " [17 10  6 26]]\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test set:\n",
    "import tensorflow as tf\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "model = tf.keras.models.load_model(\"./checkpoints/Adaptive_prune_model_classify_baseline.h5\")\n",
    "y_pred_class = model.predict(X_test_normalized_new)\n",
    "from collections import Counter\n",
    "\n",
    "def find_mode(nums):\n",
    "    count = Counter(nums)\n",
    "    return count.most_common(1)[0][0]\n",
    "\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 1))\n",
    "gt_trace = np.empty((0, 1))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred_class[trace_idx,:]\n",
    "  pred_class = np.argmax(y_pred_trace, axis=1)\n",
    "  pred_trace = np.vstack((pred_trace, find_mode(pred_class)))\n",
    "  gt_t = y_test_class[trace_idx[0],:]\n",
    "  gt_t =np.argmax(gt_t)\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(gt_trace, pred_trace)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(gt_trace, pred_trace)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab7fa29-4c8d-4a41-bf40-a584dab97609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Normalize the matrix to get percentages\n",
    "matrix = cm\n",
    "normalized_matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "percentage_matrix = normalized_matrix * 100\n",
    "\n",
    "# Plot the matrix\n",
    "plt.imshow(percentage_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix in Percentage')\n",
    "plt.colorbar(label='%')\n",
    "tick_marks = np.arange(4)  # Adjust if you have a different number of classes\n",
    "plt.xticks(tick_marks, range(4), rotation=45)\n",
    "plt.yticks(tick_marks, range(4))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Display percentages on the matrix\n",
    "for i in range(percentage_matrix.shape[0]):\n",
    "    for j in range(percentage_matrix.shape[1]):\n",
    "        plt.text(j, i, format(percentage_matrix[i, j], '.2f') + '%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if percentage_matrix[i, j] > 50 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7b1c40-87e5-42e9-9e88-3d2d4baeff26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5566343042071198"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(gt_trace, pred_trace, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ba8a0c-d9d1-466b-bb0e-609931782665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:58:22.184728: W tensorflow/c/c_api.cc:304] Operation '{name:'classification_output_5/kernel/Assign' id:1753 op device:{requested: '', assigned: ''} def:{{{node classification_output_5/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](classification_output_5/kernel, classification_output_5/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-06 16:58:22.309768: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_5_1/bias/m/Assign' id:1913 op device:{requested: '', assigned: ''} def:{{{node dense_5_1/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_5_1/bias/m, dense_5_1/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.49%\n",
      "Confusion Matrix:\n",
      "[[14 35  3  7]\n",
      " [11 95  4  6]\n",
      " [ 2 47 24  2]\n",
      " [ 3 31  2 23]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 16:58:22.386017: W tensorflow/c/c_api.cc:304] Operation '{name:'classification_output_5/Softmax' id:1764 op device:{requested: '', assigned: ''} def:{{{node classification_output_5/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](classification_output_5/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test set:\n",
    "import tensorflow as tf\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "model = tf.keras.models.load_model(\"./checkpoints/Adaptive_prune_model_classify_baseline_nobalance.h5\")\n",
    "y_pred_class = model.predict(X_test_normalized_new)\n",
    "from collections import Counter\n",
    "\n",
    "def find_mode(nums):\n",
    "    count = Counter(nums)\n",
    "    return count.most_common(1)[0][0]\n",
    "\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 1))\n",
    "gt_trace = np.empty((0, 1))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred_class[trace_idx,:]\n",
    "  pred_class = np.argmax(y_pred_trace, axis=1)\n",
    "  pred_trace = np.vstack((pred_trace, find_mode(pred_class)))\n",
    "  gt_t = y_test_class[trace_idx[0],:]\n",
    "  gt_t =np.argmax(gt_t)\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(gt_trace, pred_trace)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(gt_trace, pred_trace)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a3c36f7-b8ad-4f62-94ba-f30fee176070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Normalize the matrix to get percentages\n",
    "matrix = cm\n",
    "normalized_matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "percentage_matrix = normalized_matrix * 100\n",
    "\n",
    "# Plot the matrix\n",
    "plt.imshow(percentage_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix in Percentage')\n",
    "plt.colorbar(label='%')\n",
    "tick_marks = np.arange(4)  # Adjust if you have a different number of classes\n",
    "plt.xticks(tick_marks, range(4), rotation=45)\n",
    "plt.yticks(tick_marks, range(4))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Display percentages on the matrix\n",
    "for i in range(percentage_matrix.shape[0]):\n",
    "    for j in range(percentage_matrix.shape[1]):\n",
    "        plt.text(j, i, format(percentage_matrix[i, j], '.2f') + '%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if percentage_matrix[i, j] > 50 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c801d9a-8cf2-4141-a710-c661d2155b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5048543689320388"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(gt_trace, pred_trace, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700151e-ab29-4c5a-84d7-93b23013d294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
