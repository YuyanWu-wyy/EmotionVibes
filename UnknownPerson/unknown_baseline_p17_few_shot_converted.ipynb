{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f8da1-2837-4bf7-b3f4-dfcaa7ab42f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T13:20:33.898022Z",
     "iopub.status.busy": "2023-11-18T13:20:33.897832Z",
     "iopub.status.idle": "2023-11-18T13:20:34.063524Z",
     "shell.execute_reply": "2023-11-18T13:20:34.062320Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe25376-b856-4296-ba02-5e3771ff9451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T13:20:34.066970Z",
     "iopub.status.busy": "2023-11-18T13:20:34.066690Z",
     "iopub.status.idle": "2023-11-19T06:01:30.786157Z",
     "shell.execute_reply": "2023-11-19T06:01:30.785526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:20:34.374528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35009\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:22:21.704955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.728378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.728915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.735923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.736190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.736422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.843538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.843807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.844036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:21.844233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-11-18 08:22:21.844820: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:22:23.324968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:23.325333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:23.325782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:23.326065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:23.326291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 08:22:23.326466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-11-18 08:22:23.326516: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-18 08:22:23.365845: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-18 08:22:23.684107: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_21/lstm_cell_21/kernel/Assign' id:3481 op device:{requested: '', assigned: ''} def:{{{node lstm_21/lstm_cell_21/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_21/lstm_cell_21/kernel, lstm_21/lstm_cell_21/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 08:22:23.910067: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 08:22:23.973389: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31495, 95)\n",
      "Train on 31495 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:22:30.671224: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign' id:17397 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_24/lstm_cell_24/kernel/v, training/Adam/lstm_24/lstm_cell_24/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:22:37.628008: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-18 08:22:42.054776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-18 08:22:42.067670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 3.3445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 08:23:13.995153: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95650, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 45s 1ms/sample - loss: 3.3445 - val_loss: 1.9565\n",
      "Epoch 2/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.8102\n",
      "Epoch 2: val_loss improved from 1.95650 to 1.61470, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 31s 988us/sample - loss: 1.8102 - val_loss: 1.6147\n",
      "Epoch 3/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.6110\n",
      "Epoch 3: val_loss improved from 1.61470 to 1.55299, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.6110 - val_loss: 1.5530\n",
      "Epoch 4/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5446\n",
      "Epoch 4: val_loss improved from 1.55299 to 1.52354, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5446 - val_loss: 1.5235\n",
      "Epoch 5/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5202\n",
      "Epoch 5: val_loss improved from 1.52354 to 1.50585, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.5202 - val_loss: 1.5058\n",
      "Epoch 6/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5005\n",
      "Epoch 6: val_loss improved from 1.50585 to 1.49894, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.5005 - val_loss: 1.4989\n",
      "Epoch 7/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4888\n",
      "Epoch 7: val_loss improved from 1.49894 to 1.48926, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 31s 972us/sample - loss: 1.4888 - val_loss: 1.4893\n",
      "Epoch 8/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4863\n",
      "Epoch 8: val_loss improved from 1.48926 to 1.47668, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 31s 986us/sample - loss: 1.4863 - val_loss: 1.4767\n",
      "Epoch 9/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 9: val_loss improved from 1.47668 to 1.47310, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4751 - val_loss: 1.4731\n",
      "Epoch 10/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 10: val_loss did not improve from 1.47310\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4787 - val_loss: 1.4736\n",
      "Epoch 11/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4742\n",
      "Epoch 11: val_loss improved from 1.47310 to 1.45763, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4742 - val_loss: 1.4576\n",
      "Epoch 12/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4693\n",
      "Epoch 12: val_loss did not improve from 1.45763\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4693 - val_loss: 1.4605\n",
      "Epoch 13/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5275\n",
      "Epoch 13: val_loss did not improve from 1.45763\n",
      "31495/31495 [==============================] - 31s 1ms/sample - loss: 1.5275 - val_loss: 1.4695\n",
      "Epoch 14/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4759\n",
      "Epoch 14: val_loss did not improve from 1.45763\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4759 - val_loss: 1.4592\n",
      "Epoch 15/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4608\n",
      "Epoch 15: val_loss improved from 1.45763 to 1.45476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4608 - val_loss: 1.4548\n",
      "Epoch 16/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4583\n",
      "Epoch 16: val_loss improved from 1.45476 to 1.45306, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4583 - val_loss: 1.4531\n",
      "Epoch 17/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4651\n",
      "Epoch 17: val_loss did not improve from 1.45306\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4651 - val_loss: 1.4562\n",
      "Epoch 18/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4650\n",
      "Epoch 18: val_loss improved from 1.45306 to 1.44749, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4650 - val_loss: 1.4475\n",
      "Epoch 19/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4891\n",
      "Epoch 19: val_loss did not improve from 1.44749\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4891 - val_loss: 1.4631\n",
      "Epoch 20/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4598\n",
      "Epoch 20: val_loss did not improve from 1.44749\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4598 - val_loss: 1.4506\n",
      "Epoch 21/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4568\n",
      "Epoch 21: val_loss improved from 1.44749 to 1.44465, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4568 - val_loss: 1.4447\n",
      "Epoch 22/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5804\n",
      "Epoch 22: val_loss did not improve from 1.44465\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5804 - val_loss: 1.4744\n",
      "Epoch 23/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4803\n",
      "Epoch 23: val_loss did not improve from 1.44465\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4803 - val_loss: 1.4588\n",
      "Epoch 24/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4517\n",
      "Epoch 24: val_loss did not improve from 1.44465\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4517 - val_loss: 1.4511\n",
      "Epoch 25/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4436\n",
      "Epoch 25: val_loss did not improve from 1.44465\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4436 - val_loss: 1.4455\n",
      "Epoch 26/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4364\n",
      "Epoch 26: val_loss improved from 1.44465 to 1.44037, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4364 - val_loss: 1.4404\n",
      "Epoch 27/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4322\n",
      "Epoch 27: val_loss improved from 1.44037 to 1.43719, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4322 - val_loss: 1.4372\n",
      "Epoch 28/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4301\n",
      "Epoch 28: val_loss did not improve from 1.43719\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4301 - val_loss: 1.4373\n",
      "Epoch 29/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 29: val_loss improved from 1.43719 to 1.43249, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4250 - val_loss: 1.4325\n",
      "Epoch 30/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4217\n",
      "Epoch 30: val_loss improved from 1.43249 to 1.42852, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4217 - val_loss: 1.4285\n",
      "Epoch 31/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4205\n",
      "Epoch 31: val_loss improved from 1.42852 to 1.42386, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4205 - val_loss: 1.4239\n",
      "Epoch 32/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4180\n",
      "Epoch 32: val_loss did not improve from 1.42386\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4180 - val_loss: 1.4264\n",
      "Epoch 33/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4154\n",
      "Epoch 33: val_loss improved from 1.42386 to 1.42255, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4154 - val_loss: 1.4226\n",
      "Epoch 34/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 34: val_loss improved from 1.42255 to 1.41924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4159 - val_loss: 1.4192\n",
      "Epoch 35/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4111\n",
      "Epoch 35: val_loss improved from 1.41924 to 1.41417, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4111 - val_loss: 1.4142\n",
      "Epoch 36/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 36: val_loss did not improve from 1.41417\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4082 - val_loss: 1.4195\n",
      "Epoch 37/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 37: val_loss did not improve from 1.41417\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4099 - val_loss: 1.4172\n",
      "Epoch 38/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4043\n",
      "Epoch 38: val_loss improved from 1.41417 to 1.40556, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4043 - val_loss: 1.4056\n",
      "Epoch 39/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4032\n",
      "Epoch 39: val_loss did not improve from 1.40556\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4032 - val_loss: 1.4115\n",
      "Epoch 40/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 40: val_loss did not improve from 1.40556\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4011 - val_loss: 1.4140\n",
      "Epoch 41/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3988\n",
      "Epoch 41: val_loss did not improve from 1.40556\n",
      "31495/31495 [==============================] - 30s 966us/sample - loss: 1.3988 - val_loss: 1.4074\n",
      "Epoch 42/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4000\n",
      "Epoch 42: val_loss improved from 1.40556 to 1.40519, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4000 - val_loss: 1.4052\n",
      "Epoch 43/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3961\n",
      "Epoch 43: val_loss improved from 1.40519 to 1.40336, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3961 - val_loss: 1.4034\n",
      "Epoch 44/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3962\n",
      "Epoch 44: val_loss improved from 1.40336 to 1.39977, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3962 - val_loss: 1.3998\n",
      "Epoch 45/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3946\n",
      "Epoch 45: val_loss did not improve from 1.39977\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3946 - val_loss: 1.4031\n",
      "Epoch 46/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 46: val_loss did not improve from 1.39977\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3928 - val_loss: 1.4033\n",
      "Epoch 47/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3941\n",
      "Epoch 47: val_loss did not improve from 1.39977\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3941 - val_loss: 1.4027\n",
      "Epoch 48/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 48: val_loss improved from 1.39977 to 1.39568, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3907 - val_loss: 1.3957\n",
      "Epoch 49/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3890\n",
      "Epoch 49: val_loss did not improve from 1.39568\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3890 - val_loss: 1.3979\n",
      "Epoch 50/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3857\n",
      "Epoch 50: val_loss improved from 1.39568 to 1.39483, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3857 - val_loss: 1.3948\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:50:17.466937: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_31_1/lstm_cell_68/kernel/Assign' id:23602 op device:{requested: '', assigned: ''} def:{{{node lstm_31_1/lstm_cell_68/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_31_1/lstm_cell_68/kernel, lstm_31_1/lstm_cell_68/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 08:50:20.311650: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_30_1/lstm_cell_67/bias/m/Assign' id:25712 op device:{requested: '', assigned: ''} def:{{{node lstm_30_1/lstm_cell_67/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_30_1/lstm_cell_67/bias/m, lstm_30_1/lstm_cell_67/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 08:50:22.652704: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_4_1/cond/Merge' id:24591 op device:{requested: '', assigned: ''} def:{{{node dropout_4_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_4_1/cond/Identity, dropout_4_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1992)\n",
      "(1514, 1992)\n",
      "(1644, 1992)\n",
      "(1764, 1992)\n",
      "(1836, 1992)\n",
      "(1699, 1992)\n",
      "(1369, 1992)\n",
      "(1766, 1992)\n",
      "(1619, 1992)\n",
      "(1692, 1992)\n",
      "(1550, 1992)\n",
      "(1667, 1992)\n",
      "(1776, 1992)\n",
      "(1872, 1992)\n",
      "(1704, 1992)\n",
      "(1812, 1992)\n",
      "(970, 1992)\n",
      "(1668, 1992)\n",
      "(1896, 1992)\n",
      "{1: 5.93976093241329, 2: 5.754380006461286, 4: 10.0, 5: 4.986402306182125, 6: 5.7690076403327835, 8: 8.559218791849943, 9: 7.108842297677526, 10: 7.250207782812427, 11: 6.921201302197666, 12: 8.85236237322487, 13: 5.798272572392636, 19: 8.361667729741521, 21: 8.424234517074087, 22: 1.0, 25: 7.436932048807561, 26: 5.747330577622412, 27: 5.7035263711594695, 28: 5.517125169470699, 29: 2.3783649080371223}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907972/3306004915.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31495 samples, validate on 3514 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:56:43.511049: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 9.6668\n",
      "Epoch 1: val_loss improved from inf to 1.42525, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 47s 1ms/sample - loss: 9.6668 - val_loss: 1.4253\n",
      "Epoch 2/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.5769\n",
      "Epoch 2: val_loss did not improve from 1.42525\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.5769 - val_loss: 1.4278\n",
      "Epoch 3/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.5497\n",
      "Epoch 3: val_loss improved from 1.42525 to 1.40289, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.5497 - val_loss: 1.4029\n",
      "Epoch 4/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.5284\n",
      "Epoch 4: val_loss improved from 1.40289 to 1.39898, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.5284 - val_loss: 1.3990\n",
      "Epoch 5/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4653\n",
      "Epoch 5: val_loss did not improve from 1.39898\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.4653 - val_loss: 1.4188\n",
      "Epoch 6/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4425\n",
      "Epoch 6: val_loss did not improve from 1.39898\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.4425 - val_loss: 1.4077\n",
      "Epoch 7/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4550\n",
      "Epoch 7: val_loss improved from 1.39898 to 1.39588, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.4550 - val_loss: 1.3959\n",
      "Epoch 8/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4166\n",
      "Epoch 8: val_loss improved from 1.39588 to 1.39275, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 9.4166 - val_loss: 1.3927\n",
      "Epoch 9/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3949\n",
      "Epoch 9: val_loss did not improve from 1.39275\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3949 - val_loss: 1.3953\n",
      "Epoch 10/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3875\n",
      "Epoch 10: val_loss did not improve from 1.39275\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3875 - val_loss: 1.4059\n",
      "Epoch 11/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3849\n",
      "Epoch 11: val_loss did not improve from 1.39275\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 9.3849 - val_loss: 1.4109\n",
      "Epoch 12/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3849\n",
      "Epoch 12: val_loss did not improve from 1.39275\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3849 - val_loss: 1.3961\n",
      "Epoch 13/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3682\n",
      "Epoch 13: val_loss did not improve from 1.39275\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3682 - val_loss: 1.3971\n",
      "Epoch 14/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3611\n",
      "Epoch 14: val_loss improved from 1.39275 to 1.38886, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3611 - val_loss: 1.3889\n",
      "Epoch 15/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3671\n",
      "Epoch 15: val_loss did not improve from 1.38886\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3671 - val_loss: 1.3991\n",
      "Epoch 16/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3233\n",
      "Epoch 16: val_loss improved from 1.38886 to 1.38205, saving model to ./checkpoints/unknown_person_few_shot_p17_30.h5\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3233 - val_loss: 1.3820\n",
      "Epoch 17/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3245\n",
      "Epoch 17: val_loss did not improve from 1.38205\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 9.3245 - val_loss: 1.3910\n",
      "Epoch 18/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3107\n",
      "Epoch 18: val_loss did not improve from 1.38205\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 9.3107 - val_loss: 1.3835\n",
      "Epoch 19/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3007\n",
      "Epoch 19: val_loss did not improve from 1.38205\n",
      "31495/31495 [==============================] - 36s 1ms/sample - loss: 9.3007 - val_loss: 1.3854\n",
      "Epoch 20/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2788\n",
      "Epoch 20: val_loss did not improve from 1.38205\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 9.2788 - val_loss: 1.3858\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:08:50.366177: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_13_2/lstm_cell_87/recurrent_kernel/Assign' id:40138 op device:{requested: '', assigned: ''} def:{{{node lstm_13_2/lstm_cell_87/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_13_2/lstm_cell_87/recurrent_kernel, lstm_13_2/lstm_cell_87/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:08:54.169185: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_26_2/lstm_cell_100/kernel/v/Assign' id:45683 op device:{requested: '', assigned: ''} def:{{{node lstm_26_2/lstm_cell_100/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_26_2/lstm_cell_100/kernel/v, lstm_26_2/lstm_cell_100/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31495 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:09:01.859127: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:09:21.602659: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_6/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:09:59.820934: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39930, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 48s 2ms/sample - loss: 1.3853 - val_loss: 1.3993\n",
      "Epoch 2/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3836\n",
      "Epoch 2: val_loss improved from 1.39930 to 1.39825, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3836 - val_loss: 1.3982\n",
      "Epoch 3/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3871\n",
      "Epoch 3: val_loss did not improve from 1.39825\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3871 - val_loss: 1.3994\n",
      "Epoch 4/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3822\n",
      "Epoch 4: val_loss improved from 1.39825 to 1.39137, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3822 - val_loss: 1.3914\n",
      "Epoch 5/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3804\n",
      "Epoch 5: val_loss did not improve from 1.39137\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3804 - val_loss: 1.3940\n",
      "Epoch 6/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3795\n",
      "Epoch 6: val_loss improved from 1.39137 to 1.39119, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3795 - val_loss: 1.3912\n",
      "Epoch 7/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3775\n",
      "Epoch 7: val_loss did not improve from 1.39119\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3775 - val_loss: 1.3951\n",
      "Epoch 8/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3795\n",
      "Epoch 8: val_loss improved from 1.39119 to 1.38692, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.3795 - val_loss: 1.3869\n",
      "Epoch 9/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3760\n",
      "Epoch 9: val_loss did not improve from 1.38692\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3760 - val_loss: 1.3883\n",
      "Epoch 10/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3750\n",
      "Epoch 10: val_loss did not improve from 1.38692\n",
      "31495/31495 [==============================] - 31s 991us/sample - loss: 1.3750 - val_loss: 1.3877\n",
      "Epoch 11/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3742\n",
      "Epoch 11: val_loss improved from 1.38692 to 1.38438, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3742 - val_loss: 1.3844\n",
      "Epoch 12/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3704\n",
      "Epoch 12: val_loss did not improve from 1.38438\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3704 - val_loss: 1.3863\n",
      "Epoch 13/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3716\n",
      "Epoch 13: val_loss did not improve from 1.38438\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3716 - val_loss: 1.3893\n",
      "Epoch 14/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3689\n",
      "Epoch 14: val_loss did not improve from 1.38438\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3689 - val_loss: 1.3863\n",
      "Epoch 15/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3658\n",
      "Epoch 15: val_loss did not improve from 1.38438\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3658 - val_loss: 1.3872\n",
      "Epoch 16/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3655\n",
      "Epoch 16: val_loss improved from 1.38438 to 1.38146, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3655 - val_loss: 1.3815\n",
      "Epoch 17/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3663\n",
      "Epoch 17: val_loss improved from 1.38146 to 1.38080, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3663 - val_loss: 1.3808\n",
      "Epoch 18/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3607\n",
      "Epoch 18: val_loss did not improve from 1.38080\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3607 - val_loss: 1.3854\n",
      "Epoch 19/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3643\n",
      "Epoch 19: val_loss improved from 1.38080 to 1.37885, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_30.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3643 - val_loss: 1.3789\n",
      "Epoch 20/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3619\n",
      "Epoch 20: val_loss did not improve from 1.37885\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3619 - val_loss: 1.3821\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:20:41.555632: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_49/lstm_cell_123/recurrent_kernel/Assign' id:59060 op device:{requested: '', assigned: ''} def:{{{node lstm_49/lstm_cell_123/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_49/lstm_cell_123/recurrent_kernel, lstm_49/lstm_cell_123/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:20:43.679176: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_1' id:60678 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:20:45.344673: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_2' id:60679 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31495, 95)\n",
      "Train on 31495 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:20:55.023593: W tensorflow/c/c_api.cc:304] Operation '{name:'training_6/Adam/dense_7/bias/v/Assign' id:74675 op device:{requested: '', assigned: ''} def:{{{node training_6/Adam/dense_7/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_6/Adam/dense_7/bias/v, training_6/Adam/dense_7/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:21:20.970178: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 3.2539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:21:57.760733: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_7/mul' id:63519 op device:{requested: '', assigned: ''} def:{{{node loss_7/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_7/mul/x, loss_7/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.90604, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 63s 2ms/sample - loss: 3.2539 - val_loss: 1.9060\n",
      "Epoch 2/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.8219\n",
      "Epoch 2: val_loss improved from 1.90604 to 1.63177, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.8219 - val_loss: 1.6318\n",
      "Epoch 3/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.6040\n",
      "Epoch 3: val_loss improved from 1.63177 to 1.55211, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.6040 - val_loss: 1.5521\n",
      "Epoch 4/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5404\n",
      "Epoch 4: val_loss improved from 1.55211 to 1.51711, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5404 - val_loss: 1.5171\n",
      "Epoch 5/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5158\n",
      "Epoch 5: val_loss improved from 1.51711 to 1.50465, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5158 - val_loss: 1.5046\n",
      "Epoch 6/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4980\n",
      "Epoch 6: val_loss improved from 1.50465 to 1.49832, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4980 - val_loss: 1.4983\n",
      "Epoch 7/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4892\n",
      "Epoch 7: val_loss improved from 1.49832 to 1.48232, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4892 - val_loss: 1.4823\n",
      "Epoch 8/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4861\n",
      "Epoch 8: val_loss improved from 1.48232 to 1.47391, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4861 - val_loss: 1.4739\n",
      "Epoch 9/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4803\n",
      "Epoch 9: val_loss improved from 1.47391 to 1.46951, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4803 - val_loss: 1.4695\n",
      "Epoch 10/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4940\n",
      "Epoch 10: val_loss did not improve from 1.46951\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4940 - val_loss: 1.4706\n",
      "Epoch 11/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4945\n",
      "Epoch 11: val_loss did not improve from 1.46951\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4945 - val_loss: 1.4747\n",
      "Epoch 12/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4733\n",
      "Epoch 12: val_loss improved from 1.46951 to 1.45534, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4733 - val_loss: 1.4553\n",
      "Epoch 13/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4783\n",
      "Epoch 13: val_loss did not improve from 1.45534\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4783 - val_loss: 1.4580\n",
      "Epoch 14/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5139\n",
      "Epoch 14: val_loss did not improve from 1.45534\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5139 - val_loss: 1.4666\n",
      "Epoch 15/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4678\n",
      "Epoch 15: val_loss improved from 1.45534 to 1.45442, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4678 - val_loss: 1.4544\n",
      "Epoch 16/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4692\n",
      "Epoch 16: val_loss improved from 1.45442 to 1.44856, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4692 - val_loss: 1.4486\n",
      "Epoch 17/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4750\n",
      "Epoch 17: val_loss improved from 1.44856 to 1.44835, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4750 - val_loss: 1.4483\n",
      "Epoch 18/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4644\n",
      "Epoch 18: val_loss improved from 1.44835 to 1.44164, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4644 - val_loss: 1.4416\n",
      "Epoch 19/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 19: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4731 - val_loss: 1.4446\n",
      "Epoch 20/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4849\n",
      "Epoch 20: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4849 - val_loss: 1.4522\n",
      "Epoch 21/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5559\n",
      "Epoch 21: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5559 - val_loss: 1.4718\n",
      "Epoch 22/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5214\n",
      "Epoch 22: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5214 - val_loss: 1.4589\n",
      "Epoch 23/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.6367\n",
      "Epoch 23: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.6367 - val_loss: 1.4799\n",
      "Epoch 24/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4963\n",
      "Epoch 24: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4963 - val_loss: 1.4659\n",
      "Epoch 25/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4600\n",
      "Epoch 25: val_loss did not improve from 1.44164\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4600 - val_loss: 1.4485\n",
      "Epoch 26/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4495\n",
      "Epoch 26: val_loss improved from 1.44164 to 1.44091, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4495 - val_loss: 1.4409\n",
      "Epoch 27/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4441\n",
      "Epoch 27: val_loss improved from 1.44091 to 1.43867, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4441 - val_loss: 1.4387\n",
      "Epoch 28/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4406\n",
      "Epoch 28: val_loss improved from 1.43867 to 1.43485, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4406 - val_loss: 1.4348\n",
      "Epoch 29/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4374\n",
      "Epoch 29: val_loss did not improve from 1.43485\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4374 - val_loss: 1.4365\n",
      "Epoch 30/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4390\n",
      "Epoch 30: val_loss improved from 1.43485 to 1.43426, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4390 - val_loss: 1.4343\n",
      "Epoch 31/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4350\n",
      "Epoch 31: val_loss improved from 1.43426 to 1.42687, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4350 - val_loss: 1.4269\n",
      "Epoch 32/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4358\n",
      "Epoch 32: val_loss did not improve from 1.42687\n",
      "31495/31495 [==============================] - 25s 805us/sample - loss: 1.4358 - val_loss: 1.4279\n",
      "Epoch 33/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4320\n",
      "Epoch 33: val_loss did not improve from 1.42687\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4320 - val_loss: 1.4271\n",
      "Epoch 34/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4281\n",
      "Epoch 34: val_loss improved from 1.42687 to 1.42365, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4281 - val_loss: 1.4237\n",
      "Epoch 35/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 35: val_loss improved from 1.42365 to 1.42018, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4255 - val_loss: 1.4202\n",
      "Epoch 36/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 36: val_loss did not improve from 1.42018\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4250 - val_loss: 1.4269\n",
      "Epoch 37/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4244\n",
      "Epoch 37: val_loss did not improve from 1.42018\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4244 - val_loss: 1.4203\n",
      "Epoch 38/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4196\n",
      "Epoch 38: val_loss improved from 1.42018 to 1.41821, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4196 - val_loss: 1.4182\n",
      "Epoch 39/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4157\n",
      "Epoch 39: val_loss did not improve from 1.41821\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4157 - val_loss: 1.4195\n",
      "Epoch 40/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 40: val_loss did not improve from 1.41821\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4172 - val_loss: 1.4218\n",
      "Epoch 41/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 41: val_loss improved from 1.41821 to 1.41748, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4159 - val_loss: 1.4175\n",
      "Epoch 42/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4118\n",
      "Epoch 42: val_loss improved from 1.41748 to 1.41298, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4118 - val_loss: 1.4130\n",
      "Epoch 43/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 43: val_loss did not improve from 1.41298\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4117 - val_loss: 1.4137\n",
      "Epoch 44/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 44: val_loss improved from 1.41298 to 1.40935, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4100 - val_loss: 1.4093\n",
      "Epoch 45/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4108\n",
      "Epoch 45: val_loss did not improve from 1.40935\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4108 - val_loss: 1.4180\n",
      "Epoch 46/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4079\n",
      "Epoch 46: val_loss improved from 1.40935 to 1.40854, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4079 - val_loss: 1.4085\n",
      "Epoch 47/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 47: val_loss improved from 1.40854 to 1.40732, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4062 - val_loss: 1.4073\n",
      "Epoch 48/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 48: val_loss did not improve from 1.40732\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4058 - val_loss: 1.4175\n",
      "Epoch 49/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 49: val_loss did not improve from 1.40732\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4010 - val_loss: 1.4084\n",
      "Epoch 50/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3999\n",
      "Epoch 50: val_loss did not improve from 1.40732\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3999 - val_loss: 1.4074\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:49:51.035515: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_40_1/lstm_cell_151/bias/Assign' id:76191 op device:{requested: '', assigned: ''} def:{{{node lstm_40_1/lstm_cell_151/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_40_1/lstm_cell_151/bias, lstm_40_1/lstm_cell_151/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:49:57.383849: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_49_1/lstm_cell_160/kernel/v/Assign' id:83117 op device:{requested: '', assigned: ''} def:{{{node lstm_49_1/lstm_cell_160/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_49_1/lstm_cell_160/kernel/v, lstm_49_1/lstm_cell_160/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:50:03.541405: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_9_1/cond/Merge' id:81633 op device:{requested: '', assigned: ''} def:{{{node dropout_9_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_9_1/cond/Identity, dropout_9_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1992)\n",
      "(1514, 1992)\n",
      "(1644, 1992)\n",
      "(1764, 1992)\n",
      "(1836, 1992)\n",
      "(1699, 1992)\n",
      "(1369, 1992)\n",
      "(1766, 1992)\n",
      "(1619, 1992)\n",
      "(1692, 1992)\n",
      "(1550, 1992)\n",
      "(1667, 1992)\n",
      "(1776, 1992)\n",
      "(1872, 1992)\n",
      "(1704, 1992)\n",
      "(1812, 1992)\n",
      "(970, 1992)\n",
      "(1668, 1992)\n",
      "(1896, 1992)\n",
      "{1: 5.886915015639087, 2: 5.623974412423233, 4: 10.0, 5: 4.251202955766146, 6: 4.70861051797331, 8: 8.517242410069963, 9: 7.287074977673564, 10: 7.167652618647547, 11: 7.117872867349228, 12: 9.33418838644415, 13: 5.872367252938413, 19: 8.620701632051873, 21: 8.415574725839834, 22: 1.0, 25: 8.088118526920814, 26: 6.069294749160907, 27: 5.5227531246428825, 28: 6.218793515387253, 29: 1.3417254102350307}\n",
      "Train on 31495 samples, validate on 3514 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:56:24.846671: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 9.7153\n",
      "Epoch 1: val_loss improved from inf to 1.43178, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 51s 2ms/sample - loss: 9.7153 - val_loss: 1.4318\n",
      "Epoch 2/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.6164\n",
      "Epoch 2: val_loss improved from 1.43178 to 1.41951, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.6164 - val_loss: 1.4195\n",
      "Epoch 3/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.5709\n",
      "Epoch 3: val_loss did not improve from 1.41951\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.5709 - val_loss: 1.4201\n",
      "Epoch 4/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.5511\n",
      "Epoch 4: val_loss did not improve from 1.41951\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.5511 - val_loss: 1.4298\n",
      "Epoch 5/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.5422\n",
      "Epoch 5: val_loss improved from 1.41951 to 1.40970, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.5422 - val_loss: 1.4097\n",
      "Epoch 6/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4953\n",
      "Epoch 6: val_loss did not improve from 1.40970\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.4953 - val_loss: 1.4110\n",
      "Epoch 7/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4762\n",
      "Epoch 7: val_loss did not improve from 1.40970\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.4762 - val_loss: 1.4225\n",
      "Epoch 8/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4634\n",
      "Epoch 8: val_loss improved from 1.40970 to 1.39931, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.4634 - val_loss: 1.3993\n",
      "Epoch 9/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4340\n",
      "Epoch 9: val_loss improved from 1.39931 to 1.39840, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.4340 - val_loss: 1.3984\n",
      "Epoch 10/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4187\n",
      "Epoch 10: val_loss did not improve from 1.39840\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.4187 - val_loss: 1.4035\n",
      "Epoch 11/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4056\n",
      "Epoch 11: val_loss did not improve from 1.39840\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.4056 - val_loss: 1.4102\n",
      "Epoch 12/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4160\n",
      "Epoch 12: val_loss did not improve from 1.39840\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.4160 - val_loss: 1.4066\n",
      "Epoch 13/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3887\n",
      "Epoch 13: val_loss improved from 1.39840 to 1.39766, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.3887 - val_loss: 1.3977\n",
      "Epoch 14/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3883\n",
      "Epoch 14: val_loss did not improve from 1.39766\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.3883 - val_loss: 1.4013\n",
      "Epoch 15/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3537\n",
      "Epoch 15: val_loss did not improve from 1.39766\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.3537 - val_loss: 1.4077\n",
      "Epoch 16/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3523\n",
      "Epoch 16: val_loss improved from 1.39766 to 1.39226, saving model to ./checkpoints/unknown_person_few_shot_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3523 - val_loss: 1.3923\n",
      "Epoch 17/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3684\n",
      "Epoch 17: val_loss did not improve from 1.39226\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.3684 - val_loss: 1.4238\n",
      "Epoch 18/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3476\n",
      "Epoch 18: val_loss did not improve from 1.39226\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.3476 - val_loss: 1.4008\n",
      "Epoch 19/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3630\n",
      "Epoch 19: val_loss did not improve from 1.39226\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3630 - val_loss: 1.4093\n",
      "Epoch 20/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3324\n",
      "Epoch 20: val_loss did not improve from 1.39226\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.3324 - val_loss: 1.4071\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:07:37.070418: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_59_2/lstm_cell_207/kernel/Assign' id:98602 op device:{requested: '', assigned: ''} def:{{{node lstm_59_2/lstm_cell_207/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_59_2/lstm_cell_207/kernel, lstm_59_2/lstm_cell_207/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:07:45.065871: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_72_2/lstm_cell_220/kernel/m/Assign' id:102217 op device:{requested: '', assigned: ''} def:{{{node lstm_72_2/lstm_cell_220/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_72_2/lstm_cell_220/kernel/m, lstm_72_2/lstm_cell_220/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31495 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:07:57.220483: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:08:37.410226: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_3/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:09:13.130030: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40618, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 53s 2ms/sample - loss: 1.4047 - val_loss: 1.4062\n",
      "Epoch 2/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4021\n",
      "Epoch 2: val_loss improved from 1.40618 to 1.40274, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4021 - val_loss: 1.4027\n",
      "Epoch 3/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 3: val_loss did not improve from 1.40274\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3995 - val_loss: 1.4064\n",
      "Epoch 4/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3985\n",
      "Epoch 4: val_loss improved from 1.40274 to 1.39844, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3985 - val_loss: 1.3984\n",
      "Epoch 5/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3973\n",
      "Epoch 5: val_loss improved from 1.39844 to 1.39823, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3973 - val_loss: 1.3982\n",
      "Epoch 6/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 6: val_loss improved from 1.39823 to 1.39245, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3936 - val_loss: 1.3924\n",
      "Epoch 7/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3926\n",
      "Epoch 7: val_loss did not improve from 1.39245\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3926 - val_loss: 1.4019\n",
      "Epoch 8/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3909\n",
      "Epoch 8: val_loss did not improve from 1.39245\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3909 - val_loss: 1.3984\n",
      "Epoch 9/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3919\n",
      "Epoch 9: val_loss did not improve from 1.39245\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3919 - val_loss: 1.4012\n",
      "Epoch 10/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3884\n",
      "Epoch 10: val_loss did not improve from 1.39245\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3884 - val_loss: 1.3974\n",
      "Epoch 11/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 11: val_loss did not improve from 1.39245\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3907 - val_loss: 1.3998\n",
      "Epoch 12/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3853\n",
      "Epoch 12: val_loss improved from 1.39245 to 1.38578, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3853 - val_loss: 1.3858\n",
      "Epoch 13/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3847\n",
      "Epoch 13: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3847 - val_loss: 1.3902\n",
      "Epoch 14/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3841\n",
      "Epoch 14: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3841 - val_loss: 1.4034\n",
      "Epoch 15/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3842\n",
      "Epoch 15: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3842 - val_loss: 1.3979\n",
      "Epoch 16/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3798\n",
      "Epoch 16: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3798 - val_loss: 1.3865\n",
      "Epoch 17/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3811\n",
      "Epoch 17: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3811 - val_loss: 1.3883\n",
      "Epoch 18/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3786\n",
      "Epoch 18: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.3786 - val_loss: 1.3891\n",
      "Epoch 19/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3781\n",
      "Epoch 19: val_loss did not improve from 1.38578\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3781 - val_loss: 1.3938\n",
      "Epoch 20/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3739\n",
      "Epoch 20: val_loss improved from 1.38578 to 1.38575, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_31.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3739 - val_loss: 1.3857\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:19:49.073929: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_78/lstm_cell_226/bias/Assign' id:114791 op device:{requested: '', assigned: ''} def:{{{node lstm_78/lstm_cell_226/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_78/lstm_cell_226/bias, lstm_78/lstm_cell_226/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:19:53.739211: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_1' id:117720 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:19:57.356328: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_2' id:117721 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31495, 95)\n",
      "Train on 31495 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:20:11.418969: W tensorflow/c/c_api.cc:304] Operation '{name:'training_12/Adam/lstm_74/lstm_cell_222/recurrent_kernel/m/Assign' id:130483 op device:{requested: '', assigned: ''} def:{{{node training_12/Adam/lstm_74/lstm_cell_222/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_12/Adam/lstm_74/lstm_cell_222/recurrent_kernel/m, training_12/Adam/lstm_74/lstm_cell_222/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:20:58.910037: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 3.4998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:21:34.679355: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_13/mul' id:120561 op device:{requested: '', assigned: ''} def:{{{node loss_13/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_13/mul/x, loss_13/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95795, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 83s 3ms/sample - loss: 3.4998 - val_loss: 1.9580\n",
      "Epoch 2/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.8516\n",
      "Epoch 2: val_loss improved from 1.95795 to 1.61878, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.8516 - val_loss: 1.6188\n",
      "Epoch 3/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.6072\n",
      "Epoch 3: val_loss improved from 1.61878 to 1.55798, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.6072 - val_loss: 1.5580\n",
      "Epoch 4/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5492\n",
      "Epoch 4: val_loss improved from 1.55798 to 1.52505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5492 - val_loss: 1.5251\n",
      "Epoch 5/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5192\n",
      "Epoch 5: val_loss improved from 1.52505 to 1.50338, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5192 - val_loss: 1.5034\n",
      "Epoch 6/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5009\n",
      "Epoch 6: val_loss improved from 1.50338 to 1.49276, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.5009 - val_loss: 1.4928\n",
      "Epoch 7/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4866\n",
      "Epoch 7: val_loss improved from 1.49276 to 1.48554, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4866 - val_loss: 1.4855\n",
      "Epoch 8/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4931\n",
      "Epoch 8: val_loss improved from 1.48554 to 1.47275, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4931 - val_loss: 1.4728\n",
      "Epoch 9/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4893\n",
      "Epoch 9: val_loss did not improve from 1.47275\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4893 - val_loss: 1.4754\n",
      "Epoch 10/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5842\n",
      "Epoch 10: val_loss did not improve from 1.47275\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.5842 - val_loss: 1.5054\n",
      "Epoch 11/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5560\n",
      "Epoch 11: val_loss did not improve from 1.47275\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5560 - val_loss: 1.4852\n",
      "Epoch 12/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5266\n",
      "Epoch 12: val_loss did not improve from 1.47275\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5266 - val_loss: 1.4796\n",
      "Epoch 13/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4868\n",
      "Epoch 13: val_loss improved from 1.47275 to 1.46850, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4868 - val_loss: 1.4685\n",
      "Epoch 14/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5412\n",
      "Epoch 14: val_loss did not improve from 1.46850\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5412 - val_loss: 1.4710\n",
      "Epoch 15/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5035\n",
      "Epoch 15: val_loss did not improve from 1.46850\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5035 - val_loss: 1.4757\n",
      "Epoch 16/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4885\n",
      "Epoch 16: val_loss did not improve from 1.46850\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4885 - val_loss: 1.4779\n",
      "Epoch 17/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4832\n",
      "Epoch 17: val_loss improved from 1.46850 to 1.46128, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4832 - val_loss: 1.4613\n",
      "Epoch 18/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4996\n",
      "Epoch 18: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4996 - val_loss: 1.4621\n",
      "Epoch 19/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5678\n",
      "Epoch 19: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.5678 - val_loss: 1.4829\n",
      "Epoch 20/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5066\n",
      "Epoch 20: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.5066 - val_loss: 1.4720\n",
      "Epoch 21/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5380\n",
      "Epoch 21: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.5380 - val_loss: 1.4751\n",
      "Epoch 22/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.7988\n",
      "Epoch 22: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.7988 - val_loss: 1.4799\n",
      "Epoch 23/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5789\n",
      "Epoch 23: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5789 - val_loss: 1.4851\n",
      "Epoch 24/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.5244\n",
      "Epoch 24: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.5244 - val_loss: 1.4764\n",
      "Epoch 25/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4909\n",
      "Epoch 25: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4909 - val_loss: 1.4687\n",
      "Epoch 26/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4811\n",
      "Epoch 26: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4811 - val_loss: 1.4713\n",
      "Epoch 27/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4708\n",
      "Epoch 27: val_loss did not improve from 1.46128\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4708 - val_loss: 1.4628\n",
      "Epoch 28/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4627\n",
      "Epoch 28: val_loss improved from 1.46128 to 1.45755, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4627 - val_loss: 1.4576\n",
      "Epoch 29/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4612\n",
      "Epoch 29: val_loss improved from 1.45755 to 1.45339, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4612 - val_loss: 1.4534\n",
      "Epoch 30/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4569\n",
      "Epoch 30: val_loss improved from 1.45339 to 1.45113, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4569 - val_loss: 1.4511\n",
      "Epoch 31/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4577\n",
      "Epoch 31: val_loss did not improve from 1.45113\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4577 - val_loss: 1.4542\n",
      "Epoch 32/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4569\n",
      "Epoch 32: val_loss improved from 1.45113 to 1.44768, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4569 - val_loss: 1.4477\n",
      "Epoch 33/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4485\n",
      "Epoch 33: val_loss did not improve from 1.44768\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4485 - val_loss: 1.4490\n",
      "Epoch 34/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 34: val_loss improved from 1.44768 to 1.44474, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4483 - val_loss: 1.4447\n",
      "Epoch 35/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4434\n",
      "Epoch 35: val_loss improved from 1.44474 to 1.43669, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4434 - val_loss: 1.4367\n",
      "Epoch 36/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4435\n",
      "Epoch 36: val_loss did not improve from 1.43669\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4435 - val_loss: 1.4391\n",
      "Epoch 37/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4433\n",
      "Epoch 37: val_loss did not improve from 1.43669\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4433 - val_loss: 1.4374\n",
      "Epoch 38/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 38: val_loss improved from 1.43669 to 1.43271, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4404 - val_loss: 1.4327\n",
      "Epoch 39/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4374\n",
      "Epoch 39: val_loss improved from 1.43271 to 1.43160, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4374 - val_loss: 1.4316\n",
      "Epoch 40/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4369\n",
      "Epoch 40: val_loss did not improve from 1.43160\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4369 - val_loss: 1.4363\n",
      "Epoch 41/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 41: val_loss improved from 1.43160 to 1.42718, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4354 - val_loss: 1.4272\n",
      "Epoch 42/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4298\n",
      "Epoch 42: val_loss did not improve from 1.42718\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4298 - val_loss: 1.4288\n",
      "Epoch 43/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4290\n",
      "Epoch 43: val_loss improved from 1.42718 to 1.42468, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4290 - val_loss: 1.4247\n",
      "Epoch 44/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 44: val_loss improved from 1.42468 to 1.42277, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4283 - val_loss: 1.4228\n",
      "Epoch 45/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4236\n",
      "Epoch 45: val_loss did not improve from 1.42277\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4236 - val_loss: 1.4242\n",
      "Epoch 46/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4259\n",
      "Epoch 46: val_loss improved from 1.42277 to 1.42211, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4259 - val_loss: 1.4221\n",
      "Epoch 47/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4238\n",
      "Epoch 47: val_loss improved from 1.42211 to 1.42002, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4238 - val_loss: 1.4200\n",
      "Epoch 48/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4203\n",
      "Epoch 48: val_loss did not improve from 1.42002\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4203 - val_loss: 1.4317\n",
      "Epoch 49/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4199\n",
      "Epoch 49: val_loss improved from 1.42002 to 1.41446, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4199 - val_loss: 1.4145\n",
      "Epoch 50/50\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4175\n",
      "Epoch 50: val_loss did not improve from 1.41446\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4175 - val_loss: 1.4204\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:49:11.383010: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_86_1/lstm_cell_271/recurrent_kernel/Assign' id:134664 op device:{requested: '', assigned: ''} def:{{{node lstm_86_1/lstm_cell_271/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_86_1/lstm_cell_271/recurrent_kernel, lstm_86_1/lstm_cell_271/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:49:22.632330: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_100_1/lstm_cell_285/recurrent_kernel/v/Assign' id:140374 op device:{requested: '', assigned: ''} def:{{{node lstm_100_1/lstm_cell_285/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_100_1/lstm_cell_285/recurrent_kernel/v, lstm_100_1/lstm_cell_285/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:49:33.182531: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_14_1/cond/Merge' id:138675 op device:{requested: '', assigned: ''} def:{{{node dropout_14_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_14_1/cond/Identity, dropout_14_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1992)\n",
      "(1514, 1992)\n",
      "(1644, 1992)\n",
      "(1764, 1992)\n",
      "(1836, 1992)\n",
      "(1699, 1992)\n",
      "(1369, 1992)\n",
      "(1766, 1992)\n",
      "(1619, 1992)\n",
      "(1692, 1992)\n",
      "(1550, 1992)\n",
      "(1667, 1992)\n",
      "(1776, 1992)\n",
      "(1872, 1992)\n",
      "(1704, 1992)\n",
      "(1812, 1992)\n",
      "(970, 1992)\n",
      "(1668, 1992)\n",
      "(1896, 1992)\n",
      "{1: 5.410522772472209, 2: 4.808614828698387, 4: 10.0, 5: 4.413189359755714, 6: 5.268918858576988, 8: 8.241902631208346, 9: 6.491937838404124, 10: 7.151899299405428, 11: 6.986907502968282, 12: 8.666865506222228, 13: 6.233367033012327, 19: 8.670527054583175, 21: 8.164889895935545, 22: 1.0, 25: 7.740702151703513, 26: 5.530906193146103, 27: 5.57765905924083, 28: 6.10102118041999, 29: 1.9140142958389101}\n",
      "Train on 31495 samples, validate on 3514 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:56:19.069798: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 9.6156\n",
      "Epoch 1: val_loss improved from inf to 1.45401, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 59s 2ms/sample - loss: 9.6156 - val_loss: 1.4540\n",
      "Epoch 2/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4791\n",
      "Epoch 2: val_loss improved from 1.45401 to 1.43647, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 9.4791 - val_loss: 1.4365\n",
      "Epoch 3/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4551\n",
      "Epoch 3: val_loss improved from 1.43647 to 1.42026, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.4551 - val_loss: 1.4203\n",
      "Epoch 4/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4551\n",
      "Epoch 4: val_loss did not improve from 1.42026\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.4551 - val_loss: 1.4362\n",
      "Epoch 5/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4422\n",
      "Epoch 5: val_loss improved from 1.42026 to 1.40713, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 9.4422 - val_loss: 1.4071\n",
      "Epoch 6/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.4142\n",
      "Epoch 6: val_loss did not improve from 1.40713\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 9.4142 - val_loss: 1.4164\n",
      "Epoch 7/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3747\n",
      "Epoch 7: val_loss did not improve from 1.40713\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3747 - val_loss: 1.4179\n",
      "Epoch 8/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3783\n",
      "Epoch 8: val_loss did not improve from 1.40713\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3783 - val_loss: 1.4131\n",
      "Epoch 9/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3474\n",
      "Epoch 9: val_loss did not improve from 1.40713\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3474 - val_loss: 1.4095\n",
      "Epoch 10/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3476\n",
      "Epoch 10: val_loss did not improve from 1.40713\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3476 - val_loss: 1.4138\n",
      "Epoch 11/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3173\n",
      "Epoch 11: val_loss did not improve from 1.40713\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 9.3173 - val_loss: 1.4140\n",
      "Epoch 12/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3030\n",
      "Epoch 12: val_loss improved from 1.40713 to 1.40535, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3030 - val_loss: 1.4054\n",
      "Epoch 13/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.3005\n",
      "Epoch 13: val_loss did not improve from 1.40535\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.3005 - val_loss: 1.4102\n",
      "Epoch 14/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2700\n",
      "Epoch 14: val_loss did not improve from 1.40535\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.2700 - val_loss: 1.4144\n",
      "Epoch 15/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2723\n",
      "Epoch 15: val_loss did not improve from 1.40535\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.2723 - val_loss: 1.4125\n",
      "Epoch 16/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2578\n",
      "Epoch 16: val_loss did not improve from 1.40535\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 9.2578 - val_loss: 1.4143\n",
      "Epoch 17/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2835\n",
      "Epoch 17: val_loss improved from 1.40535 to 1.39961, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 9.2835 - val_loss: 1.3996\n",
      "Epoch 18/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2609\n",
      "Epoch 18: val_loss improved from 1.39961 to 1.39930, saving model to ./checkpoints/unknown_person_few_shot_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 9.2609 - val_loss: 1.3993\n",
      "Epoch 19/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2485\n",
      "Epoch 19: val_loss did not improve from 1.39930\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.2485 - val_loss: 1.4014\n",
      "Epoch 20/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 9.2436\n",
      "Epoch 20: val_loss did not improve from 1.39930\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 9.2436 - val_loss: 1.4014\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:07:57.541466: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_94_2/lstm_cell_316/kernel/Assign' id:155322 op device:{requested: '', assigned: ''} def:{{{node lstm_94_2/lstm_cell_316/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_94_2/lstm_cell_316/kernel, lstm_94_2/lstm_cell_316/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:08:10.306076: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_75_2/lstm_cell_297/recurrent_kernel/v/Assign' id:159397 op device:{requested: '', assigned: ''} def:{{{node lstm_75_2/lstm_cell_297/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_75_2/lstm_cell_297/recurrent_kernel/v, lstm_75_2/lstm_cell_297/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31495 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:08:26.366285: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:09:27.976494: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:10:03.746289: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.42428, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_32.h5\n",
      "31495/31495 [==============================] - 60s 2ms/sample - loss: 1.4197 - val_loss: 1.4243\n",
      "Epoch 2/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 2: val_loss improved from 1.42428 to 1.40882, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_32.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4126 - val_loss: 1.4088\n",
      "Epoch 3/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4140\n",
      "Epoch 3: val_loss did not improve from 1.40882\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4140 - val_loss: 1.4089\n",
      "Epoch 4/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 4: val_loss did not improve from 1.40882\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4126 - val_loss: 1.4133\n",
      "Epoch 5/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4115\n",
      "Epoch 5: val_loss did not improve from 1.40882\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4115 - val_loss: 1.4150\n",
      "Epoch 6/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4075\n",
      "Epoch 6: val_loss improved from 1.40882 to 1.40746, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.4075 - val_loss: 1.4075\n",
      "Epoch 7/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 7: val_loss did not improve from 1.40746\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.4062 - val_loss: 1.4092\n",
      "Epoch 8/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 8: val_loss did not improve from 1.40746\n",
      "31495/31495 [==============================] - 35s 1ms/sample - loss: 1.4045 - val_loss: 1.4106\n",
      "Epoch 9/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4029\n",
      "Epoch 9: val_loss did not improve from 1.40746\n",
      "31495/31495 [==============================] - 31s 996us/sample - loss: 1.4029 - val_loss: 1.4082\n",
      "Epoch 10/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.4019\n",
      "Epoch 10: val_loss improved from 1.40746 to 1.40014, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_32.h5\n",
      "31495/31495 [==============================] - 33s 1ms/sample - loss: 1.4019 - val_loss: 1.4001\n",
      "Epoch 11/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 11: val_loss did not improve from 1.40014\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3997 - val_loss: 1.4033\n",
      "Epoch 12/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3990\n",
      "Epoch 12: val_loss did not improve from 1.40014\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3990 - val_loss: 1.4104\n",
      "Epoch 13/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 13: val_loss did not improve from 1.40014\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3983 - val_loss: 1.4043\n",
      "Epoch 14/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 14: val_loss improved from 1.40014 to 1.39814, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_32.h5\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3977 - val_loss: 1.3981\n",
      "Epoch 15/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3955\n",
      "Epoch 15: val_loss did not improve from 1.39814\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3955 - val_loss: 1.4034\n",
      "Epoch 16/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3951\n",
      "Epoch 16: val_loss did not improve from 1.39814\n",
      "31495/31495 [==============================] - 31s 988us/sample - loss: 1.3951 - val_loss: 1.4069\n",
      "Epoch 17/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3924\n",
      "Epoch 17: val_loss improved from 1.39814 to 1.39458, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_32.h5\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3924 - val_loss: 1.3946\n",
      "Epoch 18/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3911\n",
      "Epoch 18: val_loss did not improve from 1.39458\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3911 - val_loss: 1.3989\n",
      "Epoch 19/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 19: val_loss did not improve from 1.39458\n",
      "31495/31495 [==============================] - 32s 1ms/sample - loss: 1.3896 - val_loss: 1.4004\n",
      "Epoch 20/20\n",
      "31495/31495 [==============================] - ETA: 0s - loss: 1.3908\n",
      "Epoch 20: val_loss did not improve from 1.39458\n",
      "31495/31495 [==============================] - 34s 1ms/sample - loss: 1.3908 - val_loss: 1.3963\n",
      "35225\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:21:09.455688: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_127/lstm_cell_349/bias/Assign' id:173813 op device:{requested: '', assigned: ''} def:{{{node lstm_127/lstm_cell_349/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_127/lstm_cell_349/bias, lstm_127/lstm_cell_349/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:21:16.567974: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_1' id:174762 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:21:22.214550: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_2' id:174763 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31687, 95)\n",
      "Train on 31687 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:21:39.060863: W tensorflow/c/c_api.cc:304] Operation '{name:'training_18/Adam/dense_15/kernel/v/Assign' id:188754 op device:{requested: '', assigned: ''} def:{{{node training_18/Adam/dense_15/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_18/Adam/dense_15/kernel/v, training_18/Adam/dense_15/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:22:48.460536: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 2.6972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 11:23:26.737773: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_19/mul' id:177603 op device:{requested: '', assigned: ''} def:{{{node loss_19/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_19/mul/x, loss_19/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.81210, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 103s 3ms/sample - loss: 2.6972 - val_loss: 1.8121\n",
      "Epoch 2/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.7087\n",
      "Epoch 2: val_loss improved from 1.81210 to 1.57508, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 34s 1ms/sample - loss: 1.7087 - val_loss: 1.5751\n",
      "Epoch 3/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5907\n",
      "Epoch 3: val_loss improved from 1.57508 to 1.51954, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 35s 1ms/sample - loss: 1.5907 - val_loss: 1.5195\n",
      "Epoch 4/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5416\n",
      "Epoch 4: val_loss improved from 1.51954 to 1.49651, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 34s 1ms/sample - loss: 1.5416 - val_loss: 1.4965\n",
      "Epoch 5/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5174\n",
      "Epoch 5: val_loss improved from 1.49651 to 1.48538, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 33s 1ms/sample - loss: 1.5174 - val_loss: 1.4854\n",
      "Epoch 6/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 6: val_loss improved from 1.48538 to 1.46806, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 33s 1ms/sample - loss: 1.4987 - val_loss: 1.4681\n",
      "Epoch 7/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4847\n",
      "Epoch 7: val_loss improved from 1.46806 to 1.45380, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 34s 1ms/sample - loss: 1.4847 - val_loss: 1.4538\n",
      "Epoch 8/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4799\n",
      "Epoch 8: val_loss did not improve from 1.45380\n",
      "31687/31687 [==============================] - 33s 1ms/sample - loss: 1.4799 - val_loss: 1.4544\n",
      "Epoch 9/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4748\n",
      "Epoch 9: val_loss improved from 1.45380 to 1.44343, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 32s 1ms/sample - loss: 1.4748 - val_loss: 1.4434\n",
      "Epoch 10/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 10: val_loss improved from 1.44343 to 1.43611, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 34s 1ms/sample - loss: 1.4689 - val_loss: 1.4361\n",
      "Epoch 11/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4661\n",
      "Epoch 11: val_loss improved from 1.43611 to 1.43148, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 34s 1ms/sample - loss: 1.4661 - val_loss: 1.4315\n",
      "Epoch 12/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4700\n",
      "Epoch 12: val_loss improved from 1.43148 to 1.42659, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 36s 1ms/sample - loss: 1.4700 - val_loss: 1.4266\n",
      "Epoch 13/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4648\n",
      "Epoch 13: val_loss improved from 1.42659 to 1.42331, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 35s 1ms/sample - loss: 1.4648 - val_loss: 1.4233\n",
      "Epoch 14/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 14: val_loss improved from 1.42331 to 1.41708, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 35s 1ms/sample - loss: 1.4731 - val_loss: 1.4171\n",
      "Epoch 15/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4494\n",
      "Epoch 15: val_loss improved from 1.41708 to 1.41365, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 35s 1ms/sample - loss: 1.4494 - val_loss: 1.4137\n",
      "Epoch 16/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4507\n",
      "Epoch 16: val_loss improved from 1.41365 to 1.41165, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 33s 1ms/sample - loss: 1.4507 - val_loss: 1.4116\n",
      "Epoch 17/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4537\n",
      "Epoch 17: val_loss improved from 1.41165 to 1.41158, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 33s 1ms/sample - loss: 1.4537 - val_loss: 1.4116\n",
      "Epoch 18/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4428\n",
      "Epoch 18: val_loss did not improve from 1.41158\n",
      "31687/31687 [==============================] - 21s 677us/sample - loss: 1.4428 - val_loss: 1.4117\n",
      "Epoch 19/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4458\n",
      "Epoch 19: val_loss improved from 1.41158 to 1.41106, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 647us/sample - loss: 1.4458 - val_loss: 1.4111\n",
      "Epoch 20/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4664\n",
      "Epoch 20: val_loss did not improve from 1.41106\n",
      "31687/31687 [==============================] - 21s 663us/sample - loss: 1.4664 - val_loss: 1.4115\n",
      "Epoch 21/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4609\n",
      "Epoch 21: val_loss did not improve from 1.41106\n",
      "31687/31687 [==============================] - 23s 720us/sample - loss: 1.4609 - val_loss: 1.4166\n",
      "Epoch 22/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4743\n",
      "Epoch 22: val_loss improved from 1.41106 to 1.40253, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 21s 650us/sample - loss: 1.4743 - val_loss: 1.4025\n",
      "Epoch 23/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4480\n",
      "Epoch 23: val_loss did not improve from 1.40253\n",
      "31687/31687 [==============================] - 20s 631us/sample - loss: 1.4480 - val_loss: 1.4094\n",
      "Epoch 24/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4290\n",
      "Epoch 24: val_loss improved from 1.40253 to 1.39883, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 21s 660us/sample - loss: 1.4290 - val_loss: 1.3988\n",
      "Epoch 25/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 25: val_loss did not improve from 1.39883\n",
      "31687/31687 [==============================] - 23s 721us/sample - loss: 1.4237 - val_loss: 1.4006\n",
      "Epoch 26/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4196\n",
      "Epoch 26: val_loss improved from 1.39883 to 1.39130, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 1.4196 - val_loss: 1.3913\n",
      "Epoch 27/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4152\n",
      "Epoch 27: val_loss improved from 1.39130 to 1.39014, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 724us/sample - loss: 1.4152 - val_loss: 1.3901\n",
      "Epoch 28/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4137\n",
      "Epoch 28: val_loss improved from 1.39014 to 1.38965, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 1.4137 - val_loss: 1.3896\n",
      "Epoch 29/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4115\n",
      "Epoch 29: val_loss improved from 1.38965 to 1.38847, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 723us/sample - loss: 1.4115 - val_loss: 1.3885\n",
      "Epoch 30/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4081\n",
      "Epoch 30: val_loss improved from 1.38847 to 1.38421, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 723us/sample - loss: 1.4081 - val_loss: 1.3842\n",
      "Epoch 31/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4064\n",
      "Epoch 31: val_loss improved from 1.38421 to 1.38220, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 726us/sample - loss: 1.4064 - val_loss: 1.3822\n",
      "Epoch 32/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4039\n",
      "Epoch 32: val_loss improved from 1.38220 to 1.38130, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 725us/sample - loss: 1.4039 - val_loss: 1.3813\n",
      "Epoch 33/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3999\n",
      "Epoch 33: val_loss did not improve from 1.38130\n",
      "31687/31687 [==============================] - 21s 657us/sample - loss: 1.3999 - val_loss: 1.3826\n",
      "Epoch 34/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3994\n",
      "Epoch 34: val_loss improved from 1.38130 to 1.38129, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 726us/sample - loss: 1.3994 - val_loss: 1.3813\n",
      "Epoch 35/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 35: val_loss improved from 1.38129 to 1.37612, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 717us/sample - loss: 1.3957 - val_loss: 1.3761\n",
      "Epoch 36/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3934\n",
      "Epoch 36: val_loss improved from 1.37612 to 1.37064, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 640us/sample - loss: 1.3934 - val_loss: 1.3706\n",
      "Epoch 37/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 37: val_loss did not improve from 1.37064\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 1.3928 - val_loss: 1.3778\n",
      "Epoch 38/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 38: val_loss did not improve from 1.37064\n",
      "31687/31687 [==============================] - 20s 629us/sample - loss: 1.3907 - val_loss: 1.3757\n",
      "Epoch 39/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3873\n",
      "Epoch 39: val_loss did not improve from 1.37064\n",
      "31687/31687 [==============================] - 20s 632us/sample - loss: 1.3873 - val_loss: 1.3710\n",
      "Epoch 40/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 40: val_loss did not improve from 1.37064\n",
      "31687/31687 [==============================] - 21s 654us/sample - loss: 1.3882 - val_loss: 1.3721\n",
      "Epoch 41/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3880\n",
      "Epoch 41: val_loss improved from 1.37064 to 1.36821, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 637us/sample - loss: 1.3880 - val_loss: 1.3682\n",
      "Epoch 42/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3842\n",
      "Epoch 42: val_loss improved from 1.36821 to 1.36735, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 630us/sample - loss: 1.3842 - val_loss: 1.3673\n",
      "Epoch 43/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3859\n",
      "Epoch 43: val_loss did not improve from 1.36735\n",
      "31687/31687 [==============================] - 20s 619us/sample - loss: 1.3859 - val_loss: 1.3738\n",
      "Epoch 44/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3835\n",
      "Epoch 44: val_loss improved from 1.36735 to 1.36632, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 634us/sample - loss: 1.3835 - val_loss: 1.3663\n",
      "Epoch 45/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 45: val_loss did not improve from 1.36632\n",
      "31687/31687 [==============================] - 20s 631us/sample - loss: 1.3796 - val_loss: 1.3742\n",
      "Epoch 46/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3835\n",
      "Epoch 46: val_loss did not improve from 1.36632\n",
      "31687/31687 [==============================] - 20s 627us/sample - loss: 1.3835 - val_loss: 1.3687\n",
      "Epoch 47/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 47: val_loss improved from 1.36632 to 1.36235, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 632us/sample - loss: 1.3796 - val_loss: 1.3623\n",
      "Epoch 48/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3766\n",
      "Epoch 48: val_loss did not improve from 1.36235\n",
      "31687/31687 [==============================] - 20s 632us/sample - loss: 1.3766 - val_loss: 1.3680\n",
      "Epoch 49/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3771\n",
      "Epoch 49: val_loss did not improve from 1.36235\n",
      "31687/31687 [==============================] - 20s 622us/sample - loss: 1.3771 - val_loss: 1.3625\n",
      "Epoch 50/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3745\n",
      "Epoch 50: val_loss did not improve from 1.36235\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 1.3745 - val_loss: 1.3630\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:45:12.731436: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_130_1/lstm_cell_389/bias/Assign' id:192835 op device:{requested: '', assigned: ''} def:{{{node lstm_130_1/lstm_cell_389/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_130_1/lstm_cell_389/bias, lstm_130_1/lstm_cell_389/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:45:23.192685: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_134_1/lstm_cell_393/bias/v/Assign' id:197376 op device:{requested: '', assigned: ''} def:{{{node lstm_134_1/lstm_cell_393/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_134_1/lstm_cell_393/bias/v, lstm_134_1/lstm_cell_393/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 11:45:32.893984: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_19_1/cond/Merge' id:195717 op device:{requested: '', assigned: ''} def:{{{node dropout_19_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_19_1/cond/Identity, dropout_19_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1776)\n",
      "(1514, 1776)\n",
      "(1644, 1776)\n",
      "(1764, 1776)\n",
      "(1836, 1776)\n",
      "(1699, 1776)\n",
      "(1369, 1776)\n",
      "(1778, 1776)\n",
      "(1631, 1776)\n",
      "(1692, 1776)\n",
      "(1550, 1776)\n",
      "(1691, 1776)\n",
      "(1800, 1776)\n",
      "(1848, 1776)\n",
      "(1704, 1776)\n",
      "(1824, 1776)\n",
      "(958, 1776)\n",
      "(1680, 1776)\n",
      "(1860, 1776)\n",
      "{1: 5.058828671376956, 2: 4.910966198491684, 4: 10.0, 5: 4.415283702771212, 6: 4.8081978586614955, 8: 7.842881510503695, 9: 6.307661364046879, 10: 6.982130793658509, 11: 7.027658679502398, 12: 8.656037490823664, 13: 5.408514204057418, 19: 8.437069388846325, 21: 8.055037580860855, 22: 1.0, 25: 7.286749535866564, 26: 5.509894286394497, 27: 5.144576253491703, 28: 5.492023422926783, 29: 1.5552980258655307}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907972/3306004915.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31687 samples, validate on 3538 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:50:20.993744: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 9.2943\n",
      "Epoch 1: val_loss improved from inf to 1.40683, saving model to ./checkpoints/unknown_person_few_shot_p17_33.h5\n",
      "31687/31687 [==============================] - 41s 1ms/sample - loss: 9.2943 - val_loss: 1.4068\n",
      "Epoch 2/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.1634\n",
      "Epoch 2: val_loss improved from 1.40683 to 1.38471, saving model to ./checkpoints/unknown_person_few_shot_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 628us/sample - loss: 9.1634 - val_loss: 1.3847\n",
      "Epoch 3/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0879\n",
      "Epoch 3: val_loss improved from 1.38471 to 1.37874, saving model to ./checkpoints/unknown_person_few_shot_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 621us/sample - loss: 9.0879 - val_loss: 1.3787\n",
      "Epoch 4/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.1019\n",
      "Epoch 4: val_loss did not improve from 1.37874\n",
      "31687/31687 [==============================] - 20s 616us/sample - loss: 9.1019 - val_loss: 1.3843\n",
      "Epoch 5/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0543\n",
      "Epoch 5: val_loss improved from 1.37874 to 1.37358, saving model to ./checkpoints/unknown_person_few_shot_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 622us/sample - loss: 9.0543 - val_loss: 1.3736\n",
      "Epoch 6/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0412\n",
      "Epoch 6: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 19s 613us/sample - loss: 9.0412 - val_loss: 1.3845\n",
      "Epoch 7/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0185\n",
      "Epoch 7: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 19s 614us/sample - loss: 9.0185 - val_loss: 1.3738\n",
      "Epoch 8/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0006\n",
      "Epoch 8: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 20s 622us/sample - loss: 9.0006 - val_loss: 1.3907\n",
      "Epoch 9/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9953\n",
      "Epoch 9: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 22s 686us/sample - loss: 8.9953 - val_loss: 1.3855\n",
      "Epoch 10/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9798\n",
      "Epoch 10: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 20s 642us/sample - loss: 8.9798 - val_loss: 1.3809\n",
      "Epoch 11/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9587\n",
      "Epoch 11: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 21s 664us/sample - loss: 8.9587 - val_loss: 1.3782\n",
      "Epoch 12/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9476\n",
      "Epoch 12: val_loss did not improve from 1.37358\n",
      "31687/31687 [==============================] - 23s 732us/sample - loss: 8.9476 - val_loss: 1.3812\n",
      "Epoch 13/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9172\n",
      "Epoch 13: val_loss improved from 1.37358 to 1.37052, saving model to ./checkpoints/unknown_person_few_shot_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 726us/sample - loss: 8.9172 - val_loss: 1.3705\n",
      "Epoch 14/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9213\n",
      "Epoch 14: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 638us/sample - loss: 8.9213 - val_loss: 1.3824\n",
      "Epoch 15/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9260\n",
      "Epoch 15: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 634us/sample - loss: 8.9260 - val_loss: 1.3794\n",
      "Epoch 16/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.8866\n",
      "Epoch 16: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 8.8866 - val_loss: 1.3795\n",
      "Epoch 17/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.8919\n",
      "Epoch 17: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 630us/sample - loss: 8.8919 - val_loss: 1.3818\n",
      "Epoch 18/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.8843\n",
      "Epoch 18: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 8.8843 - val_loss: 1.3813\n",
      "Epoch 19/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.8828\n",
      "Epoch 19: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 8.8828 - val_loss: 1.3867\n",
      "Epoch 20/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.8395\n",
      "Epoch 20: val_loss did not improve from 1.37052\n",
      "31687/31687 [==============================] - 20s 632us/sample - loss: 8.8395 - val_loss: 1.3946\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:57:33.315397: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_121_2/lstm_cell_417/recurrent_kernel/Assign' id:210784 op device:{requested: '', assigned: ''} def:{{{node lstm_121_2/lstm_cell_417/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_121_2/lstm_cell_417/recurrent_kernel, lstm_121_2/lstm_cell_417/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:57:43.941298: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_111_2/lstm_cell_407/bias/m/Assign' id:215786 op device:{requested: '', assigned: ''} def:{{{node lstm_111_2/lstm_cell_407/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_111_2/lstm_cell_407/bias/m, lstm_111_2/lstm_cell_407/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31687 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:57:57.119621: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:58:54.191096: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:59:15.274786: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36395, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_33.h5\n",
      "31687/31687 [==============================] - 42s 1ms/sample - loss: 1.3774 - val_loss: 1.3640\n",
      "Epoch 2/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3769\n",
      "Epoch 2: val_loss improved from 1.36395 to 1.35849, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_33.h5\n",
      "31687/31687 [==============================] - 21s 668us/sample - loss: 1.3769 - val_loss: 1.3585\n",
      "Epoch 3/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3754\n",
      "Epoch 3: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 20s 634us/sample - loss: 1.3754 - val_loss: 1.3635\n",
      "Epoch 4/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3736\n",
      "Epoch 4: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 21s 667us/sample - loss: 1.3736 - val_loss: 1.3629\n",
      "Epoch 5/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3709\n",
      "Epoch 5: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 20s 639us/sample - loss: 1.3709 - val_loss: 1.3609\n",
      "Epoch 6/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3711\n",
      "Epoch 6: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 22s 708us/sample - loss: 1.3711 - val_loss: 1.3622\n",
      "Epoch 7/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3692\n",
      "Epoch 7: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 23s 732us/sample - loss: 1.3692 - val_loss: 1.3601\n",
      "Epoch 8/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3662\n",
      "Epoch 8: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 23s 725us/sample - loss: 1.3662 - val_loss: 1.3611\n",
      "Epoch 9/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3658\n",
      "Epoch 9: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 23s 740us/sample - loss: 1.3658 - val_loss: 1.3615\n",
      "Epoch 10/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3626\n",
      "Epoch 10: val_loss did not improve from 1.35849\n",
      "31687/31687 [==============================] - 23s 735us/sample - loss: 1.3626 - val_loss: 1.3600\n",
      "Epoch 11/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3655\n",
      "Epoch 11: val_loss improved from 1.35849 to 1.35581, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_33.h5\n",
      "31687/31687 [==============================] - 23s 738us/sample - loss: 1.3655 - val_loss: 1.3558\n",
      "Epoch 12/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3631\n",
      "Epoch 12: val_loss did not improve from 1.35581\n",
      "31687/31687 [==============================] - 23s 739us/sample - loss: 1.3631 - val_loss: 1.3591\n",
      "Epoch 13/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3601\n",
      "Epoch 13: val_loss did not improve from 1.35581\n",
      "31687/31687 [==============================] - 20s 619us/sample - loss: 1.3601 - val_loss: 1.3622\n",
      "Epoch 14/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3605\n",
      "Epoch 14: val_loss did not improve from 1.35581\n",
      "31687/31687 [==============================] - 19s 614us/sample - loss: 1.3605 - val_loss: 1.3565\n",
      "Epoch 15/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3581\n",
      "Epoch 15: val_loss improved from 1.35581 to 1.35559, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_33.h5\n",
      "31687/31687 [==============================] - 19s 612us/sample - loss: 1.3581 - val_loss: 1.3556\n",
      "Epoch 16/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3573\n",
      "Epoch 16: val_loss improved from 1.35559 to 1.35420, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_33.h5\n",
      "31687/31687 [==============================] - 20s 618us/sample - loss: 1.3573 - val_loss: 1.3542\n",
      "Epoch 17/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3562\n",
      "Epoch 17: val_loss did not improve from 1.35420\n",
      "31687/31687 [==============================] - 19s 611us/sample - loss: 1.3562 - val_loss: 1.3561\n",
      "Epoch 18/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3563\n",
      "Epoch 18: val_loss did not improve from 1.35420\n",
      "31687/31687 [==============================] - 23s 711us/sample - loss: 1.3563 - val_loss: 1.3563\n",
      "Epoch 19/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3539\n",
      "Epoch 19: val_loss improved from 1.35420 to 1.34932, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_33.h5\n",
      "31687/31687 [==============================] - 22s 700us/sample - loss: 1.3539 - val_loss: 1.3493\n",
      "Epoch 20/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3509\n",
      "Epoch 20: val_loss did not improve from 1.34932\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 1.3509 - val_loss: 1.3527\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:27.065011: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_167/lstm_cell_463/recurrent_kernel/Assign' id:231341 op device:{requested: '', assigned: ''} def:{{{node lstm_167/lstm_cell_463/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_167/lstm_cell_463/recurrent_kernel, lstm_167/lstm_cell_463/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:06:33.217438: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_1' id:231804 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:06:38.144970: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_2' id:231805 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31687, 95)\n",
      "Train on 31687 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:06:53.125439: W tensorflow/c/c_api.cc:304] Operation '{name:'training_24/Adam/lstm_156/lstm_cell_452/bias/m/Assign' id:244692 op device:{requested: '', assigned: ''} def:{{{node training_24/Adam/lstm_156/lstm_cell_452/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_24/Adam/lstm_156/lstm_cell_452/bias/m, training_24/Adam/lstm_156/lstm_cell_452/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:07:56.320876: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 3.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:08:18.893383: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_25/mul' id:234645 op device:{requested: '', assigned: ''} def:{{{node loss_25/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_25/mul/x, loss_25/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.87478, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 79s 2ms/sample - loss: 3.0014 - val_loss: 1.8748\n",
      "Epoch 2/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.7713\n",
      "Epoch 2: val_loss improved from 1.87478 to 1.56572, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 627us/sample - loss: 1.7713 - val_loss: 1.5657\n",
      "Epoch 3/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5927\n",
      "Epoch 3: val_loss improved from 1.56572 to 1.51580, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 645us/sample - loss: 1.5927 - val_loss: 1.5158\n",
      "Epoch 4/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5404\n",
      "Epoch 4: val_loss improved from 1.51580 to 1.49870, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 22s 699us/sample - loss: 1.5404 - val_loss: 1.4987\n",
      "Epoch 5/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5151\n",
      "Epoch 5: val_loss improved from 1.49870 to 1.48336, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 726us/sample - loss: 1.5151 - val_loss: 1.4834\n",
      "Epoch 6/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5008\n",
      "Epoch 6: val_loss improved from 1.48336 to 1.46972, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 1.5008 - val_loss: 1.4697\n",
      "Epoch 7/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4917\n",
      "Epoch 7: val_loss did not improve from 1.46972\n",
      "31687/31687 [==============================] - 22s 709us/sample - loss: 1.4917 - val_loss: 1.4725\n",
      "Epoch 8/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4969\n",
      "Epoch 8: val_loss improved from 1.46972 to 1.45834, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 22s 694us/sample - loss: 1.4969 - val_loss: 1.4583\n",
      "Epoch 9/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5039\n",
      "Epoch 9: val_loss did not improve from 1.45834\n",
      "31687/31687 [==============================] - 24s 748us/sample - loss: 1.5039 - val_loss: 1.4619\n",
      "Epoch 10/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4885\n",
      "Epoch 10: val_loss improved from 1.45834 to 1.45511, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 22s 684us/sample - loss: 1.4885 - val_loss: 1.4551\n",
      "Epoch 11/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5188\n",
      "Epoch 11: val_loss did not improve from 1.45511\n",
      "31687/31687 [==============================] - 20s 618us/sample - loss: 1.5188 - val_loss: 1.4592\n",
      "Epoch 12/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5053\n",
      "Epoch 12: val_loss improved from 1.45511 to 1.44474, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 616us/sample - loss: 1.5053 - val_loss: 1.4447\n",
      "Epoch 13/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4822\n",
      "Epoch 13: val_loss improved from 1.44474 to 1.44459, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 19s 615us/sample - loss: 1.4822 - val_loss: 1.4446\n",
      "Epoch 14/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4812\n",
      "Epoch 14: val_loss improved from 1.44459 to 1.44232, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 617us/sample - loss: 1.4812 - val_loss: 1.4423\n",
      "Epoch 15/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4799\n",
      "Epoch 15: val_loss improved from 1.44232 to 1.43872, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 616us/sample - loss: 1.4799 - val_loss: 1.4387\n",
      "Epoch 16/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5070\n",
      "Epoch 16: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 19s 609us/sample - loss: 1.5070 - val_loss: 1.4484\n",
      "Epoch 17/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5796\n",
      "Epoch 17: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 20s 620us/sample - loss: 1.5796 - val_loss: 1.4494\n",
      "Epoch 18/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5111\n",
      "Epoch 18: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 20s 621us/sample - loss: 1.5111 - val_loss: 1.4474\n",
      "Epoch 19/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5519\n",
      "Epoch 19: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 20s 623us/sample - loss: 1.5519 - val_loss: 1.4547\n",
      "Epoch 20/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4914\n",
      "Epoch 20: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 19s 608us/sample - loss: 1.4914 - val_loss: 1.4502\n",
      "Epoch 21/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4963\n",
      "Epoch 21: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 19s 610us/sample - loss: 1.4963 - val_loss: 1.4461\n",
      "Epoch 22/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5183\n",
      "Epoch 22: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 19s 611us/sample - loss: 1.5183 - val_loss: 1.4434\n",
      "Epoch 23/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4880\n",
      "Epoch 23: val_loss did not improve from 1.43872\n",
      "31687/31687 [==============================] - 19s 612us/sample - loss: 1.4880 - val_loss: 1.4439\n",
      "Epoch 24/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4692\n",
      "Epoch 24: val_loss improved from 1.43872 to 1.43738, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 1.4692 - val_loss: 1.4374\n",
      "Epoch 25/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4638\n",
      "Epoch 25: val_loss improved from 1.43738 to 1.43409, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 651us/sample - loss: 1.4638 - val_loss: 1.4341\n",
      "Epoch 26/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4591\n",
      "Epoch 26: val_loss improved from 1.43409 to 1.43205, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 669us/sample - loss: 1.4591 - val_loss: 1.4321\n",
      "Epoch 27/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4552\n",
      "Epoch 27: val_loss improved from 1.43205 to 1.42894, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 619us/sample - loss: 1.4552 - val_loss: 1.4289\n",
      "Epoch 28/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4530\n",
      "Epoch 28: val_loss improved from 1.42894 to 1.42830, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 19s 615us/sample - loss: 1.4530 - val_loss: 1.4283\n",
      "Epoch 29/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4512\n",
      "Epoch 29: val_loss improved from 1.42830 to 1.42417, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 19s 615us/sample - loss: 1.4512 - val_loss: 1.4242\n",
      "Epoch 30/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4461\n",
      "Epoch 30: val_loss improved from 1.42417 to 1.42273, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 622us/sample - loss: 1.4461 - val_loss: 1.4227\n",
      "Epoch 31/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4468\n",
      "Epoch 31: val_loss improved from 1.42273 to 1.42234, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 717us/sample - loss: 1.4468 - val_loss: 1.4223\n",
      "Epoch 32/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4424\n",
      "Epoch 32: val_loss improved from 1.42234 to 1.41936, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 719us/sample - loss: 1.4424 - val_loss: 1.4194\n",
      "Epoch 33/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4386\n",
      "Epoch 33: val_loss improved from 1.41936 to 1.41702, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 723us/sample - loss: 1.4386 - val_loss: 1.4170\n",
      "Epoch 34/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4362\n",
      "Epoch 34: val_loss improved from 1.41702 to 1.41633, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 22s 689us/sample - loss: 1.4362 - val_loss: 1.4163\n",
      "Epoch 35/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4322\n",
      "Epoch 35: val_loss improved from 1.41633 to 1.41216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 637us/sample - loss: 1.4322 - val_loss: 1.4122\n",
      "Epoch 36/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4335\n",
      "Epoch 36: val_loss did not improve from 1.41216\n",
      "31687/31687 [==============================] - 20s 634us/sample - loss: 1.4335 - val_loss: 1.4187\n",
      "Epoch 37/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4291\n",
      "Epoch 37: val_loss did not improve from 1.41216\n",
      "31687/31687 [==============================] - 21s 652us/sample - loss: 1.4291 - val_loss: 1.4133\n",
      "Epoch 38/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 38: val_loss improved from 1.41216 to 1.41176, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 724us/sample - loss: 1.4277 - val_loss: 1.4118\n",
      "Epoch 39/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 39: val_loss improved from 1.41176 to 1.40995, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 633us/sample - loss: 1.4252 - val_loss: 1.4099\n",
      "Epoch 40/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4224\n",
      "Epoch 40: val_loss improved from 1.40995 to 1.40719, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 673us/sample - loss: 1.4224 - val_loss: 1.4072\n",
      "Epoch 41/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 41: val_loss improved from 1.40719 to 1.40390, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 1.4204 - val_loss: 1.4039\n",
      "Epoch 42/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4200\n",
      "Epoch 42: val_loss improved from 1.40390 to 1.40163, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 718us/sample - loss: 1.4200 - val_loss: 1.4016\n",
      "Epoch 43/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4170\n",
      "Epoch 43: val_loss did not improve from 1.40163\n",
      "31687/31687 [==============================] - 23s 714us/sample - loss: 1.4170 - val_loss: 1.4037\n",
      "Epoch 44/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 44: val_loss improved from 1.40163 to 1.40035, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 668us/sample - loss: 1.4166 - val_loss: 1.4003\n",
      "Epoch 45/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4152\n",
      "Epoch 45: val_loss did not improve from 1.40035\n",
      "31687/31687 [==============================] - 20s 627us/sample - loss: 1.4152 - val_loss: 1.4023\n",
      "Epoch 46/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 46: val_loss did not improve from 1.40035\n",
      "31687/31687 [==============================] - 20s 627us/sample - loss: 1.4145 - val_loss: 1.4011\n",
      "Epoch 47/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4116\n",
      "Epoch 47: val_loss did not improve from 1.40035\n",
      "31687/31687 [==============================] - 20s 632us/sample - loss: 1.4116 - val_loss: 1.4043\n",
      "Epoch 48/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4092\n",
      "Epoch 48: val_loss improved from 1.40035 to 1.39830, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 22s 700us/sample - loss: 1.4092 - val_loss: 1.3983\n",
      "Epoch 49/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4086\n",
      "Epoch 49: val_loss improved from 1.39830 to 1.39455, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 724us/sample - loss: 1.4086 - val_loss: 1.3946\n",
      "Epoch 50/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4037\n",
      "Epoch 50: val_loss improved from 1.39455 to 1.39431, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 652us/sample - loss: 1.4037 - val_loss: 1.3943\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:26:22.386985: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_155_1/lstm_cell_488/recurrent_kernel/Assign' id:247948 op device:{requested: '', assigned: ''} def:{{{node lstm_155_1/lstm_cell_488/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_155_1/lstm_cell_488/recurrent_kernel, lstm_155_1/lstm_cell_488/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:26:35.445180: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_166_1/lstm_cell_499/kernel/v/Assign' id:254333 op device:{requested: '', assigned: ''} def:{{{node lstm_166_1/lstm_cell_499/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_166_1/lstm_cell_499/kernel/v, lstm_166_1/lstm_cell_499/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:26:48.267645: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_24_1/cond/Merge' id:252759 op device:{requested: '', assigned: ''} def:{{{node dropout_24_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_24_1/cond/Identity, dropout_24_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1776)\n",
      "(1514, 1776)\n",
      "(1644, 1776)\n",
      "(1764, 1776)\n",
      "(1836, 1776)\n",
      "(1699, 1776)\n",
      "(1369, 1776)\n",
      "(1778, 1776)\n",
      "(1631, 1776)\n",
      "(1692, 1776)\n",
      "(1550, 1776)\n",
      "(1691, 1776)\n",
      "(1800, 1776)\n",
      "(1848, 1776)\n",
      "(1704, 1776)\n",
      "(1824, 1776)\n",
      "(958, 1776)\n",
      "(1680, 1776)\n",
      "(1860, 1776)\n",
      "{1: 4.811908184813488, 2: 4.9127020346192305, 4: 10.0, 5: 4.158436537976912, 6: 5.031635805846662, 8: 7.605275990217419, 9: 6.069606026630081, 10: 6.750848096730239, 11: 6.958325980556151, 12: 8.311562317678744, 13: 5.691360075139025, 19: 8.503428343095695, 21: 7.839306414769171, 22: 1.0, 25: 7.349965263208579, 26: 5.7107910420974894, 27: 4.832900337612848, 28: 5.1072345699547705, 29: 1.8451429461176398}\n",
      "Train on 31687 samples, validate on 3538 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:32:03.190114: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 9.2356\n",
      "Epoch 1: val_loss improved from inf to 1.42060, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 48s 2ms/sample - loss: 9.2356 - val_loss: 1.4206\n",
      "Epoch 2/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.1856\n",
      "Epoch 2: val_loss did not improve from 1.42060\n",
      "31687/31687 [==============================] - 23s 717us/sample - loss: 9.1856 - val_loss: 1.4209\n",
      "Epoch 3/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.1395\n",
      "Epoch 3: val_loss improved from 1.42060 to 1.41682, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 725us/sample - loss: 9.1395 - val_loss: 1.4168\n",
      "Epoch 4/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0883\n",
      "Epoch 4: val_loss improved from 1.41682 to 1.39622, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 710us/sample - loss: 9.0883 - val_loss: 1.3962\n",
      "Epoch 5/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0710\n",
      "Epoch 5: val_loss did not improve from 1.39622\n",
      "31687/31687 [==============================] - 21s 653us/sample - loss: 9.0710 - val_loss: 1.4004\n",
      "Epoch 6/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0639\n",
      "Epoch 6: val_loss did not improve from 1.39622\n",
      "31687/31687 [==============================] - 21s 653us/sample - loss: 9.0639 - val_loss: 1.4075\n",
      "Epoch 7/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0613\n",
      "Epoch 7: val_loss did not improve from 1.39622\n",
      "31687/31687 [==============================] - 22s 701us/sample - loss: 9.0613 - val_loss: 1.3984\n",
      "Epoch 8/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0238\n",
      "Epoch 8: val_loss improved from 1.39622 to 1.38914, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 727us/sample - loss: 9.0238 - val_loss: 1.3891\n",
      "Epoch 9/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.0061\n",
      "Epoch 9: val_loss improved from 1.38914 to 1.38754, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 727us/sample - loss: 9.0061 - val_loss: 1.3875\n",
      "Epoch 10/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9894\n",
      "Epoch 10: val_loss did not improve from 1.38754\n",
      "31687/31687 [==============================] - 22s 706us/sample - loss: 8.9894 - val_loss: 1.3932\n",
      "Epoch 11/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9623\n",
      "Epoch 11: val_loss did not improve from 1.38754\n",
      "31687/31687 [==============================] - 20s 635us/sample - loss: 8.9623 - val_loss: 1.3913\n",
      "Epoch 12/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9847\n",
      "Epoch 12: val_loss did not improve from 1.38754\n",
      "31687/31687 [==============================] - 21s 648us/sample - loss: 8.9847 - val_loss: 1.3938\n",
      "Epoch 13/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9832\n",
      "Epoch 13: val_loss improved from 1.38754 to 1.38743, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 23s 723us/sample - loss: 8.9832 - val_loss: 1.3874\n",
      "Epoch 14/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9434\n",
      "Epoch 14: val_loss did not improve from 1.38743\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 8.9434 - val_loss: 1.3925\n",
      "Epoch 15/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9277\n",
      "Epoch 15: val_loss did not improve from 1.38743\n",
      "31687/31687 [==============================] - 20s 639us/sample - loss: 8.9277 - val_loss: 1.3901\n",
      "Epoch 16/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9228\n",
      "Epoch 16: val_loss did not improve from 1.38743\n",
      "31687/31687 [==============================] - 20s 628us/sample - loss: 8.9228 - val_loss: 1.4019\n",
      "Epoch 17/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9163\n",
      "Epoch 17: val_loss improved from 1.38743 to 1.38211, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 633us/sample - loss: 8.9163 - val_loss: 1.3821\n",
      "Epoch 18/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9146\n",
      "Epoch 18: val_loss did not improve from 1.38211\n",
      "31687/31687 [==============================] - 20s 626us/sample - loss: 8.9146 - val_loss: 1.3844\n",
      "Epoch 19/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.9213\n",
      "Epoch 19: val_loss improved from 1.38211 to 1.38029, saving model to ./checkpoints/unknown_person_few_shot_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 624us/sample - loss: 8.9213 - val_loss: 1.3803\n",
      "Epoch 20/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 8.8888\n",
      "Epoch 20: val_loss did not improve from 1.38029\n",
      "31687/31687 [==============================] - 20s 616us/sample - loss: 8.8888 - val_loss: 1.3864\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:39:42.977911: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_17_2/bias/Assign' id:272172 op device:{requested: '', assigned: ''} def:{{{node dense_17_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_17_2/bias, dense_17_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:39:56.676765: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_175_2/lstm_cell_545/kernel/v/Assign' id:273866 op device:{requested: '', assigned: ''} def:{{{node lstm_175_2/lstm_cell_545/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_175_2/lstm_cell_545/kernel/v, lstm_175_2/lstm_cell_545/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31687 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:40:12.815290: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:41:25.132070: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:41:46.514759: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39562, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 47s 1ms/sample - loss: 1.4042 - val_loss: 1.3956\n",
      "Epoch 2/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 2: val_loss improved from 1.39562 to 1.38734, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 627us/sample - loss: 1.3992 - val_loss: 1.3873\n",
      "Epoch 3/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4006\n",
      "Epoch 3: val_loss did not improve from 1.38734\n",
      "31687/31687 [==============================] - 20s 621us/sample - loss: 1.4006 - val_loss: 1.3939\n",
      "Epoch 4/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 4: val_loss did not improve from 1.38734\n",
      "31687/31687 [==============================] - 20s 635us/sample - loss: 1.3996 - val_loss: 1.3878\n",
      "Epoch 5/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3973\n",
      "Epoch 5: val_loss did not improve from 1.38734\n",
      "31687/31687 [==============================] - 21s 678us/sample - loss: 1.3973 - val_loss: 1.3908\n",
      "Epoch 6/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3945\n",
      "Epoch 6: val_loss improved from 1.38734 to 1.38201, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 22s 697us/sample - loss: 1.3945 - val_loss: 1.3820\n",
      "Epoch 7/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 7: val_loss did not improve from 1.38201\n",
      "31687/31687 [==============================] - 23s 717us/sample - loss: 1.3917 - val_loss: 1.3933\n",
      "Epoch 8/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 8: val_loss did not improve from 1.38201\n",
      "31687/31687 [==============================] - 21s 668us/sample - loss: 1.3887 - val_loss: 1.3866\n",
      "Epoch 9/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3897\n",
      "Epoch 9: val_loss did not improve from 1.38201\n",
      "31687/31687 [==============================] - 21s 670us/sample - loss: 1.3897 - val_loss: 1.3864\n",
      "Epoch 10/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3871\n",
      "Epoch 10: val_loss improved from 1.38201 to 1.37758, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 626us/sample - loss: 1.3871 - val_loss: 1.3776\n",
      "Epoch 11/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3861\n",
      "Epoch 11: val_loss did not improve from 1.37758\n",
      "31687/31687 [==============================] - 20s 619us/sample - loss: 1.3861 - val_loss: 1.3805\n",
      "Epoch 12/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3834\n",
      "Epoch 12: val_loss did not improve from 1.37758\n",
      "31687/31687 [==============================] - 20s 638us/sample - loss: 1.3834 - val_loss: 1.3787\n",
      "Epoch 13/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3835\n",
      "Epoch 13: val_loss did not improve from 1.37758\n",
      "31687/31687 [==============================] - 22s 688us/sample - loss: 1.3835 - val_loss: 1.3780\n",
      "Epoch 14/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3824\n",
      "Epoch 14: val_loss improved from 1.37758 to 1.37490, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 658us/sample - loss: 1.3824 - val_loss: 1.3749\n",
      "Epoch 15/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3808\n",
      "Epoch 15: val_loss did not improve from 1.37490\n",
      "31687/31687 [==============================] - 23s 723us/sample - loss: 1.3808 - val_loss: 1.3758\n",
      "Epoch 16/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3786\n",
      "Epoch 16: val_loss did not improve from 1.37490\n",
      "31687/31687 [==============================] - 22s 708us/sample - loss: 1.3786 - val_loss: 1.3765\n",
      "Epoch 17/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3789\n",
      "Epoch 17: val_loss did not improve from 1.37490\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 1.3789 - val_loss: 1.3752\n",
      "Epoch 18/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3790\n",
      "Epoch 18: val_loss did not improve from 1.37490\n",
      "31687/31687 [==============================] - 23s 712us/sample - loss: 1.3790 - val_loss: 1.3754\n",
      "Epoch 19/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3771\n",
      "Epoch 19: val_loss improved from 1.37490 to 1.37355, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 20s 638us/sample - loss: 1.3771 - val_loss: 1.3735\n",
      "Epoch 20/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3750\n",
      "Epoch 20: val_loss improved from 1.37355 to 1.37282, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_34.h5\n",
      "31687/31687 [==============================] - 21s 671us/sample - loss: 1.3750 - val_loss: 1.3728\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:49:00.916918: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_188/lstm_cell_558/bias/Assign' id:285752 op device:{requested: '', assigned: ''} def:{{{node lstm_188/lstm_cell_558/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_188/lstm_cell_558/bias, lstm_188/lstm_cell_558/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:49:08.893723: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_1' id:288846 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:49:15.369434: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_2' id:288847 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31687, 95)\n",
      "Train on 31687 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:49:33.537941: W tensorflow/c/c_api.cc:304] Operation '{name:'training_30/Adam/lstm_189/lstm_cell_559/recurrent_kernel/m/Assign' id:301669 op device:{requested: '', assigned: ''} def:{{{node training_30/Adam/lstm_189/lstm_cell_559/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_30/Adam/lstm_189/lstm_cell_559/recurrent_kernel/m, training_30/Adam/lstm_189/lstm_cell_559/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:50:55.097251: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 3.2012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:51:19.795204: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_31/mul' id:291687 op device:{requested: '', assigned: ''} def:{{{node loss_31/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_31/mul/x, loss_31/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.93714, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 94s 3ms/sample - loss: 3.2012 - val_loss: 1.9371\n",
      "Epoch 2/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.7898\n",
      "Epoch 2: val_loss improved from 1.93714 to 1.56918, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 24s 749us/sample - loss: 1.7898 - val_loss: 1.5692\n",
      "Epoch 3/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5821\n",
      "Epoch 3: val_loss improved from 1.56918 to 1.51210, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 736us/sample - loss: 1.5821 - val_loss: 1.5121\n",
      "Epoch 4/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5289\n",
      "Epoch 4: val_loss improved from 1.51210 to 1.48291, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 717us/sample - loss: 1.5289 - val_loss: 1.4829\n",
      "Epoch 5/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5067\n",
      "Epoch 5: val_loss improved from 1.48291 to 1.47654, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 635us/sample - loss: 1.5067 - val_loss: 1.4765\n",
      "Epoch 6/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4899\n",
      "Epoch 6: val_loss improved from 1.47654 to 1.46167, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 637us/sample - loss: 1.4899 - val_loss: 1.4617\n",
      "Epoch 7/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4790\n",
      "Epoch 7: val_loss improved from 1.46167 to 1.45400, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 662us/sample - loss: 1.4790 - val_loss: 1.4540\n",
      "Epoch 8/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4793\n",
      "Epoch 8: val_loss improved from 1.45400 to 1.44668, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 728us/sample - loss: 1.4793 - val_loss: 1.4467\n",
      "Epoch 9/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4803\n",
      "Epoch 9: val_loss improved from 1.44668 to 1.44146, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 733us/sample - loss: 1.4803 - val_loss: 1.4415\n",
      "Epoch 10/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4761\n",
      "Epoch 10: val_loss did not improve from 1.44146\n",
      "31687/31687 [==============================] - 22s 696us/sample - loss: 1.4761 - val_loss: 1.4426\n",
      "Epoch 11/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 11: val_loss improved from 1.44146 to 1.43577, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 639us/sample - loss: 1.4658 - val_loss: 1.4358\n",
      "Epoch 12/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 12: val_loss improved from 1.43577 to 1.43467, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 636us/sample - loss: 1.4829 - val_loss: 1.4347\n",
      "Epoch 13/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4678\n",
      "Epoch 13: val_loss did not improve from 1.43467\n",
      "31687/31687 [==============================] - 20s 633us/sample - loss: 1.4678 - val_loss: 1.4396\n",
      "Epoch 14/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4811\n",
      "Epoch 14: val_loss did not improve from 1.43467\n",
      "31687/31687 [==============================] - 21s 657us/sample - loss: 1.4811 - val_loss: 1.4378\n",
      "Epoch 15/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 15: val_loss did not improve from 1.43467\n",
      "31687/31687 [==============================] - 21s 661us/sample - loss: 1.4987 - val_loss: 1.4395\n",
      "Epoch 16/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4622\n",
      "Epoch 16: val_loss improved from 1.43467 to 1.43305, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 729us/sample - loss: 1.4622 - val_loss: 1.4330\n",
      "Epoch 17/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4668\n",
      "Epoch 17: val_loss improved from 1.43305 to 1.42854, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 666us/sample - loss: 1.4668 - val_loss: 1.4285\n",
      "Epoch 18/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4778\n",
      "Epoch 18: val_loss improved from 1.42854 to 1.42843, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 22s 692us/sample - loss: 1.4778 - val_loss: 1.4284\n",
      "Epoch 19/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5259\n",
      "Epoch 19: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 21s 676us/sample - loss: 1.5259 - val_loss: 1.4447\n",
      "Epoch 20/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 20: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 23s 722us/sample - loss: 1.5028 - val_loss: 1.4297\n",
      "Epoch 21/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5254\n",
      "Epoch 21: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 23s 724us/sample - loss: 1.5254 - val_loss: 1.4391\n",
      "Epoch 22/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.5226\n",
      "Epoch 22: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 24s 765us/sample - loss: 1.5226 - val_loss: 1.4418\n",
      "Epoch 23/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4948\n",
      "Epoch 23: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 22s 710us/sample - loss: 1.4948 - val_loss: 1.4352\n",
      "Epoch 24/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4732\n",
      "Epoch 24: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 24s 745us/sample - loss: 1.4732 - val_loss: 1.4332\n",
      "Epoch 25/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4729\n",
      "Epoch 25: val_loss did not improve from 1.42843\n",
      "31687/31687 [==============================] - 23s 739us/sample - loss: 1.4729 - val_loss: 1.4317\n",
      "Epoch 26/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4620\n",
      "Epoch 26: val_loss improved from 1.42843 to 1.42627, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 640us/sample - loss: 1.4620 - val_loss: 1.4263\n",
      "Epoch 27/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4646\n",
      "Epoch 27: val_loss improved from 1.42627 to 1.42548, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 621us/sample - loss: 1.4646 - val_loss: 1.4255\n",
      "Epoch 28/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 28: val_loss improved from 1.42548 to 1.42314, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 620us/sample - loss: 1.4597 - val_loss: 1.4231\n",
      "Epoch 29/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4537\n",
      "Epoch 29: val_loss improved from 1.42314 to 1.41876, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 618us/sample - loss: 1.4537 - val_loss: 1.4188\n",
      "Epoch 30/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4468\n",
      "Epoch 30: val_loss improved from 1.41876 to 1.41273, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 617us/sample - loss: 1.4468 - val_loss: 1.4127\n",
      "Epoch 31/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4465\n",
      "Epoch 31: val_loss improved from 1.41273 to 1.41031, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 619us/sample - loss: 1.4465 - val_loss: 1.4103\n",
      "Epoch 32/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4425\n",
      "Epoch 32: val_loss did not improve from 1.41031\n",
      "31687/31687 [==============================] - 19s 612us/sample - loss: 1.4425 - val_loss: 1.4112\n",
      "Epoch 33/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4416\n",
      "Epoch 33: val_loss improved from 1.41031 to 1.40779, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 661us/sample - loss: 1.4416 - val_loss: 1.4078\n",
      "Epoch 34/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4377\n",
      "Epoch 34: val_loss improved from 1.40779 to 1.40343, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 740us/sample - loss: 1.4377 - val_loss: 1.4034\n",
      "Epoch 35/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4360\n",
      "Epoch 35: val_loss did not improve from 1.40343\n",
      "31687/31687 [==============================] - 24s 744us/sample - loss: 1.4360 - val_loss: 1.4063\n",
      "Epoch 36/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4299\n",
      "Epoch 36: val_loss improved from 1.40343 to 1.40148, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 24s 748us/sample - loss: 1.4299 - val_loss: 1.4015\n",
      "Epoch 37/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 37: val_loss improved from 1.40148 to 1.40097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 735us/sample - loss: 1.4305 - val_loss: 1.4010\n",
      "Epoch 38/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4248\n",
      "Epoch 38: val_loss improved from 1.40097 to 1.39793, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 643us/sample - loss: 1.4248 - val_loss: 1.3979\n",
      "Epoch 39/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 39: val_loss improved from 1.39793 to 1.39650, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 22s 709us/sample - loss: 1.4242 - val_loss: 1.3965\n",
      "Epoch 40/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4234\n",
      "Epoch 40: val_loss did not improve from 1.39650\n",
      "31687/31687 [==============================] - 20s 628us/sample - loss: 1.4234 - val_loss: 1.3979\n",
      "Epoch 41/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4203\n",
      "Epoch 41: val_loss improved from 1.39650 to 1.39642, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 659us/sample - loss: 1.4203 - val_loss: 1.3964\n",
      "Epoch 42/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4189\n",
      "Epoch 42: val_loss improved from 1.39642 to 1.39328, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 661us/sample - loss: 1.4189 - val_loss: 1.3933\n",
      "Epoch 43/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 43: val_loss did not improve from 1.39328\n",
      "31687/31687 [==============================] - 20s 637us/sample - loss: 1.4166 - val_loss: 1.3939\n",
      "Epoch 44/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4160\n",
      "Epoch 44: val_loss did not improve from 1.39328\n",
      "31687/31687 [==============================] - 20s 622us/sample - loss: 1.4160 - val_loss: 1.3940\n",
      "Epoch 45/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4153\n",
      "Epoch 45: val_loss improved from 1.39328 to 1.38690, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 633us/sample - loss: 1.4153 - val_loss: 1.3869\n",
      "Epoch 46/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4129\n",
      "Epoch 46: val_loss did not improve from 1.38690\n",
      "31687/31687 [==============================] - 20s 621us/sample - loss: 1.4129 - val_loss: 1.3909\n",
      "Epoch 47/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 47: val_loss improved from 1.38690 to 1.38661, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 22s 709us/sample - loss: 1.4132 - val_loss: 1.3866\n",
      "Epoch 48/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 48: val_loss improved from 1.38661 to 1.38602, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 678us/sample - loss: 1.4093 - val_loss: 1.3860\n",
      "Epoch 49/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4112\n",
      "Epoch 49: val_loss did not improve from 1.38602\n",
      "31687/31687 [==============================] - 20s 634us/sample - loss: 1.4112 - val_loss: 1.3877\n",
      "Epoch 50/50\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4064\n",
      "Epoch 50: val_loss did not improve from 1.38602\n",
      "31687/31687 [==============================] - 23s 725us/sample - loss: 1.4064 - val_loss: 1.3908\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:10:08.171307: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_185_1/lstm_cell_592/bias/Assign' id:303879 op device:{requested: '', assigned: ''} def:{{{node lstm_185_1/lstm_cell_592/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_185_1/lstm_cell_592/bias, lstm_185_1/lstm_cell_592/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:10:23.908602: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_217_1/lstm_cell_624/bias/m/Assign' id:310952 op device:{requested: '', assigned: ''} def:{{{node lstm_217_1/lstm_cell_624/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_217_1/lstm_cell_624/bias/m, lstm_217_1/lstm_cell_624/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:10:39.377603: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_29_1/cond/Merge' id:309801 op device:{requested: '', assigned: ''} def:{{{node dropout_29_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_29_1/cond/Identity, dropout_29_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1776)\n",
      "(1514, 1776)\n",
      "(1644, 1776)\n",
      "(1764, 1776)\n",
      "(1836, 1776)\n",
      "(1699, 1776)\n",
      "(1369, 1776)\n",
      "(1778, 1776)\n",
      "(1631, 1776)\n",
      "(1692, 1776)\n",
      "(1550, 1776)\n",
      "(1691, 1776)\n",
      "(1800, 1776)\n",
      "(1848, 1776)\n",
      "(1704, 1776)\n",
      "(1824, 1776)\n",
      "(958, 1776)\n",
      "(1680, 1776)\n",
      "(1860, 1776)\n",
      "{1: 5.480057669101618, 2: 5.044436838053312, 4: 10.0, 5: 4.6337369221183735, 6: 4.937331646963241, 8: 8.151011179229169, 9: 6.400303828630588, 10: 7.03125461815233, 11: 6.892439024491397, 12: 8.954157653853507, 13: 6.262563206045938, 19: 8.596480935092124, 21: 8.13162188611251, 22: 1.0, 25: 7.599246193121816, 26: 5.952315853487082, 27: 5.186777192199326, 28: 5.80093031447466, 29: 2.072771366950971}\n",
      "Train on 31687 samples, validate on 3538 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:15:33.622176: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 9.7565\n",
      "Epoch 1: val_loss improved from inf to 1.41292, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 54s 2ms/sample - loss: 9.7565 - val_loss: 1.4129\n",
      "Epoch 2/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.6384\n",
      "Epoch 2: val_loss improved from 1.41292 to 1.40464, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 735us/sample - loss: 9.6384 - val_loss: 1.4046\n",
      "Epoch 3/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.6718\n",
      "Epoch 3: val_loss improved from 1.40464 to 1.40243, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 734us/sample - loss: 9.6718 - val_loss: 1.4024\n",
      "Epoch 4/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.5488\n",
      "Epoch 4: val_loss improved from 1.40243 to 1.38666, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 22s 686us/sample - loss: 9.5488 - val_loss: 1.3867\n",
      "Epoch 5/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.5376\n",
      "Epoch 5: val_loss did not improve from 1.38666\n",
      "31687/31687 [==============================] - 23s 728us/sample - loss: 9.5376 - val_loss: 1.3887\n",
      "Epoch 6/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.5161\n",
      "Epoch 6: val_loss did not improve from 1.38666\n",
      "31687/31687 [==============================] - 23s 728us/sample - loss: 9.5161 - val_loss: 1.3962\n",
      "Epoch 7/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4932\n",
      "Epoch 7: val_loss did not improve from 1.38666\n",
      "31687/31687 [==============================] - 22s 698us/sample - loss: 9.4932 - val_loss: 1.3895\n",
      "Epoch 8/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4729\n",
      "Epoch 8: val_loss did not improve from 1.38666\n",
      "31687/31687 [==============================] - 22s 679us/sample - loss: 9.4729 - val_loss: 1.3868\n",
      "Epoch 9/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4641\n",
      "Epoch 9: val_loss did not improve from 1.38666\n",
      "31687/31687 [==============================] - 21s 652us/sample - loss: 9.4641 - val_loss: 1.4042\n",
      "Epoch 10/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4423\n",
      "Epoch 10: val_loss did not improve from 1.38666\n",
      "31687/31687 [==============================] - 21s 655us/sample - loss: 9.4423 - val_loss: 1.3945\n",
      "Epoch 11/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4317\n",
      "Epoch 11: val_loss improved from 1.38666 to 1.38030, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 665us/sample - loss: 9.4317 - val_loss: 1.3803\n",
      "Epoch 12/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4112\n",
      "Epoch 12: val_loss did not improve from 1.38030\n",
      "31687/31687 [==============================] - 23s 728us/sample - loss: 9.4112 - val_loss: 1.3833\n",
      "Epoch 13/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4161\n",
      "Epoch 13: val_loss did not improve from 1.38030\n",
      "31687/31687 [==============================] - 23s 732us/sample - loss: 9.4161 - val_loss: 1.3869\n",
      "Epoch 14/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.4180\n",
      "Epoch 14: val_loss did not improve from 1.38030\n",
      "31687/31687 [==============================] - 22s 681us/sample - loss: 9.4180 - val_loss: 1.3849\n",
      "Epoch 15/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.3859\n",
      "Epoch 15: val_loss did not improve from 1.38030\n",
      "31687/31687 [==============================] - 22s 707us/sample - loss: 9.3859 - val_loss: 1.3848\n",
      "Epoch 16/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.3931\n",
      "Epoch 16: val_loss did not improve from 1.38030\n",
      "31687/31687 [==============================] - 22s 704us/sample - loss: 9.3931 - val_loss: 1.3868\n",
      "Epoch 17/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.3866\n",
      "Epoch 17: val_loss improved from 1.38030 to 1.37978, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 740us/sample - loss: 9.3866 - val_loss: 1.3798\n",
      "Epoch 18/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.3792\n",
      "Epoch 18: val_loss improved from 1.37978 to 1.37753, saving model to ./checkpoints/unknown_person_few_shot_p17_35.h5\n",
      "31687/31687 [==============================] - 22s 697us/sample - loss: 9.3792 - val_loss: 1.3775\n",
      "Epoch 19/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.3420\n",
      "Epoch 19: val_loss did not improve from 1.37753\n",
      "31687/31687 [==============================] - 22s 691us/sample - loss: 9.3420 - val_loss: 1.3835\n",
      "Epoch 20/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 9.3620\n",
      "Epoch 20: val_loss did not improve from 1.37753\n",
      "31687/31687 [==============================] - 23s 738us/sample - loss: 9.3620 - val_loss: 1.3811\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:23:38.110722: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_23_2/bias/Assign' id:323067 op device:{requested: '', assigned: ''} def:{{{node conv2d_23_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_23_2/bias, conv2d_23_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:23:54.615513: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_20_2/kernel/v/Assign' id:330461 op device:{requested: '', assigned: ''} def:{{{node conv2d_20_2/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_20_2/kernel/v, conv2d_20_2/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31687 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:24:13.635408: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:25:40.759958: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:26:04.647525: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38573, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 55s 2ms/sample - loss: 1.4076 - val_loss: 1.3857\n",
      "Epoch 2/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4039\n",
      "Epoch 2: val_loss improved from 1.38573 to 1.38245, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 623us/sample - loss: 1.4039 - val_loss: 1.3824\n",
      "Epoch 3/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 3: val_loss did not improve from 1.38245\n",
      "31687/31687 [==============================] - 20s 621us/sample - loss: 1.4045 - val_loss: 1.3864\n",
      "Epoch 4/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4030\n",
      "Epoch 4: val_loss improved from 1.38245 to 1.37866, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 20s 623us/sample - loss: 1.4030 - val_loss: 1.3787\n",
      "Epoch 5/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 5: val_loss improved from 1.37866 to 1.37758, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 669us/sample - loss: 1.4011 - val_loss: 1.3776\n",
      "Epoch 6/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.4013\n",
      "Epoch 6: val_loss did not improve from 1.37758\n",
      "31687/31687 [==============================] - 23s 732us/sample - loss: 1.4013 - val_loss: 1.3796\n",
      "Epoch 7/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 7: val_loss did not improve from 1.37758\n",
      "31687/31687 [==============================] - 21s 658us/sample - loss: 1.3991 - val_loss: 1.3802\n",
      "Epoch 8/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3946\n",
      "Epoch 8: val_loss improved from 1.37758 to 1.37545, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 655us/sample - loss: 1.3946 - val_loss: 1.3755\n",
      "Epoch 9/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 9: val_loss did not improve from 1.37545\n",
      "31687/31687 [==============================] - 20s 646us/sample - loss: 1.3972 - val_loss: 1.3756\n",
      "Epoch 10/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3954\n",
      "Epoch 10: val_loss did not improve from 1.37545\n",
      "31687/31687 [==============================] - 22s 700us/sample - loss: 1.3954 - val_loss: 1.3785\n",
      "Epoch 11/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3923\n",
      "Epoch 11: val_loss improved from 1.37545 to 1.37071, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 719us/sample - loss: 1.3923 - val_loss: 1.3707\n",
      "Epoch 12/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 12: val_loss did not improve from 1.37071\n",
      "31687/31687 [==============================] - 23s 732us/sample - loss: 1.3912 - val_loss: 1.3732\n",
      "Epoch 13/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3906\n",
      "Epoch 13: val_loss improved from 1.37071 to 1.36815, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 23s 726us/sample - loss: 1.3906 - val_loss: 1.3682\n",
      "Epoch 14/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3895\n",
      "Epoch 14: val_loss did not improve from 1.36815\n",
      "31687/31687 [==============================] - 23s 724us/sample - loss: 1.3895 - val_loss: 1.3728\n",
      "Epoch 15/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3848\n",
      "Epoch 15: val_loss did not improve from 1.36815\n",
      "31687/31687 [==============================] - 23s 720us/sample - loss: 1.3848 - val_loss: 1.3715\n",
      "Epoch 16/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3855\n",
      "Epoch 16: val_loss did not improve from 1.36815\n",
      "31687/31687 [==============================] - 22s 700us/sample - loss: 1.3855 - val_loss: 1.3733\n",
      "Epoch 17/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3834\n",
      "Epoch 17: val_loss did not improve from 1.36815\n",
      "31687/31687 [==============================] - 22s 697us/sample - loss: 1.3834 - val_loss: 1.3687\n",
      "Epoch 18/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3841\n",
      "Epoch 18: val_loss improved from 1.36815 to 1.36696, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_35.h5\n",
      "31687/31687 [==============================] - 21s 670us/sample - loss: 1.3841 - val_loss: 1.3670\n",
      "Epoch 19/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3859\n",
      "Epoch 19: val_loss did not improve from 1.36696\n",
      "31687/31687 [==============================] - 21s 669us/sample - loss: 1.3859 - val_loss: 1.3670\n",
      "Epoch 20/20\n",
      "31687/31687 [==============================] - ETA: 0s - loss: 1.3808\n",
      "Epoch 20: val_loss did not improve from 1.36696\n",
      "31687/31687 [==============================] - 20s 641us/sample - loss: 1.3808 - val_loss: 1.3695\n",
      "35453\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:33:40.681256: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_239/lstm_cell_683/recurrent_kernel/Assign' id:345095 op device:{requested: '', assigned: ''} def:{{{node lstm_239/lstm_cell_683/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_239/lstm_cell_683/recurrent_kernel, lstm_239/lstm_cell_683/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:33:50.073853: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_1' id:345888 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:33:57.695970: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_2' id:345889 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31892, 95)\n",
      "Train on 31892 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:34:18.480499: W tensorflow/c/c_api.cc:304] Operation '{name:'training_36/Adam/lstm_224/lstm_cell_668/bias/v/Assign' id:359329 op device:{requested: '', assigned: ''} def:{{{node training_36/Adam/lstm_224/lstm_cell_668/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_36/Adam/lstm_224/lstm_cell_668/bias/v, training_36/Adam/lstm_224/lstm_cell_668/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:35:54.988507: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 2.7722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 13:36:17.417945: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_37/mul' id:348729 op device:{requested: '', assigned: ''} def:{{{node loss_37/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_37/mul/x, loss_37/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.86633, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 104s 3ms/sample - loss: 2.7722 - val_loss: 1.8663\n",
      "Epoch 2/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.7408\n",
      "Epoch 2: val_loss improved from 1.86633 to 1.55685, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 23s 729us/sample - loss: 1.7408 - val_loss: 1.5569\n",
      "Epoch 3/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5802\n",
      "Epoch 3: val_loss improved from 1.55685 to 1.49597, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 763us/sample - loss: 1.5802 - val_loss: 1.4960\n",
      "Epoch 4/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5312\n",
      "Epoch 4: val_loss improved from 1.49597 to 1.46933, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 758us/sample - loss: 1.5312 - val_loss: 1.4693\n",
      "Epoch 5/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5104\n",
      "Epoch 5: val_loss improved from 1.46933 to 1.46852, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 23s 710us/sample - loss: 1.5104 - val_loss: 1.4685\n",
      "Epoch 6/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4984\n",
      "Epoch 6: val_loss improved from 1.46852 to 1.44292, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 758us/sample - loss: 1.4984 - val_loss: 1.4429\n",
      "Epoch 7/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4880\n",
      "Epoch 7: val_loss improved from 1.44292 to 1.44095, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 22s 694us/sample - loss: 1.4880 - val_loss: 1.4409\n",
      "Epoch 8/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4793\n",
      "Epoch 8: val_loss improved from 1.44095 to 1.42956, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 22s 682us/sample - loss: 1.4793 - val_loss: 1.4296\n",
      "Epoch 9/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4811\n",
      "Epoch 9: val_loss improved from 1.42956 to 1.42187, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 22s 685us/sample - loss: 1.4811 - val_loss: 1.4219\n",
      "Epoch 10/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4699\n",
      "Epoch 10: val_loss did not improve from 1.42187\n",
      "31892/31892 [==============================] - 22s 676us/sample - loss: 1.4699 - val_loss: 1.4280\n",
      "Epoch 11/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4655\n",
      "Epoch 11: val_loss improved from 1.42187 to 1.41582, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 22s 685us/sample - loss: 1.4655 - val_loss: 1.4158\n",
      "Epoch 12/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4669\n",
      "Epoch 12: val_loss did not improve from 1.41582\n",
      "31892/31892 [==============================] - 21s 669us/sample - loss: 1.4669 - val_loss: 1.4239\n",
      "Epoch 13/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 13: val_loss did not improve from 1.41582\n",
      "31892/31892 [==============================] - 20s 642us/sample - loss: 1.4623 - val_loss: 1.4171\n",
      "Epoch 14/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4828\n",
      "Epoch 14: val_loss did not improve from 1.41582\n",
      "31892/31892 [==============================] - 21s 662us/sample - loss: 1.4828 - val_loss: 1.4253\n",
      "Epoch 15/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4819\n",
      "Epoch 15: val_loss improved from 1.41582 to 1.40777, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 21s 669us/sample - loss: 1.4819 - val_loss: 1.4078\n",
      "Epoch 16/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4645\n",
      "Epoch 16: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 21s 649us/sample - loss: 1.4645 - val_loss: 1.4183\n",
      "Epoch 17/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4578\n",
      "Epoch 17: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 21s 652us/sample - loss: 1.4578 - val_loss: 1.4124\n",
      "Epoch 18/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 18: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 21s 649us/sample - loss: 1.4597 - val_loss: 1.4106\n",
      "Epoch 19/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5042\n",
      "Epoch 19: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 22s 695us/sample - loss: 1.5042 - val_loss: 1.4094\n",
      "Epoch 20/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.6419\n",
      "Epoch 20: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 24s 745us/sample - loss: 1.6419 - val_loss: 1.4127\n",
      "Epoch 21/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5296\n",
      "Epoch 21: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 24s 744us/sample - loss: 1.5296 - val_loss: 1.4185\n",
      "Epoch 22/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5072\n",
      "Epoch 22: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 23s 737us/sample - loss: 1.5072 - val_loss: 1.4202\n",
      "Epoch 23/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4643\n",
      "Epoch 23: val_loss did not improve from 1.40777\n",
      "31892/31892 [==============================] - 24s 744us/sample - loss: 1.4643 - val_loss: 1.4137\n",
      "Epoch 24/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4522\n",
      "Epoch 24: val_loss improved from 1.40777 to 1.40568, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 746us/sample - loss: 1.4522 - val_loss: 1.4057\n",
      "Epoch 25/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4475\n",
      "Epoch 25: val_loss improved from 1.40568 to 1.39979, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 23s 714us/sample - loss: 1.4475 - val_loss: 1.3998\n",
      "Epoch 26/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4414\n",
      "Epoch 26: val_loss did not improve from 1.39979\n",
      "31892/31892 [==============================] - 24s 743us/sample - loss: 1.4414 - val_loss: 1.4021\n",
      "Epoch 27/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4401\n",
      "Epoch 27: val_loss improved from 1.39979 to 1.39814, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.4401 - val_loss: 1.3981\n",
      "Epoch 28/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4357\n",
      "Epoch 28: val_loss did not improve from 1.39814\n",
      "31892/31892 [==============================] - 23s 720us/sample - loss: 1.4357 - val_loss: 1.3993\n",
      "Epoch 29/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4292\n",
      "Epoch 29: val_loss improved from 1.39814 to 1.39530, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 22s 698us/sample - loss: 1.4292 - val_loss: 1.3953\n",
      "Epoch 30/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 30: val_loss did not improve from 1.39530\n",
      "31892/31892 [==============================] - 21s 661us/sample - loss: 1.4308 - val_loss: 1.3970\n",
      "Epoch 31/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 31: val_loss improved from 1.39530 to 1.38853, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 21s 656us/sample - loss: 1.4243 - val_loss: 1.3885\n",
      "Epoch 32/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 32: val_loss improved from 1.38853 to 1.38561, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 21s 656us/sample - loss: 1.4252 - val_loss: 1.3856\n",
      "Epoch 33/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4214\n",
      "Epoch 33: val_loss improved from 1.38561 to 1.38550, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 21s 649us/sample - loss: 1.4214 - val_loss: 1.3855\n",
      "Epoch 34/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4195\n",
      "Epoch 34: val_loss improved from 1.38550 to 1.38187, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 21s 643us/sample - loss: 1.4195 - val_loss: 1.3819\n",
      "Epoch 35/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4161\n",
      "Epoch 35: val_loss improved from 1.38187 to 1.38015, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 742us/sample - loss: 1.4161 - val_loss: 1.3802\n",
      "Epoch 36/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4142\n",
      "Epoch 36: val_loss improved from 1.38015 to 1.37952, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 758us/sample - loss: 1.4142 - val_loss: 1.3795\n",
      "Epoch 37/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4140\n",
      "Epoch 37: val_loss did not improve from 1.37952\n",
      "31892/31892 [==============================] - 24s 756us/sample - loss: 1.4140 - val_loss: 1.3840\n",
      "Epoch 38/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4130\n",
      "Epoch 38: val_loss did not improve from 1.37952\n",
      "31892/31892 [==============================] - 24s 746us/sample - loss: 1.4130 - val_loss: 1.3915\n",
      "Epoch 39/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4089\n",
      "Epoch 39: val_loss did not improve from 1.37952\n",
      "31892/31892 [==============================] - 24s 755us/sample - loss: 1.4089 - val_loss: 1.3873\n",
      "Epoch 40/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 40: val_loss improved from 1.37952 to 1.37766, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 761us/sample - loss: 1.4078 - val_loss: 1.3777\n",
      "Epoch 41/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4072\n",
      "Epoch 41: val_loss improved from 1.37766 to 1.37688, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 763us/sample - loss: 1.4072 - val_loss: 1.3769\n",
      "Epoch 42/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4057\n",
      "Epoch 42: val_loss did not improve from 1.37688\n",
      "31892/31892 [==============================] - 25s 771us/sample - loss: 1.4057 - val_loss: 1.3785\n",
      "Epoch 43/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4021\n",
      "Epoch 43: val_loss did not improve from 1.37688\n",
      "31892/31892 [==============================] - 24s 753us/sample - loss: 1.4021 - val_loss: 1.3774\n",
      "Epoch 44/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4031\n",
      "Epoch 44: val_loss improved from 1.37688 to 1.37433, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 753us/sample - loss: 1.4031 - val_loss: 1.3743\n",
      "Epoch 45/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4007\n",
      "Epoch 45: val_loss improved from 1.37433 to 1.37381, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 762us/sample - loss: 1.4007 - val_loss: 1.3738\n",
      "Epoch 46/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4014\n",
      "Epoch 46: val_loss did not improve from 1.37381\n",
      "31892/31892 [==============================] - 24s 756us/sample - loss: 1.4014 - val_loss: 1.3757\n",
      "Epoch 47/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3967\n",
      "Epoch 47: val_loss did not improve from 1.37381\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.3967 - val_loss: 1.3739\n",
      "Epoch 48/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 48: val_loss improved from 1.37381 to 1.36844, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.3953 - val_loss: 1.3684\n",
      "Epoch 49/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 49: val_loss did not improve from 1.36844\n",
      "31892/31892 [==============================] - 24s 756us/sample - loss: 1.3936 - val_loss: 1.3720\n",
      "Epoch 50/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3940\n",
      "Epoch 50: val_loss improved from 1.36844 to 1.36800, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 1.3940 - val_loss: 1.3680\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:56:26.972573: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_232_1/lstm_cell_713/bias/Assign' id:362521 op device:{requested: '', assigned: ''} def:{{{node lstm_232_1/lstm_cell_713/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_232_1/lstm_cell_713/bias, lstm_232_1/lstm_cell_713/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:56:45.606309: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_256_1/lstm_cell_737/bias/v/Assign' id:368667 op device:{requested: '', assigned: ''} def:{{{node lstm_256_1/lstm_cell_737/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_256_1/lstm_cell_737/bias/v, lstm_256_1/lstm_cell_737/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 13:57:04.002341: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_34_1/cond/Merge' id:366843 op device:{requested: '', assigned: ''} def:{{{node dropout_34_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_34_1/cond/Identity, dropout_34_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1548)\n",
      "(1514, 1548)\n",
      "(1644, 1548)\n",
      "(1764, 1548)\n",
      "(1836, 1548)\n",
      "(1699, 1548)\n",
      "(1369, 1548)\n",
      "(1778, 1548)\n",
      "(1631, 1548)\n",
      "(1692, 1548)\n",
      "(1550, 1548)\n",
      "(1727, 1548)\n",
      "(1788, 1548)\n",
      "(1836, 1548)\n",
      "(1728, 1548)\n",
      "(1812, 1548)\n",
      "(959, 1548)\n",
      "(1668, 1548)\n",
      "(1872, 1548)\n",
      "{1: 6.31951268539791, 2: 6.02803812090344, 4: 10.0, 5: 5.393380426092791, 6: 5.400564580749917, 8: 8.66847241943641, 9: 7.041268273609178, 10: 7.54190802776735, 11: 7.165509540781344, 12: 9.201694201183866, 13: 6.685305663889503, 19: 8.577625493239442, 21: 8.76552321701801, 22: 1.0, 25: 7.707341844419499, 26: 6.142175035636234, 27: 5.745443931560073, 28: 5.64597959946066, 29: 1.932250768944112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907972/3306004915.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31892 samples, validate on 3561 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:03:07.493018: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 10.6702\n",
      "Epoch 1: val_loss improved from inf to 1.39935, saving model to ./checkpoints/unknown_person_few_shot_p17_36.h5\n",
      "31892/31892 [==============================] - 57s 2ms/sample - loss: 10.6702 - val_loss: 1.3994\n",
      "Epoch 2/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.5248\n",
      "Epoch 2: val_loss improved from 1.39935 to 1.38177, saving model to ./checkpoints/unknown_person_few_shot_p17_36.h5\n",
      "31892/31892 [==============================] - 21s 662us/sample - loss: 10.5248 - val_loss: 1.3818\n",
      "Epoch 3/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.4501\n",
      "Epoch 3: val_loss did not improve from 1.38177\n",
      "31892/31892 [==============================] - 23s 713us/sample - loss: 10.4501 - val_loss: 1.4017\n",
      "Epoch 4/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.5130\n",
      "Epoch 4: val_loss did not improve from 1.38177\n",
      "31892/31892 [==============================] - 21s 665us/sample - loss: 10.5130 - val_loss: 1.3839\n",
      "Epoch 5/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.4135\n",
      "Epoch 5: val_loss did not improve from 1.38177\n",
      "31892/31892 [==============================] - 21s 654us/sample - loss: 10.4135 - val_loss: 1.3865\n",
      "Epoch 6/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.4318\n",
      "Epoch 6: val_loss did not improve from 1.38177\n",
      "31892/31892 [==============================] - 22s 690us/sample - loss: 10.4318 - val_loss: 1.3914\n",
      "Epoch 7/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3684\n",
      "Epoch 7: val_loss improved from 1.38177 to 1.37963, saving model to ./checkpoints/unknown_person_few_shot_p17_36.h5\n",
      "31892/31892 [==============================] - 22s 684us/sample - loss: 10.3684 - val_loss: 1.3796\n",
      "Epoch 8/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3488\n",
      "Epoch 8: val_loss improved from 1.37963 to 1.37864, saving model to ./checkpoints/unknown_person_few_shot_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 757us/sample - loss: 10.3488 - val_loss: 1.3786\n",
      "Epoch 9/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2786\n",
      "Epoch 9: val_loss improved from 1.37864 to 1.37779, saving model to ./checkpoints/unknown_person_few_shot_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 753us/sample - loss: 10.2786 - val_loss: 1.3778\n",
      "Epoch 10/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2860\n",
      "Epoch 10: val_loss improved from 1.37779 to 1.37695, saving model to ./checkpoints/unknown_person_few_shot_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 752us/sample - loss: 10.2860 - val_loss: 1.3770\n",
      "Epoch 11/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3098\n",
      "Epoch 11: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 23s 731us/sample - loss: 10.3098 - val_loss: 1.3855\n",
      "Epoch 12/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2864\n",
      "Epoch 12: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 24s 741us/sample - loss: 10.2864 - val_loss: 1.3840\n",
      "Epoch 13/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2458\n",
      "Epoch 13: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 23s 714us/sample - loss: 10.2458 - val_loss: 1.3836\n",
      "Epoch 14/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2652\n",
      "Epoch 14: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 22s 700us/sample - loss: 10.2652 - val_loss: 1.3785\n",
      "Epoch 15/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2452\n",
      "Epoch 15: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 24s 743us/sample - loss: 10.2452 - val_loss: 1.3912\n",
      "Epoch 16/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2262\n",
      "Epoch 16: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 23s 733us/sample - loss: 10.2262 - val_loss: 1.3912\n",
      "Epoch 17/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2074\n",
      "Epoch 17: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 10.2074 - val_loss: 1.3794\n",
      "Epoch 18/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1725\n",
      "Epoch 18: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 24s 746us/sample - loss: 10.1725 - val_loss: 1.3811\n",
      "Epoch 19/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1874\n",
      "Epoch 19: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 23s 732us/sample - loss: 10.1874 - val_loss: 1.3827\n",
      "Epoch 20/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1783\n",
      "Epoch 20: val_loss did not improve from 1.37695\n",
      "31892/31892 [==============================] - 24s 743us/sample - loss: 10.1783 - val_loss: 1.3796\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:11:28.677048: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_25_2/bias/Assign' id:386256 op device:{requested: '', assigned: ''} def:{{{node dense_25_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_25_2/bias, dense_25_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:11:48.553522: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_242_2/lstm_cell_760/bias/m/Assign' id:387212 op device:{requested: '', assigned: ''} def:{{{node lstm_242_2/lstm_cell_760/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_242_2/lstm_cell_760/bias/m, lstm_242_2/lstm_cell_760/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31892 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:12:10.957209: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:13:55.742783: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:14:21.144080: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36817, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 63s 2ms/sample - loss: 1.3937 - val_loss: 1.3682\n",
      "Epoch 2/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3877\n",
      "Epoch 2: val_loss improved from 1.36817 to 1.36587, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.3877 - val_loss: 1.3659\n",
      "Epoch 3/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3892\n",
      "Epoch 3: val_loss improved from 1.36587 to 1.36574, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 740us/sample - loss: 1.3892 - val_loss: 1.3657\n",
      "Epoch 4/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3898\n",
      "Epoch 4: val_loss did not improve from 1.36574\n",
      "31892/31892 [==============================] - 23s 734us/sample - loss: 1.3898 - val_loss: 1.3662\n",
      "Epoch 5/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3860\n",
      "Epoch 5: val_loss improved from 1.36574 to 1.35939, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 23s 735us/sample - loss: 1.3860 - val_loss: 1.3594\n",
      "Epoch 6/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3833\n",
      "Epoch 6: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 22s 699us/sample - loss: 1.3833 - val_loss: 1.3621\n",
      "Epoch 7/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 7: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 22s 679us/sample - loss: 1.3830 - val_loss: 1.3617\n",
      "Epoch 8/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3810\n",
      "Epoch 8: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 23s 706us/sample - loss: 1.3810 - val_loss: 1.3655\n",
      "Epoch 9/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3792\n",
      "Epoch 9: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 22s 686us/sample - loss: 1.3792 - val_loss: 1.3688\n",
      "Epoch 10/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3773\n",
      "Epoch 10: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 21s 648us/sample - loss: 1.3773 - val_loss: 1.3629\n",
      "Epoch 11/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3767\n",
      "Epoch 11: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 21s 646us/sample - loss: 1.3767 - val_loss: 1.3720\n",
      "Epoch 12/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3766\n",
      "Epoch 12: val_loss did not improve from 1.35939\n",
      "31892/31892 [==============================] - 22s 679us/sample - loss: 1.3766 - val_loss: 1.3620\n",
      "Epoch 13/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3746\n",
      "Epoch 13: val_loss improved from 1.35939 to 1.35757, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 23s 734us/sample - loss: 1.3746 - val_loss: 1.3576\n",
      "Epoch 14/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3741\n",
      "Epoch 14: val_loss improved from 1.35757 to 1.35746, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.3741 - val_loss: 1.3575\n",
      "Epoch 15/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3746\n",
      "Epoch 15: val_loss did not improve from 1.35746\n",
      "31892/31892 [==============================] - 25s 770us/sample - loss: 1.3746 - val_loss: 1.3683\n",
      "Epoch 16/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3699\n",
      "Epoch 16: val_loss did not improve from 1.35746\n",
      "31892/31892 [==============================] - 25s 774us/sample - loss: 1.3699 - val_loss: 1.3628\n",
      "Epoch 17/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3733\n",
      "Epoch 17: val_loss did not improve from 1.35746\n",
      "31892/31892 [==============================] - 24s 767us/sample - loss: 1.3733 - val_loss: 1.3645\n",
      "Epoch 18/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3696\n",
      "Epoch 18: val_loss did not improve from 1.35746\n",
      "31892/31892 [==============================] - 25s 773us/sample - loss: 1.3696 - val_loss: 1.3576\n",
      "Epoch 19/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3667\n",
      "Epoch 19: val_loss did not improve from 1.35746\n",
      "31892/31892 [==============================] - 24s 765us/sample - loss: 1.3667 - val_loss: 1.3603\n",
      "Epoch 20/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3664\n",
      "Epoch 20: val_loss improved from 1.35746 to 1.35449, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_36.h5\n",
      "31892/31892 [==============================] - 25s 774us/sample - loss: 1.3664 - val_loss: 1.3545\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:22:26.606730: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_259/lstm_cell_777/bias/Assign' id:399341 op device:{requested: '', assigned: ''} def:{{{node lstm_259/lstm_cell_777/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_259/lstm_cell_777/bias, lstm_259/lstm_cell_777/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:22:37.582596: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_1' id:402930 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:22:46.578051: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_2' id:402931 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31892, 95)\n",
      "Train on 31892 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:23:09.401367: W tensorflow/c/c_api.cc:304] Operation '{name:'training_42/Adam/conv2d_28/kernel/m/Assign' id:415646 op device:{requested: '', assigned: ''} def:{{{node training_42/Adam/conv2d_28/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_42/Adam/conv2d_28/kernel/m, training_42/Adam/conv2d_28/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:25:00.137004: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 2.8471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:25:25.543789: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_43/mul' id:405771 op device:{requested: '', assigned: ''} def:{{{node loss_43/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_43/mul/x, loss_43/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.83640, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 122s 4ms/sample - loss: 2.8471 - val_loss: 1.8364\n",
      "Epoch 2/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.7486\n",
      "Epoch 2: val_loss improved from 1.83640 to 1.55983, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 746us/sample - loss: 1.7486 - val_loss: 1.5598\n",
      "Epoch 3/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5868\n",
      "Epoch 3: val_loss improved from 1.55983 to 1.51007, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.5868 - val_loss: 1.5101\n",
      "Epoch 4/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5443\n",
      "Epoch 4: val_loss improved from 1.51007 to 1.48118, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.5443 - val_loss: 1.4812\n",
      "Epoch 5/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5171\n",
      "Epoch 5: val_loss improved from 1.48118 to 1.46265, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 749us/sample - loss: 1.5171 - val_loss: 1.4626\n",
      "Epoch 6/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5037\n",
      "Epoch 6: val_loss improved from 1.46265 to 1.45636, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 752us/sample - loss: 1.5037 - val_loss: 1.4564\n",
      "Epoch 7/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4917\n",
      "Epoch 7: val_loss improved from 1.45636 to 1.44952, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 754us/sample - loss: 1.4917 - val_loss: 1.4495\n",
      "Epoch 8/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4890\n",
      "Epoch 8: val_loss improved from 1.44952 to 1.43952, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 1.4890 - val_loss: 1.4395\n",
      "Epoch 9/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4933\n",
      "Epoch 9: val_loss improved from 1.43952 to 1.43615, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 1.4933 - val_loss: 1.4362\n",
      "Epoch 10/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4930\n",
      "Epoch 10: val_loss did not improve from 1.43615\n",
      "31892/31892 [==============================] - 24s 757us/sample - loss: 1.4930 - val_loss: 1.4501\n",
      "Epoch 11/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5097\n",
      "Epoch 11: val_loss did not improve from 1.43615\n",
      "31892/31892 [==============================] - 24s 756us/sample - loss: 1.5097 - val_loss: 1.4379\n",
      "Epoch 12/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4861\n",
      "Epoch 12: val_loss improved from 1.43615 to 1.43597, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 23s 726us/sample - loss: 1.4861 - val_loss: 1.4360\n",
      "Epoch 13/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4851\n",
      "Epoch 13: val_loss improved from 1.43597 to 1.42341, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 761us/sample - loss: 1.4851 - val_loss: 1.4234\n",
      "Epoch 14/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4730\n",
      "Epoch 14: val_loss did not improve from 1.42341\n",
      "31892/31892 [==============================] - 24s 756us/sample - loss: 1.4730 - val_loss: 1.4314\n",
      "Epoch 15/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4842\n",
      "Epoch 15: val_loss improved from 1.42341 to 1.42061, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 25s 769us/sample - loss: 1.4842 - val_loss: 1.4206\n",
      "Epoch 16/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5093\n",
      "Epoch 16: val_loss did not improve from 1.42061\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.5093 - val_loss: 1.4221\n",
      "Epoch 17/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4851\n",
      "Epoch 17: val_loss did not improve from 1.42061\n",
      "31892/31892 [==============================] - 24s 762us/sample - loss: 1.4851 - val_loss: 1.4228\n",
      "Epoch 18/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5056\n",
      "Epoch 18: val_loss did not improve from 1.42061\n",
      "31892/31892 [==============================] - 23s 712us/sample - loss: 1.5056 - val_loss: 1.4236\n",
      "Epoch 19/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4837\n",
      "Epoch 19: val_loss improved from 1.42061 to 1.41890, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 21s 644us/sample - loss: 1.4837 - val_loss: 1.4189\n",
      "Epoch 20/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5084\n",
      "Epoch 20: val_loss did not improve from 1.41890\n",
      "31892/31892 [==============================] - 20s 633us/sample - loss: 1.5084 - val_loss: 1.4277\n",
      "Epoch 21/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4842\n",
      "Epoch 21: val_loss did not improve from 1.41890\n",
      "31892/31892 [==============================] - 22s 678us/sample - loss: 1.4842 - val_loss: 1.4261\n",
      "Epoch 22/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5227\n",
      "Epoch 22: val_loss did not improve from 1.41890\n",
      "31892/31892 [==============================] - 23s 732us/sample - loss: 1.5227 - val_loss: 1.4273\n",
      "Epoch 23/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4934\n",
      "Epoch 23: val_loss did not improve from 1.41890\n",
      "31892/31892 [==============================] - 21s 647us/sample - loss: 1.4934 - val_loss: 1.4237\n",
      "Epoch 24/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 24: val_loss did not improve from 1.41890\n",
      "31892/31892 [==============================] - 24s 741us/sample - loss: 1.4751 - val_loss: 1.4239\n",
      "Epoch 25/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4638\n",
      "Epoch 25: val_loss did not improve from 1.41890\n",
      "31892/31892 [==============================] - 24s 743us/sample - loss: 1.4638 - val_loss: 1.4200\n",
      "Epoch 26/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4568\n",
      "Epoch 26: val_loss improved from 1.41890 to 1.41708, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 23s 710us/sample - loss: 1.4568 - val_loss: 1.4171\n",
      "Epoch 27/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4510\n",
      "Epoch 27: val_loss improved from 1.41708 to 1.41457, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 747us/sample - loss: 1.4510 - val_loss: 1.4146\n",
      "Epoch 28/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4490\n",
      "Epoch 28: val_loss improved from 1.41457 to 1.40899, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 1.4490 - val_loss: 1.4090\n",
      "Epoch 29/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4449\n",
      "Epoch 29: val_loss improved from 1.40899 to 1.40688, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.4449 - val_loss: 1.4069\n",
      "Epoch 30/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4408\n",
      "Epoch 30: val_loss improved from 1.40688 to 1.40520, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 746us/sample - loss: 1.4408 - val_loss: 1.4052\n",
      "Epoch 31/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 31: val_loss did not improve from 1.40520\n",
      "31892/31892 [==============================] - 23s 721us/sample - loss: 1.4375 - val_loss: 1.4068\n",
      "Epoch 32/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 32: val_loss improved from 1.40520 to 1.40295, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 752us/sample - loss: 1.4330 - val_loss: 1.4030\n",
      "Epoch 33/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 33: val_loss improved from 1.40295 to 1.39781, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.4312 - val_loss: 1.3978\n",
      "Epoch 34/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4290\n",
      "Epoch 34: val_loss improved from 1.39781 to 1.39489, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.4290 - val_loss: 1.3949\n",
      "Epoch 35/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4276\n",
      "Epoch 35: val_loss improved from 1.39489 to 1.39367, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 1.4276 - val_loss: 1.3937\n",
      "Epoch 36/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4260\n",
      "Epoch 36: val_loss did not improve from 1.39367\n",
      "31892/31892 [==============================] - 24s 745us/sample - loss: 1.4260 - val_loss: 1.3992\n",
      "Epoch 37/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4222\n",
      "Epoch 37: val_loss did not improve from 1.39367\n",
      "31892/31892 [==============================] - 23s 706us/sample - loss: 1.4222 - val_loss: 1.3980\n",
      "Epoch 38/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4203\n",
      "Epoch 38: val_loss improved from 1.39367 to 1.38615, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 23s 731us/sample - loss: 1.4203 - val_loss: 1.3862\n",
      "Epoch 39/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4224\n",
      "Epoch 39: val_loss improved from 1.38615 to 1.38221, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 746us/sample - loss: 1.4224 - val_loss: 1.3822\n",
      "Epoch 40/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 40: val_loss did not improve from 1.38221\n",
      "31892/31892 [==============================] - 21s 668us/sample - loss: 1.4178 - val_loss: 1.3874\n",
      "Epoch 41/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 41: val_loss did not improve from 1.38221\n",
      "31892/31892 [==============================] - 22s 675us/sample - loss: 1.4173 - val_loss: 1.3862\n",
      "Epoch 42/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 42: val_loss did not improve from 1.38221\n",
      "31892/31892 [==============================] - 24s 760us/sample - loss: 1.4149 - val_loss: 1.3852\n",
      "Epoch 43/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 43: val_loss improved from 1.38221 to 1.38070, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 768us/sample - loss: 1.4124 - val_loss: 1.3807\n",
      "Epoch 44/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4121\n",
      "Epoch 44: val_loss improved from 1.38070 to 1.37923, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 25s 782us/sample - loss: 1.4121 - val_loss: 1.3792\n",
      "Epoch 45/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4072\n",
      "Epoch 45: val_loss did not improve from 1.37923\n",
      "31892/31892 [==============================] - 24s 741us/sample - loss: 1.4072 - val_loss: 1.3844\n",
      "Epoch 46/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4086\n",
      "Epoch 46: val_loss did not improve from 1.37923\n",
      "31892/31892 [==============================] - 20s 633us/sample - loss: 1.4086 - val_loss: 1.3851\n",
      "Epoch 47/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 47: val_loss improved from 1.37923 to 1.37900, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_37.h5\n",
      "31892/31892 [==============================] - 21s 645us/sample - loss: 1.4070 - val_loss: 1.3790\n",
      "Epoch 48/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 48: val_loss did not improve from 1.37900\n",
      "31892/31892 [==============================] - 20s 639us/sample - loss: 1.4055 - val_loss: 1.3820\n",
      "Epoch 49/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 49: val_loss did not improve from 1.37900\n",
      "31892/31892 [==============================] - 20s 636us/sample - loss: 1.4042 - val_loss: 1.3804\n",
      "Epoch 50/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4002\n",
      "Epoch 50: val_loss did not improve from 1.37900\n",
      "31892/31892 [==============================] - 20s 634us/sample - loss: 1.4002 - val_loss: 1.3805\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:46:03.242957: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_277_1/lstm_cell_832/kernel/Assign' id:420814 op device:{requested: '', assigned: ''} def:{{{node lstm_277_1/lstm_cell_832/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_277_1/lstm_cell_832/kernel, lstm_277_1/lstm_cell_832/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:46:24.852855: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_273_1/lstm_cell_828/kernel/v/Assign' id:425399 op device:{requested: '', assigned: ''} def:{{{node lstm_273_1/lstm_cell_828/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_273_1/lstm_cell_828/kernel/v, lstm_273_1/lstm_cell_828/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:46:46.304891: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_39_1/cond/Merge' id:423885 op device:{requested: '', assigned: ''} def:{{{node dropout_39_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_39_1/cond/Identity, dropout_39_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1548)\n",
      "(1514, 1548)\n",
      "(1644, 1548)\n",
      "(1764, 1548)\n",
      "(1836, 1548)\n",
      "(1699, 1548)\n",
      "(1369, 1548)\n",
      "(1778, 1548)\n",
      "(1631, 1548)\n",
      "(1692, 1548)\n",
      "(1550, 1548)\n",
      "(1727, 1548)\n",
      "(1788, 1548)\n",
      "(1836, 1548)\n",
      "(1728, 1548)\n",
      "(1812, 1548)\n",
      "(959, 1548)\n",
      "(1668, 1548)\n",
      "(1872, 1548)\n",
      "{1: 6.229406199965516, 2: 5.329786094526419, 4: 10.0, 5: 4.624807101529935, 6: 5.124468841273573, 8: 8.721570366776357, 9: 7.065703453534535, 10: 7.180336670529192, 11: 6.675590167744288, 12: 9.550320257630357, 13: 6.548943134306682, 19: 8.79012823749933, 21: 8.690728034469304, 22: 1.0, 25: 8.281945796508717, 26: 6.43201220012183, 27: 5.210307460031141, 28: 6.492275418163993, 29: 2.292850202047527}\n",
      "Train on 31892 samples, validate on 3561 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:52:21.008614: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 10.6443\n",
      "Epoch 1: val_loss improved from inf to 1.40813, saving model to ./checkpoints/unknown_person_few_shot_p17_37.h5\n",
      "31892/31892 [==============================] - 63s 2ms/sample - loss: 10.6443 - val_loss: 1.4081\n",
      "Epoch 2/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.5950\n",
      "Epoch 2: val_loss improved from 1.40813 to 1.38914, saving model to ./checkpoints/unknown_person_few_shot_p17_37.h5\n",
      "31892/31892 [==============================] - 21s 661us/sample - loss: 10.5950 - val_loss: 1.3891\n",
      "Epoch 3/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.5141\n",
      "Epoch 3: val_loss did not improve from 1.38914\n",
      "31892/31892 [==============================] - 21s 650us/sample - loss: 10.5141 - val_loss: 1.4077\n",
      "Epoch 4/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.5386\n",
      "Epoch 4: val_loss improved from 1.38914 to 1.38711, saving model to ./checkpoints/unknown_person_few_shot_p17_37.h5\n",
      "31892/31892 [==============================] - 21s 659us/sample - loss: 10.5386 - val_loss: 1.3871\n",
      "Epoch 5/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.4684\n",
      "Epoch 5: val_loss did not improve from 1.38711\n",
      "31892/31892 [==============================] - 21s 656us/sample - loss: 10.4684 - val_loss: 1.3872\n",
      "Epoch 6/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.4218\n",
      "Epoch 6: val_loss did not improve from 1.38711\n",
      "31892/31892 [==============================] - 21s 663us/sample - loss: 10.4218 - val_loss: 1.3904\n",
      "Epoch 7/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.4244\n",
      "Epoch 7: val_loss did not improve from 1.38711\n",
      "31892/31892 [==============================] - 23s 713us/sample - loss: 10.4244 - val_loss: 1.3909\n",
      "Epoch 8/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3800\n",
      "Epoch 8: val_loss did not improve from 1.38711\n",
      "31892/31892 [==============================] - 20s 640us/sample - loss: 10.3800 - val_loss: 1.3969\n",
      "Epoch 9/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3437\n",
      "Epoch 9: val_loss improved from 1.38711 to 1.38494, saving model to ./checkpoints/unknown_person_few_shot_p17_37.h5\n",
      "31892/31892 [==============================] - 21s 647us/sample - loss: 10.3437 - val_loss: 1.3849\n",
      "Epoch 10/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3703\n",
      "Epoch 10: val_loss improved from 1.38494 to 1.38177, saving model to ./checkpoints/unknown_person_few_shot_p17_37.h5\n",
      "31892/31892 [==============================] - 21s 650us/sample - loss: 10.3703 - val_loss: 1.3818\n",
      "Epoch 11/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3410\n",
      "Epoch 11: val_loss improved from 1.38177 to 1.37208, saving model to ./checkpoints/unknown_person_few_shot_p17_37.h5\n",
      "31892/31892 [==============================] - 23s 706us/sample - loss: 10.3410 - val_loss: 1.3721\n",
      "Epoch 12/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2969\n",
      "Epoch 12: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 22s 704us/sample - loss: 10.2969 - val_loss: 1.3919\n",
      "Epoch 13/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3374\n",
      "Epoch 13: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 21s 664us/sample - loss: 10.3374 - val_loss: 1.3775\n",
      "Epoch 14/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3643\n",
      "Epoch 14: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 21s 659us/sample - loss: 10.3643 - val_loss: 1.3806\n",
      "Epoch 15/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.3285\n",
      "Epoch 15: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 22s 690us/sample - loss: 10.3285 - val_loss: 1.3786\n",
      "Epoch 16/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2973\n",
      "Epoch 16: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 24s 747us/sample - loss: 10.2973 - val_loss: 1.3856\n",
      "Epoch 17/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2462\n",
      "Epoch 17: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 23s 736us/sample - loss: 10.2462 - val_loss: 1.3771\n",
      "Epoch 18/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2544\n",
      "Epoch 18: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 24s 747us/sample - loss: 10.2544 - val_loss: 1.3791\n",
      "Epoch 19/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2637\n",
      "Epoch 19: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 10.2637 - val_loss: 1.3794\n",
      "Epoch 20/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2370\n",
      "Epoch 20: val_loss did not improve from 1.37208\n",
      "31892/31892 [==============================] - 23s 723us/sample - loss: 10.2370 - val_loss: 1.3824\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:00:30.403741: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_289_2/lstm_cell_881/bias/Assign' id:442163 op device:{requested: '', assigned: ''} def:{{{node lstm_289_2/lstm_cell_881/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_289_2/lstm_cell_881/bias, lstm_289_2/lstm_cell_881/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:00:53.393380: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_278_2/lstm_cell_870/recurrent_kernel/v/Assign' id:444877 op device:{requested: '', assigned: ''} def:{{{node lstm_278_2/lstm_cell_870/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_278_2/lstm_cell_870/recurrent_kernel/v, lstm_278_2/lstm_cell_870/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31892 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:01:18.913423: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:03:19.366129: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:03:44.556846: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38212, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 67s 2ms/sample - loss: 1.4045 - val_loss: 1.3821\n",
      "Epoch 2/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4020\n",
      "Epoch 2: val_loss improved from 1.38212 to 1.37815, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 22s 701us/sample - loss: 1.4020 - val_loss: 1.3781\n",
      "Epoch 3/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4018\n",
      "Epoch 3: val_loss improved from 1.37815 to 1.37465, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 755us/sample - loss: 1.4018 - val_loss: 1.3746\n",
      "Epoch 4/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 4: val_loss improved from 1.37465 to 1.37257, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 751us/sample - loss: 1.3977 - val_loss: 1.3726\n",
      "Epoch 5/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3982\n",
      "Epoch 5: val_loss did not improve from 1.37257\n",
      "31892/31892 [==============================] - 22s 696us/sample - loss: 1.3982 - val_loss: 1.3771\n",
      "Epoch 6/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 6: val_loss improved from 1.37257 to 1.37244, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 23s 708us/sample - loss: 1.3980 - val_loss: 1.3724\n",
      "Epoch 7/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3930\n",
      "Epoch 7: val_loss did not improve from 1.37244\n",
      "31892/31892 [==============================] - 24s 752us/sample - loss: 1.3930 - val_loss: 1.3734\n",
      "Epoch 8/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 8: val_loss improved from 1.37244 to 1.36723, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 754us/sample - loss: 1.3896 - val_loss: 1.3672\n",
      "Epoch 9/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 9: val_loss did not improve from 1.36723\n",
      "31892/31892 [==============================] - 24s 757us/sample - loss: 1.3905 - val_loss: 1.3702\n",
      "Epoch 10/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3860\n",
      "Epoch 10: val_loss did not improve from 1.36723\n",
      "31892/31892 [==============================] - 24s 761us/sample - loss: 1.3860 - val_loss: 1.3743\n",
      "Epoch 11/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3861\n",
      "Epoch 11: val_loss did not improve from 1.36723\n",
      "31892/31892 [==============================] - 22s 676us/sample - loss: 1.3861 - val_loss: 1.3679\n",
      "Epoch 12/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 12: val_loss improved from 1.36723 to 1.36195, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 23s 709us/sample - loss: 1.3882 - val_loss: 1.3620\n",
      "Epoch 13/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3835\n",
      "Epoch 13: val_loss did not improve from 1.36195\n",
      "31892/31892 [==============================] - 24s 741us/sample - loss: 1.3835 - val_loss: 1.3679\n",
      "Epoch 14/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3826\n",
      "Epoch 14: val_loss did not improve from 1.36195\n",
      "31892/31892 [==============================] - 23s 731us/sample - loss: 1.3826 - val_loss: 1.3661\n",
      "Epoch 15/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 15: val_loss did not improve from 1.36195\n",
      "31892/31892 [==============================] - 23s 727us/sample - loss: 1.3796 - val_loss: 1.3623\n",
      "Epoch 16/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3764\n",
      "Epoch 16: val_loss did not improve from 1.36195\n",
      "31892/31892 [==============================] - 24s 739us/sample - loss: 1.3764 - val_loss: 1.3699\n",
      "Epoch 17/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3779\n",
      "Epoch 17: val_loss did not improve from 1.36195\n",
      "31892/31892 [==============================] - 21s 647us/sample - loss: 1.3779 - val_loss: 1.3675\n",
      "Epoch 18/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3763\n",
      "Epoch 18: val_loss did not improve from 1.36195\n",
      "31892/31892 [==============================] - 21s 662us/sample - loss: 1.3763 - val_loss: 1.3645\n",
      "Epoch 19/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3770\n",
      "Epoch 19: val_loss improved from 1.36195 to 1.36128, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_37.h5\n",
      "31892/31892 [==============================] - 24s 749us/sample - loss: 1.3770 - val_loss: 1.3613\n",
      "Epoch 20/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3749\n",
      "Epoch 20: val_loss did not improve from 1.36128\n",
      "31892/31892 [==============================] - 23s 706us/sample - loss: 1.3749 - val_loss: 1.3649\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:11:53.308111: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_302/lstm_cell_894/kernel/Assign' id:457344 op device:{requested: '', assigned: ''} def:{{{node lstm_302/lstm_cell_894/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_302/lstm_cell_894/kernel, lstm_302/lstm_cell_894/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:12:06.860919: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_1' id:459972 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:12:17.827963: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_2' id:459973 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31892, 95)\n",
      "Train on 31892 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:12:43.998350: W tensorflow/c/c_api.cc:304] Operation '{name:'training_48/Adam/lstm_326/lstm_cell_918/bias/v/Assign' id:473833 op device:{requested: '', assigned: ''} def:{{{node training_48/Adam/lstm_326/lstm_cell_918/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_48/Adam/lstm_326/lstm_cell_918/bias/v, training_48/Adam/lstm_326/lstm_cell_918/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:14:53.141734: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 3.2739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:15:16.191144: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_49/mul' id:462813 op device:{requested: '', assigned: ''} def:{{{node loss_49/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_49/mul/x, loss_49/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.86522, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 139s 4ms/sample - loss: 3.2739 - val_loss: 1.8652\n",
      "Epoch 2/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.8026\n",
      "Epoch 2: val_loss improved from 1.86522 to 1.59938, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 654us/sample - loss: 1.8026 - val_loss: 1.5994\n",
      "Epoch 3/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.6148\n",
      "Epoch 3: val_loss improved from 1.59938 to 1.52510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 648us/sample - loss: 1.6148 - val_loss: 1.5251\n",
      "Epoch 4/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5500\n",
      "Epoch 4: val_loss improved from 1.52510 to 1.49015, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 651us/sample - loss: 1.5500 - val_loss: 1.4902\n",
      "Epoch 5/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5230\n",
      "Epoch 5: val_loss improved from 1.49015 to 1.47245, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 22s 692us/sample - loss: 1.5230 - val_loss: 1.4724\n",
      "Epoch 6/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5053\n",
      "Epoch 6: val_loss improved from 1.47245 to 1.45535, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 24s 744us/sample - loss: 1.5053 - val_loss: 1.4553\n",
      "Epoch 7/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4921\n",
      "Epoch 7: val_loss improved from 1.45535 to 1.44648, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 658us/sample - loss: 1.4921 - val_loss: 1.4465\n",
      "Epoch 8/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4957\n",
      "Epoch 8: val_loss improved from 1.44648 to 1.44407, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 648us/sample - loss: 1.4957 - val_loss: 1.4441\n",
      "Epoch 9/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5195\n",
      "Epoch 9: val_loss improved from 1.44407 to 1.44316, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 20s 640us/sample - loss: 1.5195 - val_loss: 1.4432\n",
      "Epoch 10/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4959\n",
      "Epoch 10: val_loss improved from 1.44316 to 1.43623, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 661us/sample - loss: 1.4959 - val_loss: 1.4362\n",
      "Epoch 11/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4806\n",
      "Epoch 11: val_loss improved from 1.43623 to 1.43452, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 22s 685us/sample - loss: 1.4806 - val_loss: 1.4345\n",
      "Epoch 12/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4989\n",
      "Epoch 12: val_loss improved from 1.43452 to 1.42393, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 665us/sample - loss: 1.4989 - val_loss: 1.4239\n",
      "Epoch 13/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5583\n",
      "Epoch 13: val_loss did not improve from 1.42393\n",
      "31892/31892 [==============================] - 23s 720us/sample - loss: 1.5583 - val_loss: 1.4444\n",
      "Epoch 14/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5085\n",
      "Epoch 14: val_loss did not improve from 1.42393\n",
      "31892/31892 [==============================] - 24s 738us/sample - loss: 1.5085 - val_loss: 1.4274\n",
      "Epoch 15/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4961\n",
      "Epoch 15: val_loss improved from 1.42393 to 1.42131, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 735us/sample - loss: 1.4961 - val_loss: 1.4213\n",
      "Epoch 16/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4821\n",
      "Epoch 16: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 24s 740us/sample - loss: 1.4821 - val_loss: 1.4288\n",
      "Epoch 17/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4766\n",
      "Epoch 17: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 23s 711us/sample - loss: 1.4766 - val_loss: 1.4230\n",
      "Epoch 18/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5653\n",
      "Epoch 18: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 21s 652us/sample - loss: 1.5653 - val_loss: 1.4407\n",
      "Epoch 19/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5196\n",
      "Epoch 19: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 639us/sample - loss: 1.5196 - val_loss: 1.4474\n",
      "Epoch 20/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5142\n",
      "Epoch 20: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 640us/sample - loss: 1.5142 - val_loss: 1.4530\n",
      "Epoch 21/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5298\n",
      "Epoch 21: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 636us/sample - loss: 1.5298 - val_loss: 1.4505\n",
      "Epoch 22/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.5316\n",
      "Epoch 22: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 637us/sample - loss: 1.5316 - val_loss: 1.4538\n",
      "Epoch 23/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4998\n",
      "Epoch 23: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 635us/sample - loss: 1.4998 - val_loss: 1.4350\n",
      "Epoch 24/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4816\n",
      "Epoch 24: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 632us/sample - loss: 1.4816 - val_loss: 1.4284\n",
      "Epoch 25/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4842\n",
      "Epoch 25: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 639us/sample - loss: 1.4842 - val_loss: 1.4295\n",
      "Epoch 26/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4714\n",
      "Epoch 26: val_loss did not improve from 1.42131\n",
      "31892/31892 [==============================] - 20s 634us/sample - loss: 1.4714 - val_loss: 1.4258\n",
      "Epoch 27/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4653\n",
      "Epoch 27: val_loss improved from 1.42131 to 1.41893, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 20s 640us/sample - loss: 1.4653 - val_loss: 1.4189\n",
      "Epoch 28/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4642\n",
      "Epoch 28: val_loss did not improve from 1.41893\n",
      "31892/31892 [==============================] - 20s 633us/sample - loss: 1.4642 - val_loss: 1.4213\n",
      "Epoch 29/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4587\n",
      "Epoch 29: val_loss did not improve from 1.41893\n",
      "31892/31892 [==============================] - 20s 637us/sample - loss: 1.4587 - val_loss: 1.4207\n",
      "Epoch 30/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4567\n",
      "Epoch 30: val_loss improved from 1.41893 to 1.41540, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 20s 639us/sample - loss: 1.4567 - val_loss: 1.4154\n",
      "Epoch 31/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4517\n",
      "Epoch 31: val_loss did not improve from 1.41540\n",
      "31892/31892 [==============================] - 21s 644us/sample - loss: 1.4517 - val_loss: 1.4162\n",
      "Epoch 32/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4500\n",
      "Epoch 32: val_loss improved from 1.41540 to 1.41432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 644us/sample - loss: 1.4500 - val_loss: 1.4143\n",
      "Epoch 33/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4498\n",
      "Epoch 33: val_loss improved from 1.41432 to 1.41216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 646us/sample - loss: 1.4498 - val_loss: 1.4122\n",
      "Epoch 34/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4474\n",
      "Epoch 34: val_loss improved from 1.41216 to 1.40666, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 20s 642us/sample - loss: 1.4474 - val_loss: 1.4067\n",
      "Epoch 35/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4431\n",
      "Epoch 35: val_loss did not improve from 1.40666\n",
      "31892/31892 [==============================] - 22s 698us/sample - loss: 1.4431 - val_loss: 1.4120\n",
      "Epoch 36/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4416\n",
      "Epoch 36: val_loss did not improve from 1.40666\n",
      "31892/31892 [==============================] - 23s 710us/sample - loss: 1.4416 - val_loss: 1.4102\n",
      "Epoch 37/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4427\n",
      "Epoch 37: val_loss improved from 1.40666 to 1.40424, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 670us/sample - loss: 1.4427 - val_loss: 1.4042\n",
      "Epoch 38/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4358\n",
      "Epoch 38: val_loss did not improve from 1.40424\n",
      "31892/31892 [==============================] - 22s 680us/sample - loss: 1.4358 - val_loss: 1.4055\n",
      "Epoch 39/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4356\n",
      "Epoch 39: val_loss improved from 1.40424 to 1.39413, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 717us/sample - loss: 1.4356 - val_loss: 1.3941\n",
      "Epoch 40/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4337\n",
      "Epoch 40: val_loss did not improve from 1.39413\n",
      "31892/31892 [==============================] - 21s 649us/sample - loss: 1.4337 - val_loss: 1.3988\n",
      "Epoch 41/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4318\n",
      "Epoch 41: val_loss improved from 1.39413 to 1.39335, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 720us/sample - loss: 1.4318 - val_loss: 1.3934\n",
      "Epoch 42/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4314\n",
      "Epoch 42: val_loss improved from 1.39335 to 1.39328, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 719us/sample - loss: 1.4314 - val_loss: 1.3933\n",
      "Epoch 43/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4295\n",
      "Epoch 43: val_loss improved from 1.39328 to 1.38778, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 22s 693us/sample - loss: 1.4295 - val_loss: 1.3878\n",
      "Epoch 44/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4285\n",
      "Epoch 44: val_loss did not improve from 1.38778\n",
      "31892/31892 [==============================] - 21s 645us/sample - loss: 1.4285 - val_loss: 1.3881\n",
      "Epoch 45/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4231\n",
      "Epoch 45: val_loss did not improve from 1.38778\n",
      "31892/31892 [==============================] - 23s 713us/sample - loss: 1.4231 - val_loss: 1.3879\n",
      "Epoch 46/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 46: val_loss did not improve from 1.38778\n",
      "31892/31892 [==============================] - 23s 729us/sample - loss: 1.4266 - val_loss: 1.3878\n",
      "Epoch 47/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 47: val_loss did not improve from 1.38778\n",
      "31892/31892 [==============================] - 21s 659us/sample - loss: 1.4225 - val_loss: 1.3906\n",
      "Epoch 48/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 48: val_loss did not improve from 1.38778\n",
      "31892/31892 [==============================] - 21s 651us/sample - loss: 1.4225 - val_loss: 1.3952\n",
      "Epoch 49/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4205\n",
      "Epoch 49: val_loss did not improve from 1.38778\n",
      "31892/31892 [==============================] - 23s 731us/sample - loss: 1.4205 - val_loss: 1.3915\n",
      "Epoch 50/50\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 50: val_loss improved from 1.38778 to 1.38585, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_38.h5\n",
      "31892/31892 [==============================] - 24s 744us/sample - loss: 1.4174 - val_loss: 1.3859\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:34:54.162787: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_329_1/lstm_cell_958/recurrent_kernel/Assign' id:480278 op device:{requested: '', assigned: ''} def:{{{node lstm_329_1/lstm_cell_958/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_329_1/lstm_cell_958/recurrent_kernel, lstm_329_1/lstm_cell_958/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:35:19.039586: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_304_1/lstm_cell_933/recurrent_kernel/m/Assign' id:481713 op device:{requested: '', assigned: ''} def:{{{node lstm_304_1/lstm_cell_933/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_304_1/lstm_cell_933/recurrent_kernel/m, lstm_304_1/lstm_cell_933/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:35:44.277773: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_44_1/cond/Merge' id:480927 op device:{requested: '', assigned: ''} def:{{{node dropout_44_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_44_1/cond/Identity, dropout_44_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1548)\n",
      "(1514, 1548)\n",
      "(1644, 1548)\n",
      "(1764, 1548)\n",
      "(1836, 1548)\n",
      "(1699, 1548)\n",
      "(1369, 1548)\n",
      "(1778, 1548)\n",
      "(1631, 1548)\n",
      "(1692, 1548)\n",
      "(1550, 1548)\n",
      "(1727, 1548)\n",
      "(1788, 1548)\n",
      "(1836, 1548)\n",
      "(1728, 1548)\n",
      "(1812, 1548)\n",
      "(959, 1548)\n",
      "(1668, 1548)\n",
      "(1872, 1548)\n",
      "{1: 5.482952445746158, 2: 5.370204570349312, 4: 10.0, 5: 4.342817611396974, 6: 4.504916189241811, 8: 8.219647543044424, 9: 6.652487785243263, 10: 6.800446204190466, 11: 6.9082611818270765, 12: 8.947519486545342, 13: 6.33525208477427, 19: 8.714558535672989, 21: 8.262406112647398, 22: 1.0, 25: 7.825583283817532, 26: 6.0428302314201465, 27: 5.206496996125208, 28: 6.058802066364726, 29: 1.5218789939676591}\n",
      "Train on 31892 samples, validate on 3561 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:42:42.424263: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 10.2215\n",
      "Epoch 1: val_loss improved from inf to 1.41340, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 69s 2ms/sample - loss: 10.2215 - val_loss: 1.4134\n",
      "Epoch 2/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1669\n",
      "Epoch 2: val_loss improved from 1.41340 to 1.39822, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 707us/sample - loss: 10.1669 - val_loss: 1.3982\n",
      "Epoch 3/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1636\n",
      "Epoch 3: val_loss did not improve from 1.39822\n",
      "31892/31892 [==============================] - 22s 699us/sample - loss: 10.1636 - val_loss: 1.3995\n",
      "Epoch 4/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1311\n",
      "Epoch 4: val_loss improved from 1.39822 to 1.39441, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 653us/sample - loss: 10.1311 - val_loss: 1.3944\n",
      "Epoch 5/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.1442\n",
      "Epoch 5: val_loss improved from 1.39441 to 1.38857, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 653us/sample - loss: 10.1442 - val_loss: 1.3886\n",
      "Epoch 6/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.0660\n",
      "Epoch 6: val_loss did not improve from 1.38857\n",
      "31892/31892 [==============================] - 21s 645us/sample - loss: 10.0660 - val_loss: 1.3891\n",
      "Epoch 7/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.0349\n",
      "Epoch 7: val_loss did not improve from 1.38857\n",
      "31892/31892 [==============================] - 21s 646us/sample - loss: 10.0349 - val_loss: 1.3931\n",
      "Epoch 8/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.0385\n",
      "Epoch 8: val_loss did not improve from 1.38857\n",
      "31892/31892 [==============================] - 22s 700us/sample - loss: 10.0385 - val_loss: 1.3963\n",
      "Epoch 9/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.0220\n",
      "Epoch 9: val_loss did not improve from 1.38857\n",
      "31892/31892 [==============================] - 24s 744us/sample - loss: 10.0220 - val_loss: 1.3907\n",
      "Epoch 10/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.0358\n",
      "Epoch 10: val_loss did not improve from 1.38857\n",
      "31892/31892 [==============================] - 24s 739us/sample - loss: 10.0358 - val_loss: 1.3989\n",
      "Epoch 11/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 10.0123\n",
      "Epoch 11: val_loss did not improve from 1.38857\n",
      "31892/31892 [==============================] - 22s 696us/sample - loss: 10.0123 - val_loss: 1.3969\n",
      "Epoch 12/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9696\n",
      "Epoch 12: val_loss improved from 1.38857 to 1.38653, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 713us/sample - loss: 9.9696 - val_loss: 1.3865\n",
      "Epoch 13/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9842\n",
      "Epoch 13: val_loss did not improve from 1.38653\n",
      "31892/31892 [==============================] - 21s 647us/sample - loss: 9.9842 - val_loss: 1.3897\n",
      "Epoch 14/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9558\n",
      "Epoch 14: val_loss did not improve from 1.38653\n",
      "31892/31892 [==============================] - 24s 744us/sample - loss: 9.9558 - val_loss: 1.3965\n",
      "Epoch 15/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9463\n",
      "Epoch 15: val_loss did not improve from 1.38653\n",
      "31892/31892 [==============================] - 24s 739us/sample - loss: 9.9463 - val_loss: 1.3987\n",
      "Epoch 16/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9561\n",
      "Epoch 16: val_loss improved from 1.38653 to 1.38578, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 728us/sample - loss: 9.9561 - val_loss: 1.3858\n",
      "Epoch 17/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9240\n",
      "Epoch 17: val_loss did not improve from 1.38578\n",
      "31892/31892 [==============================] - 20s 643us/sample - loss: 9.9240 - val_loss: 1.3894\n",
      "Epoch 18/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9217\n",
      "Epoch 18: val_loss did not improve from 1.38578\n",
      "31892/31892 [==============================] - 21s 652us/sample - loss: 9.9217 - val_loss: 1.3929\n",
      "Epoch 19/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9287\n",
      "Epoch 19: val_loss did not improve from 1.38578\n",
      "31892/31892 [==============================] - 21s 660us/sample - loss: 9.9287 - val_loss: 1.3901\n",
      "Epoch 20/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 9.9085\n",
      "Epoch 20: val_loss improved from 1.38578 to 1.38426, saving model to ./checkpoints/unknown_person_few_shot_p17_38.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 9.9085 - val_loss: 1.3843\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:51:01.253967: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_296_2/lstm_cell_962/bias/Assign' id:494403 op device:{requested: '', assigned: ''} def:{{{node lstm_296_2/lstm_cell_962/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_296_2/lstm_cell_962/bias, lstm_296_2/lstm_cell_962/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:51:26.899817: W tensorflow/c/c_api.cc:304] Operation '{name:'iter_17/Assign' id:500919 op device:{requested: '', assigned: ''} def:{{{node iter_17/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_INT64, validate_shape=false](iter_17, iter_17/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31892 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:51:55.185639: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:54:06.488368: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:54:32.065378: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39897, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 71s 2ms/sample - loss: 1.4176 - val_loss: 1.3990\n",
      "Epoch 2/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4147\n",
      "Epoch 2: val_loss improved from 1.39897 to 1.38246, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 24s 750us/sample - loss: 1.4147 - val_loss: 1.3825\n",
      "Epoch 3/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4138\n",
      "Epoch 3: val_loss improved from 1.38246 to 1.38001, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 653us/sample - loss: 1.4138 - val_loss: 1.3800\n",
      "Epoch 4/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 4: val_loss improved from 1.38001 to 1.37646, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 21s 651us/sample - loss: 1.4123 - val_loss: 1.3765\n",
      "Epoch 5/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 5: val_loss improved from 1.37646 to 1.37426, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 22s 694us/sample - loss: 1.4078 - val_loss: 1.3743\n",
      "Epoch 6/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4076\n",
      "Epoch 6: val_loss did not improve from 1.37426\n",
      "31892/31892 [==============================] - 21s 653us/sample - loss: 1.4076 - val_loss: 1.3783\n",
      "Epoch 7/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 7: val_loss did not improve from 1.37426\n",
      "31892/31892 [==============================] - 21s 664us/sample - loss: 1.4070 - val_loss: 1.3814\n",
      "Epoch 8/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 8: val_loss improved from 1.37426 to 1.37275, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 733us/sample - loss: 1.4055 - val_loss: 1.3728\n",
      "Epoch 9/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4033\n",
      "Epoch 9: val_loss did not improve from 1.37275\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.4033 - val_loss: 1.3765\n",
      "Epoch 10/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 10: val_loss improved from 1.37275 to 1.36906, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 722us/sample - loss: 1.4049 - val_loss: 1.3691\n",
      "Epoch 11/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 11: val_loss did not improve from 1.36906\n",
      "31892/31892 [==============================] - 20s 643us/sample - loss: 1.4008 - val_loss: 1.3707\n",
      "Epoch 12/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.4037\n",
      "Epoch 12: val_loss did not improve from 1.36906\n",
      "31892/31892 [==============================] - 21s 648us/sample - loss: 1.4037 - val_loss: 1.3727\n",
      "Epoch 13/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 13: val_loss improved from 1.36906 to 1.36617, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_38.h5\n",
      "31892/31892 [==============================] - 23s 714us/sample - loss: 1.3972 - val_loss: 1.3662\n",
      "Epoch 14/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3982\n",
      "Epoch 14: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 22s 679us/sample - loss: 1.3982 - val_loss: 1.3776\n",
      "Epoch 15/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3982\n",
      "Epoch 15: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 21s 664us/sample - loss: 1.3982 - val_loss: 1.3716\n",
      "Epoch 16/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 16: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 23s 708us/sample - loss: 1.3947 - val_loss: 1.3672\n",
      "Epoch 17/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3950\n",
      "Epoch 17: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 22s 694us/sample - loss: 1.3950 - val_loss: 1.3672\n",
      "Epoch 18/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3943\n",
      "Epoch 18: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 24s 754us/sample - loss: 1.3943 - val_loss: 1.3738\n",
      "Epoch 19/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 19: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 24s 753us/sample - loss: 1.3905 - val_loss: 1.3677\n",
      "Epoch 20/20\n",
      "31892/31892 [==============================] - ETA: 0s - loss: 1.3913\n",
      "Epoch 20: val_loss did not improve from 1.36617\n",
      "31892/31892 [==============================] - 24s 748us/sample - loss: 1.3913 - val_loss: 1.3693\n",
      "35669\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:02:40.333254: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_334/lstm_cell_1000/recurrent_kernel/Assign' id:513581 op device:{requested: '', assigned: ''} def:{{{node lstm_334/lstm_cell_1000/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_334/lstm_cell_1000/recurrent_kernel, lstm_334/lstm_cell_1000/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:02:54.380547: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_1' id:517014 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:03:05.705985: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_2' id:517015 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32096, 95)\n",
      "Train on 32096 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:03:34.423394: W tensorflow/c/c_api.cc:304] Operation '{name:'training_54/Adam/lstm_358/lstm_cell_1024/recurrent_kernel/v/Assign' id:530795 op device:{requested: '', assigned: ''} def:{{{node training_54/Adam/lstm_358/lstm_cell_1024/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_54/Adam/lstm_358/lstm_cell_1024/recurrent_kernel/v, training_54/Adam/lstm_358/lstm_cell_1024/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:05:50.506298: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 2.9247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 16:06:16.002383: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_55/mul' id:519855 op device:{requested: '', assigned: ''} def:{{{node loss_55/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_55/mul/x, loss_55/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.85251, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 152s 5ms/sample - loss: 2.9247 - val_loss: 1.8525\n",
      "Epoch 2/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.7682\n",
      "Epoch 2: val_loss improved from 1.85251 to 1.56925, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 666us/sample - loss: 1.7682 - val_loss: 1.5693\n",
      "Epoch 3/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.6019\n",
      "Epoch 3: val_loss improved from 1.56925 to 1.50521, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 713us/sample - loss: 1.6019 - val_loss: 1.5052\n",
      "Epoch 4/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5505\n",
      "Epoch 4: val_loss improved from 1.50521 to 1.47935, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 745us/sample - loss: 1.5505 - val_loss: 1.4794\n",
      "Epoch 5/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5211\n",
      "Epoch 5: val_loss improved from 1.47935 to 1.46559, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 22s 695us/sample - loss: 1.5211 - val_loss: 1.4656\n",
      "Epoch 6/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5073\n",
      "Epoch 6: val_loss improved from 1.46559 to 1.45497, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 643us/sample - loss: 1.5073 - val_loss: 1.4550\n",
      "Epoch 7/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4953\n",
      "Epoch 7: val_loss improved from 1.45497 to 1.44106, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 20s 638us/sample - loss: 1.4953 - val_loss: 1.4411\n",
      "Epoch 8/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4944\n",
      "Epoch 8: val_loss did not improve from 1.44106\n",
      "32096/32096 [==============================] - 20s 632us/sample - loss: 1.4944 - val_loss: 1.4417\n",
      "Epoch 9/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4844\n",
      "Epoch 9: val_loss improved from 1.44106 to 1.44024, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 20s 636us/sample - loss: 1.4844 - val_loss: 1.4402\n",
      "Epoch 10/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4815\n",
      "Epoch 10: val_loss improved from 1.44024 to 1.42591, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 20s 635us/sample - loss: 1.4815 - val_loss: 1.4259\n",
      "Epoch 11/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4813\n",
      "Epoch 11: val_loss improved from 1.42591 to 1.42078, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 656us/sample - loss: 1.4813 - val_loss: 1.4208\n",
      "Epoch 12/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4703\n",
      "Epoch 12: val_loss improved from 1.42078 to 1.41321, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 742us/sample - loss: 1.4703 - val_loss: 1.4132\n",
      "Epoch 13/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4647\n",
      "Epoch 13: val_loss did not improve from 1.41321\n",
      "32096/32096 [==============================] - 23s 711us/sample - loss: 1.4647 - val_loss: 1.4172\n",
      "Epoch 14/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4693\n",
      "Epoch 14: val_loss improved from 1.41321 to 1.41141, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 649us/sample - loss: 1.4693 - val_loss: 1.4114\n",
      "Epoch 15/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4590\n",
      "Epoch 15: val_loss did not improve from 1.41141\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 1.4590 - val_loss: 1.4141\n",
      "Epoch 16/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4584\n",
      "Epoch 16: val_loss improved from 1.41141 to 1.40924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 704us/sample - loss: 1.4584 - val_loss: 1.4092\n",
      "Epoch 17/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4591\n",
      "Epoch 17: val_loss did not improve from 1.40924\n",
      "32096/32096 [==============================] - 23s 719us/sample - loss: 1.4591 - val_loss: 1.4192\n",
      "Epoch 18/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4493\n",
      "Epoch 18: val_loss improved from 1.40924 to 1.40685, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.4493 - val_loss: 1.4068\n",
      "Epoch 19/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4695\n",
      "Epoch 19: val_loss did not improve from 1.40685\n",
      "32096/32096 [==============================] - 21s 641us/sample - loss: 1.4695 - val_loss: 1.4137\n",
      "Epoch 20/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5344\n",
      "Epoch 20: val_loss did not improve from 1.40685\n",
      "32096/32096 [==============================] - 23s 730us/sample - loss: 1.5344 - val_loss: 1.4244\n",
      "Epoch 21/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4723\n",
      "Epoch 21: val_loss did not improve from 1.40685\n",
      "32096/32096 [==============================] - 21s 668us/sample - loss: 1.4723 - val_loss: 1.4094\n",
      "Epoch 22/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4634\n",
      "Epoch 22: val_loss did not improve from 1.40685\n",
      "32096/32096 [==============================] - 21s 642us/sample - loss: 1.4634 - val_loss: 1.4093\n",
      "Epoch 23/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4459\n",
      "Epoch 23: val_loss did not improve from 1.40685\n",
      "32096/32096 [==============================] - 21s 646us/sample - loss: 1.4459 - val_loss: 1.4105\n",
      "Epoch 24/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4385\n",
      "Epoch 24: val_loss improved from 1.40685 to 1.40041, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 652us/sample - loss: 1.4385 - val_loss: 1.4004\n",
      "Epoch 25/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 25: val_loss improved from 1.40041 to 1.39940, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 655us/sample - loss: 1.4334 - val_loss: 1.3994\n",
      "Epoch 26/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 26: val_loss improved from 1.39940 to 1.38928, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 668us/sample - loss: 1.4321 - val_loss: 1.3893\n",
      "Epoch 27/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 27: val_loss did not improve from 1.38928\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 1.4275 - val_loss: 1.3931\n",
      "Epoch 28/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4236\n",
      "Epoch 28: val_loss did not improve from 1.38928\n",
      "32096/32096 [==============================] - 23s 732us/sample - loss: 1.4236 - val_loss: 1.3900\n",
      "Epoch 29/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4231\n",
      "Epoch 29: val_loss improved from 1.38928 to 1.38448, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 1.4231 - val_loss: 1.3845\n",
      "Epoch 30/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 30: val_loss improved from 1.38448 to 1.38401, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 745us/sample - loss: 1.4211 - val_loss: 1.3840\n",
      "Epoch 31/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4188\n",
      "Epoch 31: val_loss improved from 1.38401 to 1.38185, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 729us/sample - loss: 1.4188 - val_loss: 1.3819\n",
      "Epoch 32/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 32: val_loss improved from 1.38185 to 1.37512, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 643us/sample - loss: 1.4155 - val_loss: 1.3751\n",
      "Epoch 33/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4151\n",
      "Epoch 33: val_loss improved from 1.37512 to 1.37241, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 707us/sample - loss: 1.4151 - val_loss: 1.3724\n",
      "Epoch 34/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4133\n",
      "Epoch 34: val_loss did not improve from 1.37241\n",
      "32096/32096 [==============================] - 20s 630us/sample - loss: 1.4133 - val_loss: 1.3765\n",
      "Epoch 35/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 35: val_loss did not improve from 1.37241\n",
      "32096/32096 [==============================] - 20s 631us/sample - loss: 1.4088 - val_loss: 1.3749\n",
      "Epoch 36/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4095\n",
      "Epoch 36: val_loss did not improve from 1.37241\n",
      "32096/32096 [==============================] - 22s 684us/sample - loss: 1.4095 - val_loss: 1.3775\n",
      "Epoch 37/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 37: val_loss improved from 1.37241 to 1.37044, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 744us/sample - loss: 1.4066 - val_loss: 1.3704\n",
      "Epoch 38/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4033\n",
      "Epoch 38: val_loss improved from 1.37044 to 1.36443, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 703us/sample - loss: 1.4033 - val_loss: 1.3644\n",
      "Epoch 39/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4018\n",
      "Epoch 39: val_loss did not improve from 1.36443\n",
      "32096/32096 [==============================] - 20s 620us/sample - loss: 1.4018 - val_loss: 1.3649\n",
      "Epoch 40/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 40: val_loss did not improve from 1.36443\n",
      "32096/32096 [==============================] - 20s 622us/sample - loss: 1.3996 - val_loss: 1.3711\n",
      "Epoch 41/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 41: val_loss improved from 1.36443 to 1.36104, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 20s 629us/sample - loss: 1.3992 - val_loss: 1.3610\n",
      "Epoch 42/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3994\n",
      "Epoch 42: val_loss did not improve from 1.36104\n",
      "32096/32096 [==============================] - 20s 622us/sample - loss: 1.3994 - val_loss: 1.3617\n",
      "Epoch 43/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3968\n",
      "Epoch 43: val_loss did not improve from 1.36104\n",
      "32096/32096 [==============================] - 20s 621us/sample - loss: 1.3968 - val_loss: 1.3647\n",
      "Epoch 44/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3919\n",
      "Epoch 44: val_loss did not improve from 1.36104\n",
      "32096/32096 [==============================] - 22s 686us/sample - loss: 1.3919 - val_loss: 1.3660\n",
      "Epoch 45/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3906\n",
      "Epoch 45: val_loss did not improve from 1.36104\n",
      "32096/32096 [==============================] - 23s 731us/sample - loss: 1.3906 - val_loss: 1.3617\n",
      "Epoch 46/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3909\n",
      "Epoch 46: val_loss did not improve from 1.36104\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.3909 - val_loss: 1.3637\n",
      "Epoch 47/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 47: val_loss did not improve from 1.36104\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 1.3936 - val_loss: 1.3690\n",
      "Epoch 48/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3889\n",
      "Epoch 48: val_loss improved from 1.36104 to 1.35392, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 743us/sample - loss: 1.3889 - val_loss: 1.3539\n",
      "Epoch 49/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3879\n",
      "Epoch 49: val_loss did not improve from 1.35392\n",
      "32096/32096 [==============================] - 21s 648us/sample - loss: 1.3879 - val_loss: 1.3580\n",
      "Epoch 50/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3863\n",
      "Epoch 50: val_loss did not improve from 1.35392\n",
      "32096/32096 [==============================] - 21s 670us/sample - loss: 1.3863 - val_loss: 1.3553\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:26:24.331985: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_341_1/lstm_cell_1044/kernel/Assign' id:533298 op device:{requested: '', assigned: ''} def:{{{node lstm_341_1/lstm_cell_1044/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_341_1/lstm_cell_1044/kernel, lstm_341_1/lstm_cell_1044/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:26:51.772333: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_336_1/lstm_cell_1039/bias/m/Assign' id:538685 op device:{requested: '', assigned: ''} def:{{{node lstm_336_1/lstm_cell_1039/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_336_1/lstm_cell_1039/bias/m, lstm_336_1/lstm_cell_1039/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 16:27:19.092558: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_49_1/cond/Merge' id:537969 op device:{requested: '', assigned: ''} def:{{{node dropout_49_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_49_1/cond/Identity, dropout_49_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1332)\n",
      "(1514, 1332)\n",
      "(1644, 1332)\n",
      "(1764, 1332)\n",
      "(1836, 1332)\n",
      "(1699, 1332)\n",
      "(1369, 1332)\n",
      "(1778, 1332)\n",
      "(1631, 1332)\n",
      "(1692, 1332)\n",
      "(1550, 1332)\n",
      "(1716, 1332)\n",
      "(1764, 1332)\n",
      "(1872, 1332)\n",
      "(1728, 1332)\n",
      "(1824, 1332)\n",
      "(934, 1332)\n",
      "(1680, 1332)\n",
      "(1872, 1332)\n",
      "{1: 5.146638392624153, 2: 5.115601231331853, 4: 10.0, 5: 5.292856809313433, 6: 5.79631094873648, 8: 8.160714453518784, 9: 6.264499253512654, 10: 7.3124087492046845, 11: 7.11924815488886, 12: 8.50205556896041, 13: 5.673545405036791, 19: 8.516754437540904, 21: 8.167484234276888, 22: 1.0, 25: 7.164618567157766, 26: 5.4087328682708256, 27: 4.984455107608532, 28: 5.281252028498223, 29: 3.1740637608765456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907972/3306004915.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32096 samples, validate on 3573 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:34:14.235455: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 10.5448\n",
      "Epoch 1: val_loss improved from inf to 1.40966, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 74s 2ms/sample - loss: 10.5448 - val_loss: 1.4097\n",
      "Epoch 2/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.4115\n",
      "Epoch 2: val_loss improved from 1.40966 to 1.38087, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 641us/sample - loss: 10.4115 - val_loss: 1.3809\n",
      "Epoch 3/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3755\n",
      "Epoch 3: val_loss did not improve from 1.38087\n",
      "32096/32096 [==============================] - 20s 636us/sample - loss: 10.3755 - val_loss: 1.3828\n",
      "Epoch 4/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3566\n",
      "Epoch 4: val_loss improved from 1.38087 to 1.38013, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 642us/sample - loss: 10.3566 - val_loss: 1.3801\n",
      "Epoch 5/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2715\n",
      "Epoch 5: val_loss did not improve from 1.38013\n",
      "32096/32096 [==============================] - 20s 631us/sample - loss: 10.2715 - val_loss: 1.3958\n",
      "Epoch 6/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3189\n",
      "Epoch 6: val_loss did not improve from 1.38013\n",
      "32096/32096 [==============================] - 20s 634us/sample - loss: 10.3189 - val_loss: 1.3919\n",
      "Epoch 7/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2182\n",
      "Epoch 7: val_loss improved from 1.38013 to 1.37080, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 708us/sample - loss: 10.2182 - val_loss: 1.3708\n",
      "Epoch 8/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2001\n",
      "Epoch 8: val_loss did not improve from 1.37080\n",
      "32096/32096 [==============================] - 24s 755us/sample - loss: 10.2001 - val_loss: 1.3850\n",
      "Epoch 9/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2094\n",
      "Epoch 9: val_loss did not improve from 1.37080\n",
      "32096/32096 [==============================] - 24s 732us/sample - loss: 10.2094 - val_loss: 1.3751\n",
      "Epoch 10/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1997\n",
      "Epoch 10: val_loss did not improve from 1.37080\n",
      "32096/32096 [==============================] - 20s 634us/sample - loss: 10.1997 - val_loss: 1.3710\n",
      "Epoch 11/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1718\n",
      "Epoch 11: val_loss did not improve from 1.37080\n",
      "32096/32096 [==============================] - 24s 740us/sample - loss: 10.1718 - val_loss: 1.3771\n",
      "Epoch 12/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1624\n",
      "Epoch 12: val_loss did not improve from 1.37080\n",
      "32096/32096 [==============================] - 24s 738us/sample - loss: 10.1624 - val_loss: 1.3764\n",
      "Epoch 13/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1347\n",
      "Epoch 13: val_loss did not improve from 1.37080\n",
      "32096/32096 [==============================] - 24s 742us/sample - loss: 10.1347 - val_loss: 1.3854\n",
      "Epoch 14/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1178\n",
      "Epoch 14: val_loss improved from 1.37080 to 1.37032, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 757us/sample - loss: 10.1178 - val_loss: 1.3703\n",
      "Epoch 15/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1253\n",
      "Epoch 15: val_loss improved from 1.37032 to 1.36963, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 748us/sample - loss: 10.1253 - val_loss: 1.3696\n",
      "Epoch 16/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1074\n",
      "Epoch 16: val_loss improved from 1.36963 to 1.36848, saving model to ./checkpoints/unknown_person_few_shot_p17_39.h5\n",
      "32096/32096 [==============================] - 22s 696us/sample - loss: 10.1074 - val_loss: 1.3685\n",
      "Epoch 17/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0866\n",
      "Epoch 17: val_loss did not improve from 1.36848\n",
      "32096/32096 [==============================] - 23s 706us/sample - loss: 10.0866 - val_loss: 1.3788\n",
      "Epoch 18/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0852\n",
      "Epoch 18: val_loss did not improve from 1.36848\n",
      "32096/32096 [==============================] - 21s 649us/sample - loss: 10.0852 - val_loss: 1.3842\n",
      "Epoch 19/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0395\n",
      "Epoch 19: val_loss did not improve from 1.36848\n",
      "32096/32096 [==============================] - 23s 711us/sample - loss: 10.0395 - val_loss: 1.3761\n",
      "Epoch 20/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0427\n",
      "Epoch 20: val_loss did not improve from 1.36848\n",
      "32096/32096 [==============================] - 22s 691us/sample - loss: 10.0427 - val_loss: 1.3740\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:42:42.835103: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_346_2/lstm_cell_1086/bias/Assign' id:553525 op device:{requested: '', assigned: ''} def:{{{node lstm_346_2/lstm_cell_1086/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_346_2/lstm_cell_1086/bias, lstm_346_2/lstm_cell_1086/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:43:11.600331: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_363_2/lstm_cell_1103/bias/v/Assign' id:559131 op device:{requested: '', assigned: ''} def:{{{node lstm_363_2/lstm_cell_1103/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_363_2/lstm_cell_1103/bias/v, lstm_363_2/lstm_cell_1103/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32096 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:43:42.996783: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:46:10.271645: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:46:33.750573: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.35785, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 74s 2ms/sample - loss: 1.3876 - val_loss: 1.3579\n",
      "Epoch 2/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3872\n",
      "Epoch 2: val_loss improved from 1.35785 to 1.35057, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 24s 739us/sample - loss: 1.3872 - val_loss: 1.3506\n",
      "Epoch 3/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3844\n",
      "Epoch 3: val_loss did not improve from 1.35057\n",
      "32096/32096 [==============================] - 23s 713us/sample - loss: 1.3844 - val_loss: 1.3518\n",
      "Epoch 4/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3854\n",
      "Epoch 4: val_loss did not improve from 1.35057\n",
      "32096/32096 [==============================] - 22s 693us/sample - loss: 1.3854 - val_loss: 1.3540\n",
      "Epoch 5/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3827\n",
      "Epoch 5: val_loss did not improve from 1.35057\n",
      "32096/32096 [==============================] - 22s 685us/sample - loss: 1.3827 - val_loss: 1.3554\n",
      "Epoch 6/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3811\n",
      "Epoch 6: val_loss did not improve from 1.35057\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 1.3811 - val_loss: 1.3575\n",
      "Epoch 7/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3797\n",
      "Epoch 7: val_loss improved from 1.35057 to 1.35010, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 22s 701us/sample - loss: 1.3797 - val_loss: 1.3501\n",
      "Epoch 8/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3783\n",
      "Epoch 8: val_loss improved from 1.35010 to 1.34927, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 646us/sample - loss: 1.3783 - val_loss: 1.3493\n",
      "Epoch 9/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3786\n",
      "Epoch 9: val_loss did not improve from 1.34927\n",
      "32096/32096 [==============================] - 22s 696us/sample - loss: 1.3786 - val_loss: 1.3543\n",
      "Epoch 10/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3778\n",
      "Epoch 10: val_loss did not improve from 1.34927\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 1.3778 - val_loss: 1.3493\n",
      "Epoch 11/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3725\n",
      "Epoch 11: val_loss did not improve from 1.34927\n",
      "32096/32096 [==============================] - 21s 649us/sample - loss: 1.3725 - val_loss: 1.3522\n",
      "Epoch 12/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3717\n",
      "Epoch 12: val_loss improved from 1.34927 to 1.34634, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 657us/sample - loss: 1.3717 - val_loss: 1.3463\n",
      "Epoch 13/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3725\n",
      "Epoch 13: val_loss improved from 1.34634 to 1.34491, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 23s 730us/sample - loss: 1.3725 - val_loss: 1.3449\n",
      "Epoch 14/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3684\n",
      "Epoch 14: val_loss did not improve from 1.34491\n",
      "32096/32096 [==============================] - 24s 738us/sample - loss: 1.3684 - val_loss: 1.3486\n",
      "Epoch 15/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3688\n",
      "Epoch 15: val_loss did not improve from 1.34491\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.3688 - val_loss: 1.3493\n",
      "Epoch 16/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3672\n",
      "Epoch 16: val_loss did not improve from 1.34491\n",
      "32096/32096 [==============================] - 24s 739us/sample - loss: 1.3672 - val_loss: 1.3477\n",
      "Epoch 17/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3641\n",
      "Epoch 17: val_loss did not improve from 1.34491\n",
      "32096/32096 [==============================] - 23s 706us/sample - loss: 1.3641 - val_loss: 1.3459\n",
      "Epoch 18/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3667\n",
      "Epoch 18: val_loss improved from 1.34491 to 1.34270, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_39.h5\n",
      "32096/32096 [==============================] - 21s 649us/sample - loss: 1.3667 - val_loss: 1.3427\n",
      "Epoch 19/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3660\n",
      "Epoch 19: val_loss did not improve from 1.34270\n",
      "32096/32096 [==============================] - 21s 644us/sample - loss: 1.3660 - val_loss: 1.3431\n",
      "Epoch 20/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3635\n",
      "Epoch 20: val_loss did not improve from 1.34270\n",
      "32096/32096 [==============================] - 21s 655us/sample - loss: 1.3635 - val_loss: 1.3472\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:54:37.588321: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_382/lstm_cell_1122/recurrent_kernel/Assign' id:572438 op device:{requested: '', assigned: ''} def:{{{node lstm_382/lstm_cell_1122/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_382/lstm_cell_1122/recurrent_kernel, lstm_382/lstm_cell_1122/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:54:53.613497: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_1' id:574056 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:55:06.463250: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_2' id:574057 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32096, 95)\n",
      "Train on 32096 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:55:36.679555: W tensorflow/c/c_api.cc:304] Operation '{name:'training_60/Adam/lstm_375/lstm_cell_1115/bias/m/Assign' id:586899 op device:{requested: '', assigned: ''} def:{{{node training_60/Adam/lstm_375/lstm_cell_1115/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_60/Adam/lstm_375/lstm_cell_1115/bias/m, training_60/Adam/lstm_375/lstm_cell_1115/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:58:11.676640: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 2.8459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:58:37.694490: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_61/mul' id:576897 op device:{requested: '', assigned: ''} def:{{{node loss_61/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_61/mul/x, loss_61/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.85478, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 168s 5ms/sample - loss: 2.8459 - val_loss: 1.8548\n",
      "Epoch 2/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.7308\n",
      "Epoch 2: val_loss improved from 1.85478 to 1.53293, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 703us/sample - loss: 1.7308 - val_loss: 1.5329\n",
      "Epoch 3/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5788\n",
      "Epoch 3: val_loss improved from 1.53293 to 1.48079, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 693us/sample - loss: 1.5788 - val_loss: 1.4808\n",
      "Epoch 4/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5334\n",
      "Epoch 4: val_loss improved from 1.48079 to 1.46080, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 731us/sample - loss: 1.5334 - val_loss: 1.4608\n",
      "Epoch 5/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5116\n",
      "Epoch 5: val_loss improved from 1.46080 to 1.44870, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 692us/sample - loss: 1.5116 - val_loss: 1.4487\n",
      "Epoch 6/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 6: val_loss improved from 1.44870 to 1.43848, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 698us/sample - loss: 1.4987 - val_loss: 1.4385\n",
      "Epoch 7/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4839\n",
      "Epoch 7: val_loss improved from 1.43848 to 1.43223, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 752us/sample - loss: 1.4839 - val_loss: 1.4322\n",
      "Epoch 8/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 8: val_loss improved from 1.43223 to 1.42730, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 743us/sample - loss: 1.4903 - val_loss: 1.4273\n",
      "Epoch 9/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4789\n",
      "Epoch 9: val_loss did not improve from 1.42730\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.4789 - val_loss: 1.4305\n",
      "Epoch 10/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4930\n",
      "Epoch 10: val_loss improved from 1.42730 to 1.42712, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 761us/sample - loss: 1.4930 - val_loss: 1.4271\n",
      "Epoch 11/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4791\n",
      "Epoch 11: val_loss improved from 1.42712 to 1.41946, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 751us/sample - loss: 1.4791 - val_loss: 1.4195\n",
      "Epoch 12/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 12: val_loss did not improve from 1.41946\n",
      "32096/32096 [==============================] - 24s 742us/sample - loss: 1.4854 - val_loss: 1.4229\n",
      "Epoch 13/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4746\n",
      "Epoch 13: val_loss did not improve from 1.41946\n",
      "32096/32096 [==============================] - 23s 709us/sample - loss: 1.4746 - val_loss: 1.4203\n",
      "Epoch 14/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4628\n",
      "Epoch 14: val_loss improved from 1.41946 to 1.41701, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 666us/sample - loss: 1.4628 - val_loss: 1.4170\n",
      "Epoch 15/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4615\n",
      "Epoch 15: val_loss improved from 1.41701 to 1.41346, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 675us/sample - loss: 1.4615 - val_loss: 1.4135\n",
      "Epoch 16/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4685\n",
      "Epoch 16: val_loss did not improve from 1.41346\n",
      "32096/32096 [==============================] - 21s 639us/sample - loss: 1.4685 - val_loss: 1.4173\n",
      "Epoch 17/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4708\n",
      "Epoch 17: val_loss did not improve from 1.41346\n",
      "32096/32096 [==============================] - 20s 633us/sample - loss: 1.4708 - val_loss: 1.4240\n",
      "Epoch 18/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4639\n",
      "Epoch 18: val_loss did not improve from 1.41346\n",
      "32096/32096 [==============================] - 20s 634us/sample - loss: 1.4639 - val_loss: 1.4226\n",
      "Epoch 19/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4641\n",
      "Epoch 19: val_loss improved from 1.41346 to 1.41204, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 654us/sample - loss: 1.4641 - val_loss: 1.4120\n",
      "Epoch 20/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4743\n",
      "Epoch 20: val_loss did not improve from 1.41204\n",
      "32096/32096 [==============================] - 23s 708us/sample - loss: 1.4743 - val_loss: 1.4133\n",
      "Epoch 21/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5225\n",
      "Epoch 21: val_loss did not improve from 1.41204\n",
      "32096/32096 [==============================] - 24s 751us/sample - loss: 1.5225 - val_loss: 1.4186\n",
      "Epoch 22/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5139\n",
      "Epoch 22: val_loss improved from 1.41204 to 1.40759, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 747us/sample - loss: 1.5139 - val_loss: 1.4076\n",
      "Epoch 23/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4979\n",
      "Epoch 23: val_loss did not improve from 1.40759\n",
      "32096/32096 [==============================] - 20s 629us/sample - loss: 1.4979 - val_loss: 1.4108\n",
      "Epoch 24/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4661\n",
      "Epoch 24: val_loss did not improve from 1.40759\n",
      "32096/32096 [==============================] - 22s 693us/sample - loss: 1.4661 - val_loss: 1.4086\n",
      "Epoch 25/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4567\n",
      "Epoch 25: val_loss improved from 1.40759 to 1.40498, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 712us/sample - loss: 1.4567 - val_loss: 1.4050\n",
      "Epoch 26/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4471\n",
      "Epoch 26: val_loss improved from 1.40498 to 1.40220, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 726us/sample - loss: 1.4471 - val_loss: 1.4022\n",
      "Epoch 27/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 27: val_loss improved from 1.40220 to 1.40052, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 692us/sample - loss: 1.4404 - val_loss: 1.4005\n",
      "Epoch 28/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4365\n",
      "Epoch 28: val_loss improved from 1.40052 to 1.40048, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 641us/sample - loss: 1.4365 - val_loss: 1.4005\n",
      "Epoch 29/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4381\n",
      "Epoch 29: val_loss improved from 1.40048 to 1.39584, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 643us/sample - loss: 1.4381 - val_loss: 1.3958\n",
      "Epoch 30/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 30: val_loss improved from 1.39584 to 1.39012, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 1.4334 - val_loss: 1.3901\n",
      "Epoch 31/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4328\n",
      "Epoch 31: val_loss did not improve from 1.39012\n",
      "32096/32096 [==============================] - 20s 632us/sample - loss: 1.4328 - val_loss: 1.3916\n",
      "Epoch 32/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4288\n",
      "Epoch 32: val_loss improved from 1.39012 to 1.38634, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 697us/sample - loss: 1.4288 - val_loss: 1.3863\n",
      "Epoch 33/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4261\n",
      "Epoch 33: val_loss improved from 1.38634 to 1.38481, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 655us/sample - loss: 1.4261 - val_loss: 1.3848\n",
      "Epoch 34/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4247\n",
      "Epoch 34: val_loss improved from 1.38481 to 1.38197, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 649us/sample - loss: 1.4247 - val_loss: 1.3820\n",
      "Epoch 35/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4239\n",
      "Epoch 35: val_loss improved from 1.38197 to 1.37629, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 657us/sample - loss: 1.4239 - val_loss: 1.3763\n",
      "Epoch 36/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4216\n",
      "Epoch 36: val_loss did not improve from 1.37629\n",
      "32096/32096 [==============================] - 21s 656us/sample - loss: 1.4216 - val_loss: 1.3901\n",
      "Epoch 37/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 37: val_loss did not improve from 1.37629\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.4178 - val_loss: 1.3798\n",
      "Epoch 38/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4183\n",
      "Epoch 38: val_loss improved from 1.37629 to 1.37475, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 745us/sample - loss: 1.4183 - val_loss: 1.3748\n",
      "Epoch 39/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 39: val_loss improved from 1.37475 to 1.37309, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 741us/sample - loss: 1.4158 - val_loss: 1.3731\n",
      "Epoch 40/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4128\n",
      "Epoch 40: val_loss did not improve from 1.37309\n",
      "32096/32096 [==============================] - 21s 652us/sample - loss: 1.4128 - val_loss: 1.3751\n",
      "Epoch 41/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4101\n",
      "Epoch 41: val_loss improved from 1.37309 to 1.36904, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 640us/sample - loss: 1.4101 - val_loss: 1.3690\n",
      "Epoch 42/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4094\n",
      "Epoch 42: val_loss improved from 1.36904 to 1.36885, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 20s 638us/sample - loss: 1.4094 - val_loss: 1.3688\n",
      "Epoch 43/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4064\n",
      "Epoch 43: val_loss did not improve from 1.36885\n",
      "32096/32096 [==============================] - 20s 633us/sample - loss: 1.4064 - val_loss: 1.3709\n",
      "Epoch 44/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 44: val_loss improved from 1.36885 to 1.36721, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 20s 638us/sample - loss: 1.4053 - val_loss: 1.3672\n",
      "Epoch 45/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4059\n",
      "Epoch 45: val_loss improved from 1.36721 to 1.36459, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 20s 634us/sample - loss: 1.4059 - val_loss: 1.3646\n",
      "Epoch 46/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4014\n",
      "Epoch 46: val_loss did not improve from 1.36459\n",
      "32096/32096 [==============================] - 20s 628us/sample - loss: 1.4014 - val_loss: 1.3648\n",
      "Epoch 47/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4025\n",
      "Epoch 47: val_loss improved from 1.36459 to 1.36230, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 20s 635us/sample - loss: 1.4025 - val_loss: 1.3623\n",
      "Epoch 48/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 48: val_loss did not improve from 1.36230\n",
      "32096/32096 [==============================] - 20s 630us/sample - loss: 1.3995 - val_loss: 1.3646\n",
      "Epoch 49/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4007\n",
      "Epoch 49: val_loss did not improve from 1.36230\n",
      "32096/32096 [==============================] - 20s 629us/sample - loss: 1.4007 - val_loss: 1.3685\n",
      "Epoch 50/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 50: val_loss improved from 1.36230 to 1.35950, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 723us/sample - loss: 1.3972 - val_loss: 1.3595\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:19:05.846440: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_404_1/lstm_cell_1181/kernel/Assign' id:594502 op device:{requested: '', assigned: ''} def:{{{node lstm_404_1/lstm_cell_1181/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_404_1/lstm_cell_1181/kernel, lstm_404_1/lstm_cell_1181/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:19:37.697660: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_400_1/lstm_cell_1177/bias/v/Assign' id:596775 op device:{requested: '', assigned: ''} def:{{{node lstm_400_1/lstm_cell_1177/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_400_1/lstm_cell_1177/bias/v, lstm_400_1/lstm_cell_1177/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:20:09.458970: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_54_1/cond/Merge' id:595011 op device:{requested: '', assigned: ''} def:{{{node dropout_54_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_54_1/cond/Identity, dropout_54_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1332)\n",
      "(1514, 1332)\n",
      "(1644, 1332)\n",
      "(1764, 1332)\n",
      "(1836, 1332)\n",
      "(1699, 1332)\n",
      "(1369, 1332)\n",
      "(1778, 1332)\n",
      "(1631, 1332)\n",
      "(1692, 1332)\n",
      "(1550, 1332)\n",
      "(1716, 1332)\n",
      "(1764, 1332)\n",
      "(1872, 1332)\n",
      "(1728, 1332)\n",
      "(1824, 1332)\n",
      "(934, 1332)\n",
      "(1680, 1332)\n",
      "(1872, 1332)\n",
      "{1: 5.478536894890059, 2: 5.162309618783199, 4: 10.0, 5: 4.591537722917682, 6: 4.133092889702018, 8: 8.120783683979413, 9: 6.032356783948338, 10: 6.933416856303845, 11: 6.551481966092173, 12: 9.26889180290782, 13: 6.448902021391455, 19: 8.460277074692158, 21: 8.59276610157859, 22: 1.0452024918356986, 25: 7.853883945224352, 26: 6.418256579260927, 27: 4.574567128383681, 28: 5.94918385581262, 29: 1.0}\n",
      "Train on 32096 samples, validate on 3573 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:26:56.503162: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 10.4735\n",
      "Epoch 1: val_loss improved from inf to 1.39929, saving model to ./checkpoints/unknown_person_few_shot_p17_40.h5\n",
      "32096/32096 [==============================] - 78s 2ms/sample - loss: 10.4735 - val_loss: 1.3993\n",
      "Epoch 2/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3844\n",
      "Epoch 2: val_loss improved from 1.39929 to 1.38654, saving model to ./checkpoints/unknown_person_few_shot_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 639us/sample - loss: 10.3844 - val_loss: 1.3865\n",
      "Epoch 3/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3294\n",
      "Epoch 3: val_loss did not improve from 1.38654\n",
      "32096/32096 [==============================] - 22s 681us/sample - loss: 10.3294 - val_loss: 1.4184\n",
      "Epoch 4/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2845\n",
      "Epoch 4: val_loss did not improve from 1.38654\n",
      "32096/32096 [==============================] - 21s 641us/sample - loss: 10.2845 - val_loss: 1.3954\n",
      "Epoch 5/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2198\n",
      "Epoch 5: val_loss improved from 1.38654 to 1.38422, saving model to ./checkpoints/unknown_person_few_shot_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 676us/sample - loss: 10.2198 - val_loss: 1.3842\n",
      "Epoch 6/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1998\n",
      "Epoch 6: val_loss improved from 1.38422 to 1.38263, saving model to ./checkpoints/unknown_person_few_shot_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 743us/sample - loss: 10.1998 - val_loss: 1.3826\n",
      "Epoch 7/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1662\n",
      "Epoch 7: val_loss did not improve from 1.38263\n",
      "32096/32096 [==============================] - 24s 733us/sample - loss: 10.1662 - val_loss: 1.4081\n",
      "Epoch 8/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1275\n",
      "Epoch 8: val_loss did not improve from 1.38263\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 10.1275 - val_loss: 1.3850\n",
      "Epoch 9/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1626\n",
      "Epoch 9: val_loss did not improve from 1.38263\n",
      "32096/32096 [==============================] - 23s 729us/sample - loss: 10.1626 - val_loss: 1.4174\n",
      "Epoch 10/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1244\n",
      "Epoch 10: val_loss did not improve from 1.38263\n",
      "32096/32096 [==============================] - 23s 732us/sample - loss: 10.1244 - val_loss: 1.3909\n",
      "Epoch 11/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0871\n",
      "Epoch 11: val_loss improved from 1.38263 to 1.38170, saving model to ./checkpoints/unknown_person_few_shot_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 742us/sample - loss: 10.0871 - val_loss: 1.3817\n",
      "Epoch 12/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0938\n",
      "Epoch 12: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 23s 720us/sample - loss: 10.0938 - val_loss: 1.3950\n",
      "Epoch 13/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0893\n",
      "Epoch 13: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 21s 668us/sample - loss: 10.0893 - val_loss: 1.3855\n",
      "Epoch 14/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0871\n",
      "Epoch 14: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 10.0871 - val_loss: 1.3898\n",
      "Epoch 15/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0711\n",
      "Epoch 15: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 24s 740us/sample - loss: 10.0711 - val_loss: 1.3882\n",
      "Epoch 16/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0486\n",
      "Epoch 16: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 10.0486 - val_loss: 1.3925\n",
      "Epoch 17/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0319\n",
      "Epoch 17: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 24s 737us/sample - loss: 10.0319 - val_loss: 1.3903\n",
      "Epoch 18/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0464\n",
      "Epoch 18: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 10.0464 - val_loss: 1.3908\n",
      "Epoch 19/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.0068\n",
      "Epoch 19: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 24s 744us/sample - loss: 10.0068 - val_loss: 1.3908\n",
      "Epoch 20/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 9.9737\n",
      "Epoch 20: val_loss did not improve from 1.38170\n",
      "32096/32096 [==============================] - 23s 732us/sample - loss: 9.9737 - val_loss: 1.3834\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:35:44.107302: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_383_2/lstm_cell_1197/recurrent_kernel/Assign' id:610558 op device:{requested: '', assigned: ''} def:{{{node lstm_383_2/lstm_cell_1197/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_383_2/lstm_cell_1197/recurrent_kernel, lstm_383_2/lstm_cell_1197/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:36:17.198937: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_401_2/lstm_cell_1215/recurrent_kernel/v/Assign' id:616183 op device:{requested: '', assigned: ''} def:{{{node lstm_401_2/lstm_cell_1215/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_401_2/lstm_cell_1215/recurrent_kernel/v, lstm_401_2/lstm_cell_1215/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32096 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:36:54.634318: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:39:41.750957: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:40:07.809396: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.35940, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 83s 3ms/sample - loss: 1.3977 - val_loss: 1.3594\n",
      "Epoch 2/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3945\n",
      "Epoch 2: val_loss improved from 1.35940 to 1.35850, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 708us/sample - loss: 1.3945 - val_loss: 1.3585\n",
      "Epoch 3/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3931\n",
      "Epoch 3: val_loss did not improve from 1.35850\n",
      "32096/32096 [==============================] - 21s 647us/sample - loss: 1.3931 - val_loss: 1.3630\n",
      "Epoch 4/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 4: val_loss improved from 1.35850 to 1.35527, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 23s 705us/sample - loss: 1.3907 - val_loss: 1.3553\n",
      "Epoch 5/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3883\n",
      "Epoch 5: val_loss did not improve from 1.35527\n",
      "32096/32096 [==============================] - 21s 655us/sample - loss: 1.3883 - val_loss: 1.3619\n",
      "Epoch 6/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3867\n",
      "Epoch 6: val_loss did not improve from 1.35527\n",
      "32096/32096 [==============================] - 21s 643us/sample - loss: 1.3867 - val_loss: 1.3567\n",
      "Epoch 7/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3872\n",
      "Epoch 7: val_loss improved from 1.35527 to 1.35451, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 1.3872 - val_loss: 1.3545\n",
      "Epoch 8/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3873\n",
      "Epoch 8: val_loss improved from 1.35451 to 1.35289, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 643us/sample - loss: 1.3873 - val_loss: 1.3529\n",
      "Epoch 9/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3833\n",
      "Epoch 9: val_loss did not improve from 1.35289\n",
      "32096/32096 [==============================] - 20s 638us/sample - loss: 1.3833 - val_loss: 1.3536\n",
      "Epoch 10/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 10: val_loss improved from 1.35289 to 1.35036, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 21s 648us/sample - loss: 1.3830 - val_loss: 1.3504\n",
      "Epoch 11/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3827\n",
      "Epoch 11: val_loss improved from 1.35036 to 1.34959, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 689us/sample - loss: 1.3827 - val_loss: 1.3496\n",
      "Epoch 12/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3794\n",
      "Epoch 12: val_loss did not improve from 1.34959\n",
      "32096/32096 [==============================] - 23s 731us/sample - loss: 1.3794 - val_loss: 1.3498\n",
      "Epoch 13/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 13: val_loss improved from 1.34959 to 1.34876, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 734us/sample - loss: 1.3796 - val_loss: 1.3488\n",
      "Epoch 14/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3782\n",
      "Epoch 14: val_loss did not improve from 1.34876\n",
      "32096/32096 [==============================] - 24s 734us/sample - loss: 1.3782 - val_loss: 1.3488\n",
      "Epoch 15/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3768\n",
      "Epoch 15: val_loss improved from 1.34876 to 1.34742, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 22s 677us/sample - loss: 1.3768 - val_loss: 1.3474\n",
      "Epoch 16/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3753\n",
      "Epoch 16: val_loss improved from 1.34742 to 1.34712, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 740us/sample - loss: 1.3753 - val_loss: 1.3471\n",
      "Epoch 17/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3741\n",
      "Epoch 17: val_loss improved from 1.34712 to 1.34164, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_40.h5\n",
      "32096/32096 [==============================] - 24s 739us/sample - loss: 1.3741 - val_loss: 1.3416\n",
      "Epoch 18/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3742\n",
      "Epoch 18: val_loss did not improve from 1.34164\n",
      "32096/32096 [==============================] - 22s 685us/sample - loss: 1.3742 - val_loss: 1.3440\n",
      "Epoch 19/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3716\n",
      "Epoch 19: val_loss did not improve from 1.34164\n",
      "32096/32096 [==============================] - 21s 642us/sample - loss: 1.3716 - val_loss: 1.3463\n",
      "Epoch 20/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3683\n",
      "Epoch 20: val_loss did not improve from 1.34164\n",
      "32096/32096 [==============================] - 21s 646us/sample - loss: 1.3683 - val_loss: 1.3432\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:48:12.917392: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_411/lstm_cell_1225/bias/Assign' id:628169 op device:{requested: '', assigned: ''} def:{{{node lstm_411/lstm_cell_1225/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_411/lstm_cell_1225/bias, lstm_411/lstm_cell_1225/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:48:30.666066: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_1' id:631098 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:48:44.832706: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_2' id:631099 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32096, 95)\n",
      "Train on 32096 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:49:17.637473: W tensorflow/c/c_api.cc:304] Operation '{name:'training_66/Adam/lstm_413/lstm_cell_1227/recurrent_kernel/v/Assign' id:644594 op device:{requested: '', assigned: ''} def:{{{node training_66/Adam/lstm_413/lstm_cell_1227/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_66/Adam/lstm_413/lstm_cell_1227/recurrent_kernel/v, training_66/Adam/lstm_413/lstm_cell_1227/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:52:08.801793: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 2.8993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:52:32.124951: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_67/mul' id:633939 op device:{requested: '', assigned: ''} def:{{{node loss_67/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_67/mul/x, loss_67/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.87727, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 178s 6ms/sample - loss: 2.8993 - val_loss: 1.8773\n",
      "Epoch 2/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.7430\n",
      "Epoch 2: val_loss improved from 1.87727 to 1.56607, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 657us/sample - loss: 1.7430 - val_loss: 1.5661\n",
      "Epoch 3/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5975\n",
      "Epoch 3: val_loss improved from 1.56607 to 1.49948, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 651us/sample - loss: 1.5975 - val_loss: 1.4995\n",
      "Epoch 4/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5435\n",
      "Epoch 4: val_loss improved from 1.49948 to 1.46714, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 656us/sample - loss: 1.5435 - val_loss: 1.4671\n",
      "Epoch 5/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5183\n",
      "Epoch 5: val_loss improved from 1.46714 to 1.45127, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 653us/sample - loss: 1.5183 - val_loss: 1.4513\n",
      "Epoch 6/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5035\n",
      "Epoch 6: val_loss improved from 1.45127 to 1.44659, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 663us/sample - loss: 1.5035 - val_loss: 1.4466\n",
      "Epoch 7/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 7: val_loss improved from 1.44659 to 1.43628, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 22s 670us/sample - loss: 1.4903 - val_loss: 1.4363\n",
      "Epoch 8/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4937\n",
      "Epoch 8: val_loss did not improve from 1.43628\n",
      "32096/32096 [==============================] - 23s 708us/sample - loss: 1.4937 - val_loss: 1.4378\n",
      "Epoch 9/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4953\n",
      "Epoch 9: val_loss improved from 1.43628 to 1.42754, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 664us/sample - loss: 1.4953 - val_loss: 1.4275\n",
      "Epoch 10/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5117\n",
      "Epoch 10: val_loss did not improve from 1.42754\n",
      "32096/32096 [==============================] - 21s 667us/sample - loss: 1.5117 - val_loss: 1.4331\n",
      "Epoch 11/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4821\n",
      "Epoch 11: val_loss improved from 1.42754 to 1.42451, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 733us/sample - loss: 1.4821 - val_loss: 1.4245\n",
      "Epoch 12/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 12: val_loss improved from 1.42451 to 1.42025, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 750us/sample - loss: 1.4787 - val_loss: 1.4202\n",
      "Epoch 13/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4847\n",
      "Epoch 13: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 24s 738us/sample - loss: 1.4847 - val_loss: 1.4257\n",
      "Epoch 14/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5008\n",
      "Epoch 14: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 24s 734us/sample - loss: 1.5008 - val_loss: 1.4231\n",
      "Epoch 15/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4838\n",
      "Epoch 15: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 23s 729us/sample - loss: 1.4838 - val_loss: 1.4221\n",
      "Epoch 16/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4994\n",
      "Epoch 16: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 24s 734us/sample - loss: 1.4994 - val_loss: 1.4248\n",
      "Epoch 17/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5168\n",
      "Epoch 17: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 24s 735us/sample - loss: 1.5168 - val_loss: 1.4279\n",
      "Epoch 18/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5032\n",
      "Epoch 18: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 23s 729us/sample - loss: 1.5032 - val_loss: 1.4227\n",
      "Epoch 19/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5037\n",
      "Epoch 19: val_loss did not improve from 1.42025\n",
      "32096/32096 [==============================] - 23s 726us/sample - loss: 1.5037 - val_loss: 1.4226\n",
      "Epoch 20/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5027\n",
      "Epoch 20: val_loss improved from 1.42025 to 1.42003, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 22s 682us/sample - loss: 1.5027 - val_loss: 1.4200\n",
      "Epoch 21/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5095\n",
      "Epoch 21: val_loss did not improve from 1.42003\n",
      "32096/32096 [==============================] - 22s 686us/sample - loss: 1.5095 - val_loss: 1.4220\n",
      "Epoch 22/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5775\n",
      "Epoch 22: val_loss did not improve from 1.42003\n",
      "32096/32096 [==============================] - 22s 685us/sample - loss: 1.5775 - val_loss: 1.4316\n",
      "Epoch 23/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.5301\n",
      "Epoch 23: val_loss did not improve from 1.42003\n",
      "32096/32096 [==============================] - 22s 680us/sample - loss: 1.5301 - val_loss: 1.4272\n",
      "Epoch 24/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4916\n",
      "Epoch 24: val_loss did not improve from 1.42003\n",
      "32096/32096 [==============================] - 23s 717us/sample - loss: 1.4916 - val_loss: 1.4211\n",
      "Epoch 25/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4674\n",
      "Epoch 25: val_loss improved from 1.42003 to 1.41163, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 748us/sample - loss: 1.4674 - val_loss: 1.4116\n",
      "Epoch 26/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4628\n",
      "Epoch 26: val_loss improved from 1.41163 to 1.40919, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 751us/sample - loss: 1.4628 - val_loss: 1.4092\n",
      "Epoch 27/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4568\n",
      "Epoch 27: val_loss improved from 1.40919 to 1.40739, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 752us/sample - loss: 1.4568 - val_loss: 1.4074\n",
      "Epoch 28/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4528\n",
      "Epoch 28: val_loss improved from 1.40739 to 1.40319, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.4528 - val_loss: 1.4032\n",
      "Epoch 29/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4493\n",
      "Epoch 29: val_loss improved from 1.40319 to 1.40269, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 22s 672us/sample - loss: 1.4493 - val_loss: 1.4027\n",
      "Epoch 30/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4455\n",
      "Epoch 30: val_loss improved from 1.40269 to 1.40007, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 22s 671us/sample - loss: 1.4455 - val_loss: 1.4001\n",
      "Epoch 31/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4406\n",
      "Epoch 31: val_loss improved from 1.40007 to 1.39464, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 660us/sample - loss: 1.4406 - val_loss: 1.3946\n",
      "Epoch 32/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4393\n",
      "Epoch 32: val_loss did not improve from 1.39464\n",
      "32096/32096 [==============================] - 21s 659us/sample - loss: 1.4393 - val_loss: 1.3998\n",
      "Epoch 33/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4338\n",
      "Epoch 33: val_loss improved from 1.39464 to 1.39099, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 23s 722us/sample - loss: 1.4338 - val_loss: 1.3910\n",
      "Epoch 34/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4356\n",
      "Epoch 34: val_loss improved from 1.39099 to 1.38995, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 754us/sample - loss: 1.4356 - val_loss: 1.3900\n",
      "Epoch 35/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4315\n",
      "Epoch 35: val_loss improved from 1.38995 to 1.38518, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 23s 721us/sample - loss: 1.4315 - val_loss: 1.3852\n",
      "Epoch 36/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4304\n",
      "Epoch 36: val_loss improved from 1.38518 to 1.38278, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 669us/sample - loss: 1.4304 - val_loss: 1.3828\n",
      "Epoch 37/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 37: val_loss did not improve from 1.38278\n",
      "32096/32096 [==============================] - 21s 654us/sample - loss: 1.4277 - val_loss: 1.3835\n",
      "Epoch 38/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 38: val_loss did not improve from 1.38278\n",
      "32096/32096 [==============================] - 22s 691us/sample - loss: 1.4249 - val_loss: 1.3829\n",
      "Epoch 39/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4227\n",
      "Epoch 39: val_loss did not improve from 1.38278\n",
      "32096/32096 [==============================] - 24s 733us/sample - loss: 1.4227 - val_loss: 1.3853\n",
      "Epoch 40/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4224\n",
      "Epoch 40: val_loss improved from 1.38278 to 1.37702, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 742us/sample - loss: 1.4224 - val_loss: 1.3770\n",
      "Epoch 41/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4188\n",
      "Epoch 41: val_loss improved from 1.37702 to 1.37277, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 736us/sample - loss: 1.4188 - val_loss: 1.3728\n",
      "Epoch 42/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 42: val_loss did not improve from 1.37277\n",
      "32096/32096 [==============================] - 21s 647us/sample - loss: 1.4191 - val_loss: 1.3754\n",
      "Epoch 43/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 43: val_loss improved from 1.37277 to 1.37183, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 658us/sample - loss: 1.4176 - val_loss: 1.3718\n",
      "Epoch 44/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4142\n",
      "Epoch 44: val_loss did not improve from 1.37183\n",
      "32096/32096 [==============================] - 21s 650us/sample - loss: 1.4142 - val_loss: 1.3766\n",
      "Epoch 45/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4133\n",
      "Epoch 45: val_loss improved from 1.37183 to 1.37128, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 654us/sample - loss: 1.4133 - val_loss: 1.3713\n",
      "Epoch 46/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4135\n",
      "Epoch 46: val_loss improved from 1.37128 to 1.37032, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 661us/sample - loss: 1.4135 - val_loss: 1.3703\n",
      "Epoch 47/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4110\n",
      "Epoch 47: val_loss did not improve from 1.37032\n",
      "32096/32096 [==============================] - 21s 648us/sample - loss: 1.4110 - val_loss: 1.3768\n",
      "Epoch 48/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 48: val_loss did not improve from 1.37032\n",
      "32096/32096 [==============================] - 21s 650us/sample - loss: 1.4080 - val_loss: 1.3718\n",
      "Epoch 49/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4116\n",
      "Epoch 49: val_loss did not improve from 1.37032\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 1.4116 - val_loss: 1.3726\n",
      "Epoch 50/50\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 50: val_loss did not improve from 1.37032\n",
      "32096/32096 [==============================] - 21s 640us/sample - loss: 1.4070 - val_loss: 1.3750\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:13:31.355876: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_432_1/lstm_cell_1283/recurrent_kernel/Assign' id:650124 op device:{requested: '', assigned: ''} def:{{{node lstm_432_1/lstm_cell_1283/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_432_1/lstm_cell_1283/recurrent_kernel, lstm_432_1/lstm_cell_1283/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:14:06.066742: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_410_1/lstm_cell_1261/recurrent_kernel/m/Assign' id:652764 op device:{requested: '', assigned: ''} def:{{{node lstm_410_1/lstm_cell_1261/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_410_1/lstm_cell_1261/recurrent_kernel/m, lstm_410_1/lstm_cell_1261/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:14:40.354987: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_59_1/cond/Merge' id:652053 op device:{requested: '', assigned: ''} def:{{{node dropout_59_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_59_1/cond/Identity, dropout_59_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1332)\n",
      "(1514, 1332)\n",
      "(1644, 1332)\n",
      "(1764, 1332)\n",
      "(1836, 1332)\n",
      "(1699, 1332)\n",
      "(1369, 1332)\n",
      "(1778, 1332)\n",
      "(1631, 1332)\n",
      "(1692, 1332)\n",
      "(1550, 1332)\n",
      "(1716, 1332)\n",
      "(1764, 1332)\n",
      "(1872, 1332)\n",
      "(1728, 1332)\n",
      "(1824, 1332)\n",
      "(934, 1332)\n",
      "(1680, 1332)\n",
      "(1872, 1332)\n",
      "{1: 5.723791857309786, 2: 4.989799414615856, 4: 10.0, 5: 4.49087902976861, 6: 5.2200568414145545, 8: 8.40937293430671, 9: 6.627007914484136, 10: 6.993368366952787, 11: 6.911880857679894, 12: 8.836482345544729, 13: 5.907396333510576, 19: 8.56359264568744, 21: 8.097158898986487, 22: 1.0, 25: 7.706358012021224, 26: 5.350594919667259, 27: 5.153832633792278, 28: 6.050556454336966, 29: 1.7962590042004787}\n",
      "Train on 32096 samples, validate on 3573 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:21:45.810024: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 10.5800\n",
      "Epoch 1: val_loss improved from inf to 1.41329, saving model to ./checkpoints/unknown_person_few_shot_p17_41.h5\n",
      "32096/32096 [==============================] - 88s 3ms/sample - loss: 10.5800 - val_loss: 1.4133\n",
      "Epoch 2/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.5324\n",
      "Epoch 2: val_loss improved from 1.41329 to 1.39689, saving model to ./checkpoints/unknown_person_few_shot_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 753us/sample - loss: 10.5324 - val_loss: 1.3969\n",
      "Epoch 3/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.4953\n",
      "Epoch 3: val_loss improved from 1.39689 to 1.38190, saving model to ./checkpoints/unknown_person_few_shot_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 738us/sample - loss: 10.4953 - val_loss: 1.3819\n",
      "Epoch 4/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.4497\n",
      "Epoch 4: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 23s 719us/sample - loss: 10.4497 - val_loss: 1.4029\n",
      "Epoch 5/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3583\n",
      "Epoch 5: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 22s 692us/sample - loss: 10.3583 - val_loss: 1.3937\n",
      "Epoch 6/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3495\n",
      "Epoch 6: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 24s 744us/sample - loss: 10.3495 - val_loss: 1.3911\n",
      "Epoch 7/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3605\n",
      "Epoch 7: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 23s 713us/sample - loss: 10.3605 - val_loss: 1.4036\n",
      "Epoch 8/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.3314\n",
      "Epoch 8: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 21s 664us/sample - loss: 10.3314 - val_loss: 1.3933\n",
      "Epoch 9/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2674\n",
      "Epoch 9: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 23s 715us/sample - loss: 10.2674 - val_loss: 1.3955\n",
      "Epoch 10/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2858\n",
      "Epoch 10: val_loss did not improve from 1.38190\n",
      "32096/32096 [==============================] - 24s 740us/sample - loss: 10.2858 - val_loss: 1.3901\n",
      "Epoch 11/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2504\n",
      "Epoch 11: val_loss improved from 1.38190 to 1.37830, saving model to ./checkpoints/unknown_person_few_shot_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 740us/sample - loss: 10.2504 - val_loss: 1.3783\n",
      "Epoch 12/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2494\n",
      "Epoch 12: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 22s 692us/sample - loss: 10.2494 - val_loss: 1.3807\n",
      "Epoch 13/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1961\n",
      "Epoch 13: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 21s 651us/sample - loss: 10.1961 - val_loss: 1.3898\n",
      "Epoch 14/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.2353\n",
      "Epoch 14: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 21s 646us/sample - loss: 10.2353 - val_loss: 1.3840\n",
      "Epoch 15/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1998\n",
      "Epoch 15: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 21s 646us/sample - loss: 10.1998 - val_loss: 1.3845\n",
      "Epoch 16/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1879\n",
      "Epoch 16: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 10.1879 - val_loss: 1.3902\n",
      "Epoch 17/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1962\n",
      "Epoch 17: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 21s 645us/sample - loss: 10.1962 - val_loss: 1.3848\n",
      "Epoch 18/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1705\n",
      "Epoch 18: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 21s 650us/sample - loss: 10.1705 - val_loss: 1.3967\n",
      "Epoch 19/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1543\n",
      "Epoch 19: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 23s 717us/sample - loss: 10.1543 - val_loss: 1.3931\n",
      "Epoch 20/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 10.1571\n",
      "Epoch 20: val_loss did not improve from 1.37830\n",
      "32096/32096 [==============================] - 22s 690us/sample - loss: 10.1571 - val_loss: 1.3839\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:30:30.554704: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_430_2/lstm_cell_1318/bias/Assign' id:669211 op device:{requested: '', assigned: ''} def:{{{node lstm_430_2/lstm_cell_1318/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_430_2/lstm_cell_1318/bias, lstm_430_2/lstm_cell_1318/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:31:05.352854: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_431_2/lstm_cell_1319/recurrent_kernel/m/Assign' id:672477 op device:{requested: '', assigned: ''} def:{{{node lstm_431_2/lstm_cell_1319/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_431_2/lstm_cell_1319/recurrent_kernel/m, lstm_431_2/lstm_cell_1319/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32096 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:31:42.704570: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:34:40.761439: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:35:03.544836: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36929, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_41.h5\n",
      "32096/32096 [==============================] - 84s 3ms/sample - loss: 1.4119 - val_loss: 1.3693\n",
      "Epoch 2/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4122\n",
      "Epoch 2: val_loss improved from 1.36929 to 1.36390, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 750us/sample - loss: 1.4122 - val_loss: 1.3639\n",
      "Epoch 3/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 3: val_loss did not improve from 1.36390\n",
      "32096/32096 [==============================] - 24s 747us/sample - loss: 1.4067 - val_loss: 1.3677\n",
      "Epoch 4/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4031\n",
      "Epoch 4: val_loss did not improve from 1.36390\n",
      "32096/32096 [==============================] - 24s 745us/sample - loss: 1.4031 - val_loss: 1.3678\n",
      "Epoch 5/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4035\n",
      "Epoch 5: val_loss improved from 1.36390 to 1.36294, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 753us/sample - loss: 1.4035 - val_loss: 1.3629\n",
      "Epoch 6/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 6: val_loss did not improve from 1.36294\n",
      "32096/32096 [==============================] - 24s 745us/sample - loss: 1.4026 - val_loss: 1.3678\n",
      "Epoch 7/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 7: val_loss did not improve from 1.36294\n",
      "32096/32096 [==============================] - 24s 747us/sample - loss: 1.3975 - val_loss: 1.3680\n",
      "Epoch 8/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 8: val_loss did not improve from 1.36294\n",
      "32096/32096 [==============================] - 24s 744us/sample - loss: 1.3992 - val_loss: 1.3660\n",
      "Epoch 9/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3959\n",
      "Epoch 9: val_loss did not improve from 1.36294\n",
      "32096/32096 [==============================] - 24s 745us/sample - loss: 1.3959 - val_loss: 1.3637\n",
      "Epoch 10/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 10: val_loss improved from 1.36294 to 1.35610, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_41.h5\n",
      "32096/32096 [==============================] - 24s 753us/sample - loss: 1.3947 - val_loss: 1.3561\n",
      "Epoch 11/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3954\n",
      "Epoch 11: val_loss did not improve from 1.35610\n",
      "32096/32096 [==============================] - 23s 732us/sample - loss: 1.3954 - val_loss: 1.3602\n",
      "Epoch 12/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 12: val_loss did not improve from 1.35610\n",
      "32096/32096 [==============================] - 21s 657us/sample - loss: 1.3928 - val_loss: 1.3598\n",
      "Epoch 13/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 13: val_loss did not improve from 1.35610\n",
      "32096/32096 [==============================] - 21s 657us/sample - loss: 1.3917 - val_loss: 1.3583\n",
      "Epoch 14/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 14: val_loss improved from 1.35610 to 1.35442, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_41.h5\n",
      "32096/32096 [==============================] - 21s 657us/sample - loss: 1.3902 - val_loss: 1.3544\n",
      "Epoch 15/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3894\n",
      "Epoch 15: val_loss did not improve from 1.35442\n",
      "32096/32096 [==============================] - 22s 695us/sample - loss: 1.3894 - val_loss: 1.3569\n",
      "Epoch 16/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3876\n",
      "Epoch 16: val_loss did not improve from 1.35442\n",
      "32096/32096 [==============================] - 23s 722us/sample - loss: 1.3876 - val_loss: 1.3567\n",
      "Epoch 17/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3865\n",
      "Epoch 17: val_loss improved from 1.35442 to 1.35230, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_41.h5\n",
      "32096/32096 [==============================] - 23s 732us/sample - loss: 1.3865 - val_loss: 1.3523\n",
      "Epoch 18/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3869\n",
      "Epoch 18: val_loss did not improve from 1.35230\n",
      "32096/32096 [==============================] - 22s 691us/sample - loss: 1.3869 - val_loss: 1.3605\n",
      "Epoch 19/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3864\n",
      "Epoch 19: val_loss did not improve from 1.35230\n",
      "32096/32096 [==============================] - 23s 704us/sample - loss: 1.3864 - val_loss: 1.3553\n",
      "Epoch 20/20\n",
      "32096/32096 [==============================] - ETA: 0s - loss: 1.3853\n",
      "Epoch 20: val_loss did not improve from 1.35230\n",
      "32096/32096 [==============================] - 24s 742us/sample - loss: 1.3853 - val_loss: 1.3527\n",
      "35897\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:43:47.648791: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_450/lstm_cell_1338/bias/Assign' id:685541 op device:{requested: '', assigned: ''} def:{{{node lstm_450/lstm_cell_1338/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_450/lstm_cell_1338/bias, lstm_450/lstm_cell_1338/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:44:07.587660: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_1' id:688140 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:44:23.740694: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_2' id:688141 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32300, 95)\n",
      "Train on 32300 samples, validate on 3597 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:45:00.463030: W tensorflow/c/c_api.cc:304] Operation '{name:'training_72/Adam/dense_51/bias/m/Assign' id:701494 op device:{requested: '', assigned: ''} def:{{{node training_72/Adam/dense_51/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_72/Adam/dense_51/bias/m, training_72/Adam/dense_51/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:48:12.068093: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 3.2634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 18:48:37.876843: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_73/mul' id:690981 op device:{requested: '', assigned: ''} def:{{{node loss_73/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_73/mul/x, loss_73/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95167, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 196s 6ms/sample - loss: 3.2634 - val_loss: 1.9517\n",
      "Epoch 2/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.7982\n",
      "Epoch 2: val_loss improved from 1.95167 to 1.55701, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 651us/sample - loss: 1.7982 - val_loss: 1.5570\n",
      "Epoch 3/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5805\n",
      "Epoch 3: val_loss improved from 1.55701 to 1.49589, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 23s 727us/sample - loss: 1.5805 - val_loss: 1.4959\n",
      "Epoch 4/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5291\n",
      "Epoch 4: val_loss improved from 1.49589 to 1.47335, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 743us/sample - loss: 1.5291 - val_loss: 1.4733\n",
      "Epoch 5/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5042\n",
      "Epoch 5: val_loss improved from 1.47335 to 1.46875, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 740us/sample - loss: 1.5042 - val_loss: 1.4687\n",
      "Epoch 6/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4923\n",
      "Epoch 6: val_loss improved from 1.46875 to 1.44755, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 735us/sample - loss: 1.4923 - val_loss: 1.4475\n",
      "Epoch 7/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4837\n",
      "Epoch 7: val_loss improved from 1.44755 to 1.44105, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 729us/sample - loss: 1.4837 - val_loss: 1.4410\n",
      "Epoch 8/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4835\n",
      "Epoch 8: val_loss did not improve from 1.44105\n",
      "32300/32300 [==============================] - 24s 730us/sample - loss: 1.4835 - val_loss: 1.4421\n",
      "Epoch 9/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4742\n",
      "Epoch 9: val_loss improved from 1.44105 to 1.43882, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 743us/sample - loss: 1.4742 - val_loss: 1.4388\n",
      "Epoch 10/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4721\n",
      "Epoch 10: val_loss improved from 1.43882 to 1.43485, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 740us/sample - loss: 1.4721 - val_loss: 1.4348\n",
      "Epoch 11/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4644\n",
      "Epoch 11: val_loss improved from 1.43485 to 1.42853, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 739us/sample - loss: 1.4644 - val_loss: 1.4285\n",
      "Epoch 12/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4676\n",
      "Epoch 12: val_loss improved from 1.42853 to 1.42691, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 23s 706us/sample - loss: 1.4676 - val_loss: 1.4269\n",
      "Epoch 13/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4661\n",
      "Epoch 13: val_loss improved from 1.42691 to 1.42684, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 737us/sample - loss: 1.4661 - val_loss: 1.4268\n",
      "Epoch 14/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4614\n",
      "Epoch 14: val_loss did not improve from 1.42684\n",
      "32300/32300 [==============================] - 24s 737us/sample - loss: 1.4614 - val_loss: 1.4282\n",
      "Epoch 15/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4815\n",
      "Epoch 15: val_loss did not improve from 1.42684\n",
      "32300/32300 [==============================] - 23s 709us/sample - loss: 1.4815 - val_loss: 1.4440\n",
      "Epoch 16/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4610\n",
      "Epoch 16: val_loss improved from 1.42684 to 1.42014, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.4610 - val_loss: 1.4201\n",
      "Epoch 17/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4604\n",
      "Epoch 17: val_loss did not improve from 1.42014\n",
      "32300/32300 [==============================] - 21s 637us/sample - loss: 1.4604 - val_loss: 1.4301\n",
      "Epoch 18/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4508\n",
      "Epoch 18: val_loss did not improve from 1.42014\n",
      "32300/32300 [==============================] - 21s 635us/sample - loss: 1.4508 - val_loss: 1.4269\n",
      "Epoch 19/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4504\n",
      "Epoch 19: val_loss did not improve from 1.42014\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.4504 - val_loss: 1.4248\n",
      "Epoch 20/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4578\n",
      "Epoch 20: val_loss did not improve from 1.42014\n",
      "32300/32300 [==============================] - 20s 634us/sample - loss: 1.4578 - val_loss: 1.4208\n",
      "Epoch 21/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4799\n",
      "Epoch 21: val_loss did not improve from 1.42014\n",
      "32300/32300 [==============================] - 20s 634us/sample - loss: 1.4799 - val_loss: 1.4240\n",
      "Epoch 22/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4617\n",
      "Epoch 22: val_loss did not improve from 1.42014\n",
      "32300/32300 [==============================] - 20s 634us/sample - loss: 1.4617 - val_loss: 1.4211\n",
      "Epoch 23/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 23: val_loss improved from 1.42014 to 1.41620, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 739us/sample - loss: 1.4432 - val_loss: 1.4162\n",
      "Epoch 24/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4348\n",
      "Epoch 24: val_loss improved from 1.41620 to 1.41105, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 23s 721us/sample - loss: 1.4348 - val_loss: 1.4111\n",
      "Epoch 25/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 25: val_loss improved from 1.41105 to 1.40909, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 656us/sample - loss: 1.4321 - val_loss: 1.4091\n",
      "Epoch 26/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4272\n",
      "Epoch 26: val_loss improved from 1.40909 to 1.40340, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 23s 721us/sample - loss: 1.4272 - val_loss: 1.4034\n",
      "Epoch 27/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 27: val_loss improved from 1.40340 to 1.40233, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 739us/sample - loss: 1.4232 - val_loss: 1.4023\n",
      "Epoch 28/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4199\n",
      "Epoch 28: val_loss improved from 1.40233 to 1.39781, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 23s 722us/sample - loss: 1.4199 - val_loss: 1.3978\n",
      "Epoch 29/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4187\n",
      "Epoch 29: val_loss did not improve from 1.39781\n",
      "32300/32300 [==============================] - 21s 656us/sample - loss: 1.4187 - val_loss: 1.3987\n",
      "Epoch 30/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4169\n",
      "Epoch 30: val_loss did not improve from 1.39781\n",
      "32300/32300 [==============================] - 23s 727us/sample - loss: 1.4169 - val_loss: 1.4004\n",
      "Epoch 31/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4135\n",
      "Epoch 31: val_loss did not improve from 1.39781\n",
      "32300/32300 [==============================] - 24s 740us/sample - loss: 1.4135 - val_loss: 1.3999\n",
      "Epoch 32/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4114\n",
      "Epoch 32: val_loss improved from 1.39781 to 1.39024, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 741us/sample - loss: 1.4114 - val_loss: 1.3902\n",
      "Epoch 33/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 33: val_loss did not improve from 1.39024\n",
      "32300/32300 [==============================] - 21s 661us/sample - loss: 1.4082 - val_loss: 1.3960\n",
      "Epoch 34/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4081\n",
      "Epoch 34: val_loss did not improve from 1.39024\n",
      "32300/32300 [==============================] - 24s 731us/sample - loss: 1.4081 - val_loss: 1.3927\n",
      "Epoch 35/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4060\n",
      "Epoch 35: val_loss improved from 1.39024 to 1.38759, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 745us/sample - loss: 1.4060 - val_loss: 1.3876\n",
      "Epoch 36/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4016\n",
      "Epoch 36: val_loss did not improve from 1.38759\n",
      "32300/32300 [==============================] - 24s 730us/sample - loss: 1.4016 - val_loss: 1.3949\n",
      "Epoch 37/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4013\n",
      "Epoch 37: val_loss did not improve from 1.38759\n",
      "32300/32300 [==============================] - 24s 739us/sample - loss: 1.4013 - val_loss: 1.3888\n",
      "Epoch 38/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 38: val_loss improved from 1.38759 to 1.38416, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 754us/sample - loss: 1.3992 - val_loss: 1.3842\n",
      "Epoch 39/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3968\n",
      "Epoch 39: val_loss did not improve from 1.38416\n",
      "32300/32300 [==============================] - 24s 740us/sample - loss: 1.3968 - val_loss: 1.3851\n",
      "Epoch 40/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 40: val_loss improved from 1.38416 to 1.38186, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 749us/sample - loss: 1.3936 - val_loss: 1.3819\n",
      "Epoch 41/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 41: val_loss improved from 1.38186 to 1.37993, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 748us/sample - loss: 1.3896 - val_loss: 1.3799\n",
      "Epoch 42/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3942\n",
      "Epoch 42: val_loss did not improve from 1.37993\n",
      "32300/32300 [==============================] - 24s 729us/sample - loss: 1.3942 - val_loss: 1.3828\n",
      "Epoch 43/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 43: val_loss did not improve from 1.37993\n",
      "32300/32300 [==============================] - 21s 657us/sample - loss: 1.3887 - val_loss: 1.3821\n",
      "Epoch 44/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3899\n",
      "Epoch 44: val_loss did not improve from 1.37993\n",
      "32300/32300 [==============================] - 21s 651us/sample - loss: 1.3899 - val_loss: 1.3855\n",
      "Epoch 45/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3866\n",
      "Epoch 45: val_loss improved from 1.37993 to 1.37912, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 658us/sample - loss: 1.3866 - val_loss: 1.3791\n",
      "Epoch 46/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3856\n",
      "Epoch 46: val_loss improved from 1.37912 to 1.37621, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 661us/sample - loss: 1.3856 - val_loss: 1.3762\n",
      "Epoch 47/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3809\n",
      "Epoch 47: val_loss improved from 1.37621 to 1.37438, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 735us/sample - loss: 1.3809 - val_loss: 1.3744\n",
      "Epoch 48/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3826\n",
      "Epoch 48: val_loss improved from 1.37438 to 1.37060, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 744us/sample - loss: 1.3826 - val_loss: 1.3706\n",
      "Epoch 49/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3817\n",
      "Epoch 49: val_loss did not improve from 1.37060\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.3817 - val_loss: 1.3716\n",
      "Epoch 50/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3756\n",
      "Epoch 50: val_loss did not improve from 1.37060\n",
      "32300/32300 [==============================] - 24s 736us/sample - loss: 1.3756 - val_loss: 1.3816\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:10:20.708842: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_478_1/lstm_cell_1403/bias/Assign' id:708615 op device:{requested: '', assigned: ''} def:{{{node lstm_478_1/lstm_cell_1403/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_478_1/lstm_cell_1403/bias, lstm_478_1/lstm_cell_1403/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:10:58.643725: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_452_1/lstm_cell_1377/bias/v/Assign' id:710529 op device:{requested: '', assigned: ''} def:{{{node lstm_452_1/lstm_cell_1377/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_452_1/lstm_cell_1377/bias/v, lstm_452_1/lstm_cell_1377/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 19:11:36.133106: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_64_1/cond/Merge' id:709095 op device:{requested: '', assigned: ''} def:{{{node dropout_64_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_64_1/cond/Identity, dropout_64_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1104)\n",
      "(1514, 1104)\n",
      "(1644, 1104)\n",
      "(1764, 1104)\n",
      "(1836, 1104)\n",
      "(1699, 1104)\n",
      "(1369, 1104)\n",
      "(1766, 1104)\n",
      "(1631, 1104)\n",
      "(1692, 1104)\n",
      "(1550, 1104)\n",
      "(1728, 1104)\n",
      "(1752, 1104)\n",
      "(1884, 1104)\n",
      "(1728, 1104)\n",
      "(1788, 1104)\n",
      "(982, 1104)\n",
      "(1668, 1104)\n",
      "(1884, 1104)\n",
      "{1: 5.682932364596893, 2: 5.626771616945458, 4: 10.0, 5: 4.786825596339696, 6: 5.250764959790262, 8: 8.561448729816085, 9: 7.210305101913381, 10: 7.198918784651277, 11: 7.126168248467408, 12: 8.882606678712198, 13: 5.934440509950666, 19: 8.433208981753026, 21: 8.303574028129887, 22: 1.0, 25: 7.3849925340089975, 26: 5.679120375028385, 27: 5.454951555707299, 28: 5.17297107824109, 29: 2.352386775917312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907972/3306004915.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32300 samples, validate on 3597 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:19:10.421995: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7713\n",
      "Epoch 1: val_loss improved from inf to 1.41174, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 93s 3ms/sample - loss: 10.7713 - val_loss: 1.4117\n",
      "Epoch 2/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7082\n",
      "Epoch 2: val_loss improved from 1.41174 to 1.39179, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 754us/sample - loss: 10.7082 - val_loss: 1.3918\n",
      "Epoch 3/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6151\n",
      "Epoch 3: val_loss improved from 1.39179 to 1.38602, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 757us/sample - loss: 10.6151 - val_loss: 1.3860\n",
      "Epoch 4/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5421\n",
      "Epoch 4: val_loss improved from 1.38602 to 1.38542, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 753us/sample - loss: 10.5421 - val_loss: 1.3854\n",
      "Epoch 5/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5510\n",
      "Epoch 5: val_loss did not improve from 1.38542\n",
      "32300/32300 [==============================] - 22s 672us/sample - loss: 10.5510 - val_loss: 1.3874\n",
      "Epoch 6/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5271\n",
      "Epoch 6: val_loss did not improve from 1.38542\n",
      "32300/32300 [==============================] - 20s 634us/sample - loss: 10.5271 - val_loss: 1.3901\n",
      "Epoch 7/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5691\n",
      "Epoch 7: val_loss improved from 1.38542 to 1.38315, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 642us/sample - loss: 10.5691 - val_loss: 1.3832\n",
      "Epoch 8/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4646\n",
      "Epoch 8: val_loss did not improve from 1.38315\n",
      "32300/32300 [==============================] - 21s 641us/sample - loss: 10.4646 - val_loss: 1.3920\n",
      "Epoch 9/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4573\n",
      "Epoch 9: val_loss improved from 1.38315 to 1.38279, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 10.4573 - val_loss: 1.3828\n",
      "Epoch 10/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4119\n",
      "Epoch 10: val_loss did not improve from 1.38279\n",
      "32300/32300 [==============================] - 24s 740us/sample - loss: 10.4119 - val_loss: 1.3874\n",
      "Epoch 11/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3699\n",
      "Epoch 11: val_loss improved from 1.38279 to 1.37877, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 24s 745us/sample - loss: 10.3699 - val_loss: 1.3788\n",
      "Epoch 12/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4205\n",
      "Epoch 12: val_loss improved from 1.37877 to 1.37323, saving model to ./checkpoints/unknown_person_few_shot_p17_42.h5\n",
      "32300/32300 [==============================] - 23s 705us/sample - loss: 10.4205 - val_loss: 1.3732\n",
      "Epoch 13/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3892\n",
      "Epoch 13: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 23s 714us/sample - loss: 10.3892 - val_loss: 1.3804\n",
      "Epoch 14/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3971\n",
      "Epoch 14: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 21s 645us/sample - loss: 10.3971 - val_loss: 1.3770\n",
      "Epoch 15/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3479\n",
      "Epoch 15: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 22s 669us/sample - loss: 10.3479 - val_loss: 1.3795\n",
      "Epoch 16/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3245\n",
      "Epoch 16: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 21s 637us/sample - loss: 10.3245 - val_loss: 1.3770\n",
      "Epoch 17/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3311\n",
      "Epoch 17: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 22s 675us/sample - loss: 10.3311 - val_loss: 1.3861\n",
      "Epoch 18/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.3205\n",
      "Epoch 18: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 24s 739us/sample - loss: 10.3205 - val_loss: 1.3787\n",
      "Epoch 19/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.2903\n",
      "Epoch 19: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 24s 732us/sample - loss: 10.2903 - val_loss: 1.3782\n",
      "Epoch 20/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.2924\n",
      "Epoch 20: val_loss did not improve from 1.37323\n",
      "32300/32300 [==============================] - 23s 721us/sample - loss: 10.2924 - val_loss: 1.3822\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:28:05.061691: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_479_2/lstm_cell_1441/kernel/Assign' id:728144 op device:{requested: '', assigned: ''} def:{{{node lstm_479_2/lstm_cell_1441/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_479_2/lstm_cell_1441/kernel, lstm_479_2/lstm_cell_1441/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:28:44.216528: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_479_2/lstm_cell_1441/kernel/v/Assign' id:730322 op device:{requested: '', assigned: ''} def:{{{node lstm_479_2/lstm_cell_1441/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_479_2/lstm_cell_1441/kernel/v, lstm_479_2/lstm_cell_1441/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32300 samples, validate on 3597 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:29:26.045447: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:32:46.306081: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:33:09.627585: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37656, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 91s 3ms/sample - loss: 1.3793 - val_loss: 1.3766\n",
      "Epoch 2/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3797\n",
      "Epoch 2: val_loss improved from 1.37656 to 1.36927, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 1.3797 - val_loss: 1.3693\n",
      "Epoch 3/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3778\n",
      "Epoch 3: val_loss did not improve from 1.36927\n",
      "32300/32300 [==============================] - 21s 642us/sample - loss: 1.3778 - val_loss: 1.3867\n",
      "Epoch 4/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3750\n",
      "Epoch 4: val_loss improved from 1.36927 to 1.36902, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 1.3750 - val_loss: 1.3690\n",
      "Epoch 5/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3745\n",
      "Epoch 5: val_loss did not improve from 1.36902\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3745 - val_loss: 1.3709\n",
      "Epoch 6/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3697\n",
      "Epoch 6: val_loss did not improve from 1.36902\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3697 - val_loss: 1.3718\n",
      "Epoch 7/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3715\n",
      "Epoch 7: val_loss did not improve from 1.36902\n",
      "32300/32300 [==============================] - 21s 648us/sample - loss: 1.3715 - val_loss: 1.3699\n",
      "Epoch 8/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3690\n",
      "Epoch 8: val_loss did not improve from 1.36902\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.3690 - val_loss: 1.3701\n",
      "Epoch 9/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3696\n",
      "Epoch 9: val_loss did not improve from 1.36902\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3696 - val_loss: 1.3741\n",
      "Epoch 10/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3662\n",
      "Epoch 10: val_loss did not improve from 1.36902\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3662 - val_loss: 1.3771\n",
      "Epoch 11/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3650\n",
      "Epoch 11: val_loss improved from 1.36902 to 1.36541, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 1.3650 - val_loss: 1.3654\n",
      "Epoch 12/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3679\n",
      "Epoch 12: val_loss did not improve from 1.36541\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.3679 - val_loss: 1.3678\n",
      "Epoch 13/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3645\n",
      "Epoch 13: val_loss improved from 1.36541 to 1.36246, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 22s 669us/sample - loss: 1.3645 - val_loss: 1.3625\n",
      "Epoch 14/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3599\n",
      "Epoch 14: val_loss improved from 1.36246 to 1.36185, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 651us/sample - loss: 1.3599 - val_loss: 1.3618\n",
      "Epoch 15/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3610\n",
      "Epoch 15: val_loss did not improve from 1.36185\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3610 - val_loss: 1.3694\n",
      "Epoch 16/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3620\n",
      "Epoch 16: val_loss did not improve from 1.36185\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.3620 - val_loss: 1.3675\n",
      "Epoch 17/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3558\n",
      "Epoch 17: val_loss did not improve from 1.36185\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3558 - val_loss: 1.3653\n",
      "Epoch 18/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3568\n",
      "Epoch 18: val_loss improved from 1.36185 to 1.36020, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.3568 - val_loss: 1.3602\n",
      "Epoch 19/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3564\n",
      "Epoch 19: val_loss did not improve from 1.36020\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3564 - val_loss: 1.3616\n",
      "Epoch 20/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3546\n",
      "Epoch 20: val_loss improved from 1.36020 to 1.35807, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_42.h5\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.3546 - val_loss: 1.3581\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:41:07.010385: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_483/lstm_cell_1445/recurrent_kernel/Assign' id:741914 op device:{requested: '', assigned: ''} def:{{{node lstm_483/lstm_cell_1445/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_483/lstm_cell_1445/recurrent_kernel, lstm_483/lstm_cell_1445/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:41:28.165610: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_1' id:745182 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:41:45.266735: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_2' id:745183 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32300, 95)\n",
      "Train on 32300 samples, validate on 3597 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:42:26.233307: W tensorflow/c/c_api.cc:304] Operation '{name:'training_78/Adam/lstm_495/lstm_cell_1457/recurrent_kernel/m/Assign' id:758155 op device:{requested: '', assigned: ''} def:{{{node training_78/Adam/lstm_495/lstm_cell_1457/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_78/Adam/lstm_495/lstm_cell_1457/recurrent_kernel/m, training_78/Adam/lstm_495/lstm_cell_1457/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:45:54.186271: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 2.9670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:46:18.443213: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_79/mul' id:748023 op device:{requested: '', assigned: ''} def:{{{node loss_79/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_79/mul/x, loss_79/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.80530, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 209s 6ms/sample - loss: 2.9670 - val_loss: 1.8053\n",
      "Epoch 2/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.7282\n",
      "Epoch 2: val_loss improved from 1.80530 to 1.55634, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 746us/sample - loss: 1.7282 - val_loss: 1.5563\n",
      "Epoch 3/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5880\n",
      "Epoch 3: val_loss improved from 1.55634 to 1.51202, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 743us/sample - loss: 1.5880 - val_loss: 1.5120\n",
      "Epoch 4/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5370\n",
      "Epoch 4: val_loss improved from 1.51202 to 1.48167, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 22s 678us/sample - loss: 1.5370 - val_loss: 1.4817\n",
      "Epoch 5/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5127\n",
      "Epoch 5: val_loss improved from 1.48167 to 1.46364, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 750us/sample - loss: 1.5127 - val_loss: 1.4636\n",
      "Epoch 6/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4963\n",
      "Epoch 6: val_loss improved from 1.46364 to 1.45732, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 718us/sample - loss: 1.4963 - val_loss: 1.4573\n",
      "Epoch 7/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4838\n",
      "Epoch 7: val_loss improved from 1.45732 to 1.44381, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 717us/sample - loss: 1.4838 - val_loss: 1.4438\n",
      "Epoch 8/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4744\n",
      "Epoch 8: val_loss improved from 1.44381 to 1.44380, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.4744 - val_loss: 1.4438\n",
      "Epoch 9/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 9: val_loss improved from 1.44380 to 1.44348, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.4752 - val_loss: 1.4435\n",
      "Epoch 10/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5119\n",
      "Epoch 10: val_loss did not improve from 1.44348\n",
      "32300/32300 [==============================] - 22s 666us/sample - loss: 1.5119 - val_loss: 1.4440\n",
      "Epoch 11/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 11: val_loss improved from 1.44348 to 1.43657, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 645us/sample - loss: 1.4731 - val_loss: 1.4366\n",
      "Epoch 12/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5251\n",
      "Epoch 12: val_loss did not improve from 1.43657\n",
      "32300/32300 [==============================] - 20s 632us/sample - loss: 1.5251 - val_loss: 1.4398\n",
      "Epoch 13/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4662\n",
      "Epoch 13: val_loss improved from 1.43657 to 1.43433, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 645us/sample - loss: 1.4662 - val_loss: 1.4343\n",
      "Epoch 14/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4659\n",
      "Epoch 14: val_loss improved from 1.43433 to 1.42892, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 644us/sample - loss: 1.4659 - val_loss: 1.4289\n",
      "Epoch 15/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5116\n",
      "Epoch 15: val_loss did not improve from 1.42892\n",
      "32300/32300 [==============================] - 21s 635us/sample - loss: 1.5116 - val_loss: 1.4442\n",
      "Epoch 16/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4669\n",
      "Epoch 16: val_loss improved from 1.42892 to 1.42887, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.4669 - val_loss: 1.4289\n",
      "Epoch 17/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4595\n",
      "Epoch 17: val_loss did not improve from 1.42887\n",
      "32300/32300 [==============================] - 22s 694us/sample - loss: 1.4595 - val_loss: 1.4318\n",
      "Epoch 18/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4559\n",
      "Epoch 18: val_loss improved from 1.42887 to 1.42658, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 1.4559 - val_loss: 1.4266\n",
      "Epoch 19/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4592\n",
      "Epoch 19: val_loss improved from 1.42658 to 1.42604, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 646us/sample - loss: 1.4592 - val_loss: 1.4260\n",
      "Epoch 20/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4562\n",
      "Epoch 20: val_loss improved from 1.42604 to 1.42520, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 643us/sample - loss: 1.4562 - val_loss: 1.4252\n",
      "Epoch 21/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4734\n",
      "Epoch 21: val_loss improved from 1.42520 to 1.41994, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 22s 676us/sample - loss: 1.4734 - val_loss: 1.4199\n",
      "Epoch 22/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4583\n",
      "Epoch 22: val_loss did not improve from 1.41994\n",
      "32300/32300 [==============================] - 21s 638us/sample - loss: 1.4583 - val_loss: 1.4235\n",
      "Epoch 23/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4628\n",
      "Epoch 23: val_loss did not improve from 1.41994\n",
      "32300/32300 [==============================] - 21s 636us/sample - loss: 1.4628 - val_loss: 1.4264\n",
      "Epoch 24/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4498\n",
      "Epoch 24: val_loss did not improve from 1.41994\n",
      "32300/32300 [==============================] - 21s 641us/sample - loss: 1.4498 - val_loss: 1.4238\n",
      "Epoch 25/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4446\n",
      "Epoch 25: val_loss did not improve from 1.41994\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 1.4446 - val_loss: 1.4207\n",
      "Epoch 26/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 26: val_loss did not improve from 1.41994\n",
      "32300/32300 [==============================] - 21s 642us/sample - loss: 1.4334 - val_loss: 1.4245\n",
      "Epoch 27/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4331\n",
      "Epoch 27: val_loss did not improve from 1.41994\n",
      "32300/32300 [==============================] - 23s 699us/sample - loss: 1.4331 - val_loss: 1.4211\n",
      "Epoch 28/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4307\n",
      "Epoch 28: val_loss improved from 1.41994 to 1.41515, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 757us/sample - loss: 1.4307 - val_loss: 1.4152\n",
      "Epoch 29/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4273\n",
      "Epoch 29: val_loss improved from 1.41515 to 1.41443, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 707us/sample - loss: 1.4273 - val_loss: 1.4144\n",
      "Epoch 30/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4244\n",
      "Epoch 30: val_loss improved from 1.41443 to 1.41273, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 727us/sample - loss: 1.4244 - val_loss: 1.4127\n",
      "Epoch 31/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4224\n",
      "Epoch 31: val_loss did not improve from 1.41273\n",
      "32300/32300 [==============================] - 23s 723us/sample - loss: 1.4224 - val_loss: 1.4178\n",
      "Epoch 32/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4188\n",
      "Epoch 32: val_loss improved from 1.41273 to 1.41031, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 712us/sample - loss: 1.4188 - val_loss: 1.4103\n",
      "Epoch 33/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 33: val_loss did not improve from 1.41031\n",
      "32300/32300 [==============================] - 21s 642us/sample - loss: 1.4149 - val_loss: 1.4139\n",
      "Epoch 34/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4139\n",
      "Epoch 34: val_loss improved from 1.41031 to 1.40235, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 659us/sample - loss: 1.4139 - val_loss: 1.4024\n",
      "Epoch 35/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4128\n",
      "Epoch 35: val_loss did not improve from 1.40235\n",
      "32300/32300 [==============================] - 21s 645us/sample - loss: 1.4128 - val_loss: 1.4074\n",
      "Epoch 36/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4114\n",
      "Epoch 36: val_loss improved from 1.40235 to 1.40216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 712us/sample - loss: 1.4114 - val_loss: 1.4022\n",
      "Epoch 37/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 37: val_loss did not improve from 1.40216\n",
      "32300/32300 [==============================] - 24s 735us/sample - loss: 1.4083 - val_loss: 1.4023\n",
      "Epoch 38/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 38: val_loss improved from 1.40216 to 1.39818, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 706us/sample - loss: 1.4065 - val_loss: 1.3982\n",
      "Epoch 39/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 39: val_loss did not improve from 1.39818\n",
      "32300/32300 [==============================] - 21s 648us/sample - loss: 1.4067 - val_loss: 1.3989\n",
      "Epoch 40/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 40: val_loss improved from 1.39818 to 1.39608, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 664us/sample - loss: 1.4026 - val_loss: 1.3961\n",
      "Epoch 41/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4029\n",
      "Epoch 41: val_loss did not improve from 1.39608\n",
      "32300/32300 [==============================] - 21s 641us/sample - loss: 1.4029 - val_loss: 1.4019\n",
      "Epoch 42/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4030\n",
      "Epoch 42: val_loss did not improve from 1.39608\n",
      "32300/32300 [==============================] - 21s 636us/sample - loss: 1.4030 - val_loss: 1.4022\n",
      "Epoch 43/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3990\n",
      "Epoch 43: val_loss did not improve from 1.39608\n",
      "32300/32300 [==============================] - 22s 684us/sample - loss: 1.3990 - val_loss: 1.4025\n",
      "Epoch 44/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3990\n",
      "Epoch 44: val_loss improved from 1.39608 to 1.39264, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 741us/sample - loss: 1.3990 - val_loss: 1.3926\n",
      "Epoch 45/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 45: val_loss improved from 1.39264 to 1.38842, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 22s 668us/sample - loss: 1.3983 - val_loss: 1.3884\n",
      "Epoch 46/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3969\n",
      "Epoch 46: val_loss did not improve from 1.38842\n",
      "32300/32300 [==============================] - 21s 663us/sample - loss: 1.3969 - val_loss: 1.3927\n",
      "Epoch 47/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3932\n",
      "Epoch 47: val_loss did not improve from 1.38842\n",
      "32300/32300 [==============================] - 23s 713us/sample - loss: 1.3932 - val_loss: 1.3885\n",
      "Epoch 48/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3952\n",
      "Epoch 48: val_loss did not improve from 1.38842\n",
      "32300/32300 [==============================] - 24s 729us/sample - loss: 1.3952 - val_loss: 1.3895\n",
      "Epoch 49/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3908\n",
      "Epoch 49: val_loss did not improve from 1.38842\n",
      "32300/32300 [==============================] - 24s 728us/sample - loss: 1.3908 - val_loss: 1.3934\n",
      "Epoch 50/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 50: val_loss improved from 1.38842 to 1.38565, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 745us/sample - loss: 1.3914 - val_loss: 1.3857\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:07:36.667127: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_493_1/lstm_cell_1492/kernel/Assign' id:762106 op device:{requested: '', assigned: ''} def:{{{node lstm_493_1/lstm_cell_1492/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_493_1/lstm_cell_1492/kernel, lstm_493_1/lstm_cell_1492/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:08:17.209223: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_514_1/lstm_cell_1513/recurrent_kernel/m/Assign' id:767298 op device:{requested: '', assigned: ''} def:{{{node lstm_514_1/lstm_cell_1513/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_514_1/lstm_cell_1513/recurrent_kernel/m, lstm_514_1/lstm_cell_1513/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:08:57.601360: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_69_1/cond/Merge' id:766137 op device:{requested: '', assigned: ''} def:{{{node dropout_69_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_69_1/cond/Identity, dropout_69_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1104)\n",
      "(1514, 1104)\n",
      "(1644, 1104)\n",
      "(1764, 1104)\n",
      "(1836, 1104)\n",
      "(1699, 1104)\n",
      "(1369, 1104)\n",
      "(1766, 1104)\n",
      "(1631, 1104)\n",
      "(1692, 1104)\n",
      "(1550, 1104)\n",
      "(1728, 1104)\n",
      "(1752, 1104)\n",
      "(1884, 1104)\n",
      "(1728, 1104)\n",
      "(1788, 1104)\n",
      "(982, 1104)\n",
      "(1668, 1104)\n",
      "(1884, 1104)\n",
      "{1: 5.973698867623996, 2: 5.377991686400596, 4: 10.0, 5: 4.567445217148988, 6: 4.823901695096838, 8: 8.344356868500721, 9: 6.607308386320273, 10: 7.4252226032321165, 11: 7.2342639563149875, 12: 9.041954010665966, 13: 6.289143794778712, 19: 8.609992052407215, 21: 8.611067268560152, 22: 1.0, 25: 8.015121293833399, 26: 6.306143310666117, 27: 5.292826306123375, 28: 5.763086869993001, 29: 1.222491651728926}\n",
      "Train on 32300 samples, validate on 3597 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:16:52.124275: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 10.9706\n",
      "Epoch 1: val_loss improved from inf to 1.40319, saving model to ./checkpoints/unknown_person_few_shot_p17_43.h5\n",
      "32300/32300 [==============================] - 97s 3ms/sample - loss: 10.9706 - val_loss: 1.4032\n",
      "Epoch 2/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.8187\n",
      "Epoch 2: val_loss did not improve from 1.40319\n",
      "32300/32300 [==============================] - 23s 727us/sample - loss: 10.8187 - val_loss: 1.4175\n",
      "Epoch 3/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7535\n",
      "Epoch 3: val_loss improved from 1.40319 to 1.40179, saving model to ./checkpoints/unknown_person_few_shot_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 752us/sample - loss: 10.7535 - val_loss: 1.4018\n",
      "Epoch 4/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6874\n",
      "Epoch 4: val_loss improved from 1.40179 to 1.39440, saving model to ./checkpoints/unknown_person_few_shot_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 750us/sample - loss: 10.6874 - val_loss: 1.3944\n",
      "Epoch 5/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6432\n",
      "Epoch 5: val_loss did not improve from 1.39440\n",
      "32300/32300 [==============================] - 24s 741us/sample - loss: 10.6432 - val_loss: 1.3952\n",
      "Epoch 6/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6313\n",
      "Epoch 6: val_loss improved from 1.39440 to 1.38870, saving model to ./checkpoints/unknown_person_few_shot_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 749us/sample - loss: 10.6313 - val_loss: 1.3887\n",
      "Epoch 7/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6053\n",
      "Epoch 7: val_loss did not improve from 1.38870\n",
      "32300/32300 [==============================] - 24s 749us/sample - loss: 10.6053 - val_loss: 1.4033\n",
      "Epoch 8/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5541\n",
      "Epoch 8: val_loss did not improve from 1.38870\n",
      "32300/32300 [==============================] - 24s 744us/sample - loss: 10.5541 - val_loss: 1.3969\n",
      "Epoch 9/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5794\n",
      "Epoch 9: val_loss did not improve from 1.38870\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 10.5794 - val_loss: 1.4004\n",
      "Epoch 10/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5528\n",
      "Epoch 10: val_loss improved from 1.38870 to 1.38811, saving model to ./checkpoints/unknown_person_few_shot_p17_43.h5\n",
      "32300/32300 [==============================] - 23s 699us/sample - loss: 10.5528 - val_loss: 1.3881\n",
      "Epoch 11/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5349\n",
      "Epoch 11: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 22s 686us/sample - loss: 10.5349 - val_loss: 1.4000\n",
      "Epoch 12/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4998\n",
      "Epoch 12: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 629us/sample - loss: 10.4998 - val_loss: 1.4010\n",
      "Epoch 13/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5140\n",
      "Epoch 13: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 630us/sample - loss: 10.5140 - val_loss: 1.3934\n",
      "Epoch 14/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4797\n",
      "Epoch 14: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 629us/sample - loss: 10.4797 - val_loss: 1.4002\n",
      "Epoch 15/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4943\n",
      "Epoch 15: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 629us/sample - loss: 10.4943 - val_loss: 1.3942\n",
      "Epoch 16/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4647\n",
      "Epoch 16: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 629us/sample - loss: 10.4647 - val_loss: 1.3890\n",
      "Epoch 17/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4545\n",
      "Epoch 17: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 630us/sample - loss: 10.4545 - val_loss: 1.3930\n",
      "Epoch 18/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4519\n",
      "Epoch 18: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 626us/sample - loss: 10.4519 - val_loss: 1.3966\n",
      "Epoch 19/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4314\n",
      "Epoch 19: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 627us/sample - loss: 10.4314 - val_loss: 1.3906\n",
      "Epoch 20/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.4238\n",
      "Epoch 20: val_loss did not improve from 1.38811\n",
      "32300/32300 [==============================] - 20s 624us/sample - loss: 10.4238 - val_loss: 1.3978\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:25:41.319877: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_493_2/lstm_cell_1529/kernel/Assign' id:781504 op device:{requested: '', assigned: ''} def:{{{node lstm_493_2/lstm_cell_1529/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_493_2/lstm_cell_1529/kernel, lstm_493_2/lstm_cell_1529/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:26:23.069939: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_502_2/lstm_cell_1538/recurrent_kernel/m/Assign' id:786516 op device:{requested: '', assigned: ''} def:{{{node lstm_502_2/lstm_cell_1538/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_502_2/lstm_cell_1538/recurrent_kernel/m, lstm_502_2/lstm_cell_1538/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32300 samples, validate on 3597 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:27:07.519474: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:30:43.928702: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:31:07.679715: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38929, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 98s 3ms/sample - loss: 1.3903 - val_loss: 1.3893\n",
      "Epoch 2/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3850\n",
      "Epoch 2: val_loss did not improve from 1.38929\n",
      "32300/32300 [==============================] - 21s 643us/sample - loss: 1.3850 - val_loss: 1.3914\n",
      "Epoch 3/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3842\n",
      "Epoch 3: val_loss improved from 1.38929 to 1.38606, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 737us/sample - loss: 1.3842 - val_loss: 1.3861\n",
      "Epoch 4/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3841\n",
      "Epoch 4: val_loss did not improve from 1.38606\n",
      "32300/32300 [==============================] - 24s 735us/sample - loss: 1.3841 - val_loss: 1.3899\n",
      "Epoch 5/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3860\n",
      "Epoch 5: val_loss did not improve from 1.38606\n",
      "32300/32300 [==============================] - 24s 736us/sample - loss: 1.3860 - val_loss: 1.3866\n",
      "Epoch 6/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3807\n",
      "Epoch 6: val_loss improved from 1.38606 to 1.38170, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 734us/sample - loss: 1.3807 - val_loss: 1.3817\n",
      "Epoch 7/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 7: val_loss did not improve from 1.38170\n",
      "32300/32300 [==============================] - 20s 631us/sample - loss: 1.3796 - val_loss: 1.3873\n",
      "Epoch 8/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3792\n",
      "Epoch 8: val_loss did not improve from 1.38170\n",
      "32300/32300 [==============================] - 20s 628us/sample - loss: 1.3792 - val_loss: 1.3844\n",
      "Epoch 9/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3782\n",
      "Epoch 9: val_loss did not improve from 1.38170\n",
      "32300/32300 [==============================] - 20s 631us/sample - loss: 1.3782 - val_loss: 1.3840\n",
      "Epoch 10/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3759\n",
      "Epoch 10: val_loss did not improve from 1.38170\n",
      "32300/32300 [==============================] - 20s 631us/sample - loss: 1.3759 - val_loss: 1.3830\n",
      "Epoch 11/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3751\n",
      "Epoch 11: val_loss did not improve from 1.38170\n",
      "32300/32300 [==============================] - 20s 627us/sample - loss: 1.3751 - val_loss: 1.3898\n",
      "Epoch 12/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3752\n",
      "Epoch 12: val_loss improved from 1.38170 to 1.37946, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 651us/sample - loss: 1.3752 - val_loss: 1.3795\n",
      "Epoch 13/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3772\n",
      "Epoch 13: val_loss improved from 1.37946 to 1.37871, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 21s 646us/sample - loss: 1.3772 - val_loss: 1.3787\n",
      "Epoch 14/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3744\n",
      "Epoch 14: val_loss did not improve from 1.37871\n",
      "32300/32300 [==============================] - 20s 628us/sample - loss: 1.3744 - val_loss: 1.3815\n",
      "Epoch 15/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3702\n",
      "Epoch 15: val_loss did not improve from 1.37871\n",
      "32300/32300 [==============================] - 20s 626us/sample - loss: 1.3702 - val_loss: 1.3794\n",
      "Epoch 16/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3676\n",
      "Epoch 16: val_loss did not improve from 1.37871\n",
      "32300/32300 [==============================] - 22s 682us/sample - loss: 1.3676 - val_loss: 1.3792\n",
      "Epoch 17/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3671\n",
      "Epoch 17: val_loss improved from 1.37871 to 1.37845, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 752us/sample - loss: 1.3671 - val_loss: 1.3784\n",
      "Epoch 18/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3677\n",
      "Epoch 18: val_loss improved from 1.37845 to 1.37570, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_43.h5\n",
      "32300/32300 [==============================] - 24s 754us/sample - loss: 1.3677 - val_loss: 1.3757\n",
      "Epoch 19/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3648\n",
      "Epoch 19: val_loss did not improve from 1.37570\n",
      "32300/32300 [==============================] - 24s 745us/sample - loss: 1.3648 - val_loss: 1.3801\n",
      "Epoch 20/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3637\n",
      "Epoch 20: val_loss did not improve from 1.37570\n",
      "32300/32300 [==============================] - 24s 743us/sample - loss: 1.3637 - val_loss: 1.3761\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:39:35.614075: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_522/lstm_cell_1558/kernel/Assign' id:799266 op device:{requested: '', assigned: ''} def:{{{node lstm_522/lstm_cell_1558/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_522/lstm_cell_1558/kernel, lstm_522/lstm_cell_1558/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:39:58.700286: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_1' id:802224 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:40:17.321662: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_2' id:802225 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32300, 95)\n",
      "Train on 32300 samples, validate on 3597 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:40:59.229263: W tensorflow/c/c_api.cc:304] Operation '{name:'training_84/Adam/lstm_518/lstm_cell_1554/bias/m/Assign' id:814992 op device:{requested: '', assigned: ''} def:{{{node training_84/Adam/lstm_518/lstm_cell_1554/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_84/Adam/lstm_518/lstm_cell_1554/bias/m, training_84/Adam/lstm_518/lstm_cell_1554/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:44:48.209662: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 3.0229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:45:13.815090: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_85/mul' id:805065 op device:{requested: '', assigned: ''} def:{{{node loss_85/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_85/mul/x, loss_85/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.86516, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 229s 7ms/sample - loss: 3.0229 - val_loss: 1.8652\n",
      "Epoch 2/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.8095\n",
      "Epoch 2: val_loss improved from 1.86516 to 1.57197, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 687us/sample - loss: 1.8095 - val_loss: 1.5720\n",
      "Epoch 3/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.6059\n",
      "Epoch 3: val_loss improved from 1.57197 to 1.50296, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 664us/sample - loss: 1.6059 - val_loss: 1.5030\n",
      "Epoch 4/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5374\n",
      "Epoch 4: val_loss improved from 1.50296 to 1.48009, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 664us/sample - loss: 1.5374 - val_loss: 1.4801\n",
      "Epoch 5/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5148\n",
      "Epoch 5: val_loss improved from 1.48009 to 1.46679, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 670us/sample - loss: 1.5148 - val_loss: 1.4668\n",
      "Epoch 6/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4951\n",
      "Epoch 6: val_loss improved from 1.46679 to 1.45682, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 661us/sample - loss: 1.4951 - val_loss: 1.4568\n",
      "Epoch 7/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4857\n",
      "Epoch 7: val_loss improved from 1.45682 to 1.44705, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 746us/sample - loss: 1.4857 - val_loss: 1.4471\n",
      "Epoch 8/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4961\n",
      "Epoch 8: val_loss improved from 1.44705 to 1.44645, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 741us/sample - loss: 1.4961 - val_loss: 1.4464\n",
      "Epoch 9/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4779\n",
      "Epoch 9: val_loss improved from 1.44645 to 1.43952, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 754us/sample - loss: 1.4779 - val_loss: 1.4395\n",
      "Epoch 10/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4726\n",
      "Epoch 10: val_loss improved from 1.43952 to 1.43595, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 23s 717us/sample - loss: 1.4726 - val_loss: 1.4360\n",
      "Epoch 11/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4927\n",
      "Epoch 11: val_loss did not improve from 1.43595\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.4927 - val_loss: 1.4484\n",
      "Epoch 12/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5242\n",
      "Epoch 12: val_loss improved from 1.43595 to 1.43191, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 23s 707us/sample - loss: 1.5242 - val_loss: 1.4319\n",
      "Epoch 13/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 13: val_loss improved from 1.43191 to 1.42981, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 23s 705us/sample - loss: 1.4829 - val_loss: 1.4298\n",
      "Epoch 14/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 14: val_loss improved from 1.42981 to 1.42703, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 659us/sample - loss: 1.4787 - val_loss: 1.4270\n",
      "Epoch 15/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4871\n",
      "Epoch 15: val_loss did not improve from 1.42703\n",
      "32300/32300 [==============================] - 21s 644us/sample - loss: 1.4871 - val_loss: 1.4289\n",
      "Epoch 16/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4749\n",
      "Epoch 16: val_loss did not improve from 1.42703\n",
      "32300/32300 [==============================] - 21s 643us/sample - loss: 1.4749 - val_loss: 1.4285\n",
      "Epoch 17/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4900\n",
      "Epoch 17: val_loss improved from 1.42703 to 1.42394, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 660us/sample - loss: 1.4900 - val_loss: 1.4239\n",
      "Epoch 18/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5480\n",
      "Epoch 18: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 21s 658us/sample - loss: 1.5480 - val_loss: 1.4413\n",
      "Epoch 19/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5091\n",
      "Epoch 19: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.5091 - val_loss: 1.4303\n",
      "Epoch 20/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5027\n",
      "Epoch 20: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 22s 688us/sample - loss: 1.5027 - val_loss: 1.4365\n",
      "Epoch 21/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.5017\n",
      "Epoch 21: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 23s 728us/sample - loss: 1.5017 - val_loss: 1.4305\n",
      "Epoch 22/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4840\n",
      "Epoch 22: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 21s 646us/sample - loss: 1.4840 - val_loss: 1.4302\n",
      "Epoch 23/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4858\n",
      "Epoch 23: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 21s 654us/sample - loss: 1.4858 - val_loss: 1.4312\n",
      "Epoch 24/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4734\n",
      "Epoch 24: val_loss did not improve from 1.42394\n",
      "32300/32300 [==============================] - 21s 647us/sample - loss: 1.4734 - val_loss: 1.4284\n",
      "Epoch 25/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4681\n",
      "Epoch 25: val_loss improved from 1.42394 to 1.42211, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 652us/sample - loss: 1.4681 - val_loss: 1.4221\n",
      "Epoch 26/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4652\n",
      "Epoch 26: val_loss improved from 1.42211 to 1.42133, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 655us/sample - loss: 1.4652 - val_loss: 1.4213\n",
      "Epoch 27/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4581\n",
      "Epoch 27: val_loss improved from 1.42133 to 1.41859, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 681us/sample - loss: 1.4581 - val_loss: 1.4186\n",
      "Epoch 28/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4601\n",
      "Epoch 28: val_loss improved from 1.41859 to 1.41804, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 665us/sample - loss: 1.4601 - val_loss: 1.4180\n",
      "Epoch 29/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4508\n",
      "Epoch 29: val_loss did not improve from 1.41804\n",
      "32300/32300 [==============================] - 24s 738us/sample - loss: 1.4508 - val_loss: 1.4208\n",
      "Epoch 30/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4498\n",
      "Epoch 30: val_loss did not improve from 1.41804\n",
      "32300/32300 [==============================] - 23s 713us/sample - loss: 1.4498 - val_loss: 1.4220\n",
      "Epoch 31/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4442\n",
      "Epoch 31: val_loss did not improve from 1.41804\n",
      "32300/32300 [==============================] - 24s 742us/sample - loss: 1.4442 - val_loss: 1.4187\n",
      "Epoch 32/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4443\n",
      "Epoch 32: val_loss improved from 1.41804 to 1.41659, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 695us/sample - loss: 1.4443 - val_loss: 1.4166\n",
      "Epoch 33/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4399\n",
      "Epoch 33: val_loss did not improve from 1.41659\n",
      "32300/32300 [==============================] - 23s 715us/sample - loss: 1.4399 - val_loss: 1.4166\n",
      "Epoch 34/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4385\n",
      "Epoch 34: val_loss improved from 1.41659 to 1.41327, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 746us/sample - loss: 1.4385 - val_loss: 1.4133\n",
      "Epoch 35/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 35: val_loss did not improve from 1.41327\n",
      "32300/32300 [==============================] - 24s 736us/sample - loss: 1.4346 - val_loss: 1.4199\n",
      "Epoch 36/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 36: val_loss improved from 1.41327 to 1.40852, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 744us/sample - loss: 1.4321 - val_loss: 1.4085\n",
      "Epoch 37/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4299\n",
      "Epoch 37: val_loss improved from 1.40852 to 1.40808, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 728us/sample - loss: 1.4299 - val_loss: 1.4081\n",
      "Epoch 38/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4286\n",
      "Epoch 38: val_loss did not improve from 1.40808\n",
      "32300/32300 [==============================] - 24s 739us/sample - loss: 1.4286 - val_loss: 1.4150\n",
      "Epoch 39/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 39: val_loss improved from 1.40808 to 1.40563, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 23s 720us/sample - loss: 1.4255 - val_loss: 1.4056\n",
      "Epoch 40/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4604\n",
      "Epoch 40: val_loss did not improve from 1.40563\n",
      "32300/32300 [==============================] - 24s 736us/sample - loss: 1.4604 - val_loss: 1.4109\n",
      "Epoch 41/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 41: val_loss improved from 1.40563 to 1.40353, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 657us/sample - loss: 1.4334 - val_loss: 1.4035\n",
      "Epoch 42/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4233\n",
      "Epoch 42: val_loss did not improve from 1.40353\n",
      "32300/32300 [==============================] - 22s 690us/sample - loss: 1.4233 - val_loss: 1.4157\n",
      "Epoch 43/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 43: val_loss improved from 1.40353 to 1.40067, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 23s 698us/sample - loss: 1.4202 - val_loss: 1.4007\n",
      "Epoch 44/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4171\n",
      "Epoch 44: val_loss did not improve from 1.40067\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.4171 - val_loss: 1.4031\n",
      "Epoch 45/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4144\n",
      "Epoch 45: val_loss improved from 1.40067 to 1.39513, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 645us/sample - loss: 1.4144 - val_loss: 1.3951\n",
      "Epoch 46/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 46: val_loss did not improve from 1.39513\n",
      "32300/32300 [==============================] - 21s 641us/sample - loss: 1.4145 - val_loss: 1.3976\n",
      "Epoch 47/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4134\n",
      "Epoch 47: val_loss did not improve from 1.39513\n",
      "32300/32300 [==============================] - 21s 655us/sample - loss: 1.4134 - val_loss: 1.3999\n",
      "Epoch 48/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4103\n",
      "Epoch 48: val_loss did not improve from 1.39513\n",
      "32300/32300 [==============================] - 21s 640us/sample - loss: 1.4103 - val_loss: 1.3959\n",
      "Epoch 49/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 49: val_loss improved from 1.39513 to 1.39220, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 649us/sample - loss: 1.4100 - val_loss: 1.3922\n",
      "Epoch 50/50\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 50: val_loss did not improve from 1.39220\n",
      "32300/32300 [==============================] - 20s 633us/sample - loss: 1.4065 - val_loss: 1.3956\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:06:59.660038: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_56_1/bias/Assign' id:816933 op device:{requested: '', assigned: ''} def:{{{node conv2d_56_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_56_1/bias, conv2d_56_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:07:44.513732: W tensorflow/c/c_api.cc:304] Operation '{name:'learning_rate_28/Assign' id:823793 op device:{requested: '', assigned: ''} def:{{{node learning_rate_28/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](learning_rate_28, learning_rate_28/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:08:28.728791: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_74_1/cond/Merge' id:823179 op device:{requested: '', assigned: ''} def:{{{node dropout_74_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_74_1/cond/Identity, dropout_74_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1104)\n",
      "(1514, 1104)\n",
      "(1644, 1104)\n",
      "(1764, 1104)\n",
      "(1836, 1104)\n",
      "(1699, 1104)\n",
      "(1369, 1104)\n",
      "(1766, 1104)\n",
      "(1631, 1104)\n",
      "(1692, 1104)\n",
      "(1550, 1104)\n",
      "(1728, 1104)\n",
      "(1752, 1104)\n",
      "(1884, 1104)\n",
      "(1728, 1104)\n",
      "(1788, 1104)\n",
      "(982, 1104)\n",
      "(1668, 1104)\n",
      "(1884, 1104)\n",
      "{1: 5.5584341124754, 2: 4.583747424638725, 4: 10.0, 5: 4.528032162535316, 6: 5.244889651833213, 8: 8.437221187304598, 9: 6.592019276049885, 10: 6.922297472910601, 11: 6.669184095006826, 12: 9.466172435871826, 13: 6.701979663650143, 19: 8.668131198933345, 21: 8.248170504379791, 22: 1.0, 25: 8.268483100061683, 26: 6.1584955648333946, 27: 4.663852516808777, 28: 6.3179075163606875, 29: 1.9450646152109086}\n",
      "Train on 32300 samples, validate on 3597 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:16:42.577162: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 11.0447\n",
      "Epoch 1: val_loss improved from inf to 1.42887, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 103s 3ms/sample - loss: 11.0447 - val_loss: 1.4289\n",
      "Epoch 2/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.9161\n",
      "Epoch 2: val_loss improved from 1.42887 to 1.40837, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 664us/sample - loss: 10.9161 - val_loss: 1.4084\n",
      "Epoch 3/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.8493\n",
      "Epoch 3: val_loss improved from 1.40837 to 1.40097, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 668us/sample - loss: 10.8493 - val_loss: 1.4010\n",
      "Epoch 4/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.8048\n",
      "Epoch 4: val_loss did not improve from 1.40097\n",
      "32300/32300 [==============================] - 22s 668us/sample - loss: 10.8048 - val_loss: 1.4062\n",
      "Epoch 5/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7883\n",
      "Epoch 5: val_loss did not improve from 1.40097\n",
      "32300/32300 [==============================] - 21s 661us/sample - loss: 10.7883 - val_loss: 1.4020\n",
      "Epoch 6/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7443\n",
      "Epoch 6: val_loss improved from 1.40097 to 1.39994, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 693us/sample - loss: 10.7443 - val_loss: 1.3999\n",
      "Epoch 7/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7281\n",
      "Epoch 7: val_loss improved from 1.39994 to 1.39799, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 22s 669us/sample - loss: 10.7281 - val_loss: 1.3980\n",
      "Epoch 8/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.7404\n",
      "Epoch 8: val_loss improved from 1.39799 to 1.39148, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 661us/sample - loss: 10.7404 - val_loss: 1.3915\n",
      "Epoch 9/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6682\n",
      "Epoch 9: val_loss did not improve from 1.39148\n",
      "32300/32300 [==============================] - 21s 654us/sample - loss: 10.6682 - val_loss: 1.4029\n",
      "Epoch 10/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6609\n",
      "Epoch 10: val_loss did not improve from 1.39148\n",
      "32300/32300 [==============================] - 23s 720us/sample - loss: 10.6609 - val_loss: 1.3975\n",
      "Epoch 11/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6808\n",
      "Epoch 11: val_loss improved from 1.39148 to 1.38964, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 737us/sample - loss: 10.6808 - val_loss: 1.3896\n",
      "Epoch 12/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6465\n",
      "Epoch 12: val_loss did not improve from 1.38964\n",
      "32300/32300 [==============================] - 22s 692us/sample - loss: 10.6465 - val_loss: 1.3984\n",
      "Epoch 13/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6091\n",
      "Epoch 13: val_loss improved from 1.38964 to 1.38759, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 744us/sample - loss: 10.6091 - val_loss: 1.3876\n",
      "Epoch 14/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.6078\n",
      "Epoch 14: val_loss improved from 1.38759 to 1.38679, saving model to ./checkpoints/unknown_person_few_shot_p17_44.h5\n",
      "32300/32300 [==============================] - 24s 753us/sample - loss: 10.6078 - val_loss: 1.3868\n",
      "Epoch 15/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5958\n",
      "Epoch 15: val_loss did not improve from 1.38679\n",
      "32300/32300 [==============================] - 23s 727us/sample - loss: 10.5958 - val_loss: 1.3912\n",
      "Epoch 16/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5773\n",
      "Epoch 16: val_loss did not improve from 1.38679\n",
      "32300/32300 [==============================] - 24s 746us/sample - loss: 10.5773 - val_loss: 1.3899\n",
      "Epoch 17/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5732\n",
      "Epoch 17: val_loss did not improve from 1.38679\n",
      "32300/32300 [==============================] - 25s 759us/sample - loss: 10.5732 - val_loss: 1.3920\n",
      "Epoch 18/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5488\n",
      "Epoch 18: val_loss did not improve from 1.38679\n",
      "32300/32300 [==============================] - 24s 745us/sample - loss: 10.5488 - val_loss: 1.3913\n",
      "Epoch 19/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5651\n",
      "Epoch 19: val_loss did not improve from 1.38679\n",
      "32300/32300 [==============================] - 21s 637us/sample - loss: 10.5651 - val_loss: 1.3940\n",
      "Epoch 20/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 10.5411\n",
      "Epoch 20: val_loss did not improve from 1.38679\n",
      "32300/32300 [==============================] - 20s 633us/sample - loss: 10.5411 - val_loss: 1.3895\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:25:50.066804: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_522_2/lstm_cell_1632/recurrent_kernel/Assign' id:837286 op device:{requested: '', assigned: ''} def:{{{node lstm_522_2/lstm_cell_1632/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_522_2/lstm_cell_1632/recurrent_kernel, lstm_522_2/lstm_cell_1632/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:26:35.027092: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_524_2/lstm_cell_1634/recurrent_kernel/v/Assign' id:843976 op device:{requested: '', assigned: ''} def:{{{node lstm_524_2/lstm_cell_1634/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_524_2/lstm_cell_1634/recurrent_kernel/v, lstm_524_2/lstm_cell_1634/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32300 samples, validate on 3597 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:27:22.666343: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:31:13.777220: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:31:37.450970: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38971, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_44.h5\n",
      "32300/32300 [==============================] - 103s 3ms/sample - loss: 1.4076 - val_loss: 1.3897\n",
      "Epoch 2/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 2: val_loss did not improve from 1.38971\n",
      "32300/32300 [==============================] - 23s 713us/sample - loss: 1.4050 - val_loss: 1.3907\n",
      "Epoch 3/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4031\n",
      "Epoch 3: val_loss improved from 1.38971 to 1.38859, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 651us/sample - loss: 1.4031 - val_loss: 1.3886\n",
      "Epoch 4/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4003\n",
      "Epoch 4: val_loss did not improve from 1.38859\n",
      "32300/32300 [==============================] - 21s 641us/sample - loss: 1.4003 - val_loss: 1.3914\n",
      "Epoch 5/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 5: val_loss improved from 1.38859 to 1.38611, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 650us/sample - loss: 1.4011 - val_loss: 1.3861\n",
      "Epoch 6/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3960\n",
      "Epoch 6: val_loss did not improve from 1.38611\n",
      "32300/32300 [==============================] - 21s 641us/sample - loss: 1.3960 - val_loss: 1.3896\n",
      "Epoch 7/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 7: val_loss did not improve from 1.38611\n",
      "32300/32300 [==============================] - 22s 666us/sample - loss: 1.3947 - val_loss: 1.3885\n",
      "Epoch 8/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3955\n",
      "Epoch 8: val_loss did not improve from 1.38611\n",
      "32300/32300 [==============================] - 20s 630us/sample - loss: 1.3955 - val_loss: 1.3866\n",
      "Epoch 9/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3919\n",
      "Epoch 9: val_loss improved from 1.38611 to 1.37777, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 645us/sample - loss: 1.3919 - val_loss: 1.3778\n",
      "Epoch 10/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 10: val_loss did not improve from 1.37777\n",
      "32300/32300 [==============================] - 21s 657us/sample - loss: 1.3918 - val_loss: 1.3825\n",
      "Epoch 11/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 11: val_loss did not improve from 1.37777\n",
      "32300/32300 [==============================] - 21s 638us/sample - loss: 1.3918 - val_loss: 1.3812\n",
      "Epoch 12/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3899\n",
      "Epoch 12: val_loss did not improve from 1.37777\n",
      "32300/32300 [==============================] - 21s 636us/sample - loss: 1.3899 - val_loss: 1.3818\n",
      "Epoch 13/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3904\n",
      "Epoch 13: val_loss did not improve from 1.37777\n",
      "32300/32300 [==============================] - 21s 637us/sample - loss: 1.3904 - val_loss: 1.3808\n",
      "Epoch 14/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 14: val_loss improved from 1.37777 to 1.37336, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_44.h5\n",
      "32300/32300 [==============================] - 21s 643us/sample - loss: 1.3896 - val_loss: 1.3734\n",
      "Epoch 15/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3870\n",
      "Epoch 15: val_loss did not improve from 1.37336\n",
      "32300/32300 [==============================] - 21s 638us/sample - loss: 1.3870 - val_loss: 1.3783\n",
      "Epoch 16/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3857\n",
      "Epoch 16: val_loss did not improve from 1.37336\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3857 - val_loss: 1.3779\n",
      "Epoch 17/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3851\n",
      "Epoch 17: val_loss did not improve from 1.37336\n",
      "32300/32300 [==============================] - 21s 639us/sample - loss: 1.3851 - val_loss: 1.3785\n",
      "Epoch 18/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3848\n",
      "Epoch 18: val_loss did not improve from 1.37336\n",
      "32300/32300 [==============================] - 21s 635us/sample - loss: 1.3848 - val_loss: 1.3745\n",
      "Epoch 19/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3840\n",
      "Epoch 19: val_loss did not improve from 1.37336\n",
      "32300/32300 [==============================] - 20s 634us/sample - loss: 1.3840 - val_loss: 1.3755\n",
      "Epoch 20/20\n",
      "32300/32300 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 20: val_loss did not improve from 1.37336\n",
      "32300/32300 [==============================] - 20s 631us/sample - loss: 1.3812 - val_loss: 1.3748\n",
      "36113\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:40:00.555039: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_555/lstm_cell_1665/recurrent_kernel/Assign' id:855668 op device:{requested: '', assigned: ''} def:{{{node lstm_555/lstm_cell_1665/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_555/lstm_cell_1665/recurrent_kernel, lstm_555/lstm_cell_1665/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:40:26.237623: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_1' id:859266 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:40:47.805714: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_2' id:859267 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32491, 95)\n",
      "Train on 32491 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:41:41.290589: W tensorflow/c/c_api.cc:304] Operation '{name:'training_90/Adam/lstm_588/lstm_cell_1698/kernel/m/Assign' id:872519 op device:{requested: '', assigned: ''} def:{{{node training_90/Adam/lstm_588/lstm_cell_1698/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_90/Adam/lstm_588/lstm_cell_1698/kernel/m, training_90/Adam/lstm_588/lstm_cell_1698/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:45:44.575315: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 3.3728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 21:46:08.580114: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_91/mul' id:862107 op device:{requested: '', assigned: ''} def:{{{node loss_91/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_91/mul/x, loss_91/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.90558, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 240s 7ms/sample - loss: 3.3728 - val_loss: 1.9056\n",
      "Epoch 2/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.8234\n",
      "Epoch 2: val_loss improved from 1.90558 to 1.55375, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 22s 671us/sample - loss: 1.8234 - val_loss: 1.5538\n",
      "Epoch 3/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.6074\n",
      "Epoch 3: val_loss improved from 1.55375 to 1.49766, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 644us/sample - loss: 1.6074 - val_loss: 1.4977\n",
      "Epoch 4/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5461\n",
      "Epoch 4: val_loss improved from 1.49766 to 1.47579, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 710us/sample - loss: 1.5461 - val_loss: 1.4758\n",
      "Epoch 5/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5186\n",
      "Epoch 5: val_loss improved from 1.47579 to 1.45979, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 749us/sample - loss: 1.5186 - val_loss: 1.4598\n",
      "Epoch 6/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5035\n",
      "Epoch 6: val_loss improved from 1.45979 to 1.45630, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 740us/sample - loss: 1.5035 - val_loss: 1.4563\n",
      "Epoch 7/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4884\n",
      "Epoch 7: val_loss improved from 1.45630 to 1.44328, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 718us/sample - loss: 1.4884 - val_loss: 1.4433\n",
      "Epoch 8/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4811\n",
      "Epoch 8: val_loss improved from 1.44328 to 1.43701, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 651us/sample - loss: 1.4811 - val_loss: 1.4370\n",
      "Epoch 9/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4784\n",
      "Epoch 9: val_loss improved from 1.43701 to 1.43159, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 649us/sample - loss: 1.4784 - val_loss: 1.4316\n",
      "Epoch 10/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4819\n",
      "Epoch 10: val_loss did not improve from 1.43159\n",
      "32491/32491 [==============================] - 21s 660us/sample - loss: 1.4819 - val_loss: 1.4345\n",
      "Epoch 11/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5250\n",
      "Epoch 11: val_loss did not improve from 1.43159\n",
      "32491/32491 [==============================] - 21s 637us/sample - loss: 1.5250 - val_loss: 1.4430\n",
      "Epoch 12/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4927\n",
      "Epoch 12: val_loss improved from 1.43159 to 1.42432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 654us/sample - loss: 1.4927 - val_loss: 1.4243\n",
      "Epoch 13/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4636\n",
      "Epoch 13: val_loss did not improve from 1.42432\n",
      "32491/32491 [==============================] - 21s 643us/sample - loss: 1.4636 - val_loss: 1.4252\n",
      "Epoch 14/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4592\n",
      "Epoch 14: val_loss improved from 1.42432 to 1.42360, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 652us/sample - loss: 1.4592 - val_loss: 1.4236\n",
      "Epoch 15/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4526\n",
      "Epoch 15: val_loss improved from 1.42360 to 1.41058, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 654us/sample - loss: 1.4526 - val_loss: 1.4106\n",
      "Epoch 16/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4747\n",
      "Epoch 16: val_loss did not improve from 1.41058\n",
      "32491/32491 [==============================] - 21s 652us/sample - loss: 1.4747 - val_loss: 1.4108\n",
      "Epoch 17/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5206\n",
      "Epoch 17: val_loss did not improve from 1.41058\n",
      "32491/32491 [==============================] - 21s 655us/sample - loss: 1.5206 - val_loss: 1.4106\n",
      "Epoch 18/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5195\n",
      "Epoch 18: val_loss did not improve from 1.41058\n",
      "32491/32491 [==============================] - 21s 643us/sample - loss: 1.5195 - val_loss: 1.4145\n",
      "Epoch 19/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4685\n",
      "Epoch 19: val_loss did not improve from 1.41058\n",
      "32491/32491 [==============================] - 21s 647us/sample - loss: 1.4685 - val_loss: 1.4111\n",
      "Epoch 20/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4510\n",
      "Epoch 20: val_loss improved from 1.41058 to 1.40596, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 731us/sample - loss: 1.4510 - val_loss: 1.4060\n",
      "Epoch 21/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4710\n",
      "Epoch 21: val_loss did not improve from 1.40596\n",
      "32491/32491 [==============================] - 24s 737us/sample - loss: 1.4710 - val_loss: 1.4064\n",
      "Epoch 22/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 22: val_loss improved from 1.40596 to 1.40390, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 743us/sample - loss: 1.4865 - val_loss: 1.4039\n",
      "Epoch 23/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4517\n",
      "Epoch 23: val_loss improved from 1.40390 to 1.40058, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 738us/sample - loss: 1.4517 - val_loss: 1.4006\n",
      "Epoch 24/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4423\n",
      "Epoch 24: val_loss improved from 1.40058 to 1.39637, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 745us/sample - loss: 1.4423 - val_loss: 1.3964\n",
      "Epoch 25/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4389\n",
      "Epoch 25: val_loss improved from 1.39637 to 1.39498, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 706us/sample - loss: 1.4389 - val_loss: 1.3950\n",
      "Epoch 26/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 26: val_loss did not improve from 1.39498\n",
      "32491/32491 [==============================] - 21s 636us/sample - loss: 1.4294 - val_loss: 1.3961\n",
      "Epoch 27/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 27: val_loss improved from 1.39498 to 1.39266, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 651us/sample - loss: 1.4277 - val_loss: 1.3927\n",
      "Epoch 28/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4239\n",
      "Epoch 28: val_loss improved from 1.39266 to 1.38924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 651us/sample - loss: 1.4239 - val_loss: 1.3892\n",
      "Epoch 29/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 29: val_loss did not improve from 1.38924\n",
      "32491/32491 [==============================] - 21s 643us/sample - loss: 1.4202 - val_loss: 1.3950\n",
      "Epoch 30/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4213\n",
      "Epoch 30: val_loss did not improve from 1.38924\n",
      "32491/32491 [==============================] - 21s 644us/sample - loss: 1.4213 - val_loss: 1.3898\n",
      "Epoch 31/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4190\n",
      "Epoch 31: val_loss improved from 1.38924 to 1.38797, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.4190 - val_loss: 1.3880\n",
      "Epoch 32/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4147\n",
      "Epoch 32: val_loss improved from 1.38797 to 1.38487, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 650us/sample - loss: 1.4147 - val_loss: 1.3849\n",
      "Epoch 33/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4138\n",
      "Epoch 33: val_loss improved from 1.38487 to 1.37793, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 721us/sample - loss: 1.4138 - val_loss: 1.3779\n",
      "Epoch 34/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4107\n",
      "Epoch 34: val_loss did not improve from 1.37793\n",
      "32491/32491 [==============================] - 22s 689us/sample - loss: 1.4107 - val_loss: 1.3828\n",
      "Epoch 35/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 35: val_loss did not improve from 1.37793\n",
      "32491/32491 [==============================] - 23s 707us/sample - loss: 1.4065 - val_loss: 1.3820\n",
      "Epoch 36/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4064\n",
      "Epoch 36: val_loss did not improve from 1.37793\n",
      "32491/32491 [==============================] - 21s 649us/sample - loss: 1.4064 - val_loss: 1.3813\n",
      "Epoch 37/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4041\n",
      "Epoch 37: val_loss improved from 1.37793 to 1.37633, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 646us/sample - loss: 1.4041 - val_loss: 1.3763\n",
      "Epoch 38/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4009\n",
      "Epoch 38: val_loss did not improve from 1.37633\n",
      "32491/32491 [==============================] - 23s 722us/sample - loss: 1.4009 - val_loss: 1.3792\n",
      "Epoch 39/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4014\n",
      "Epoch 39: val_loss did not improve from 1.37633\n",
      "32491/32491 [==============================] - 21s 647us/sample - loss: 1.4014 - val_loss: 1.3773\n",
      "Epoch 40/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4004\n",
      "Epoch 40: val_loss improved from 1.37633 to 1.36990, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 726us/sample - loss: 1.4004 - val_loss: 1.3699\n",
      "Epoch 41/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 41: val_loss did not improve from 1.36990\n",
      "32491/32491 [==============================] - 23s 703us/sample - loss: 1.3977 - val_loss: 1.3831\n",
      "Epoch 42/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 42: val_loss did not improve from 1.36990\n",
      "32491/32491 [==============================] - 22s 667us/sample - loss: 1.3972 - val_loss: 1.3747\n",
      "Epoch 43/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 43: val_loss improved from 1.36990 to 1.36793, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 720us/sample - loss: 1.3948 - val_loss: 1.3679\n",
      "Epoch 44/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3927\n",
      "Epoch 44: val_loss did not improve from 1.36793\n",
      "32491/32491 [==============================] - 23s 703us/sample - loss: 1.3927 - val_loss: 1.3699\n",
      "Epoch 45/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3927\n",
      "Epoch 45: val_loss improved from 1.36793 to 1.36679, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 654us/sample - loss: 1.3927 - val_loss: 1.3668\n",
      "Epoch 46/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3920\n",
      "Epoch 46: val_loss improved from 1.36679 to 1.36403, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 710us/sample - loss: 1.3920 - val_loss: 1.3640\n",
      "Epoch 47/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 47: val_loss did not improve from 1.36403\n",
      "32491/32491 [==============================] - 23s 717us/sample - loss: 1.3912 - val_loss: 1.3696\n",
      "Epoch 48/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3885\n",
      "Epoch 48: val_loss improved from 1.36403 to 1.36307, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 741us/sample - loss: 1.3885 - val_loss: 1.3631\n",
      "Epoch 49/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4023\n",
      "Epoch 49: val_loss did not improve from 1.36307\n",
      "32491/32491 [==============================] - 24s 733us/sample - loss: 1.4023 - val_loss: 1.3714\n",
      "Epoch 50/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3853\n",
      "Epoch 50: val_loss did not improve from 1.36307\n",
      "32491/32491 [==============================] - 22s 667us/sample - loss: 1.3853 - val_loss: 1.3640\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:08:10.759259: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_562_1/lstm_cell_1709/bias/Assign' id:875419 op device:{requested: '', assigned: ''} def:{{{node lstm_562_1/lstm_cell_1709/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_562_1/lstm_cell_1709/bias, lstm_562_1/lstm_cell_1709/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 22:08:58.036957: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_563_1/lstm_cell_1710/bias/v/Assign' id:881655 op device:{requested: '', assigned: ''} def:{{{node lstm_563_1/lstm_cell_1710/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_563_1/lstm_cell_1710/bias/v, lstm_563_1/lstm_cell_1710/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 22:09:45.705447: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_79_1/cond/Merge' id:880221 op device:{requested: '', assigned: ''} def:{{{node dropout_79_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_79_1/cond/Identity, dropout_79_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 888)\n",
      "(1514, 888)\n",
      "(1644, 888)\n",
      "(1764, 888)\n",
      "(1836, 888)\n",
      "(1699, 888)\n",
      "(1369, 888)\n",
      "(1766, 888)\n",
      "(1619, 888)\n",
      "(1692, 888)\n",
      "(1550, 888)\n",
      "(1739, 888)\n",
      "(1764, 888)\n",
      "(1860, 888)\n",
      "(1764, 888)\n",
      "(1788, 888)\n",
      "(970, 888)\n",
      "(1668, 888)\n",
      "(1884, 888)\n",
      "{1: 5.415738137782684, 2: 5.212499857733062, 4: 10.0, 5: 4.706854705621251, 6: 4.314304656112357, 8: 8.333830793394261, 9: 6.492943559860237, 10: 6.8674755016332245, 11: 6.466614217588746, 12: 9.085663191559586, 13: 6.085444100474603, 19: 8.310604293047131, 21: 8.569345173736385, 22: 1.0645166338504262, 25: 7.823539203077519, 26: 5.978204705052184, 27: 4.838669291965902, 28: 5.823934705165997, 29: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907972/3306004915.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32491 samples, validate on 3622 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:18:33.451956: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0642\n",
      "Epoch 1: val_loss improved from inf to 1.40998, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 110s 3ms/sample - loss: 11.0642 - val_loss: 1.4100\n",
      "Epoch 2/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9343\n",
      "Epoch 2: val_loss improved from 1.40998 to 1.39419, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 736us/sample - loss: 10.9343 - val_loss: 1.3942\n",
      "Epoch 3/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8415\n",
      "Epoch 3: val_loss improved from 1.39419 to 1.39126, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 752us/sample - loss: 10.8415 - val_loss: 1.3913\n",
      "Epoch 4/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8008\n",
      "Epoch 4: val_loss improved from 1.39126 to 1.38118, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 22s 677us/sample - loss: 10.8008 - val_loss: 1.3812\n",
      "Epoch 5/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.7463\n",
      "Epoch 5: val_loss improved from 1.38118 to 1.37786, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 649us/sample - loss: 10.7463 - val_loss: 1.3779\n",
      "Epoch 6/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.7379\n",
      "Epoch 6: val_loss did not improve from 1.37786\n",
      "32491/32491 [==============================] - 21s 640us/sample - loss: 10.7379 - val_loss: 1.3798\n",
      "Epoch 7/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.6946\n",
      "Epoch 7: val_loss did not improve from 1.37786\n",
      "32491/32491 [==============================] - 22s 686us/sample - loss: 10.6946 - val_loss: 1.3886\n",
      "Epoch 8/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.6869\n",
      "Epoch 8: val_loss improved from 1.37786 to 1.37216, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 743us/sample - loss: 10.6869 - val_loss: 1.3722\n",
      "Epoch 9/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.6664\n",
      "Epoch 9: val_loss did not improve from 1.37216\n",
      "32491/32491 [==============================] - 24s 734us/sample - loss: 10.6664 - val_loss: 1.3798\n",
      "Epoch 10/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.6048\n",
      "Epoch 10: val_loss improved from 1.37216 to 1.36591, saving model to ./checkpoints/unknown_person_few_shot_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 750us/sample - loss: 10.6048 - val_loss: 1.3659\n",
      "Epoch 11/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.6196\n",
      "Epoch 11: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 23s 703us/sample - loss: 10.6196 - val_loss: 1.3786\n",
      "Epoch 12/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5976\n",
      "Epoch 12: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 24s 736us/sample - loss: 10.5976 - val_loss: 1.3725\n",
      "Epoch 13/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.6072\n",
      "Epoch 13: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 22s 669us/sample - loss: 10.6072 - val_loss: 1.3796\n",
      "Epoch 14/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5639\n",
      "Epoch 14: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 22s 682us/sample - loss: 10.5639 - val_loss: 1.3856\n",
      "Epoch 15/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5533\n",
      "Epoch 15: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 21s 645us/sample - loss: 10.5533 - val_loss: 1.3793\n",
      "Epoch 16/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5284\n",
      "Epoch 16: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 21s 639us/sample - loss: 10.5284 - val_loss: 1.3769\n",
      "Epoch 17/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5347\n",
      "Epoch 17: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 21s 638us/sample - loss: 10.5347 - val_loss: 1.3799\n",
      "Epoch 18/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5256\n",
      "Epoch 18: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 21s 642us/sample - loss: 10.5256 - val_loss: 1.3780\n",
      "Epoch 19/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.5039\n",
      "Epoch 19: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 21s 640us/sample - loss: 10.5039 - val_loss: 1.3705\n",
      "Epoch 20/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.4870\n",
      "Epoch 20: val_loss did not improve from 1.36591\n",
      "32491/32491 [==============================] - 21s 639us/sample - loss: 10.4870 - val_loss: 1.3820\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:27:44.699364: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_569_2/lstm_cell_1753/bias/Assign' id:895937 op device:{requested: '', assigned: ''} def:{{{node lstm_569_2/lstm_cell_1753/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_569_2/lstm_cell_1753/bias, lstm_569_2/lstm_cell_1753/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 22:28:32.997460: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_571_2/lstm_cell_1755/kernel/m/Assign' id:900520 op device:{requested: '', assigned: ''} def:{{{node lstm_571_2/lstm_cell_1755/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_571_2/lstm_cell_1755/kernel/m, lstm_571_2/lstm_cell_1755/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32491 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:29:24.238064: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:33:31.850557: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:33:54.983979: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36083, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 107s 3ms/sample - loss: 1.3989 - val_loss: 1.3608\n",
      "Epoch 2/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3858\n",
      "Epoch 2: val_loss did not improve from 1.36083\n",
      "32491/32491 [==============================] - 21s 646us/sample - loss: 1.3858 - val_loss: 1.3613\n",
      "Epoch 3/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3836\n",
      "Epoch 3: val_loss improved from 1.36083 to 1.35420, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 634us/sample - loss: 1.3836 - val_loss: 1.3542\n",
      "Epoch 4/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3809\n",
      "Epoch 4: val_loss did not improve from 1.35420\n",
      "32491/32491 [==============================] - 20s 622us/sample - loss: 1.3809 - val_loss: 1.3559\n",
      "Epoch 5/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3814\n",
      "Epoch 5: val_loss did not improve from 1.35420\n",
      "32491/32491 [==============================] - 20s 627us/sample - loss: 1.3814 - val_loss: 1.3656\n",
      "Epoch 6/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3790\n",
      "Epoch 6: val_loss improved from 1.35420 to 1.35253, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 641us/sample - loss: 1.3790 - val_loss: 1.3525\n",
      "Epoch 7/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3758\n",
      "Epoch 7: val_loss did not improve from 1.35253\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.3758 - val_loss: 1.3635\n",
      "Epoch 8/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3777\n",
      "Epoch 8: val_loss did not improve from 1.35253\n",
      "32491/32491 [==============================] - 24s 727us/sample - loss: 1.3777 - val_loss: 1.3676\n",
      "Epoch 9/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3750\n",
      "Epoch 9: val_loss did not improve from 1.35253\n",
      "32491/32491 [==============================] - 21s 659us/sample - loss: 1.3750 - val_loss: 1.3533\n",
      "Epoch 10/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3730\n",
      "Epoch 10: val_loss improved from 1.35253 to 1.35210, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 22s 685us/sample - loss: 1.3730 - val_loss: 1.3521\n",
      "Epoch 11/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3713\n",
      "Epoch 11: val_loss did not improve from 1.35210\n",
      "32491/32491 [==============================] - 24s 726us/sample - loss: 1.3713 - val_loss: 1.3528\n",
      "Epoch 12/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3701\n",
      "Epoch 12: val_loss did not improve from 1.35210\n",
      "32491/32491 [==============================] - 23s 714us/sample - loss: 1.3701 - val_loss: 1.3526\n",
      "Epoch 13/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3682\n",
      "Epoch 13: val_loss did not improve from 1.35210\n",
      "32491/32491 [==============================] - 21s 645us/sample - loss: 1.3682 - val_loss: 1.3541\n",
      "Epoch 14/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3705\n",
      "Epoch 14: val_loss improved from 1.35210 to 1.35060, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 21s 654us/sample - loss: 1.3705 - val_loss: 1.3506\n",
      "Epoch 15/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3664\n",
      "Epoch 15: val_loss did not improve from 1.35060\n",
      "32491/32491 [==============================] - 23s 699us/sample - loss: 1.3664 - val_loss: 1.3540\n",
      "Epoch 16/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3650\n",
      "Epoch 16: val_loss improved from 1.35060 to 1.34746, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 727us/sample - loss: 1.3650 - val_loss: 1.3475\n",
      "Epoch 17/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3662\n",
      "Epoch 17: val_loss did not improve from 1.34746\n",
      "32491/32491 [==============================] - 22s 667us/sample - loss: 1.3662 - val_loss: 1.3517\n",
      "Epoch 18/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3650\n",
      "Epoch 18: val_loss improved from 1.34746 to 1.34704, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 23s 709us/sample - loss: 1.3650 - val_loss: 1.3470\n",
      "Epoch 19/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3649\n",
      "Epoch 19: val_loss improved from 1.34704 to 1.34263, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_45.h5\n",
      "32491/32491 [==============================] - 24s 735us/sample - loss: 1.3649 - val_loss: 1.3426\n",
      "Epoch 20/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3653\n",
      "Epoch 20: val_loss did not improve from 1.34263\n",
      "32491/32491 [==============================] - 24s 727us/sample - loss: 1.3653 - val_loss: 1.3592\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:42:36.122393: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_604/lstm_cell_1788/recurrent_kernel/Assign' id:914690 op device:{requested: '', assigned: ''} def:{{{node lstm_604/lstm_cell_1788/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_604/lstm_cell_1788/recurrent_kernel, lstm_604/lstm_cell_1788/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 22:43:03.018876: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_1' id:916308 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 22:43:24.853216: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_2' id:916309 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32491, 95)\n",
      "Train on 32491 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:44:15.029798: W tensorflow/c/c_api.cc:304] Operation '{name:'training_96/Adam/lstm_594/lstm_cell_1778/kernel/m/Assign' id:929096 op device:{requested: '', assigned: ''} def:{{{node training_96/Adam/lstm_594/lstm_cell_1778/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_96/Adam/lstm_594/lstm_cell_1778/kernel/m, training_96/Adam/lstm_594/lstm_cell_1778/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:48:34.734734: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 3.3967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 22:49:01.207668: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_97/mul' id:919149 op device:{requested: '', assigned: ''} def:{{{node loss_97/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_97/mul/x, loss_97/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95254, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 269s 8ms/sample - loss: 3.3967 - val_loss: 1.9525\n",
      "Epoch 2/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.7736\n",
      "Epoch 2: val_loss improved from 1.95254 to 1.55650, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 742us/sample - loss: 1.7736 - val_loss: 1.5565\n",
      "Epoch 3/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5888\n",
      "Epoch 3: val_loss improved from 1.55650 to 1.50743, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.5888 - val_loss: 1.5074\n",
      "Epoch 4/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5370\n",
      "Epoch 4: val_loss improved from 1.50743 to 1.48234, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 22s 689us/sample - loss: 1.5370 - val_loss: 1.4823\n",
      "Epoch 5/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5140\n",
      "Epoch 5: val_loss improved from 1.48234 to 1.46955, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 22s 671us/sample - loss: 1.5140 - val_loss: 1.4695\n",
      "Epoch 6/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5004\n",
      "Epoch 6: val_loss improved from 1.46955 to 1.45844, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 647us/sample - loss: 1.5004 - val_loss: 1.4584\n",
      "Epoch 7/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4902\n",
      "Epoch 7: val_loss improved from 1.45844 to 1.44962, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 726us/sample - loss: 1.4902 - val_loss: 1.4496\n",
      "Epoch 8/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4926\n",
      "Epoch 8: val_loss did not improve from 1.44962\n",
      "32491/32491 [==============================] - 24s 729us/sample - loss: 1.4926 - val_loss: 1.4503\n",
      "Epoch 9/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4850\n",
      "Epoch 9: val_loss improved from 1.44962 to 1.44246, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 739us/sample - loss: 1.4850 - val_loss: 1.4425\n",
      "Epoch 10/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 10: val_loss improved from 1.44246 to 1.43977, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 739us/sample - loss: 1.4827 - val_loss: 1.4398\n",
      "Epoch 11/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4857\n",
      "Epoch 11: val_loss improved from 1.43977 to 1.43461, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 23s 709us/sample - loss: 1.4857 - val_loss: 1.4346\n",
      "Epoch 12/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4878\n",
      "Epoch 12: val_loss did not improve from 1.43461\n",
      "32491/32491 [==============================] - 23s 710us/sample - loss: 1.4878 - val_loss: 1.4519\n",
      "Epoch 13/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4686\n",
      "Epoch 13: val_loss improved from 1.43461 to 1.42876, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 736us/sample - loss: 1.4686 - val_loss: 1.4288\n",
      "Epoch 14/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4671\n",
      "Epoch 14: val_loss did not improve from 1.42876\n",
      "32491/32491 [==============================] - 20s 629us/sample - loss: 1.4671 - val_loss: 1.4423\n",
      "Epoch 15/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4599\n",
      "Epoch 15: val_loss did not improve from 1.42876\n",
      "32491/32491 [==============================] - 24s 732us/sample - loss: 1.4599 - val_loss: 1.4335\n",
      "Epoch 16/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4716\n",
      "Epoch 16: val_loss did not improve from 1.42876\n",
      "32491/32491 [==============================] - 24s 732us/sample - loss: 1.4716 - val_loss: 1.4321\n",
      "Epoch 17/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4890\n",
      "Epoch 17: val_loss did not improve from 1.42876\n",
      "32491/32491 [==============================] - 24s 724us/sample - loss: 1.4890 - val_loss: 1.4322\n",
      "Epoch 18/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4755\n",
      "Epoch 18: val_loss did not improve from 1.42876\n",
      "32491/32491 [==============================] - 22s 681us/sample - loss: 1.4755 - val_loss: 1.4310\n",
      "Epoch 19/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5011\n",
      "Epoch 19: val_loss improved from 1.42876 to 1.42034, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 739us/sample - loss: 1.5011 - val_loss: 1.4203\n",
      "Epoch 20/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4810\n",
      "Epoch 20: val_loss improved from 1.42034 to 1.41711, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 23s 700us/sample - loss: 1.4810 - val_loss: 1.4171\n",
      "Epoch 21/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5173\n",
      "Epoch 21: val_loss did not improve from 1.41711\n",
      "32491/32491 [==============================] - 21s 657us/sample - loss: 1.5173 - val_loss: 1.4259\n",
      "Epoch 22/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5289\n",
      "Epoch 22: val_loss did not improve from 1.41711\n",
      "32491/32491 [==============================] - 23s 703us/sample - loss: 1.5289 - val_loss: 1.4209\n",
      "Epoch 23/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 23: val_loss did not improve from 1.41711\n",
      "32491/32491 [==============================] - 21s 641us/sample - loss: 1.4772 - val_loss: 1.4229\n",
      "Epoch 24/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5050\n",
      "Epoch 24: val_loss did not improve from 1.41711\n",
      "32491/32491 [==============================] - 21s 634us/sample - loss: 1.5050 - val_loss: 1.4290\n",
      "Epoch 25/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4582\n",
      "Epoch 25: val_loss did not improve from 1.41711\n",
      "32491/32491 [==============================] - 23s 704us/sample - loss: 1.4582 - val_loss: 1.4201\n",
      "Epoch 26/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4453\n",
      "Epoch 26: val_loss did not improve from 1.41711\n",
      "32491/32491 [==============================] - 24s 733us/sample - loss: 1.4453 - val_loss: 1.4223\n",
      "Epoch 27/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4416\n",
      "Epoch 27: val_loss improved from 1.41711 to 1.40978, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 739us/sample - loss: 1.4416 - val_loss: 1.4098\n",
      "Epoch 28/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4368\n",
      "Epoch 28: val_loss improved from 1.40978 to 1.40882, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 23s 693us/sample - loss: 1.4368 - val_loss: 1.4088\n",
      "Epoch 29/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 29: val_loss improved from 1.40882 to 1.40270, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 744us/sample - loss: 1.4349 - val_loss: 1.4027\n",
      "Epoch 30/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 30: val_loss did not improve from 1.40270\n",
      "32491/32491 [==============================] - 24s 728us/sample - loss: 1.4334 - val_loss: 1.4070\n",
      "Epoch 31/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4318\n",
      "Epoch 31: val_loss did not improve from 1.40270\n",
      "32491/32491 [==============================] - 24s 732us/sample - loss: 1.4318 - val_loss: 1.4057\n",
      "Epoch 32/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 32: val_loss did not improve from 1.40270\n",
      "32491/32491 [==============================] - 21s 661us/sample - loss: 1.4269 - val_loss: 1.4052\n",
      "Epoch 33/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4259\n",
      "Epoch 33: val_loss improved from 1.40270 to 1.40171, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 649us/sample - loss: 1.4259 - val_loss: 1.4017\n",
      "Epoch 34/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4259\n",
      "Epoch 34: val_loss did not improve from 1.40171\n",
      "32491/32491 [==============================] - 21s 642us/sample - loss: 1.4259 - val_loss: 1.4020\n",
      "Epoch 35/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4208\n",
      "Epoch 35: val_loss improved from 1.40171 to 1.39216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 650us/sample - loss: 1.4208 - val_loss: 1.3922\n",
      "Epoch 36/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 36: val_loss did not improve from 1.39216\n",
      "32491/32491 [==============================] - 21s 649us/sample - loss: 1.4204 - val_loss: 1.3939\n",
      "Epoch 37/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4194\n",
      "Epoch 37: val_loss did not improve from 1.39216\n",
      "32491/32491 [==============================] - 21s 642us/sample - loss: 1.4194 - val_loss: 1.3992\n",
      "Epoch 38/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 38: val_loss did not improve from 1.39216\n",
      "32491/32491 [==============================] - 21s 642us/sample - loss: 1.4163 - val_loss: 1.3957\n",
      "Epoch 39/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 39: val_loss improved from 1.39216 to 1.39074, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 646us/sample - loss: 1.4132 - val_loss: 1.3907\n",
      "Epoch 40/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4151\n",
      "Epoch 40: val_loss improved from 1.39074 to 1.38926, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 22s 686us/sample - loss: 1.4151 - val_loss: 1.3893\n",
      "Epoch 41/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4144\n",
      "Epoch 41: val_loss did not improve from 1.38926\n",
      "32491/32491 [==============================] - 23s 704us/sample - loss: 1.4144 - val_loss: 1.3945\n",
      "Epoch 42/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4113\n",
      "Epoch 42: val_loss did not improve from 1.38926\n",
      "32491/32491 [==============================] - 21s 661us/sample - loss: 1.4113 - val_loss: 1.3933\n",
      "Epoch 43/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 43: val_loss did not improve from 1.38926\n",
      "32491/32491 [==============================] - 21s 640us/sample - loss: 1.4093 - val_loss: 1.3932\n",
      "Epoch 44/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 44: val_loss improved from 1.38926 to 1.38490, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 650us/sample - loss: 1.4065 - val_loss: 1.3849\n",
      "Epoch 45/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 45: val_loss improved from 1.38490 to 1.38368, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 652us/sample - loss: 1.4051 - val_loss: 1.3837\n",
      "Epoch 46/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4036\n",
      "Epoch 46: val_loss improved from 1.38368 to 1.37777, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 650us/sample - loss: 1.4036 - val_loss: 1.3778\n",
      "Epoch 47/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4017\n",
      "Epoch 47: val_loss improved from 1.37777 to 1.37681, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 658us/sample - loss: 1.4017 - val_loss: 1.3768\n",
      "Epoch 48/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4021\n",
      "Epoch 48: val_loss did not improve from 1.37681\n",
      "32491/32491 [==============================] - 22s 675us/sample - loss: 1.4021 - val_loss: 1.3806\n",
      "Epoch 49/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3993\n",
      "Epoch 49: val_loss did not improve from 1.37681\n",
      "32491/32491 [==============================] - 24s 733us/sample - loss: 1.3993 - val_loss: 1.3797\n",
      "Epoch 50/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3970\n",
      "Epoch 50: val_loss did not improve from 1.37681\n",
      "32491/32491 [==============================] - 24s 730us/sample - loss: 1.3970 - val_loss: 1.3802\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:11:41.511749: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_613_1/lstm_cell_1834/bias/Assign' id:934701 op device:{requested: '', assigned: ''} def:{{{node lstm_613_1/lstm_cell_1834/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_613_1/lstm_cell_1834/bias, lstm_613_1/lstm_cell_1834/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 23:12:34.918631: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_600_1/lstm_cell_1821/kernel/m/Assign' id:938044 op device:{requested: '', assigned: ''} def:{{{node lstm_600_1/lstm_cell_1821/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_600_1/lstm_cell_1821/kernel/m, lstm_600_1/lstm_cell_1821/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 23:13:28.405023: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_84_1/cond/Merge' id:937263 op device:{requested: '', assigned: ''} def:{{{node dropout_84_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_84_1/cond/Identity, dropout_84_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 888)\n",
      "(1514, 888)\n",
      "(1644, 888)\n",
      "(1764, 888)\n",
      "(1836, 888)\n",
      "(1699, 888)\n",
      "(1369, 888)\n",
      "(1766, 888)\n",
      "(1619, 888)\n",
      "(1692, 888)\n",
      "(1550, 888)\n",
      "(1739, 888)\n",
      "(1764, 888)\n",
      "(1860, 888)\n",
      "(1764, 888)\n",
      "(1788, 888)\n",
      "(970, 888)\n",
      "(1668, 888)\n",
      "(1884, 888)\n",
      "{1: 5.6835278132953775, 2: 5.263714442675397, 4: 10.0, 5: 4.899392130543137, 6: 4.622796334551516, 8: 8.266954194434302, 9: 6.239200948050627, 10: 7.145364868782096, 11: 6.701527559594407, 12: 9.578163774105812, 13: 6.351962830396078, 19: 8.503994343336515, 21: 8.657482466417179, 22: 1.0, 25: 8.154930263583733, 26: 6.209412306040543, 27: 4.669239528926493, 28: 6.426966194586716, 29: 1.9629586935268148}\n",
      "Train on 32491 samples, validate on 3622 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:22:24.983250: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 11.4570\n",
      "Epoch 1: val_loss improved from inf to 1.40724, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 114s 3ms/sample - loss: 11.4570 - val_loss: 1.4072\n",
      "Epoch 2/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.2606\n",
      "Epoch 2: val_loss improved from 1.40724 to 1.39834, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 726us/sample - loss: 11.2606 - val_loss: 1.3983\n",
      "Epoch 3/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.2242\n",
      "Epoch 3: val_loss improved from 1.39834 to 1.39381, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 734us/sample - loss: 11.2242 - val_loss: 1.3938\n",
      "Epoch 4/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.1584\n",
      "Epoch 4: val_loss did not improve from 1.39381\n",
      "32491/32491 [==============================] - 24s 736us/sample - loss: 11.1584 - val_loss: 1.4075\n",
      "Epoch 5/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.1568\n",
      "Epoch 5: val_loss did not improve from 1.39381\n",
      "32491/32491 [==============================] - 24s 742us/sample - loss: 11.1568 - val_loss: 1.3972\n",
      "Epoch 6/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.1239\n",
      "Epoch 6: val_loss did not improve from 1.39381\n",
      "32491/32491 [==============================] - 24s 743us/sample - loss: 11.1239 - val_loss: 1.4106\n",
      "Epoch 7/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0820\n",
      "Epoch 7: val_loss improved from 1.39381 to 1.39122, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 25s 756us/sample - loss: 11.0820 - val_loss: 1.3912\n",
      "Epoch 8/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0752\n",
      "Epoch 8: val_loss did not improve from 1.39122\n",
      "32491/32491 [==============================] - 20s 629us/sample - loss: 11.0752 - val_loss: 1.3956\n",
      "Epoch 9/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0780\n",
      "Epoch 9: val_loss improved from 1.39122 to 1.38973, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 641us/sample - loss: 11.0780 - val_loss: 1.3897\n",
      "Epoch 10/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0215\n",
      "Epoch 10: val_loss improved from 1.38973 to 1.38667, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 23s 715us/sample - loss: 11.0215 - val_loss: 1.3867\n",
      "Epoch 11/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9968\n",
      "Epoch 11: val_loss did not improve from 1.38667\n",
      "32491/32491 [==============================] - 21s 655us/sample - loss: 10.9968 - val_loss: 1.3930\n",
      "Epoch 12/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9980\n",
      "Epoch 12: val_loss did not improve from 1.38667\n",
      "32491/32491 [==============================] - 21s 645us/sample - loss: 10.9980 - val_loss: 1.3904\n",
      "Epoch 13/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9783\n",
      "Epoch 13: val_loss did not improve from 1.38667\n",
      "32491/32491 [==============================] - 21s 657us/sample - loss: 10.9783 - val_loss: 1.3891\n",
      "Epoch 14/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9650\n",
      "Epoch 14: val_loss did not improve from 1.38667\n",
      "32491/32491 [==============================] - 21s 647us/sample - loss: 10.9650 - val_loss: 1.3949\n",
      "Epoch 15/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9944\n",
      "Epoch 15: val_loss improved from 1.38667 to 1.37943, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 660us/sample - loss: 10.9944 - val_loss: 1.3794\n",
      "Epoch 16/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9555\n",
      "Epoch 16: val_loss improved from 1.37943 to 1.37369, saving model to ./checkpoints/unknown_person_few_shot_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 658us/sample - loss: 10.9555 - val_loss: 1.3737\n",
      "Epoch 17/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9304\n",
      "Epoch 17: val_loss did not improve from 1.37369\n",
      "32491/32491 [==============================] - 21s 661us/sample - loss: 10.9304 - val_loss: 1.3796\n",
      "Epoch 18/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8862\n",
      "Epoch 18: val_loss did not improve from 1.37369\n",
      "32491/32491 [==============================] - 24s 745us/sample - loss: 10.8862 - val_loss: 1.3871\n",
      "Epoch 19/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9121\n",
      "Epoch 19: val_loss did not improve from 1.37369\n",
      "32491/32491 [==============================] - 24s 737us/sample - loss: 10.9121 - val_loss: 1.3824\n",
      "Epoch 20/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9094\n",
      "Epoch 20: val_loss did not improve from 1.37369\n",
      "32491/32491 [==============================] - 24s 738us/sample - loss: 10.9094 - val_loss: 1.3893\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:31:49.945571: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_593_2/lstm_cell_1851/recurrent_kernel/Assign' id:950890 op device:{requested: '', assigned: ''} def:{{{node lstm_593_2/lstm_cell_1851/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_593_2/lstm_cell_1851/recurrent_kernel, lstm_593_2/lstm_cell_1851/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 23:32:44.495105: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_595_2/lstm_cell_1853/recurrent_kernel/v/Assign' id:958015 op device:{requested: '', assigned: ''} def:{{{node lstm_595_2/lstm_cell_1853/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_595_2/lstm_cell_1853/recurrent_kernel/v, lstm_595_2/lstm_cell_1853/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32491 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:33:41.254492: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:38:05.474857: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:38:31.945386: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38344, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 119s 4ms/sample - loss: 1.4040 - val_loss: 1.3834\n",
      "Epoch 2/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4019\n",
      "Epoch 2: val_loss improved from 1.38344 to 1.37833, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 24s 741us/sample - loss: 1.4019 - val_loss: 1.3783\n",
      "Epoch 3/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3974\n",
      "Epoch 3: val_loss did not improve from 1.37833\n",
      "32491/32491 [==============================] - 21s 658us/sample - loss: 1.3974 - val_loss: 1.3807\n",
      "Epoch 4/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 4: val_loss did not improve from 1.37833\n",
      "32491/32491 [==============================] - 21s 632us/sample - loss: 1.3984 - val_loss: 1.3809\n",
      "Epoch 5/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 5: val_loss improved from 1.37833 to 1.37671, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 648us/sample - loss: 1.3936 - val_loss: 1.3767\n",
      "Epoch 6/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 6: val_loss improved from 1.37671 to 1.37342, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 648us/sample - loss: 1.3948 - val_loss: 1.3734\n",
      "Epoch 7/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3921\n",
      "Epoch 7: val_loss improved from 1.37342 to 1.36915, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 648us/sample - loss: 1.3921 - val_loss: 1.3692\n",
      "Epoch 8/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3856\n",
      "Epoch 8: val_loss did not improve from 1.36915\n",
      "32491/32491 [==============================] - 21s 634us/sample - loss: 1.3856 - val_loss: 1.3712\n",
      "Epoch 9/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 9: val_loss improved from 1.36915 to 1.36819, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.3882 - val_loss: 1.3682\n",
      "Epoch 10/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3870\n",
      "Epoch 10: val_loss did not improve from 1.36819\n",
      "32491/32491 [==============================] - 21s 639us/sample - loss: 1.3870 - val_loss: 1.3756\n",
      "Epoch 11/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3881\n",
      "Epoch 11: val_loss did not improve from 1.36819\n",
      "32491/32491 [==============================] - 24s 726us/sample - loss: 1.3881 - val_loss: 1.3703\n",
      "Epoch 12/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3863\n",
      "Epoch 12: val_loss did not improve from 1.36819\n",
      "32491/32491 [==============================] - 20s 621us/sample - loss: 1.3863 - val_loss: 1.3691\n",
      "Epoch 13/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 13: val_loss improved from 1.36819 to 1.36669, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 631us/sample - loss: 1.3862 - val_loss: 1.3667\n",
      "Epoch 14/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3822\n",
      "Epoch 14: val_loss improved from 1.36669 to 1.36281, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 644us/sample - loss: 1.3822 - val_loss: 1.3628\n",
      "Epoch 15/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3824\n",
      "Epoch 15: val_loss did not improve from 1.36281\n",
      "32491/32491 [==============================] - 23s 715us/sample - loss: 1.3824 - val_loss: 1.3652\n",
      "Epoch 16/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3813\n",
      "Epoch 16: val_loss did not improve from 1.36281\n",
      "32491/32491 [==============================] - 22s 675us/sample - loss: 1.3813 - val_loss: 1.3658\n",
      "Epoch 17/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3804\n",
      "Epoch 17: val_loss improved from 1.36281 to 1.35868, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_46.h5\n",
      "32491/32491 [==============================] - 21s 646us/sample - loss: 1.3804 - val_loss: 1.3587\n",
      "Epoch 18/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3788\n",
      "Epoch 18: val_loss did not improve from 1.35868\n",
      "32491/32491 [==============================] - 21s 651us/sample - loss: 1.3788 - val_loss: 1.3602\n",
      "Epoch 19/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3784\n",
      "Epoch 19: val_loss did not improve from 1.35868\n",
      "32491/32491 [==============================] - 24s 730us/sample - loss: 1.3784 - val_loss: 1.3594\n",
      "Epoch 20/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3766\n",
      "Epoch 20: val_loss did not improve from 1.35868\n",
      "32491/32491 [==============================] - 24s 733us/sample - loss: 1.3766 - val_loss: 1.3681\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:47:16.977623: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_631/lstm_cell_1889/bias/Assign' id:970091 op device:{requested: '', assigned: ''} def:{{{node lstm_631/lstm_cell_1889/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_631/lstm_cell_1889/bias, lstm_631/lstm_cell_1889/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 23:47:47.143610: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_1' id:973350 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 23:48:11.909130: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_2' id:973351 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32491, 95)\n",
      "Train on 32491 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:49:06.149209: W tensorflow/c/c_api.cc:304] Operation '{name:'training_102/Adam/lstm_644/lstm_cell_1902/bias/v/Assign' id:986986 op device:{requested: '', assigned: ''} def:{{{node training_102/Adam/lstm_644/lstm_cell_1902/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_102/Adam/lstm_644/lstm_cell_1902/bias/v, training_102/Adam/lstm_644/lstm_cell_1902/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:53:43.354148: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 3.2088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 23:54:09.445858: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_103/mul' id:976191 op device:{requested: '', assigned: ''} def:{{{node loss_103/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_103/mul/x, loss_103/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.78834, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 280s 9ms/sample - loss: 3.2088 - val_loss: 1.7883\n",
      "Epoch 2/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.7704\n",
      "Epoch 2: val_loss improved from 1.78834 to 1.57580, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 23s 694us/sample - loss: 1.7704 - val_loss: 1.5758\n",
      "Epoch 3/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.6138\n",
      "Epoch 3: val_loss improved from 1.57580 to 1.51504, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 742us/sample - loss: 1.6138 - val_loss: 1.5150\n",
      "Epoch 4/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5567\n",
      "Epoch 4: val_loss improved from 1.51504 to 1.48736, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 729us/sample - loss: 1.5567 - val_loss: 1.4874\n",
      "Epoch 5/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5257\n",
      "Epoch 5: val_loss improved from 1.48736 to 1.46925, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.5257 - val_loss: 1.4692\n",
      "Epoch 6/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5061\n",
      "Epoch 6: val_loss improved from 1.46925 to 1.45256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 22s 673us/sample - loss: 1.5061 - val_loss: 1.4526\n",
      "Epoch 7/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4918\n",
      "Epoch 7: val_loss improved from 1.45256 to 1.44284, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 22s 665us/sample - loss: 1.4918 - val_loss: 1.4428\n",
      "Epoch 8/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5009\n",
      "Epoch 8: val_loss did not improve from 1.44284\n",
      "32491/32491 [==============================] - 22s 671us/sample - loss: 1.5009 - val_loss: 1.4505\n",
      "Epoch 9/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4828\n",
      "Epoch 9: val_loss improved from 1.44284 to 1.43348, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.4828 - val_loss: 1.4335\n",
      "Epoch 10/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5204\n",
      "Epoch 10: val_loss did not improve from 1.43348\n",
      "32491/32491 [==============================] - 23s 702us/sample - loss: 1.5204 - val_loss: 1.4432\n",
      "Epoch 11/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5034\n",
      "Epoch 11: val_loss did not improve from 1.43348\n",
      "32491/32491 [==============================] - 24s 738us/sample - loss: 1.5034 - val_loss: 1.4357\n",
      "Epoch 12/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.6055\n",
      "Epoch 12: val_loss did not improve from 1.43348\n",
      "32491/32491 [==============================] - 24s 737us/sample - loss: 1.6055 - val_loss: 1.4548\n",
      "Epoch 13/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4994\n",
      "Epoch 13: val_loss did not improve from 1.43348\n",
      "32491/32491 [==============================] - 21s 653us/sample - loss: 1.4994 - val_loss: 1.4400\n",
      "Epoch 14/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4918\n",
      "Epoch 14: val_loss did not improve from 1.43348\n",
      "32491/32491 [==============================] - 21s 641us/sample - loss: 1.4918 - val_loss: 1.4403\n",
      "Epoch 15/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4801\n",
      "Epoch 15: val_loss improved from 1.43348 to 1.43291, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 730us/sample - loss: 1.4801 - val_loss: 1.4329\n",
      "Epoch 16/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4908\n",
      "Epoch 16: val_loss improved from 1.43291 to 1.43268, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 747us/sample - loss: 1.4908 - val_loss: 1.4327\n",
      "Epoch 17/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4885\n",
      "Epoch 17: val_loss improved from 1.43268 to 1.42989, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 659us/sample - loss: 1.4885 - val_loss: 1.4299\n",
      "Epoch 18/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4985\n",
      "Epoch 18: val_loss improved from 1.42989 to 1.42867, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.4985 - val_loss: 1.4287\n",
      "Epoch 19/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4867\n",
      "Epoch 19: val_loss improved from 1.42867 to 1.42602, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 22s 662us/sample - loss: 1.4867 - val_loss: 1.4260\n",
      "Epoch 20/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4792\n",
      "Epoch 20: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 21s 648us/sample - loss: 1.4792 - val_loss: 1.4295\n",
      "Epoch 21/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5215\n",
      "Epoch 21: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 21s 647us/sample - loss: 1.5215 - val_loss: 1.4306\n",
      "Epoch 22/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5534\n",
      "Epoch 22: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 22s 677us/sample - loss: 1.5534 - val_loss: 1.4384\n",
      "Epoch 23/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5626\n",
      "Epoch 23: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 24s 741us/sample - loss: 1.5626 - val_loss: 1.4522\n",
      "Epoch 24/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.5041\n",
      "Epoch 24: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 23s 699us/sample - loss: 1.5041 - val_loss: 1.4495\n",
      "Epoch 25/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4763\n",
      "Epoch 25: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 21s 657us/sample - loss: 1.4763 - val_loss: 1.4328\n",
      "Epoch 26/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 26: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 23s 717us/sample - loss: 1.4689 - val_loss: 1.4340\n",
      "Epoch 27/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4621\n",
      "Epoch 27: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 24s 741us/sample - loss: 1.4621 - val_loss: 1.4274\n",
      "Epoch 28/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4564\n",
      "Epoch 28: val_loss did not improve from 1.42602\n",
      "32491/32491 [==============================] - 23s 702us/sample - loss: 1.4564 - val_loss: 1.4312\n",
      "Epoch 29/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4545\n",
      "Epoch 29: val_loss improved from 1.42602 to 1.41660, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 635us/sample - loss: 1.4545 - val_loss: 1.4166\n",
      "Epoch 30/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4559\n",
      "Epoch 30: val_loss improved from 1.41660 to 1.41621, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 636us/sample - loss: 1.4559 - val_loss: 1.4162\n",
      "Epoch 31/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4454\n",
      "Epoch 31: val_loss improved from 1.41621 to 1.41395, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 635us/sample - loss: 1.4454 - val_loss: 1.4140\n",
      "Epoch 32/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4446\n",
      "Epoch 32: val_loss did not improve from 1.41395\n",
      "32491/32491 [==============================] - 20s 625us/sample - loss: 1.4446 - val_loss: 1.4211\n",
      "Epoch 33/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4410\n",
      "Epoch 33: val_loss improved from 1.41395 to 1.41094, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 659us/sample - loss: 1.4410 - val_loss: 1.4109\n",
      "Epoch 34/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 34: val_loss improved from 1.41094 to 1.40925, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 745us/sample - loss: 1.4412 - val_loss: 1.4092\n",
      "Epoch 35/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 35: val_loss improved from 1.40925 to 1.40701, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 749us/sample - loss: 1.4383 - val_loss: 1.4070\n",
      "Epoch 36/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 36: val_loss did not improve from 1.40701\n",
      "32491/32491 [==============================] - 24s 740us/sample - loss: 1.4361 - val_loss: 1.4136\n",
      "Epoch 37/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4351\n",
      "Epoch 37: val_loss improved from 1.40701 to 1.40377, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 23s 719us/sample - loss: 1.4351 - val_loss: 1.4038\n",
      "Epoch 38/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4317\n",
      "Epoch 38: val_loss did not improve from 1.40377\n",
      "32491/32491 [==============================] - 24s 741us/sample - loss: 1.4317 - val_loss: 1.4069\n",
      "Epoch 39/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4300\n",
      "Epoch 39: val_loss improved from 1.40377 to 1.40288, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 748us/sample - loss: 1.4300 - val_loss: 1.4029\n",
      "Epoch 40/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4264\n",
      "Epoch 40: val_loss improved from 1.40288 to 1.39816, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 22s 690us/sample - loss: 1.4264 - val_loss: 1.3982\n",
      "Epoch 41/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 41: val_loss did not improve from 1.39816\n",
      "32491/32491 [==============================] - 21s 650us/sample - loss: 1.4250 - val_loss: 1.3982\n",
      "Epoch 42/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4240\n",
      "Epoch 42: val_loss did not improve from 1.39816\n",
      "32491/32491 [==============================] - 21s 646us/sample - loss: 1.4240 - val_loss: 1.3982\n",
      "Epoch 43/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4222\n",
      "Epoch 43: val_loss improved from 1.39816 to 1.39750, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.4222 - val_loss: 1.3975\n",
      "Epoch 44/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4201\n",
      "Epoch 44: val_loss improved from 1.39750 to 1.38832, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 656us/sample - loss: 1.4201 - val_loss: 1.3883\n",
      "Epoch 45/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 45: val_loss did not improve from 1.38832\n",
      "32491/32491 [==============================] - 21s 642us/sample - loss: 1.4207 - val_loss: 1.3912\n",
      "Epoch 46/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 46: val_loss did not improve from 1.38832\n",
      "32491/32491 [==============================] - 21s 646us/sample - loss: 1.4178 - val_loss: 1.3935\n",
      "Epoch 47/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 47: val_loss improved from 1.38832 to 1.38595, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 661us/sample - loss: 1.4158 - val_loss: 1.3860\n",
      "Epoch 48/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 48: val_loss did not improve from 1.38595\n",
      "32491/32491 [==============================] - 21s 654us/sample - loss: 1.4145 - val_loss: 1.3903\n",
      "Epoch 49/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 49: val_loss improved from 1.38595 to 1.38432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p17_47.h5\n",
      "32491/32491 [==============================] - 23s 712us/sample - loss: 1.4126 - val_loss: 1.3843\n",
      "Epoch 50/50\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4137\n",
      "Epoch 50: val_loss did not improve from 1.38432\n",
      "32491/32491 [==============================] - 22s 673us/sample - loss: 1.4137 - val_loss: 1.3864\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:16:56.700334: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_636_1/lstm_cell_1931/recurrent_kernel/Assign' id:989494 op device:{requested: '', assigned: ''} def:{{{node lstm_636_1/lstm_cell_1931/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_636_1/lstm_cell_1931/recurrent_kernel, lstm_636_1/lstm_cell_1931/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-19 00:17:55.182741: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_636_1/lstm_cell_1931/bias/v/Assign' id:995724 op device:{requested: '', assigned: ''} def:{{{node lstm_636_1/lstm_cell_1931/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_636_1/lstm_cell_1931/bias/v, lstm_636_1/lstm_cell_1931/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-19 00:18:53.487861: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_89_1/cond/Merge' id:994305 op device:{requested: '', assigned: ''} def:{{{node dropout_89_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_89_1/cond/Identity, dropout_89_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 888)\n",
      "(1514, 888)\n",
      "(1644, 888)\n",
      "(1764, 888)\n",
      "(1836, 888)\n",
      "(1699, 888)\n",
      "(1369, 888)\n",
      "(1766, 888)\n",
      "(1619, 888)\n",
      "(1692, 888)\n",
      "(1550, 888)\n",
      "(1739, 888)\n",
      "(1764, 888)\n",
      "(1860, 888)\n",
      "(1764, 888)\n",
      "(1788, 888)\n",
      "(970, 888)\n",
      "(1668, 888)\n",
      "(1884, 888)\n",
      "{1: 5.691244296051185, 2: 4.340386689355185, 4: 10.0, 5: 4.445961909551292, 6: 4.662032242528605, 8: 8.347604766180375, 9: 6.5237956264254615, 10: 7.049726909844361, 11: 7.103333354248641, 12: 9.324425197599922, 13: 6.294939357594989, 19: 8.728864762486019, 21: 8.388405991837827, 22: 1.0, 25: 8.1692930937092, 26: 5.962605571929861, 27: 5.350580300320356, 28: 6.275199183874482, 29: 1.7015392187275462}\n",
      "Train on 32491 samples, validate on 3622 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:28:44.257622: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 11.3246\n",
      "Epoch 1: val_loss improved from inf to 1.40831, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 172s 5ms/sample - loss: 11.3246 - val_loss: 1.4083\n",
      "Epoch 2/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.2720\n",
      "Epoch 2: val_loss improved from 1.40831 to 1.40541, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 36s 1ms/sample - loss: 11.2720 - val_loss: 1.4054\n",
      "Epoch 3/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.1700\n",
      "Epoch 3: val_loss improved from 1.40541 to 1.39942, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 11.1700 - val_loss: 1.3994\n",
      "Epoch 4/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.1080\n",
      "Epoch 4: val_loss improved from 1.39942 to 1.39003, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 36s 1ms/sample - loss: 11.1080 - val_loss: 1.3900\n",
      "Epoch 5/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0841\n",
      "Epoch 5: val_loss did not improve from 1.39003\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 11.0841 - val_loss: 1.3928\n",
      "Epoch 6/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0354\n",
      "Epoch 6: val_loss did not improve from 1.39003\n",
      "32491/32491 [==============================] - 33s 1ms/sample - loss: 11.0354 - val_loss: 1.3951\n",
      "Epoch 7/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0344\n",
      "Epoch 7: val_loss did not improve from 1.39003\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 11.0344 - val_loss: 1.3904\n",
      "Epoch 8/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0340\n",
      "Epoch 8: val_loss did not improve from 1.39003\n",
      "32491/32491 [==============================] - 33s 1ms/sample - loss: 11.0340 - val_loss: 1.4071\n",
      "Epoch 9/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 11.0426\n",
      "Epoch 9: val_loss improved from 1.39003 to 1.38696, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 34s 1ms/sample - loss: 11.0426 - val_loss: 1.3870\n",
      "Epoch 10/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9688\n",
      "Epoch 10: val_loss improved from 1.38696 to 1.38569, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.9688 - val_loss: 1.3857\n",
      "Epoch 11/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9328\n",
      "Epoch 11: val_loss did not improve from 1.38569\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.9328 - val_loss: 1.3893\n",
      "Epoch 12/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9494\n",
      "Epoch 12: val_loss did not improve from 1.38569\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.9494 - val_loss: 1.3871\n",
      "Epoch 13/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9371\n",
      "Epoch 13: val_loss did not improve from 1.38569\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.9371 - val_loss: 1.3949\n",
      "Epoch 14/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9105\n",
      "Epoch 14: val_loss improved from 1.38569 to 1.38510, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 34s 1ms/sample - loss: 10.9105 - val_loss: 1.3851\n",
      "Epoch 15/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9349\n",
      "Epoch 15: val_loss improved from 1.38510 to 1.38380, saving model to ./checkpoints/unknown_person_few_shot_p17_47.h5\n",
      "32491/32491 [==============================] - 36s 1ms/sample - loss: 10.9349 - val_loss: 1.3838\n",
      "Epoch 16/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.9063\n",
      "Epoch 16: val_loss did not improve from 1.38380\n",
      "32491/32491 [==============================] - 33s 1ms/sample - loss: 10.9063 - val_loss: 1.3880\n",
      "Epoch 17/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8858\n",
      "Epoch 17: val_loss did not improve from 1.38380\n",
      "32491/32491 [==============================] - 34s 1ms/sample - loss: 10.8858 - val_loss: 1.3994\n",
      "Epoch 18/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8630\n",
      "Epoch 18: val_loss did not improve from 1.38380\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.8630 - val_loss: 1.3893\n",
      "Epoch 19/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8606\n",
      "Epoch 19: val_loss did not improve from 1.38380\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.8606 - val_loss: 1.3994\n",
      "Epoch 20/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 10.8286\n",
      "Epoch 20: val_loss did not improve from 1.38380\n",
      "32491/32491 [==============================] - 35s 1ms/sample - loss: 10.8286 - val_loss: 1.3840\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:43:09.938020: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_638_2/lstm_cell_1970/kernel/Assign' id:1009192 op device:{requested: '', assigned: ''} def:{{{node lstm_638_2/lstm_cell_1970/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_638_2/lstm_cell_1970/kernel, lstm_638_2/lstm_cell_1970/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-19 00:44:32.298457: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_69_2/bias/v/Assign' id:1014982 op device:{requested: '', assigned: ''} def:{{{node conv2d_69_2/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_69_2/bias/v, conv2d_69_2/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32491 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:45:59.249904: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:52:19.394389: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:52:45.784991: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38247, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 124s 4ms/sample - loss: 1.4109 - val_loss: 1.3825\n",
      "Epoch 2/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 2: val_loss did not improve from 1.38247\n",
      "32491/32491 [==============================] - 23s 716us/sample - loss: 1.4096 - val_loss: 1.3848\n",
      "Epoch 3/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 3: val_loss improved from 1.38247 to 1.38243, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 23s 697us/sample - loss: 1.4062 - val_loss: 1.3824\n",
      "Epoch 4/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4059\n",
      "Epoch 4: val_loss did not improve from 1.38243\n",
      "32491/32491 [==============================] - 22s 679us/sample - loss: 1.4059 - val_loss: 1.3844\n",
      "Epoch 5/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4030\n",
      "Epoch 5: val_loss did not improve from 1.38243\n",
      "32491/32491 [==============================] - 24s 733us/sample - loss: 1.4030 - val_loss: 1.3827\n",
      "Epoch 6/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 6: val_loss improved from 1.38243 to 1.38210, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 23s 694us/sample - loss: 1.4011 - val_loss: 1.3821\n",
      "Epoch 7/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.4019\n",
      "Epoch 7: val_loss improved from 1.38210 to 1.37499, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 23s 701us/sample - loss: 1.4019 - val_loss: 1.3750\n",
      "Epoch 8/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 8: val_loss did not improve from 1.37499\n",
      "32491/32491 [==============================] - 24s 750us/sample - loss: 1.3995 - val_loss: 1.3800\n",
      "Epoch 9/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3951\n",
      "Epoch 9: val_loss did not improve from 1.37499\n",
      "32491/32491 [==============================] - 23s 705us/sample - loss: 1.3951 - val_loss: 1.3751\n",
      "Epoch 10/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 10: val_loss improved from 1.37499 to 1.37425, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 652us/sample - loss: 1.3965 - val_loss: 1.3743\n",
      "Epoch 11/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 11: val_loss did not improve from 1.37425\n",
      "32491/32491 [==============================] - 21s 634us/sample - loss: 1.3975 - val_loss: 1.3752\n",
      "Epoch 12/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3916\n",
      "Epoch 12: val_loss did not improve from 1.37425\n",
      "32491/32491 [==============================] - 22s 674us/sample - loss: 1.3916 - val_loss: 1.3753\n",
      "Epoch 13/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3888\n",
      "Epoch 13: val_loss did not improve from 1.37425\n",
      "32491/32491 [==============================] - 24s 752us/sample - loss: 1.3888 - val_loss: 1.3786\n",
      "Epoch 14/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 14: val_loss improved from 1.37425 to 1.37126, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 25s 761us/sample - loss: 1.3905 - val_loss: 1.3713\n",
      "Epoch 15/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3891\n",
      "Epoch 15: val_loss did not improve from 1.37126\n",
      "32491/32491 [==============================] - 24s 750us/sample - loss: 1.3891 - val_loss: 1.3777\n",
      "Epoch 16/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3909\n",
      "Epoch 16: val_loss improved from 1.37126 to 1.36916, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 25s 757us/sample - loss: 1.3909 - val_loss: 1.3692\n",
      "Epoch 17/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3863\n",
      "Epoch 17: val_loss improved from 1.36916 to 1.36686, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 24s 730us/sample - loss: 1.3863 - val_loss: 1.3669\n",
      "Epoch 18/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3842\n",
      "Epoch 18: val_loss did not improve from 1.36686\n",
      "32491/32491 [==============================] - 21s 639us/sample - loss: 1.3842 - val_loss: 1.3701\n",
      "Epoch 19/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3854\n",
      "Epoch 19: val_loss did not improve from 1.36686\n",
      "32491/32491 [==============================] - 21s 636us/sample - loss: 1.3854 - val_loss: 1.3675\n",
      "Epoch 20/20\n",
      "32491/32491 [==============================] - ETA: 0s - loss: 1.3816\n",
      "Epoch 20: val_loss improved from 1.36686 to 1.36557, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p17_47.h5\n",
      "32491/32491 [==============================] - 21s 652us/sample - loss: 1.3816 - val_loss: 1.3656\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "\n",
    "test_person_id = [17]\n",
    "ra_all = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "idx = 30\n",
    "for ra in ra_all:\n",
    "    flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "    ## Data Normalization before training ans testing\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalers = []\n",
    "    X_train_normalized = []\n",
    "    X_val_normalized = []\n",
    "    X_test_normalized = []\n",
    "    train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "    np.random.shuffle(train_idx)\n",
    "    val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "    test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "    \n",
    "    for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "        scaler = StandardScaler()\n",
    "        if len(feature.shape)==2:\n",
    "            X_train_i = feature[train_idx,:]\n",
    "            X_val_i = feature[val_idx,:]\n",
    "            X_test_i = feature[test_idx,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i)\n",
    "            scalers.append(scaler)\n",
    "        else:\n",
    "            X_train_i = feature[train_idx,:,:]\n",
    "            X_val_i = feature[val_idx,:,:]\n",
    "            X_test_i = feature[test_idx,:,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "            scalers.append(scaler)\n",
    "        X_train_normalized.append(X_train_normalized_i)\n",
    "        X_val_normalized.append(X_val_normalized_i)\n",
    "        X_test_normalized.append(X_test_normalized_i)\n",
    "    y_train = gts[train_idx,:]\n",
    "    y_val = gts[val_idx,:]\n",
    "    y_test = gts[test_idx,:]\n",
    "    X_train_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "    for feature in X_train_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_train_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_train_normalized_new.append(feature)\n",
    "    X_train_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_val_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "    for feature in X_val_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_val_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_val_normalized_new.append(feature)\n",
    "    X_val_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_test_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "    for feature in X_test_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_test_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_test_normalized_new.append(feature)\n",
    "    X_test_normalized_new.append(combined_feature)\n",
    "    \n",
    "    \n",
    "    num_epochs = 50\n",
    "    \n",
    "    \n",
    "    # Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    \n",
    "    \n",
    "    rates = [0.4, 0.5, 0.6]\n",
    "    \n",
    "    for r in rates:\n",
    "        model = individual_model(X_train_normalized)\n",
    "        model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=20, frequency=1)\n",
    "        model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import tensorflow as tf\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        from tensorflow.keras.models import Model\n",
    "        layers = model.layers\n",
    "        second_last_layer_output = layers[-4].output\n",
    "        feature_extractor_model = Model(inputs=model.input, outputs=second_last_layer_output)\n",
    "        train_features = feature_extractor_model.predict(X_train_normalized_new)\n",
    "        test_features = feature_extractor_model.predict(X_test_normalized_new)\n",
    "        \n",
    "        p_train = people_nums[train_idx,:]\n",
    "        p_val = people_nums[val_idx,:]\n",
    "        p_test = people_nums[test_idx,:]\n",
    "        ## Calculate the distance between test person and training person\n",
    "        def euclidean_distance(a, b):\n",
    "            return np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "        \n",
    "        distance_dict = {}\n",
    "        for ii in range(len(person_nums)):\n",
    "            if person_nums[ii] == test_person_id[0]:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                ind = np.where(p_train ==person_nums[ii])[0]\n",
    "                tmp_train_features = train_features[ind, :]\n",
    "                distances = np.array([euclidean_distance(train_sample, test_features) for train_sample in tmp_train_features])\n",
    "                print(distances.shape)\n",
    "                average_distances = np.mean(distances, axis=1)\n",
    "        \n",
    "                # Step 4: Find the overall average distance\n",
    "                overall_average_distance = np.mean(average_distances)\n",
    "                distance_dict[person_nums[ii]] = overall_average_distance\n",
    "        \n",
    "        \n",
    "        def normalize_to_weights(distance_dict):\n",
    "            distances = np.array(list(distance_dict.values()))\n",
    "            # Handle the case where a distance is zero to avoid division by zero\n",
    "            distances = np.clip(distances, a_min=1e-10, a_max=None)\n",
    "            weights = 1 / distances\n",
    "            normalized_weights = weights\n",
    "            # normalized_weights = weights / sum(weights)\n",
    "            # print(sum(weights))\n",
    "            # print(sum(normalized_weights))\n",
    "            # Assign the normalized weights back to the dictionary\n",
    "            normalized_weight_dict = dict(zip(distance_dict.keys(), normalized_weights))\n",
    "            return normalized_weight_dict\n",
    "        def scale_dict_values(my_dict):\n",
    "            scaled_dict = my_dict.copy()\n",
    "            min_val = min(scaled_dict.values())\n",
    "            max_val = max(scaled_dict.values())\n",
    "            \n",
    "            for key in scaled_dict:\n",
    "                scaled_dict[key] = 1 + 9 * (scaled_dict[key] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            return scaled_dict\n",
    "        weights_dict = normalize_to_weights(distance_dict)\n",
    "        weights_dict = scale_dict_values(weights_dict)\n",
    "        print(weights_dict)\n",
    "        \n",
    "        w_train = np.zeros_like(p_train)\n",
    "        for i in range(len(w_train)):\n",
    "            if p_train[i] == test_person_id[0]:\n",
    "                w_train[i] = 50\n",
    "            else:\n",
    "                w_train[i] = weights_dict[int(p_train[i])]\n",
    "        \n",
    "        w_train = np.squeeze(w_train)\n",
    "        \n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,sample_weight= w_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_2_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        idx += 1\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508e9a1-9544-41f8-af41-e3d3b02a8d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b59e4-6581-4ea8-994d-a02a6654ab6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
