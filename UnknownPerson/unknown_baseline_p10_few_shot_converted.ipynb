{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f8da1-2837-4bf7-b3f4-dfcaa7ab42f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T15:14:59.069618Z",
     "iopub.status.busy": "2023-11-22T15:14:59.069486Z",
     "iopub.status.idle": "2023-11-22T15:14:59.157458Z",
     "shell.execute_reply": "2023-11-22T15:14:59.156885Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe25376-b856-4296-ba02-5e3771ff9451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T15:14:59.159763Z",
     "iopub.status.busy": "2023-11-22T15:14:59.159595Z",
     "iopub.status.idle": "2023-11-23T06:17:49.386918Z",
     "shell.execute_reply": "2023-11-23T06:17:49.386279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:14:59.340879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35211\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:16:22.772418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.783850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.784103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.787995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.788196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.788382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.875589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.875795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.875975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:22.876135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-22 10:16:22.876509: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:16:23.814367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:23.814608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:23.814799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:23.815023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:23.815217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-22 10:16:23.815377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-22 10:16:23.815407: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-22 10:16:23.836471: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-22 10:16:24.051537: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_15/lstm_cell_15/kernel/Assign' id:2491 op device:{requested: '', assigned: ''} def:{{{node lstm_15/lstm_cell_15/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_15/lstm_cell_15/kernel, lstm_15/lstm_cell_15/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 10:16:24.184416: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 10:16:24.218623: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31684, 95)\n",
      "Train on 31684 samples, validate on 3527 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:16:28.619993: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign' id:17397 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_24/lstm_cell_24/kernel/v, training/Adam/lstm_24/lstm_cell_24/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:16:32.466149: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-22 10:16:34.571558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-22 10:16:34.586444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 3.1287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-22 10:16:54.797807: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.97498, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 27s 863us/sample - loss: 3.1287 - val_loss: 1.9750\n",
      "Epoch 2/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.7978\n",
      "Epoch 2: val_loss improved from 1.97498 to 1.67270, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 647us/sample - loss: 1.7978 - val_loss: 1.6727\n",
      "Epoch 3/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.6226\n",
      "Epoch 3: val_loss improved from 1.67270 to 1.58733, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 21s 669us/sample - loss: 1.6226 - val_loss: 1.5873\n",
      "Epoch 4/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5677\n",
      "Epoch 4: val_loss improved from 1.58733 to 1.55715, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 21s 653us/sample - loss: 1.5677 - val_loss: 1.5571\n",
      "Epoch 5/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5382\n",
      "Epoch 5: val_loss improved from 1.55715 to 1.53124, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.5382 - val_loss: 1.5312\n",
      "Epoch 6/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5191\n",
      "Epoch 6: val_loss improved from 1.53124 to 1.51281, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.5191 - val_loss: 1.5128\n",
      "Epoch 7/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5071\n",
      "Epoch 7: val_loss improved from 1.51281 to 1.50202, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 647us/sample - loss: 1.5071 - val_loss: 1.5020\n",
      "Epoch 8/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4995\n",
      "Epoch 8: val_loss improved from 1.50202 to 1.48929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4995 - val_loss: 1.4893\n",
      "Epoch 9/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4912\n",
      "Epoch 9: val_loss improved from 1.48929 to 1.48806, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 706us/sample - loss: 1.4912 - val_loss: 1.4881\n",
      "Epoch 10/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4846\n",
      "Epoch 10: val_loss improved from 1.48806 to 1.48132, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 612us/sample - loss: 1.4846 - val_loss: 1.4813\n",
      "Epoch 11/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4831\n",
      "Epoch 11: val_loss improved from 1.48132 to 1.47771, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 606us/sample - loss: 1.4831 - val_loss: 1.4777\n",
      "Epoch 12/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4872\n",
      "Epoch 12: val_loss improved from 1.47771 to 1.47692, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 682us/sample - loss: 1.4872 - val_loss: 1.4769\n",
      "Epoch 13/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4786\n",
      "Epoch 13: val_loss improved from 1.47692 to 1.46923, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 686us/sample - loss: 1.4786 - val_loss: 1.4692\n",
      "Epoch 14/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5143\n",
      "Epoch 14: val_loss improved from 1.46923 to 1.46606, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 609us/sample - loss: 1.5143 - val_loss: 1.4661\n",
      "Epoch 15/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4748\n",
      "Epoch 15: val_loss improved from 1.46606 to 1.46581, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 614us/sample - loss: 1.4748 - val_loss: 1.4658\n",
      "Epoch 16/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4661\n",
      "Epoch 16: val_loss improved from 1.46581 to 1.45928, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 609us/sample - loss: 1.4661 - val_loss: 1.4593\n",
      "Epoch 17/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4613\n",
      "Epoch 17: val_loss improved from 1.45928 to 1.45589, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 637us/sample - loss: 1.4613 - val_loss: 1.4559\n",
      "Epoch 18/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4592\n",
      "Epoch 18: val_loss improved from 1.45589 to 1.44986, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 633us/sample - loss: 1.4592 - val_loss: 1.4499\n",
      "Epoch 19/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 19: val_loss improved from 1.44986 to 1.44901, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 21s 659us/sample - loss: 1.4525 - val_loss: 1.4490\n",
      "Epoch 20/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4557\n",
      "Epoch 20: val_loss did not improve from 1.44901\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.4557 - val_loss: 1.4530\n",
      "Epoch 21/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4715\n",
      "Epoch 21: val_loss did not improve from 1.44901\n",
      "31684/31684 [==============================] - 21s 666us/sample - loss: 1.4715 - val_loss: 1.4513\n",
      "Epoch 22/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4808\n",
      "Epoch 22: val_loss improved from 1.44901 to 1.44832, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 637us/sample - loss: 1.4808 - val_loss: 1.4483\n",
      "Epoch 23/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4472\n",
      "Epoch 23: val_loss improved from 1.44832 to 1.44420, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 707us/sample - loss: 1.4472 - val_loss: 1.4442\n",
      "Epoch 24/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4425\n",
      "Epoch 24: val_loss improved from 1.44420 to 1.44044, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4425 - val_loss: 1.4404\n",
      "Epoch 25/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4364\n",
      "Epoch 25: val_loss improved from 1.44044 to 1.43445, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 705us/sample - loss: 1.4364 - val_loss: 1.4344\n",
      "Epoch 26/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4319\n",
      "Epoch 26: val_loss did not improve from 1.43445\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4319 - val_loss: 1.4363\n",
      "Epoch 27/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4281\n",
      "Epoch 27: val_loss improved from 1.43445 to 1.42934, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 707us/sample - loss: 1.4281 - val_loss: 1.4293\n",
      "Epoch 28/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 28: val_loss did not improve from 1.42934\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.4252 - val_loss: 1.4311\n",
      "Epoch 29/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4287\n",
      "Epoch 29: val_loss improved from 1.42934 to 1.42645, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.4287 - val_loss: 1.4265\n",
      "Epoch 30/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 30: val_loss improved from 1.42645 to 1.42310, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.4255 - val_loss: 1.4231\n",
      "Epoch 31/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 31: val_loss did not improve from 1.42310\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 1.4202 - val_loss: 1.4239\n",
      "Epoch 32/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4177\n",
      "Epoch 32: val_loss improved from 1.42310 to 1.42184, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.4177 - val_loss: 1.4218\n",
      "Epoch 33/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4157\n",
      "Epoch 33: val_loss improved from 1.42184 to 1.41963, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.4157 - val_loss: 1.4196\n",
      "Epoch 34/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4125\n",
      "Epoch 34: val_loss did not improve from 1.41963\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 1.4125 - val_loss: 1.4238\n",
      "Epoch 35/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4103\n",
      "Epoch 35: val_loss improved from 1.41963 to 1.41629, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 643us/sample - loss: 1.4103 - val_loss: 1.4163\n",
      "Epoch 36/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4111\n",
      "Epoch 36: val_loss did not improve from 1.41629\n",
      "31684/31684 [==============================] - 19s 606us/sample - loss: 1.4111 - val_loss: 1.4184\n",
      "Epoch 37/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4072\n",
      "Epoch 37: val_loss improved from 1.41629 to 1.41238, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 615us/sample - loss: 1.4072 - val_loss: 1.4124\n",
      "Epoch 38/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4077\n",
      "Epoch 38: val_loss improved from 1.41238 to 1.41178, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 617us/sample - loss: 1.4077 - val_loss: 1.4118\n",
      "Epoch 39/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 39: val_loss did not improve from 1.41178\n",
      "31684/31684 [==============================] - 20s 619us/sample - loss: 1.4045 - val_loss: 1.4137\n",
      "Epoch 40/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4035\n",
      "Epoch 40: val_loss did not improve from 1.41178\n",
      "31684/31684 [==============================] - 20s 618us/sample - loss: 1.4035 - val_loss: 1.4156\n",
      "Epoch 41/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4000\n",
      "Epoch 41: val_loss improved from 1.41178 to 1.41021, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 623us/sample - loss: 1.4000 - val_loss: 1.4102\n",
      "Epoch 42/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4006\n",
      "Epoch 42: val_loss improved from 1.41021 to 1.40889, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 632us/sample - loss: 1.4006 - val_loss: 1.4089\n",
      "Epoch 43/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3993\n",
      "Epoch 43: val_loss did not improve from 1.40889\n",
      "31684/31684 [==============================] - 21s 676us/sample - loss: 1.3993 - val_loss: 1.4123\n",
      "Epoch 44/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 44: val_loss did not improve from 1.40889\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.4008 - val_loss: 1.4122\n",
      "Epoch 45/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 45: val_loss improved from 1.40889 to 1.40639, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 602us/sample - loss: 1.3980 - val_loss: 1.4064\n",
      "Epoch 46/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 46: val_loss did not improve from 1.40639\n",
      "31684/31684 [==============================] - 22s 691us/sample - loss: 1.3949 - val_loss: 1.4068\n",
      "Epoch 47/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3932\n",
      "Epoch 47: val_loss improved from 1.40639 to 1.40466, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 707us/sample - loss: 1.3932 - val_loss: 1.4047\n",
      "Epoch 48/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 48: val_loss improved from 1.40466 to 1.39833, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 704us/sample - loss: 1.3917 - val_loss: 1.3983\n",
      "Epoch 49/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3923\n",
      "Epoch 49: val_loss did not improve from 1.39833\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.3923 - val_loss: 1.4068\n",
      "Epoch 50/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3878\n",
      "Epoch 50: val_loss did not improve from 1.39833\n",
      "31684/31684 [==============================] - 21s 668us/sample - loss: 1.3878 - val_loss: 1.4007\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:34:14.052735: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_4/bias/Assign' id:24567 op device:{requested: '', assigned: ''} def:{{{node dense_4/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_4/bias, dense_4/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 10:34:15.742918: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_32_1/lstm_cell_69/kernel/v/Assign' id:26375 op device:{requested: '', assigned: ''} def:{{{node lstm_32_1/lstm_cell_69/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_32_1/lstm_cell_69/kernel/v, lstm_32_1/lstm_cell_69/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-22 10:34:17.073218: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_4_1/cond/Merge' id:24591 op device:{requested: '', assigned: ''} def:{{{node dropout_4_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_4_1/cond/Identity, dropout_4_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1790)\n",
      "(1514, 1790)\n",
      "(1644, 1790)\n",
      "(1764, 1790)\n",
      "(1836, 1790)\n",
      "(1699, 1790)\n",
      "(1369, 1790)\n",
      "(1582, 1790)\n",
      "(1788, 1790)\n",
      "(1550, 1790)\n",
      "(1920, 1790)\n",
      "(1679, 1790)\n",
      "(1800, 1790)\n",
      "(1860, 1790)\n",
      "(1692, 1790)\n",
      "(1824, 1790)\n",
      "(970, 1790)\n",
      "(1668, 1790)\n",
      "(1860, 1790)\n",
      "{1: 6.756299998448484, 2: 3.7574393508996433, 4: 9.589806809266733, 5: 7.668629896635301, 6: 8.075417172314747, 8: 9.239477179559653, 9: 5.12615984258183, 11: 6.875063831394725, 12: 9.300158322096085, 13: 6.724689545007795, 17: 9.410177675572594, 19: 8.810507946123266, 21: 10.0, 22: 1.0, 25: 7.608454683251249, 26: 6.251166166696235, 27: 4.175415755713121, 28: 6.523602944102923, 29: 3.2947469038822303}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916958/459382369.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31684 samples, validate on 3527 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:37:52.125620: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 10.4899\n",
      "Epoch 1: val_loss improved from inf to 1.42623, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 28s 875us/sample - loss: 10.4899 - val_loss: 1.4262\n",
      "Epoch 2/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.3710\n",
      "Epoch 2: val_loss improved from 1.42623 to 1.41573, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 10.3710 - val_loss: 1.4157\n",
      "Epoch 3/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.3356\n",
      "Epoch 3: val_loss did not improve from 1.41573\n",
      "31684/31684 [==============================] - 19s 611us/sample - loss: 10.3356 - val_loss: 1.4237\n",
      "Epoch 4/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.2673\n",
      "Epoch 4: val_loss improved from 1.41573 to 1.41182, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 613us/sample - loss: 10.2673 - val_loss: 1.4118\n",
      "Epoch 5/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.2734\n",
      "Epoch 5: val_loss did not improve from 1.41182\n",
      "31684/31684 [==============================] - 22s 681us/sample - loss: 10.2734 - val_loss: 1.4195\n",
      "Epoch 6/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.2165\n",
      "Epoch 6: val_loss improved from 1.41182 to 1.41023, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 608us/sample - loss: 10.2165 - val_loss: 1.4102\n",
      "Epoch 7/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.2008\n",
      "Epoch 7: val_loss improved from 1.41023 to 1.40990, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 620us/sample - loss: 10.2008 - val_loss: 1.4099\n",
      "Epoch 8/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1582\n",
      "Epoch 8: val_loss improved from 1.40990 to 1.39982, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 696us/sample - loss: 10.1582 - val_loss: 1.3998\n",
      "Epoch 9/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1355\n",
      "Epoch 9: val_loss did not improve from 1.39982\n",
      "31684/31684 [==============================] - 22s 679us/sample - loss: 10.1355 - val_loss: 1.4003\n",
      "Epoch 10/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1632\n",
      "Epoch 10: val_loss improved from 1.39982 to 1.39820, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 695us/sample - loss: 10.1632 - val_loss: 1.3982\n",
      "Epoch 11/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1568\n",
      "Epoch 11: val_loss improved from 1.39820 to 1.39804, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 10.1568 - val_loss: 1.3980\n",
      "Epoch 12/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1159\n",
      "Epoch 12: val_loss did not improve from 1.39804\n",
      "31684/31684 [==============================] - 22s 692us/sample - loss: 10.1159 - val_loss: 1.4036\n",
      "Epoch 13/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0998\n",
      "Epoch 13: val_loss did not improve from 1.39804\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 10.0998 - val_loss: 1.3991\n",
      "Epoch 14/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0875\n",
      "Epoch 14: val_loss did not improve from 1.39804\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 10.0875 - val_loss: 1.4016\n",
      "Epoch 15/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0712\n",
      "Epoch 15: val_loss did not improve from 1.39804\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 10.0712 - val_loss: 1.4253\n",
      "Epoch 16/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0696\n",
      "Epoch 16: val_loss improved from 1.39804 to 1.39319, saving model to ./checkpoints/unknown_person_few_shot_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 10.0696 - val_loss: 1.3932\n",
      "Epoch 17/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0379\n",
      "Epoch 17: val_loss did not improve from 1.39319\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 10.0379 - val_loss: 1.3987\n",
      "Epoch 18/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0587\n",
      "Epoch 18: val_loss did not improve from 1.39319\n",
      "31684/31684 [==============================] - 22s 695us/sample - loss: 10.0587 - val_loss: 1.3955\n",
      "Epoch 19/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0264\n",
      "Epoch 19: val_loss did not improve from 1.39319\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 10.0264 - val_loss: 1.3973\n",
      "Epoch 20/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0282\n",
      "Epoch 20: val_loss did not improve from 1.39319\n",
      "31684/31684 [==============================] - 20s 638us/sample - loss: 10.0282 - val_loss: 1.3993\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:45:07.144135: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_26_2/lstm_cell_100/kernel/Assign' id:42200 op device:{requested: '', assigned: ''} def:{{{node lstm_26_2/lstm_cell_100/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_26_2/lstm_cell_100/kernel, lstm_26_2/lstm_cell_100/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 10:45:09.502516: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_25_2/lstm_cell_99/recurrent_kernel/m/Assign' id:45030 op device:{requested: '', assigned: ''} def:{{{node lstm_25_2/lstm_cell_99/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_25_2/lstm_cell_99/recurrent_kernel/m, lstm_25_2/lstm_cell_99/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31684 samples, validate on 3527 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:45:14.551187: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:45:26.856341: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_6/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:45:47.121343: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40467, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 26s 829us/sample - loss: 1.3891 - val_loss: 1.4047\n",
      "Epoch 2/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3892\n",
      "Epoch 2: val_loss improved from 1.40467 to 1.40062, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 604us/sample - loss: 1.3892 - val_loss: 1.4006\n",
      "Epoch 3/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3873\n",
      "Epoch 3: val_loss improved from 1.40062 to 1.39789, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 602us/sample - loss: 1.3873 - val_loss: 1.3979\n",
      "Epoch 4/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3881\n",
      "Epoch 4: val_loss did not improve from 1.39789\n",
      "31684/31684 [==============================] - 19s 597us/sample - loss: 1.3881 - val_loss: 1.4004\n",
      "Epoch 5/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3865\n",
      "Epoch 5: val_loss did not improve from 1.39789\n",
      "31684/31684 [==============================] - 19s 599us/sample - loss: 1.3865 - val_loss: 1.4030\n",
      "Epoch 6/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3850\n",
      "Epoch 6: val_loss did not improve from 1.39789\n",
      "31684/31684 [==============================] - 19s 598us/sample - loss: 1.3850 - val_loss: 1.4056\n",
      "Epoch 7/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3823\n",
      "Epoch 7: val_loss improved from 1.39789 to 1.39257, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 19s 603us/sample - loss: 1.3823 - val_loss: 1.3926\n",
      "Epoch 8/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3804\n",
      "Epoch 8: val_loss did not improve from 1.39257\n",
      "31684/31684 [==============================] - 19s 601us/sample - loss: 1.3804 - val_loss: 1.3968\n",
      "Epoch 9/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3817\n",
      "Epoch 9: val_loss did not improve from 1.39257\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.3817 - val_loss: 1.3967\n",
      "Epoch 10/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3811\n",
      "Epoch 10: val_loss improved from 1.39257 to 1.38966, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 703us/sample - loss: 1.3811 - val_loss: 1.3897\n",
      "Epoch 11/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3774\n",
      "Epoch 11: val_loss did not improve from 1.38966\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.3774 - val_loss: 1.3926\n",
      "Epoch 12/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3780\n",
      "Epoch 12: val_loss improved from 1.38966 to 1.38939, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 707us/sample - loss: 1.3780 - val_loss: 1.3894\n",
      "Epoch 13/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3749\n",
      "Epoch 13: val_loss improved from 1.38939 to 1.38878, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 705us/sample - loss: 1.3749 - val_loss: 1.3888\n",
      "Epoch 14/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3753\n",
      "Epoch 14: val_loss improved from 1.38878 to 1.38835, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 22s 706us/sample - loss: 1.3753 - val_loss: 1.3884\n",
      "Epoch 15/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3739\n",
      "Epoch 15: val_loss did not improve from 1.38835\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.3739 - val_loss: 1.3942\n",
      "Epoch 16/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3754\n",
      "Epoch 16: val_loss did not improve from 1.38835\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.3754 - val_loss: 1.3919\n",
      "Epoch 17/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3715\n",
      "Epoch 17: val_loss did not improve from 1.38835\n",
      "31684/31684 [==============================] - 22s 683us/sample - loss: 1.3715 - val_loss: 1.3911\n",
      "Epoch 18/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3704\n",
      "Epoch 18: val_loss improved from 1.38835 to 1.38772, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_30.h5\n",
      "31684/31684 [==============================] - 20s 645us/sample - loss: 1.3704 - val_loss: 1.3877\n",
      "Epoch 19/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3684\n",
      "Epoch 19: val_loss did not improve from 1.38772\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.3684 - val_loss: 1.3892\n",
      "Epoch 20/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3682\n",
      "Epoch 20: val_loss did not improve from 1.38772\n",
      "31684/31684 [==============================] - 20s 631us/sample - loss: 1.3682 - val_loss: 1.3898\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:52:29.655480: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_48/lstm_cell_122/kernel/Assign' id:58875 op device:{requested: '', assigned: ''} def:{{{node lstm_48/lstm_cell_122/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_48/lstm_cell_122/kernel, lstm_48/lstm_cell_122/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 10:52:31.018794: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_1' id:60678 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 10:52:32.068740: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_2' id:60679 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31684, 95)\n",
      "Train on 31684 samples, validate on 3527 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:52:38.681770: W tensorflow/c/c_api.cc:304] Operation '{name:'training_6/Adam/lstm_46/lstm_cell_120/kernel/m/Assign' id:73571 op device:{requested: '', assigned: ''} def:{{{node training_6/Adam/lstm_46/lstm_cell_120/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_6/Adam/lstm_46/lstm_cell_120/kernel/m, training_6/Adam/lstm_46/lstm_cell_120/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:52:55.384292: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 3.2773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:53:18.301585: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_7/mul' id:63519 op device:{requested: '', assigned: ''} def:{{{node loss_7/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_7/mul/x, loss_7/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.92525, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 40s 1ms/sample - loss: 3.2773 - val_loss: 1.9253\n",
      "Epoch 2/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.7846\n",
      "Epoch 2: val_loss improved from 1.92525 to 1.68785, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 633us/sample - loss: 1.7846 - val_loss: 1.6879\n",
      "Epoch 3/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.6145\n",
      "Epoch 3: val_loss improved from 1.68785 to 1.61166, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.6145 - val_loss: 1.6117\n",
      "Epoch 4/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5601\n",
      "Epoch 4: val_loss improved from 1.61166 to 1.57180, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.5601 - val_loss: 1.5718\n",
      "Epoch 5/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5343\n",
      "Epoch 5: val_loss improved from 1.57180 to 1.55345, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.5343 - val_loss: 1.5535\n",
      "Epoch 6/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5144\n",
      "Epoch 6: val_loss improved from 1.55345 to 1.52505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 649us/sample - loss: 1.5144 - val_loss: 1.5250\n",
      "Epoch 7/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5026\n",
      "Epoch 7: val_loss improved from 1.52505 to 1.51000, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 601us/sample - loss: 1.5026 - val_loss: 1.5100\n",
      "Epoch 8/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5006\n",
      "Epoch 8: val_loss improved from 1.51000 to 1.49876, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 622us/sample - loss: 1.5006 - val_loss: 1.4988\n",
      "Epoch 9/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4937\n",
      "Epoch 9: val_loss improved from 1.49876 to 1.48545, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 614us/sample - loss: 1.4937 - val_loss: 1.4854\n",
      "Epoch 10/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4943\n",
      "Epoch 10: val_loss did not improve from 1.48545\n",
      "31684/31684 [==============================] - 20s 631us/sample - loss: 1.4943 - val_loss: 1.4874\n",
      "Epoch 11/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4823\n",
      "Epoch 11: val_loss improved from 1.48545 to 1.47806, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 696us/sample - loss: 1.4823 - val_loss: 1.4781\n",
      "Epoch 12/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4740\n",
      "Epoch 12: val_loss improved from 1.47806 to 1.47361, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 23s 711us/sample - loss: 1.4740 - val_loss: 1.4736\n",
      "Epoch 13/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4697\n",
      "Epoch 13: val_loss improved from 1.47361 to 1.46510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.4697 - val_loss: 1.4651\n",
      "Epoch 14/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4709\n",
      "Epoch 14: val_loss improved from 1.46510 to 1.46463, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 610us/sample - loss: 1.4709 - val_loss: 1.4646\n",
      "Epoch 15/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 15: val_loss improved from 1.46463 to 1.46256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 590us/sample - loss: 1.4827 - val_loss: 1.4626\n",
      "Epoch 16/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4793\n",
      "Epoch 16: val_loss improved from 1.46256 to 1.46197, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 590us/sample - loss: 1.4793 - val_loss: 1.4620\n",
      "Epoch 17/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4967\n",
      "Epoch 17: val_loss improved from 1.46197 to 1.45654, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 674us/sample - loss: 1.4967 - val_loss: 1.4565\n",
      "Epoch 18/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4806\n",
      "Epoch 18: val_loss improved from 1.45654 to 1.45416, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.4806 - val_loss: 1.4542\n",
      "Epoch 19/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4796\n",
      "Epoch 19: val_loss did not improve from 1.45416\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 1.4796 - val_loss: 1.4568\n",
      "Epoch 20/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4816\n",
      "Epoch 20: val_loss did not improve from 1.45416\n",
      "31684/31684 [==============================] - 22s 696us/sample - loss: 1.4816 - val_loss: 1.4634\n",
      "Epoch 21/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4897\n",
      "Epoch 21: val_loss did not improve from 1.45416\n",
      "31684/31684 [==============================] - 20s 643us/sample - loss: 1.4897 - val_loss: 1.4561\n",
      "Epoch 22/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5201\n",
      "Epoch 22: val_loss did not improve from 1.45416\n",
      "31684/31684 [==============================] - 19s 585us/sample - loss: 1.5201 - val_loss: 1.4639\n",
      "Epoch 23/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4870\n",
      "Epoch 23: val_loss improved from 1.45416 to 1.45191, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 590us/sample - loss: 1.4870 - val_loss: 1.4519\n",
      "Epoch 24/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4613\n",
      "Epoch 24: val_loss improved from 1.45191 to 1.44714, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 590us/sample - loss: 1.4613 - val_loss: 1.4471\n",
      "Epoch 25/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4509\n",
      "Epoch 25: val_loss improved from 1.44714 to 1.44545, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 590us/sample - loss: 1.4509 - val_loss: 1.4455\n",
      "Epoch 26/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 26: val_loss improved from 1.44545 to 1.43924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 591us/sample - loss: 1.4432 - val_loss: 1.4392\n",
      "Epoch 27/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4407\n",
      "Epoch 27: val_loss improved from 1.43924 to 1.43642, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 1.4407 - val_loss: 1.4364\n",
      "Epoch 28/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 28: val_loss improved from 1.43642 to 1.43558, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.4379 - val_loss: 1.4356\n",
      "Epoch 29/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4356\n",
      "Epoch 29: val_loss improved from 1.43558 to 1.43147, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.4356 - val_loss: 1.4315\n",
      "Epoch 30/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4310\n",
      "Epoch 30: val_loss improved from 1.43147 to 1.42918, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.4310 - val_loss: 1.4292\n",
      "Epoch 31/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 31: val_loss did not improve from 1.42918\n",
      "31684/31684 [==============================] - 22s 679us/sample - loss: 1.4324 - val_loss: 1.4322\n",
      "Epoch 32/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 32: val_loss did not improve from 1.42918\n",
      "31684/31684 [==============================] - 19s 606us/sample - loss: 1.4283 - val_loss: 1.4298\n",
      "Epoch 33/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4260\n",
      "Epoch 33: val_loss improved from 1.42918 to 1.42438, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 605us/sample - loss: 1.4260 - val_loss: 1.4244\n",
      "Epoch 34/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4239\n",
      "Epoch 34: val_loss improved from 1.42438 to 1.42240, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 596us/sample - loss: 1.4239 - val_loss: 1.4224\n",
      "Epoch 35/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 35: val_loss did not improve from 1.42240\n",
      "31684/31684 [==============================] - 22s 688us/sample - loss: 1.4232 - val_loss: 1.4259\n",
      "Epoch 36/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4233\n",
      "Epoch 36: val_loss did not improve from 1.42240\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 1.4233 - val_loss: 1.4267\n",
      "Epoch 37/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 37: val_loss improved from 1.42240 to 1.42062, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.4172 - val_loss: 1.4206\n",
      "Epoch 38/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 38: val_loss improved from 1.42062 to 1.41664, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 672us/sample - loss: 1.4186 - val_loss: 1.4166\n",
      "Epoch 39/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4179\n",
      "Epoch 39: val_loss did not improve from 1.41664\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 1.4179 - val_loss: 1.4201\n",
      "Epoch 40/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 40: val_loss improved from 1.41664 to 1.41642, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.4158 - val_loss: 1.4164\n",
      "Epoch 41/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4136\n",
      "Epoch 41: val_loss did not improve from 1.41642\n",
      "31684/31684 [==============================] - 20s 628us/sample - loss: 1.4136 - val_loss: 1.4182\n",
      "Epoch 42/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4111\n",
      "Epoch 42: val_loss improved from 1.41642 to 1.41619, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 602us/sample - loss: 1.4111 - val_loss: 1.4162\n",
      "Epoch 43/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 43: val_loss improved from 1.41619 to 1.41517, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 654us/sample - loss: 1.4099 - val_loss: 1.4152\n",
      "Epoch 44/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4071\n",
      "Epoch 44: val_loss improved from 1.41517 to 1.41388, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 606us/sample - loss: 1.4071 - val_loss: 1.4139\n",
      "Epoch 45/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4075\n",
      "Epoch 45: val_loss improved from 1.41388 to 1.41348, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 666us/sample - loss: 1.4075 - val_loss: 1.4135\n",
      "Epoch 46/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4074\n",
      "Epoch 46: val_loss improved from 1.41348 to 1.41321, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 669us/sample - loss: 1.4074 - val_loss: 1.4132\n",
      "Epoch 47/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4048\n",
      "Epoch 47: val_loss improved from 1.41321 to 1.41178, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4048 - val_loss: 1.4118\n",
      "Epoch 48/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 48: val_loss improved from 1.41178 to 1.40989, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.4051 - val_loss: 1.4099\n",
      "Epoch 49/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4022\n",
      "Epoch 49: val_loss improved from 1.40989 to 1.40618, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 1.4022 - val_loss: 1.4062\n",
      "Epoch 50/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4033\n",
      "Epoch 50: val_loss improved from 1.40618 to 1.40568, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 650us/sample - loss: 1.4033 - val_loss: 1.4057\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:10:33.888652: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_48_1/lstm_cell_159/bias/Assign' id:77471 op device:{requested: '', assigned: ''} def:{{{node lstm_48_1/lstm_cell_159/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_48_1/lstm_cell_159/bias, lstm_48_1/lstm_cell_159/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:10:38.148468: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_37_2/lstm_cell_148/bias/v/Assign' id:82947 op device:{requested: '', assigned: ''} def:{{{node lstm_37_2/lstm_cell_148/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_37_2/lstm_cell_148/bias/v, lstm_37_2/lstm_cell_148/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:10:42.219996: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_9_1/cond/Merge' id:81633 op device:{requested: '', assigned: ''} def:{{{node dropout_9_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_9_1/cond/Identity, dropout_9_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1790)\n",
      "(1514, 1790)\n",
      "(1644, 1790)\n",
      "(1764, 1790)\n",
      "(1836, 1790)\n",
      "(1699, 1790)\n",
      "(1369, 1790)\n",
      "(1582, 1790)\n",
      "(1788, 1790)\n",
      "(1550, 1790)\n",
      "(1920, 1790)\n",
      "(1679, 1790)\n",
      "(1800, 1790)\n",
      "(1860, 1790)\n",
      "(1692, 1790)\n",
      "(1824, 1790)\n",
      "(970, 1790)\n",
      "(1668, 1790)\n",
      "(1860, 1790)\n",
      "{1: 7.135983012408232, 2: 4.833673050088808, 4: 8.31641590132731, 5: 8.100774133243911, 6: 7.4561887367750845, 8: 9.288706781786079, 9: 4.572811003474343, 11: 6.106565662122387, 12: 8.347077949568206, 13: 7.322107930907304, 17: 8.271286033216501, 19: 7.731824276585089, 21: 10.0, 22: 1.0, 25: 6.759395627866883, 26: 6.757544366880702, 27: 3.028407288897648, 28: 5.708105413766398, 29: 4.255954769915048}\n",
      "Train on 31684 samples, validate on 3527 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:15:16.299829: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1040\n",
      "Epoch 1: val_loss improved from inf to 1.42430, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 33s 1ms/sample - loss: 10.1040 - val_loss: 1.4243\n",
      "Epoch 2/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0013\n",
      "Epoch 2: val_loss improved from 1.42430 to 1.42264, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 710us/sample - loss: 10.0013 - val_loss: 1.4226\n",
      "Epoch 3/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.9865\n",
      "Epoch 3: val_loss improved from 1.42264 to 1.41425, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 705us/sample - loss: 9.9865 - val_loss: 1.4143\n",
      "Epoch 4/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.9338\n",
      "Epoch 4: val_loss did not improve from 1.41425\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 9.9338 - val_loss: 1.4254\n",
      "Epoch 5/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8992\n",
      "Epoch 5: val_loss improved from 1.41425 to 1.40686, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 623us/sample - loss: 9.8992 - val_loss: 1.4069\n",
      "Epoch 6/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8744\n",
      "Epoch 6: val_loss improved from 1.40686 to 1.40649, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 619us/sample - loss: 9.8744 - val_loss: 1.4065\n",
      "Epoch 7/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8640\n",
      "Epoch 7: val_loss improved from 1.40649 to 1.40632, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 657us/sample - loss: 9.8640 - val_loss: 1.4063\n",
      "Epoch 8/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8550\n",
      "Epoch 8: val_loss did not improve from 1.40632\n",
      "31684/31684 [==============================] - 22s 681us/sample - loss: 9.8550 - val_loss: 1.4117\n",
      "Epoch 9/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8520\n",
      "Epoch 9: val_loss did not improve from 1.40632\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 9.8520 - val_loss: 1.4094\n",
      "Epoch 10/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7959\n",
      "Epoch 10: val_loss improved from 1.40632 to 1.40568, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 640us/sample - loss: 9.7959 - val_loss: 1.4057\n",
      "Epoch 11/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7929\n",
      "Epoch 11: val_loss improved from 1.40568 to 1.40541, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 607us/sample - loss: 9.7929 - val_loss: 1.4054\n",
      "Epoch 12/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7729\n",
      "Epoch 12: val_loss did not improve from 1.40541\n",
      "31684/31684 [==============================] - 19s 596us/sample - loss: 9.7729 - val_loss: 1.4067\n",
      "Epoch 13/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7640\n",
      "Epoch 13: val_loss improved from 1.40541 to 1.39850, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 678us/sample - loss: 9.7640 - val_loss: 1.3985\n",
      "Epoch 14/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7476\n",
      "Epoch 14: val_loss did not improve from 1.39850\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 9.7476 - val_loss: 1.3986\n",
      "Epoch 15/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7442\n",
      "Epoch 15: val_loss did not improve from 1.39850\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 9.7442 - val_loss: 1.4040\n",
      "Epoch 16/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7362\n",
      "Epoch 16: val_loss did not improve from 1.39850\n",
      "31684/31684 [==============================] - 20s 639us/sample - loss: 9.7362 - val_loss: 1.4034\n",
      "Epoch 17/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7383\n",
      "Epoch 17: val_loss improved from 1.39850 to 1.39795, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 625us/sample - loss: 9.7383 - val_loss: 1.3980\n",
      "Epoch 18/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7115\n",
      "Epoch 18: val_loss did not improve from 1.39795\n",
      "31684/31684 [==============================] - 22s 695us/sample - loss: 9.7115 - val_loss: 1.4062\n",
      "Epoch 19/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7047\n",
      "Epoch 19: val_loss did not improve from 1.39795\n",
      "31684/31684 [==============================] - 22s 696us/sample - loss: 9.7047 - val_loss: 1.3980\n",
      "Epoch 20/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.6798\n",
      "Epoch 20: val_loss improved from 1.39795 to 1.39787, saving model to ./checkpoints/unknown_person_few_shot_p10_31.h5\n",
      "31684/31684 [==============================] - 23s 711us/sample - loss: 9.6798 - val_loss: 1.3979\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:22:34.261879: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_67_2/lstm_cell_215/recurrent_kernel/Assign' id:99902 op device:{requested: '', assigned: ''} def:{{{node lstm_67_2/lstm_cell_215/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_67_2/lstm_cell_215/recurrent_kernel, lstm_67_2/lstm_cell_215/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:22:39.467865: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_71_2/lstm_cell_219/bias/v/Assign' id:102855 op device:{requested: '', assigned: ''} def:{{{node lstm_71_2/lstm_cell_219/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_71_2/lstm_cell_219/bias/v, lstm_71_2/lstm_cell_219/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31684 samples, validate on 3527 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:22:47.194040: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:23:14.374085: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_3/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:23:38.121765: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40735, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 35s 1ms/sample - loss: 1.4023 - val_loss: 1.4073\n",
      "Epoch 2/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 2: val_loss improved from 1.40735 to 1.40478, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 703us/sample - loss: 1.3997 - val_loss: 1.4048\n",
      "Epoch 3/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 3: val_loss improved from 1.40478 to 1.40324, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 695us/sample - loss: 1.3980 - val_loss: 1.4032\n",
      "Epoch 4/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3963\n",
      "Epoch 4: val_loss improved from 1.40324 to 1.40266, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.3963 - val_loss: 1.4027\n",
      "Epoch 5/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 5: val_loss did not improve from 1.40266\n",
      "31684/31684 [==============================] - 22s 692us/sample - loss: 1.3949 - val_loss: 1.4056\n",
      "Epoch 6/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3929\n",
      "Epoch 6: val_loss did not improve from 1.40266\n",
      "31684/31684 [==============================] - 22s 696us/sample - loss: 1.3929 - val_loss: 1.4048\n",
      "Epoch 7/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 7: val_loss improved from 1.40266 to 1.39927, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 21s 674us/sample - loss: 1.3912 - val_loss: 1.3993\n",
      "Epoch 8/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3890\n",
      "Epoch 8: val_loss improved from 1.39927 to 1.39628, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.3890 - val_loss: 1.3963\n",
      "Epoch 9/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3872\n",
      "Epoch 9: val_loss improved from 1.39628 to 1.39474, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.3872 - val_loss: 1.3947\n",
      "Epoch 10/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3880\n",
      "Epoch 10: val_loss did not improve from 1.39474\n",
      "31684/31684 [==============================] - 21s 667us/sample - loss: 1.3880 - val_loss: 1.4006\n",
      "Epoch 11/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3849\n",
      "Epoch 11: val_loss improved from 1.39474 to 1.39369, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.3849 - val_loss: 1.3937\n",
      "Epoch 12/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3846\n",
      "Epoch 12: val_loss improved from 1.39369 to 1.39186, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 646us/sample - loss: 1.3846 - val_loss: 1.3919\n",
      "Epoch 13/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3832\n",
      "Epoch 13: val_loss did not improve from 1.39186\n",
      "31684/31684 [==============================] - 22s 694us/sample - loss: 1.3832 - val_loss: 1.3927\n",
      "Epoch 14/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3814\n",
      "Epoch 14: val_loss did not improve from 1.39186\n",
      "31684/31684 [==============================] - 21s 671us/sample - loss: 1.3814 - val_loss: 1.3955\n",
      "Epoch 15/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3814\n",
      "Epoch 15: val_loss improved from 1.39186 to 1.38945, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 20s 645us/sample - loss: 1.3814 - val_loss: 1.3894\n",
      "Epoch 16/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3810\n",
      "Epoch 16: val_loss did not improve from 1.38945\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 1.3810 - val_loss: 1.3934\n",
      "Epoch 17/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3783\n",
      "Epoch 17: val_loss did not improve from 1.38945\n",
      "31684/31684 [==============================] - 21s 654us/sample - loss: 1.3783 - val_loss: 1.3954\n",
      "Epoch 18/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3794\n",
      "Epoch 18: val_loss did not improve from 1.38945\n",
      "31684/31684 [==============================] - 22s 680us/sample - loss: 1.3794 - val_loss: 1.3961\n",
      "Epoch 19/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3758\n",
      "Epoch 19: val_loss did not improve from 1.38945\n",
      "31684/31684 [==============================] - 20s 643us/sample - loss: 1.3758 - val_loss: 1.3935\n",
      "Epoch 20/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.3754\n",
      "Epoch 20: val_loss improved from 1.38945 to 1.38740, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_31.h5\n",
      "31684/31684 [==============================] - 19s 603us/sample - loss: 1.3754 - val_loss: 1.3874\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:30:38.305429: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_81/lstm_cell_229/bias/Assign' id:115286 op device:{requested: '', assigned: ''} def:{{{node lstm_81/lstm_cell_229/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_81/lstm_cell_229/bias, lstm_81/lstm_cell_229/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:30:41.162914: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_1' id:117720 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:30:43.413708: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_2' id:117721 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31684, 95)\n",
      "Train on 31684 samples, validate on 3527 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:30:52.689186: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_96/lstm_cell_244/kernel/Assign' id:117961 op device:{requested: '', assigned: ''} def:{{{node lstm_96/lstm_cell_244/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_96/lstm_cell_244/kernel, lstm_96/lstm_cell_244/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:31:23.889929: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 2.8791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:31:45.085221: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_13/mul' id:120561 op device:{requested: '', assigned: ''} def:{{{node loss_13/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_13/mul/x, loss_13/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.93298, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 50s 2ms/sample - loss: 2.8791 - val_loss: 1.9330\n",
      "Epoch 2/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.7592\n",
      "Epoch 2: val_loss improved from 1.93298 to 1.67613, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 616us/sample - loss: 1.7592 - val_loss: 1.6761\n",
      "Epoch 3/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5982\n",
      "Epoch 3: val_loss improved from 1.67613 to 1.59422, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.5982 - val_loss: 1.5942\n",
      "Epoch 4/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5492\n",
      "Epoch 4: val_loss improved from 1.59422 to 1.55981, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.5492 - val_loss: 1.5598\n",
      "Epoch 5/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5255\n",
      "Epoch 5: val_loss improved from 1.55981 to 1.53586, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.5255 - val_loss: 1.5359\n",
      "Epoch 6/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5086\n",
      "Epoch 6: val_loss improved from 1.53586 to 1.52025, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.5086 - val_loss: 1.5203\n",
      "Epoch 7/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4963\n",
      "Epoch 7: val_loss improved from 1.52025 to 1.50823, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 1.4963 - val_loss: 1.5082\n",
      "Epoch 8/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4961\n",
      "Epoch 8: val_loss improved from 1.50823 to 1.50233, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 601us/sample - loss: 1.4961 - val_loss: 1.5023\n",
      "Epoch 9/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5010\n",
      "Epoch 9: val_loss improved from 1.50233 to 1.49952, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 597us/sample - loss: 1.5010 - val_loss: 1.4995\n",
      "Epoch 10/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5246\n",
      "Epoch 10: val_loss improved from 1.49952 to 1.49248, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 593us/sample - loss: 1.5246 - val_loss: 1.4925\n",
      "Epoch 11/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5363\n",
      "Epoch 11: val_loss improved from 1.49248 to 1.49021, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 595us/sample - loss: 1.5363 - val_loss: 1.4902\n",
      "Epoch 12/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4978\n",
      "Epoch 12: val_loss improved from 1.49021 to 1.48416, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 670us/sample - loss: 1.4978 - val_loss: 1.4842\n",
      "Epoch 13/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5008\n",
      "Epoch 13: val_loss did not improve from 1.48416\n",
      "31684/31684 [==============================] - 20s 625us/sample - loss: 1.5008 - val_loss: 1.4853\n",
      "Epoch 14/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4997\n",
      "Epoch 14: val_loss improved from 1.48416 to 1.48142, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.4997 - val_loss: 1.4814\n",
      "Epoch 15/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4945\n",
      "Epoch 15: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.4945 - val_loss: 1.4845\n",
      "Epoch 16/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5031\n",
      "Epoch 16: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 22s 685us/sample - loss: 1.5031 - val_loss: 1.4818\n",
      "Epoch 17/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5312\n",
      "Epoch 17: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 20s 637us/sample - loss: 1.5312 - val_loss: 1.4902\n",
      "Epoch 18/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5261\n",
      "Epoch 18: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 21s 653us/sample - loss: 1.5261 - val_loss: 1.4891\n",
      "Epoch 19/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.6803\n",
      "Epoch 19: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 21s 660us/sample - loss: 1.6803 - val_loss: 1.5092\n",
      "Epoch 20/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5534\n",
      "Epoch 20: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 21s 651us/sample - loss: 1.5534 - val_loss: 1.4987\n",
      "Epoch 21/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5262\n",
      "Epoch 21: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.5262 - val_loss: 1.4899\n",
      "Epoch 22/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5168\n",
      "Epoch 22: val_loss did not improve from 1.48142\n",
      "31684/31684 [==============================] - 22s 693us/sample - loss: 1.5168 - val_loss: 1.4889\n",
      "Epoch 23/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5035\n",
      "Epoch 23: val_loss improved from 1.48142 to 1.47929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 698us/sample - loss: 1.5035 - val_loss: 1.4793\n",
      "Epoch 24/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.5040\n",
      "Epoch 24: val_loss did not improve from 1.47929\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.5040 - val_loss: 1.4833\n",
      "Epoch 25/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4880\n",
      "Epoch 25: val_loss improved from 1.47929 to 1.47323, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 685us/sample - loss: 1.4880 - val_loss: 1.4732\n",
      "Epoch 26/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4803\n",
      "Epoch 26: val_loss did not improve from 1.47323\n",
      "31684/31684 [==============================] - 21s 669us/sample - loss: 1.4803 - val_loss: 1.4748\n",
      "Epoch 27/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4782\n",
      "Epoch 27: val_loss improved from 1.47323 to 1.46684, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 703us/sample - loss: 1.4782 - val_loss: 1.4668\n",
      "Epoch 28/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4770\n",
      "Epoch 28: val_loss improved from 1.46684 to 1.46476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 651us/sample - loss: 1.4770 - val_loss: 1.4648\n",
      "Epoch 29/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4712\n",
      "Epoch 29: val_loss improved from 1.46476 to 1.46417, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 658us/sample - loss: 1.4712 - val_loss: 1.4642\n",
      "Epoch 30/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4687\n",
      "Epoch 30: val_loss improved from 1.46417 to 1.45713, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 607us/sample - loss: 1.4687 - val_loss: 1.4571\n",
      "Epoch 31/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4663\n",
      "Epoch 31: val_loss improved from 1.45713 to 1.45521, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 675us/sample - loss: 1.4663 - val_loss: 1.4552\n",
      "Epoch 32/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 32: val_loss did not improve from 1.45521\n",
      "31684/31684 [==============================] - 22s 687us/sample - loss: 1.4623 - val_loss: 1.4556\n",
      "Epoch 33/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4566\n",
      "Epoch 33: val_loss improved from 1.45521 to 1.45102, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 659us/sample - loss: 1.4566 - val_loss: 1.4510\n",
      "Epoch 34/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4574\n",
      "Epoch 34: val_loss improved from 1.45102 to 1.45073, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4574 - val_loss: 1.4507\n",
      "Epoch 35/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4541\n",
      "Epoch 35: val_loss improved from 1.45073 to 1.44917, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 703us/sample - loss: 1.4541 - val_loss: 1.4492\n",
      "Epoch 36/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4514\n",
      "Epoch 36: val_loss improved from 1.44917 to 1.44610, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 659us/sample - loss: 1.4514 - val_loss: 1.4461\n",
      "Epoch 37/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4528\n",
      "Epoch 37: val_loss improved from 1.44610 to 1.44552, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 21s 662us/sample - loss: 1.4528 - val_loss: 1.4455\n",
      "Epoch 38/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4473\n",
      "Epoch 38: val_loss improved from 1.44552 to 1.44128, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 704us/sample - loss: 1.4473 - val_loss: 1.4413\n",
      "Epoch 39/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4466\n",
      "Epoch 39: val_loss did not improve from 1.44128\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 1.4466 - val_loss: 1.4436\n",
      "Epoch 40/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4450\n",
      "Epoch 40: val_loss did not improve from 1.44128\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.4450 - val_loss: 1.4422\n",
      "Epoch 41/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4454\n",
      "Epoch 41: val_loss improved from 1.44128 to 1.43640, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4454 - val_loss: 1.4364\n",
      "Epoch 42/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4430\n",
      "Epoch 42: val_loss did not improve from 1.43640\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4430 - val_loss: 1.4411\n",
      "Epoch 43/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 43: val_loss did not improve from 1.43640\n",
      "31684/31684 [==============================] - 22s 696us/sample - loss: 1.4375 - val_loss: 1.4400\n",
      "Epoch 44/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4372\n",
      "Epoch 44: val_loss did not improve from 1.43640\n",
      "31684/31684 [==============================] - 22s 697us/sample - loss: 1.4372 - val_loss: 1.4366\n",
      "Epoch 45/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 45: val_loss did not improve from 1.43640\n",
      "31684/31684 [==============================] - 19s 599us/sample - loss: 1.4354 - val_loss: 1.4372\n",
      "Epoch 46/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4363\n",
      "Epoch 46: val_loss did not improve from 1.43640\n",
      "31684/31684 [==============================] - 19s 599us/sample - loss: 1.4363 - val_loss: 1.4378\n",
      "Epoch 47/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 47: val_loss improved from 1.43640 to 1.43462, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 682us/sample - loss: 1.4305 - val_loss: 1.4346\n",
      "Epoch 48/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4342\n",
      "Epoch 48: val_loss improved from 1.43462 to 1.42992, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 707us/sample - loss: 1.4342 - val_loss: 1.4299\n",
      "Epoch 49/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 49: val_loss did not improve from 1.42992\n",
      "31684/31684 [==============================] - 22s 705us/sample - loss: 1.4308 - val_loss: 1.4343\n",
      "Epoch 50/50\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4296\n",
      "Epoch 50: val_loss did not improve from 1.42992\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 1.4296 - val_loss: 1.4302\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:49:39.594381: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_97_1/lstm_cell_282/bias/Assign' id:136435 op device:{requested: '', assigned: ''} def:{{{node lstm_97_1/lstm_cell_282/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_97_1/lstm_cell_282/bias, lstm_97_1/lstm_cell_282/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:49:47.018837: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_78_1/lstm_cell_263/recurrent_kernel/m/Assign' id:139401 op device:{requested: '', assigned: ''} def:{{{node lstm_78_1/lstm_cell_263/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_78_1/lstm_cell_263/recurrent_kernel/m, lstm_78_1/lstm_cell_263/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 11:49:54.276733: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_14_1/cond/Merge' id:138675 op device:{requested: '', assigned: ''} def:{{{node dropout_14_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_14_1/cond/Identity, dropout_14_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1790)\n",
      "(1514, 1790)\n",
      "(1644, 1790)\n",
      "(1764, 1790)\n",
      "(1836, 1790)\n",
      "(1699, 1790)\n",
      "(1369, 1790)\n",
      "(1582, 1790)\n",
      "(1788, 1790)\n",
      "(1550, 1790)\n",
      "(1920, 1790)\n",
      "(1679, 1790)\n",
      "(1800, 1790)\n",
      "(1860, 1790)\n",
      "(1692, 1790)\n",
      "(1824, 1790)\n",
      "(970, 1790)\n",
      "(1668, 1790)\n",
      "(1860, 1790)\n",
      "{1: 6.738559590546991, 2: 3.4054062559453224, 4: 8.471331566246448, 5: 7.163166108551394, 6: 6.208512199622646, 8: 8.639078702120933, 9: 3.8582306148518266, 11: 5.982157953536009, 12: 8.872243337305225, 13: 7.692050540782945, 17: 8.761356727923452, 19: 8.24348607238953, 21: 10.0, 22: 1.0, 25: 7.727975665125115, 26: 6.926918130855025, 27: 3.0353322013677997, 28: 7.570182339907221, 29: 2.0523145452802902}\n",
      "Train on 31684 samples, validate on 3527 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 11:54:14.808519: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 10.1598\n",
      "Epoch 1: val_loss improved from inf to 1.46610, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 38s 1ms/sample - loss: 10.1598 - val_loss: 1.4661\n",
      "Epoch 2/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0540\n",
      "Epoch 2: val_loss improved from 1.46610 to 1.45984, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 682us/sample - loss: 10.0540 - val_loss: 1.4598\n",
      "Epoch 3/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 10.0619\n",
      "Epoch 3: val_loss improved from 1.45984 to 1.43598, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 685us/sample - loss: 10.0619 - val_loss: 1.4360\n",
      "Epoch 4/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.9783\n",
      "Epoch 4: val_loss improved from 1.43598 to 1.43453, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 710us/sample - loss: 9.9783 - val_loss: 1.4345\n",
      "Epoch 5/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.9477\n",
      "Epoch 5: val_loss did not improve from 1.43453\n",
      "31684/31684 [==============================] - 22s 706us/sample - loss: 9.9477 - val_loss: 1.4353\n",
      "Epoch 6/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.9025\n",
      "Epoch 6: val_loss did not improve from 1.43453\n",
      "31684/31684 [==============================] - 20s 621us/sample - loss: 9.9025 - val_loss: 1.4413\n",
      "Epoch 7/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8978\n",
      "Epoch 7: val_loss improved from 1.43453 to 1.42673, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 623us/sample - loss: 9.8978 - val_loss: 1.4267\n",
      "Epoch 8/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.9144\n",
      "Epoch 8: val_loss did not improve from 1.42673\n",
      "31684/31684 [==============================] - 22s 701us/sample - loss: 9.9144 - val_loss: 1.4543\n",
      "Epoch 9/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8550\n",
      "Epoch 9: val_loss did not improve from 1.42673\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 9.8550 - val_loss: 1.4295\n",
      "Epoch 10/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8370\n",
      "Epoch 10: val_loss did not improve from 1.42673\n",
      "31684/31684 [==============================] - 22s 703us/sample - loss: 9.8370 - val_loss: 1.4382\n",
      "Epoch 11/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8351\n",
      "Epoch 11: val_loss improved from 1.42673 to 1.42427, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 681us/sample - loss: 9.8351 - val_loss: 1.4243\n",
      "Epoch 12/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.8053\n",
      "Epoch 12: val_loss did not improve from 1.42427\n",
      "31684/31684 [==============================] - 21s 671us/sample - loss: 9.8053 - val_loss: 1.4264\n",
      "Epoch 13/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7957\n",
      "Epoch 13: val_loss did not improve from 1.42427\n",
      "31684/31684 [==============================] - 21s 662us/sample - loss: 9.7957 - val_loss: 1.4319\n",
      "Epoch 14/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7785\n",
      "Epoch 14: val_loss improved from 1.42427 to 1.42391, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 700us/sample - loss: 9.7785 - val_loss: 1.4239\n",
      "Epoch 15/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7553\n",
      "Epoch 15: val_loss did not improve from 1.42391\n",
      "31684/31684 [==============================] - 20s 619us/sample - loss: 9.7553 - val_loss: 1.4251\n",
      "Epoch 16/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7598\n",
      "Epoch 16: val_loss improved from 1.42391 to 1.42150, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 615us/sample - loss: 9.7598 - val_loss: 1.4215\n",
      "Epoch 17/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7702\n",
      "Epoch 17: val_loss improved from 1.42150 to 1.41713, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 622us/sample - loss: 9.7702 - val_loss: 1.4171\n",
      "Epoch 18/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7408\n",
      "Epoch 18: val_loss did not improve from 1.41713\n",
      "31684/31684 [==============================] - 20s 619us/sample - loss: 9.7408 - val_loss: 1.4205\n",
      "Epoch 19/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7172\n",
      "Epoch 19: val_loss did not improve from 1.41713\n",
      "31684/31684 [==============================] - 20s 623us/sample - loss: 9.7172 - val_loss: 1.4199\n",
      "Epoch 20/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 9.7106\n",
      "Epoch 20: val_loss improved from 1.41713 to 1.41511, saving model to ./checkpoints/unknown_person_few_shot_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 627us/sample - loss: 9.7106 - val_loss: 1.4151\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:01:35.323246: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_92_2/lstm_cell_314/kernel/Assign' id:155002 op device:{requested: '', assigned: ''} def:{{{node lstm_92_2/lstm_cell_314/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_92_2/lstm_cell_314/kernel, lstm_92_2/lstm_cell_314/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:01:43.061519: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_81_2/lstm_cell_303/recurrent_kernel/m/Assign' id:158844 op device:{requested: '', assigned: ''} def:{{{node lstm_81_2/lstm_cell_303/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_81_2/lstm_cell_303/recurrent_kernel/m, lstm_81_2/lstm_cell_303/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31684 samples, validate on 3527 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:01:53.293496: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:02:34.380157: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4311"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:02:55.416644: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.42993, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 37s 1ms/sample - loss: 1.4311 - val_loss: 1.4299\n",
      "Epoch 2/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 2: val_loss improved from 1.42993 to 1.42975, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 621us/sample - loss: 1.4275 - val_loss: 1.4298\n",
      "Epoch 3/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 3: val_loss improved from 1.42975 to 1.42654, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 617us/sample - loss: 1.4277 - val_loss: 1.4265\n",
      "Epoch 4/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4233\n",
      "Epoch 4: val_loss improved from 1.42654 to 1.42483, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 635us/sample - loss: 1.4233 - val_loss: 1.4248\n",
      "Epoch 5/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4258\n",
      "Epoch 5: val_loss did not improve from 1.42483\n",
      "31684/31684 [==============================] - 22s 699us/sample - loss: 1.4258 - val_loss: 1.4321\n",
      "Epoch 6/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 6: val_loss did not improve from 1.42483\n",
      "31684/31684 [==============================] - 21s 653us/sample - loss: 1.4212 - val_loss: 1.4266\n",
      "Epoch 7/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 7: val_loss improved from 1.42483 to 1.42021, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 620us/sample - loss: 1.4207 - val_loss: 1.4202\n",
      "Epoch 8/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4175\n",
      "Epoch 8: val_loss did not improve from 1.42021\n",
      "31684/31684 [==============================] - 20s 619us/sample - loss: 1.4175 - val_loss: 1.4209\n",
      "Epoch 9/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 9: val_loss did not improve from 1.42021\n",
      "31684/31684 [==============================] - 20s 620us/sample - loss: 1.4141 - val_loss: 1.4258\n",
      "Epoch 10/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 10: val_loss improved from 1.42021 to 1.41938, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 616us/sample - loss: 1.4158 - val_loss: 1.4194\n",
      "Epoch 11/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 11: val_loss improved from 1.41938 to 1.41583, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 617us/sample - loss: 1.4149 - val_loss: 1.4158\n",
      "Epoch 12/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4125\n",
      "Epoch 12: val_loss did not improve from 1.41583\n",
      "31684/31684 [==============================] - 19s 605us/sample - loss: 1.4125 - val_loss: 1.4174\n",
      "Epoch 13/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 13: val_loss did not improve from 1.41583\n",
      "31684/31684 [==============================] - 19s 605us/sample - loss: 1.4123 - val_loss: 1.4204\n",
      "Epoch 14/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 14: val_loss did not improve from 1.41583\n",
      "31684/31684 [==============================] - 19s 606us/sample - loss: 1.4117 - val_loss: 1.4223\n",
      "Epoch 15/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 15: val_loss improved from 1.41583 to 1.41543, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 20s 617us/sample - loss: 1.4082 - val_loss: 1.4154\n",
      "Epoch 16/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4076\n",
      "Epoch 16: val_loss improved from 1.41543 to 1.41429, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 609us/sample - loss: 1.4076 - val_loss: 1.4143\n",
      "Epoch 17/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4071\n",
      "Epoch 17: val_loss did not improve from 1.41429\n",
      "31684/31684 [==============================] - 19s 605us/sample - loss: 1.4071 - val_loss: 1.4183\n",
      "Epoch 18/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 18: val_loss improved from 1.41429 to 1.41140, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 19s 612us/sample - loss: 1.4063 - val_loss: 1.4114\n",
      "Epoch 19/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 19: val_loss did not improve from 1.41140\n",
      "31684/31684 [==============================] - 21s 660us/sample - loss: 1.4053 - val_loss: 1.4121\n",
      "Epoch 20/20\n",
      "31684/31684 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 20: val_loss improved from 1.41140 to 1.41054, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_32.h5\n",
      "31684/31684 [==============================] - 22s 702us/sample - loss: 1.4042 - val_loss: 1.4105\n",
      "35414\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:09:38.790883: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_124/lstm_cell_346/recurrent_kernel/Assign' id:173309 op device:{requested: '', assigned: ''} def:{{{node lstm_124/lstm_cell_346/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_124/lstm_cell_346/recurrent_kernel, lstm_124/lstm_cell_346/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:09:43.482242: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_1' id:174762 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:09:47.187972: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_2' id:174763 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31873, 95)\n",
      "Train on 31873 samples, validate on 3541 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:09:58.857197: W tensorflow/c/c_api.cc:304] Operation '{name:'training_18/Adam/lstm_119/lstm_cell_341/bias/v/Assign' id:188293 op device:{requested: '', assigned: ''} def:{{{node training_18/Adam/lstm_119/lstm_cell_341/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_18/Adam/lstm_119/lstm_cell_341/bias/v, training_18/Adam/lstm_119/lstm_cell_341/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:10:47.943330: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 2.7078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-22 12:11:10.799180: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_19/mul' id:177603 op device:{requested: '', assigned: ''} def:{{{node loss_19/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_19/mul/x, loss_19/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.84331, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 65s 2ms/sample - loss: 2.7078 - val_loss: 1.8433\n",
      "Epoch 2/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.7404\n",
      "Epoch 2: val_loss improved from 1.84331 to 1.62841, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 21s 649us/sample - loss: 1.7404 - val_loss: 1.6284\n",
      "Epoch 3/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.6131\n",
      "Epoch 3: val_loss improved from 1.62841 to 1.56555, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 20s 637us/sample - loss: 1.6131 - val_loss: 1.5655\n",
      "Epoch 4/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5595\n",
      "Epoch 4: val_loss improved from 1.56555 to 1.53432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 722us/sample - loss: 1.5595 - val_loss: 1.5343\n",
      "Epoch 5/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5302\n",
      "Epoch 5: val_loss improved from 1.53432 to 1.50616, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 22s 679us/sample - loss: 1.5302 - val_loss: 1.5062\n",
      "Epoch 6/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5116\n",
      "Epoch 6: val_loss improved from 1.50616 to 1.50002, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 731us/sample - loss: 1.5116 - val_loss: 1.5000\n",
      "Epoch 7/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5014\n",
      "Epoch 7: val_loss improved from 1.50002 to 1.48259, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 730us/sample - loss: 1.5014 - val_loss: 1.4826\n",
      "Epoch 8/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4962\n",
      "Epoch 8: val_loss improved from 1.48259 to 1.48094, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 22s 693us/sample - loss: 1.4962 - val_loss: 1.4809\n",
      "Epoch 9/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4904\n",
      "Epoch 9: val_loss improved from 1.48094 to 1.46016, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 729us/sample - loss: 1.4904 - val_loss: 1.4602\n",
      "Epoch 10/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4897\n",
      "Epoch 10: val_loss did not improve from 1.46016\n",
      "31873/31873 [==============================] - 22s 692us/sample - loss: 1.4897 - val_loss: 1.4642\n",
      "Epoch 11/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 11: val_loss improved from 1.46016 to 1.45111, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 709us/sample - loss: 1.4987 - val_loss: 1.4511\n",
      "Epoch 12/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 12: val_loss did not improve from 1.45111\n",
      "31873/31873 [==============================] - 22s 679us/sample - loss: 1.4827 - val_loss: 1.4565\n",
      "Epoch 13/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 13: val_loss improved from 1.45111 to 1.44781, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 725us/sample - loss: 1.4751 - val_loss: 1.4478\n",
      "Epoch 14/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4849\n",
      "Epoch 14: val_loss improved from 1.44781 to 1.44637, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 20s 642us/sample - loss: 1.4849 - val_loss: 1.4464\n",
      "Epoch 15/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4746\n",
      "Epoch 15: val_loss improved from 1.44637 to 1.43470, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 723us/sample - loss: 1.4746 - val_loss: 1.4347\n",
      "Epoch 16/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4660\n",
      "Epoch 16: val_loss improved from 1.43470 to 1.43419, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 729us/sample - loss: 1.4660 - val_loss: 1.4342\n",
      "Epoch 17/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4716\n",
      "Epoch 17: val_loss did not improve from 1.43419\n",
      "31873/31873 [==============================] - 23s 727us/sample - loss: 1.4716 - val_loss: 1.4405\n",
      "Epoch 18/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4645\n",
      "Epoch 18: val_loss improved from 1.43419 to 1.42932, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 21s 644us/sample - loss: 1.4645 - val_loss: 1.4293\n",
      "Epoch 19/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5013\n",
      "Epoch 19: val_loss did not improve from 1.42932\n",
      "31873/31873 [==============================] - 20s 639us/sample - loss: 1.5013 - val_loss: 1.4462\n",
      "Epoch 20/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4739\n",
      "Epoch 20: val_loss did not improve from 1.42932\n",
      "31873/31873 [==============================] - 23s 725us/sample - loss: 1.4739 - val_loss: 1.4307\n",
      "Epoch 21/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4670\n",
      "Epoch 21: val_loss improved from 1.42932 to 1.42573, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 22s 681us/sample - loss: 1.4670 - val_loss: 1.4257\n",
      "Epoch 22/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4607\n",
      "Epoch 22: val_loss did not improve from 1.42573\n",
      "31873/31873 [==============================] - 22s 704us/sample - loss: 1.4607 - val_loss: 1.4292\n",
      "Epoch 23/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 23: val_loss improved from 1.42573 to 1.42301, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 21s 650us/sample - loss: 1.4525 - val_loss: 1.4230\n",
      "Epoch 24/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4481\n",
      "Epoch 24: val_loss did not improve from 1.42301\n",
      "31873/31873 [==============================] - 22s 676us/sample - loss: 1.4481 - val_loss: 1.4266\n",
      "Epoch 25/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4460\n",
      "Epoch 25: val_loss did not improve from 1.42301\n",
      "31873/31873 [==============================] - 23s 712us/sample - loss: 1.4460 - val_loss: 1.4380\n",
      "Epoch 26/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4434\n",
      "Epoch 26: val_loss improved from 1.42301 to 1.41008, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 728us/sample - loss: 1.4434 - val_loss: 1.4101\n",
      "Epoch 27/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4415\n",
      "Epoch 27: val_loss improved from 1.41008 to 1.40303, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 727us/sample - loss: 1.4415 - val_loss: 1.4030\n",
      "Epoch 28/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4386\n",
      "Epoch 28: val_loss did not improve from 1.40303\n",
      "31873/31873 [==============================] - 23s 731us/sample - loss: 1.4386 - val_loss: 1.4083\n",
      "Epoch 29/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4345\n",
      "Epoch 29: val_loss improved from 1.40303 to 1.40253, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 22s 678us/sample - loss: 1.4345 - val_loss: 1.4025\n",
      "Epoch 30/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4301\n",
      "Epoch 30: val_loss did not improve from 1.40253\n",
      "31873/31873 [==============================] - 21s 652us/sample - loss: 1.4301 - val_loss: 1.4089\n",
      "Epoch 31/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4286\n",
      "Epoch 31: val_loss improved from 1.40253 to 1.39737, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 21s 653us/sample - loss: 1.4286 - val_loss: 1.3974\n",
      "Epoch 32/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4313\n",
      "Epoch 32: val_loss did not improve from 1.39737\n",
      "31873/31873 [==============================] - 21s 653us/sample - loss: 1.4313 - val_loss: 1.4167\n",
      "Epoch 33/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4264\n",
      "Epoch 33: val_loss did not improve from 1.39737\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.4264 - val_loss: 1.4049\n",
      "Epoch 34/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 34: val_loss improved from 1.39737 to 1.39535, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 725us/sample - loss: 1.4232 - val_loss: 1.3954\n",
      "Epoch 35/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 35: val_loss did not improve from 1.39535\n",
      "31873/31873 [==============================] - 20s 625us/sample - loss: 1.4211 - val_loss: 1.3984\n",
      "Epoch 36/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4209\n",
      "Epoch 36: val_loss did not improve from 1.39535\n",
      "31873/31873 [==============================] - 20s 625us/sample - loss: 1.4209 - val_loss: 1.3992\n",
      "Epoch 37/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 37: val_loss did not improve from 1.39535\n",
      "31873/31873 [==============================] - 21s 652us/sample - loss: 1.4155 - val_loss: 1.4058\n",
      "Epoch 38/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 38: val_loss did not improve from 1.39535\n",
      "31873/31873 [==============================] - 22s 675us/sample - loss: 1.4158 - val_loss: 1.4039\n",
      "Epoch 39/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4167\n",
      "Epoch 39: val_loss improved from 1.39535 to 1.38854, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 21s 649us/sample - loss: 1.4167 - val_loss: 1.3885\n",
      "Epoch 40/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4136\n",
      "Epoch 40: val_loss improved from 1.38854 to 1.38352, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 20s 638us/sample - loss: 1.4136 - val_loss: 1.3835\n",
      "Epoch 41/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4133\n",
      "Epoch 41: val_loss did not improve from 1.38352\n",
      "31873/31873 [==============================] - 20s 633us/sample - loss: 1.4133 - val_loss: 1.3989\n",
      "Epoch 42/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4150\n",
      "Epoch 42: val_loss did not improve from 1.38352\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.4150 - val_loss: 1.4052\n",
      "Epoch 43/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4081\n",
      "Epoch 43: val_loss did not improve from 1.38352\n",
      "31873/31873 [==============================] - 20s 633us/sample - loss: 1.4081 - val_loss: 1.3877\n",
      "Epoch 44/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 44: val_loss did not improve from 1.38352\n",
      "31873/31873 [==============================] - 20s 632us/sample - loss: 1.4069 - val_loss: 1.3874\n",
      "Epoch 45/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4085\n",
      "Epoch 45: val_loss did not improve from 1.38352\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4085 - val_loss: 1.3890\n",
      "Epoch 46/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 46: val_loss did not improve from 1.38352\n",
      "31873/31873 [==============================] - 21s 672us/sample - loss: 1.4058 - val_loss: 1.3883\n",
      "Epoch 47/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 47: val_loss improved from 1.38352 to 1.37933, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 726us/sample - loss: 1.4051 - val_loss: 1.3793\n",
      "Epoch 48/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 48: val_loss did not improve from 1.37933\n",
      "31873/31873 [==============================] - 23s 717us/sample - loss: 1.4010 - val_loss: 1.3858\n",
      "Epoch 49/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4031\n",
      "Epoch 49: val_loss did not improve from 1.37933\n",
      "31873/31873 [==============================] - 23s 728us/sample - loss: 1.4031 - val_loss: 1.3935\n",
      "Epoch 50/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3999\n",
      "Epoch 50: val_loss did not improve from 1.37933\n",
      "31873/31873 [==============================] - 23s 725us/sample - loss: 1.3999 - val_loss: 1.3830\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:29:43.075573: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_144_1/lstm_cell_403/bias/Assign' id:195077 op device:{requested: '', assigned: ''} def:{{{node lstm_144_1/lstm_cell_403/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_144_1/lstm_cell_403/bias, lstm_144_1/lstm_cell_403/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:29:53.279889: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_13_1/bias/m/Assign' id:196353 op device:{requested: '', assigned: ''} def:{{{node conv2d_13_1/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_13_1/bias/m, conv2d_13_1/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-22 12:30:03.360470: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_19_1/cond/Merge' id:195717 op device:{requested: '', assigned: ''} def:{{{node dropout_19_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_19_1/cond/Identity, dropout_19_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1587)\n",
      "(1514, 1587)\n",
      "(1644, 1587)\n",
      "(1764, 1587)\n",
      "(1836, 1587)\n",
      "(1699, 1587)\n",
      "(1369, 1587)\n",
      "(1594, 1587)\n",
      "(1764, 1587)\n",
      "(1560, 1587)\n",
      "(1896, 1587)\n",
      "(1727, 1587)\n",
      "(1800, 1587)\n",
      "(1824, 1587)\n",
      "(1728, 1587)\n",
      "(1824, 1587)\n",
      "(946, 1587)\n",
      "(1692, 1587)\n",
      "(1848, 1587)\n",
      "{1: 6.348952464203255, 2: 5.314564785694604, 4: 9.681360988911798, 5: 6.791530399916387, 6: 7.022786397712049, 8: 8.946119129286345, 9: 5.257160774178836, 11: 7.405351221412487, 12: 9.607985025701446, 13: 6.40557545583247, 17: 9.80071260938554, 19: 8.884450863207501, 21: 10.0, 22: 1.0, 25: 7.787013406557906, 26: 6.185424762701075, 27: 4.107090938459054, 28: 6.673756021549308, 29: 2.2023886666603323}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916958/459382369.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31873 samples, validate on 3541 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:35:04.728563: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7766\n",
      "Epoch 1: val_loss improved from inf to 1.39711, saving model to ./checkpoints/unknown_person_few_shot_p10_33.h5\n",
      "31873/31873 [==============================] - 43s 1ms/sample - loss: 10.7766 - val_loss: 1.3971\n",
      "Epoch 2/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6725\n",
      "Epoch 2: val_loss did not improve from 1.39711\n",
      "31873/31873 [==============================] - 23s 716us/sample - loss: 10.6725 - val_loss: 1.4019\n",
      "Epoch 3/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6537\n",
      "Epoch 3: val_loss did not improve from 1.39711\n",
      "31873/31873 [==============================] - 23s 724us/sample - loss: 10.6537 - val_loss: 1.4063\n",
      "Epoch 4/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6081\n",
      "Epoch 4: val_loss did not improve from 1.39711\n",
      "31873/31873 [==============================] - 23s 721us/sample - loss: 10.6081 - val_loss: 1.4062\n",
      "Epoch 5/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.5472\n",
      "Epoch 5: val_loss did not improve from 1.39711\n",
      "31873/31873 [==============================] - 23s 723us/sample - loss: 10.5472 - val_loss: 1.4120\n",
      "Epoch 6/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.5099\n",
      "Epoch 6: val_loss did not improve from 1.39711\n",
      "31873/31873 [==============================] - 23s 718us/sample - loss: 10.5099 - val_loss: 1.4272\n",
      "Epoch 7/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.4749\n",
      "Epoch 7: val_loss improved from 1.39711 to 1.38938, saving model to ./checkpoints/unknown_person_few_shot_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 724us/sample - loss: 10.4749 - val_loss: 1.3894\n",
      "Epoch 8/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.4702\n",
      "Epoch 8: val_loss did not improve from 1.38938\n",
      "31873/31873 [==============================] - 23s 719us/sample - loss: 10.4702 - val_loss: 1.4040\n",
      "Epoch 9/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.4243\n",
      "Epoch 9: val_loss did not improve from 1.38938\n",
      "31873/31873 [==============================] - 21s 667us/sample - loss: 10.4243 - val_loss: 1.4013\n",
      "Epoch 10/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.4421\n",
      "Epoch 10: val_loss did not improve from 1.38938\n",
      "31873/31873 [==============================] - 20s 613us/sample - loss: 10.4421 - val_loss: 1.4052\n",
      "Epoch 11/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3971\n",
      "Epoch 11: val_loss did not improve from 1.38938\n",
      "31873/31873 [==============================] - 20s 614us/sample - loss: 10.3971 - val_loss: 1.4015\n",
      "Epoch 12/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3717\n",
      "Epoch 12: val_loss improved from 1.38938 to 1.38469, saving model to ./checkpoints/unknown_person_few_shot_p10_33.h5\n",
      "31873/31873 [==============================] - 20s 618us/sample - loss: 10.3717 - val_loss: 1.3847\n",
      "Epoch 13/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3814\n",
      "Epoch 13: val_loss did not improve from 1.38469\n",
      "31873/31873 [==============================] - 20s 613us/sample - loss: 10.3814 - val_loss: 1.3965\n",
      "Epoch 14/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3578\n",
      "Epoch 14: val_loss did not improve from 1.38469\n",
      "31873/31873 [==============================] - 20s 616us/sample - loss: 10.3578 - val_loss: 1.3925\n",
      "Epoch 15/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3588\n",
      "Epoch 15: val_loss did not improve from 1.38469\n",
      "31873/31873 [==============================] - 20s 612us/sample - loss: 10.3588 - val_loss: 1.3893\n",
      "Epoch 16/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3615\n",
      "Epoch 16: val_loss did not improve from 1.38469\n",
      "31873/31873 [==============================] - 19s 610us/sample - loss: 10.3615 - val_loss: 1.3867\n",
      "Epoch 17/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3251\n",
      "Epoch 17: val_loss did not improve from 1.38469\n",
      "31873/31873 [==============================] - 19s 611us/sample - loss: 10.3251 - val_loss: 1.3993\n",
      "Epoch 18/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3123\n",
      "Epoch 18: val_loss did not improve from 1.38469\n",
      "31873/31873 [==============================] - 19s 611us/sample - loss: 10.3123 - val_loss: 1.3961\n",
      "Epoch 19/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3118\n",
      "Epoch 19: val_loss improved from 1.38469 to 1.37436, saving model to ./checkpoints/unknown_person_few_shot_p10_33.h5\n",
      "31873/31873 [==============================] - 20s 613us/sample - loss: 10.3118 - val_loss: 1.3744\n",
      "Epoch 20/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.2604\n",
      "Epoch 20: val_loss did not improve from 1.37436\n",
      "31873/31873 [==============================] - 20s 616us/sample - loss: 10.2604 - val_loss: 1.3763\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:42:29.024357: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_139_2/lstm_cell_435/recurrent_kernel/Assign' id:213666 op device:{requested: '', assigned: ''} def:{{{node lstm_139_2/lstm_cell_435/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_139_2/lstm_cell_435/recurrent_kernel, lstm_139_2/lstm_cell_435/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:42:39.731426: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_144_2/lstm_cell_440/bias/m/Assign' id:216281 op device:{requested: '', assigned: ''} def:{{{node lstm_144_2/lstm_cell_440/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_144_2/lstm_cell_440/bias/m, lstm_144_2/lstm_cell_440/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31873 samples, validate on 3541 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:42:52.918765: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:43:49.394818: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:44:13.750630: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38038, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 45s 1ms/sample - loss: 1.4025 - val_loss: 1.3804\n",
      "Epoch 2/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4018\n",
      "Epoch 2: val_loss did not improve from 1.38038\n",
      "31873/31873 [==============================] - 20s 626us/sample - loss: 1.4018 - val_loss: 1.3832\n",
      "Epoch 3/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3955\n",
      "Epoch 3: val_loss did not improve from 1.38038\n",
      "31873/31873 [==============================] - 20s 623us/sample - loss: 1.3955 - val_loss: 1.3853\n",
      "Epoch 4/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3967\n",
      "Epoch 4: val_loss did not improve from 1.38038\n",
      "31873/31873 [==============================] - 22s 675us/sample - loss: 1.3967 - val_loss: 1.3847\n",
      "Epoch 5/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 5: val_loss did not improve from 1.38038\n",
      "31873/31873 [==============================] - 23s 717us/sample - loss: 1.3912 - val_loss: 1.3859\n",
      "Epoch 6/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 6: val_loss improved from 1.38038 to 1.38027, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 725us/sample - loss: 1.3928 - val_loss: 1.3803\n",
      "Epoch 7/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 7: val_loss did not improve from 1.38027\n",
      "31873/31873 [==============================] - 23s 717us/sample - loss: 1.3914 - val_loss: 1.3894\n",
      "Epoch 8/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3900\n",
      "Epoch 8: val_loss improved from 1.38027 to 1.37196, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 21s 665us/sample - loss: 1.3900 - val_loss: 1.3720\n",
      "Epoch 9/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3876\n",
      "Epoch 9: val_loss did not improve from 1.37196\n",
      "31873/31873 [==============================] - 20s 628us/sample - loss: 1.3876 - val_loss: 1.3773\n",
      "Epoch 10/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 10: val_loss did not improve from 1.37196\n",
      "31873/31873 [==============================] - 21s 660us/sample - loss: 1.3887 - val_loss: 1.3759\n",
      "Epoch 11/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 11: val_loss did not improve from 1.37196\n",
      "31873/31873 [==============================] - 23s 715us/sample - loss: 1.3862 - val_loss: 1.3777\n",
      "Epoch 12/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3839\n",
      "Epoch 12: val_loss did not improve from 1.37196\n",
      "31873/31873 [==============================] - 22s 675us/sample - loss: 1.3839 - val_loss: 1.3725\n",
      "Epoch 13/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3810\n",
      "Epoch 13: val_loss improved from 1.37196 to 1.36981, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 726us/sample - loss: 1.3810 - val_loss: 1.3698\n",
      "Epoch 14/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 14: val_loss did not improve from 1.36981\n",
      "31873/31873 [==============================] - 23s 722us/sample - loss: 1.3830 - val_loss: 1.3705\n",
      "Epoch 15/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3803\n",
      "Epoch 15: val_loss did not improve from 1.36981\n",
      "31873/31873 [==============================] - 23s 719us/sample - loss: 1.3803 - val_loss: 1.3741\n",
      "Epoch 16/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 16: val_loss improved from 1.36981 to 1.36956, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 727us/sample - loss: 1.3796 - val_loss: 1.3696\n",
      "Epoch 17/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3785\n",
      "Epoch 17: val_loss improved from 1.36956 to 1.36553, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 23s 726us/sample - loss: 1.3785 - val_loss: 1.3655\n",
      "Epoch 18/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3763\n",
      "Epoch 18: val_loss did not improve from 1.36553\n",
      "31873/31873 [==============================] - 23s 718us/sample - loss: 1.3763 - val_loss: 1.3713\n",
      "Epoch 19/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3739\n",
      "Epoch 19: val_loss improved from 1.36553 to 1.35822, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_33.h5\n",
      "31873/31873 [==============================] - 20s 624us/sample - loss: 1.3739 - val_loss: 1.3582\n",
      "Epoch 20/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3751\n",
      "Epoch 20: val_loss did not improve from 1.35822\n",
      "31873/31873 [==============================] - 20s 616us/sample - loss: 1.3751 - val_loss: 1.3727\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:51:33.273546: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_151/lstm_cell_447/bias/Assign' id:228710 op device:{requested: '', assigned: ''} def:{{{node lstm_151/lstm_cell_447/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_151/lstm_cell_447/bias, lstm_151/lstm_cell_447/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:51:39.356157: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_1' id:231804 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 12:51:44.240566: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_2' id:231805 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31873, 95)\n",
      "Train on 31873 samples, validate on 3541 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:51:59.091035: W tensorflow/c/c_api.cc:304] Operation '{name:'training_24/Adam/lstm_166/lstm_cell_462/kernel/m/Assign' id:244832 op device:{requested: '', assigned: ''} def:{{{node training_24/Adam/lstm_166/lstm_cell_462/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_24/Adam/lstm_166/lstm_cell_462/kernel/m, training_24/Adam/lstm_166/lstm_cell_462/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:53:01.265368: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 3.3845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:53:22.551570: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_25/mul' id:234645 op device:{requested: '', assigned: ''} def:{{{node loss_25/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_25/mul/x, loss_25/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95970, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 77s 2ms/sample - loss: 3.3845 - val_loss: 1.9597\n",
      "Epoch 2/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.7983\n",
      "Epoch 2: val_loss improved from 1.95970 to 1.59525, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 728us/sample - loss: 1.7983 - val_loss: 1.5953\n",
      "Epoch 3/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5920\n",
      "Epoch 3: val_loss improved from 1.59525 to 1.55036, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 731us/sample - loss: 1.5920 - val_loss: 1.5504\n",
      "Epoch 4/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5490\n",
      "Epoch 4: val_loss improved from 1.55036 to 1.52278, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 728us/sample - loss: 1.5490 - val_loss: 1.5228\n",
      "Epoch 5/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5296\n",
      "Epoch 5: val_loss improved from 1.52278 to 1.51120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 725us/sample - loss: 1.5296 - val_loss: 1.5112\n",
      "Epoch 6/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5159\n",
      "Epoch 6: val_loss improved from 1.51120 to 1.50256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 726us/sample - loss: 1.5159 - val_loss: 1.5026\n",
      "Epoch 7/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5039\n",
      "Epoch 7: val_loss improved from 1.50256 to 1.48487, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 729us/sample - loss: 1.5039 - val_loss: 1.4849\n",
      "Epoch 8/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5128\n",
      "Epoch 8: val_loss improved from 1.48487 to 1.48385, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 731us/sample - loss: 1.5128 - val_loss: 1.4839\n",
      "Epoch 9/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5011\n",
      "Epoch 9: val_loss did not improve from 1.48385\n",
      "31873/31873 [==============================] - 21s 656us/sample - loss: 1.5011 - val_loss: 1.4971\n",
      "Epoch 10/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5022\n",
      "Epoch 10: val_loss improved from 1.48385 to 1.47317, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 22s 695us/sample - loss: 1.5022 - val_loss: 1.4732\n",
      "Epoch 11/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5001\n",
      "Epoch 11: val_loss improved from 1.47317 to 1.46561, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 723us/sample - loss: 1.5001 - val_loss: 1.4656\n",
      "Epoch 12/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5008\n",
      "Epoch 12: val_loss improved from 1.46561 to 1.46209, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 657us/sample - loss: 1.5008 - val_loss: 1.4621\n",
      "Epoch 13/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 13: val_loss improved from 1.46209 to 1.45576, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 638us/sample - loss: 1.4865 - val_loss: 1.4558\n",
      "Epoch 14/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5409\n",
      "Epoch 14: val_loss did not improve from 1.45576\n",
      "31873/31873 [==============================] - 22s 697us/sample - loss: 1.5409 - val_loss: 1.4744\n",
      "Epoch 15/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5093\n",
      "Epoch 15: val_loss did not improve from 1.45576\n",
      "31873/31873 [==============================] - 23s 716us/sample - loss: 1.5093 - val_loss: 1.4633\n",
      "Epoch 16/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4914\n",
      "Epoch 16: val_loss improved from 1.45576 to 1.45471, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 721us/sample - loss: 1.4914 - val_loss: 1.4547\n",
      "Epoch 17/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5657\n",
      "Epoch 17: val_loss did not improve from 1.45471\n",
      "31873/31873 [==============================] - 22s 678us/sample - loss: 1.5657 - val_loss: 1.4635\n",
      "Epoch 18/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4951\n",
      "Epoch 18: val_loss improved from 1.45471 to 1.45188, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4951 - val_loss: 1.4519\n",
      "Epoch 19/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4855\n",
      "Epoch 19: val_loss improved from 1.45188 to 1.44677, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 635us/sample - loss: 1.4855 - val_loss: 1.4468\n",
      "Epoch 20/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5035\n",
      "Epoch 20: val_loss improved from 1.44677 to 1.44463, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 643us/sample - loss: 1.5035 - val_loss: 1.4446\n",
      "Epoch 21/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4940\n",
      "Epoch 21: val_loss improved from 1.44463 to 1.43828, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 637us/sample - loss: 1.4940 - val_loss: 1.4383\n",
      "Epoch 22/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5572\n",
      "Epoch 22: val_loss did not improve from 1.43828\n",
      "31873/31873 [==============================] - 21s 665us/sample - loss: 1.5572 - val_loss: 1.4645\n",
      "Epoch 23/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4939\n",
      "Epoch 23: val_loss did not improve from 1.43828\n",
      "31873/31873 [==============================] - 23s 718us/sample - loss: 1.4939 - val_loss: 1.4559\n",
      "Epoch 24/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4755\n",
      "Epoch 24: val_loss improved from 1.43828 to 1.43636, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 714us/sample - loss: 1.4755 - val_loss: 1.4364\n",
      "Epoch 25/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4632\n",
      "Epoch 25: val_loss did not improve from 1.43636\n",
      "31873/31873 [==============================] - 20s 630us/sample - loss: 1.4632 - val_loss: 1.4368\n",
      "Epoch 26/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4679\n",
      "Epoch 26: val_loss improved from 1.43636 to 1.43259, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.4679 - val_loss: 1.4326\n",
      "Epoch 27/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4657\n",
      "Epoch 27: val_loss did not improve from 1.43259\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4657 - val_loss: 1.4391\n",
      "Epoch 28/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4679\n",
      "Epoch 28: val_loss did not improve from 1.43259\n",
      "31873/31873 [==============================] - 20s 623us/sample - loss: 1.4679 - val_loss: 1.4378\n",
      "Epoch 29/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4576\n",
      "Epoch 29: val_loss did not improve from 1.43259\n",
      "31873/31873 [==============================] - 20s 621us/sample - loss: 1.4576 - val_loss: 1.4364\n",
      "Epoch 30/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4513\n",
      "Epoch 30: val_loss improved from 1.43259 to 1.42693, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 626us/sample - loss: 1.4513 - val_loss: 1.4269\n",
      "Epoch 31/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4497\n",
      "Epoch 31: val_loss improved from 1.42693 to 1.41314, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 625us/sample - loss: 1.4497 - val_loss: 1.4131\n",
      "Epoch 32/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4439\n",
      "Epoch 32: val_loss improved from 1.41314 to 1.41216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 628us/sample - loss: 1.4439 - val_loss: 1.4122\n",
      "Epoch 33/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4428\n",
      "Epoch 33: val_loss did not improve from 1.41216\n",
      "31873/31873 [==============================] - 20s 623us/sample - loss: 1.4428 - val_loss: 1.4226\n",
      "Epoch 34/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4402\n",
      "Epoch 34: val_loss improved from 1.41216 to 1.41182, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 628us/sample - loss: 1.4402 - val_loss: 1.4118\n",
      "Epoch 35/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4376\n",
      "Epoch 35: val_loss improved from 1.41182 to 1.41139, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 627us/sample - loss: 1.4376 - val_loss: 1.4114\n",
      "Epoch 36/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4372\n",
      "Epoch 36: val_loss improved from 1.41139 to 1.40771, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 630us/sample - loss: 1.4372 - val_loss: 1.4077\n",
      "Epoch 37/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4355\n",
      "Epoch 37: val_loss did not improve from 1.40771\n",
      "31873/31873 [==============================] - 20s 623us/sample - loss: 1.4355 - val_loss: 1.4105\n",
      "Epoch 38/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4317\n",
      "Epoch 38: val_loss did not improve from 1.40771\n",
      "31873/31873 [==============================] - 20s 625us/sample - loss: 1.4317 - val_loss: 1.4149\n",
      "Epoch 39/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 39: val_loss did not improve from 1.40771\n",
      "31873/31873 [==============================] - 20s 622us/sample - loss: 1.4305 - val_loss: 1.4128\n",
      "Epoch 40/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4314\n",
      "Epoch 40: val_loss did not improve from 1.40771\n",
      "31873/31873 [==============================] - 20s 621us/sample - loss: 1.4314 - val_loss: 1.4078\n",
      "Epoch 41/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 41: val_loss improved from 1.40771 to 1.39902, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4266 - val_loss: 1.3990\n",
      "Epoch 42/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4251\n",
      "Epoch 42: val_loss did not improve from 1.39902\n",
      "31873/31873 [==============================] - 20s 626us/sample - loss: 1.4251 - val_loss: 1.4019\n",
      "Epoch 43/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 43: val_loss did not improve from 1.39902\n",
      "31873/31873 [==============================] - 20s 622us/sample - loss: 1.4243 - val_loss: 1.4068\n",
      "Epoch 44/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 44: val_loss improved from 1.39902 to 1.39862, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 625us/sample - loss: 1.4246 - val_loss: 1.3986\n",
      "Epoch 45/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4196\n",
      "Epoch 45: val_loss did not improve from 1.39862\n",
      "31873/31873 [==============================] - 20s 626us/sample - loss: 1.4196 - val_loss: 1.4035\n",
      "Epoch 46/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 46: val_loss improved from 1.39862 to 1.39243, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4176 - val_loss: 1.3924\n",
      "Epoch 47/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 47: val_loss did not improve from 1.39243\n",
      "31873/31873 [==============================] - 20s 622us/sample - loss: 1.4178 - val_loss: 1.3938\n",
      "Epoch 48/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 48: val_loss improved from 1.39243 to 1.38838, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 634us/sample - loss: 1.4159 - val_loss: 1.3884\n",
      "Epoch 49/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 49: val_loss did not improve from 1.38838\n",
      "31873/31873 [==============================] - 20s 624us/sample - loss: 1.4145 - val_loss: 1.3894\n",
      "Epoch 50/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 50: val_loss improved from 1.38838 to 1.38271, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4164 - val_loss: 1.3827\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:11:30.690021: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_149_1/lstm_cell_482/recurrent_kernel/Assign' id:246988 op device:{requested: '', assigned: ''} def:{{{node lstm_149_1/lstm_cell_482/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_149_1/lstm_cell_482/recurrent_kernel, lstm_149_1/lstm_cell_482/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:11:43.484322: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_19_1/bias/v/Assign' id:254659 op device:{requested: '', assigned: ''} def:{{{node dense_19_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_19_1/bias/v, dense_19_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:11:56.138908: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_24_1/cond/Merge' id:252759 op device:{requested: '', assigned: ''} def:{{{node dropout_24_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_24_1/cond/Identity, dropout_24_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1587)\n",
      "(1514, 1587)\n",
      "(1644, 1587)\n",
      "(1764, 1587)\n",
      "(1836, 1587)\n",
      "(1699, 1587)\n",
      "(1369, 1587)\n",
      "(1594, 1587)\n",
      "(1764, 1587)\n",
      "(1560, 1587)\n",
      "(1896, 1587)\n",
      "(1727, 1587)\n",
      "(1800, 1587)\n",
      "(1824, 1587)\n",
      "(1728, 1587)\n",
      "(1824, 1587)\n",
      "(946, 1587)\n",
      "(1692, 1587)\n",
      "(1848, 1587)\n",
      "{1: 5.693487123355781, 2: 2.3495374947929966, 4: 8.953998593659552, 5: 8.242845409900987, 6: 8.106553145852093, 8: 7.961424512955745, 9: 2.6849820509251385, 11: 5.560181149798885, 12: 9.052571604969344, 13: 7.207048703655098, 17: 9.170523145292227, 19: 8.715058372374092, 21: 10.0, 22: 1.0, 25: 7.561767777134589, 26: 6.4052135269611075, 27: 1.7310818189149195, 28: 7.679377234645695, 29: 4.265504030259433}\n",
      "Train on 31873 samples, validate on 3541 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:16:37.886560: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 10.4753\n",
      "Epoch 1: val_loss improved from inf to 1.42207, saving model to ./checkpoints/unknown_person_few_shot_p10_34.h5\n",
      "31873/31873 [==============================] - 46s 1ms/sample - loss: 10.4753 - val_loss: 1.4221\n",
      "Epoch 2/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.4569\n",
      "Epoch 2: val_loss improved from 1.42207 to 1.41541, saving model to ./checkpoints/unknown_person_few_shot_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 638us/sample - loss: 10.4569 - val_loss: 1.4154\n",
      "Epoch 3/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3845\n",
      "Epoch 3: val_loss did not improve from 1.41541\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 10.3845 - val_loss: 1.4438\n",
      "Epoch 4/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.3247\n",
      "Epoch 4: val_loss improved from 1.41541 to 1.41291, saving model to ./checkpoints/unknown_person_few_shot_p10_34.h5\n",
      "31873/31873 [==============================] - 20s 638us/sample - loss: 10.3247 - val_loss: 1.4129\n",
      "Epoch 5/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.2557\n",
      "Epoch 5: val_loss did not improve from 1.41291\n",
      "31873/31873 [==============================] - 20s 629us/sample - loss: 10.2557 - val_loss: 1.4305\n",
      "Epoch 6/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.2208\n",
      "Epoch 6: val_loss did not improve from 1.41291\n",
      "31873/31873 [==============================] - 23s 711us/sample - loss: 10.2208 - val_loss: 1.4203\n",
      "Epoch 7/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.2282\n",
      "Epoch 7: val_loss improved from 1.41291 to 1.40481, saving model to ./checkpoints/unknown_person_few_shot_p10_34.h5\n",
      "31873/31873 [==============================] - 22s 701us/sample - loss: 10.2282 - val_loss: 1.4048\n",
      "Epoch 8/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.2104\n",
      "Epoch 8: val_loss did not improve from 1.40481\n",
      "31873/31873 [==============================] - 21s 649us/sample - loss: 10.2104 - val_loss: 1.4181\n",
      "Epoch 9/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.1699\n",
      "Epoch 9: val_loss did not improve from 1.40481\n",
      "31873/31873 [==============================] - 21s 675us/sample - loss: 10.1699 - val_loss: 1.4092\n",
      "Epoch 10/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.1852\n",
      "Epoch 10: val_loss improved from 1.40481 to 1.39777, saving model to ./checkpoints/unknown_person_few_shot_p10_34.h5\n",
      "31873/31873 [==============================] - 22s 701us/sample - loss: 10.1852 - val_loss: 1.3978\n",
      "Epoch 11/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.1443\n",
      "Epoch 11: val_loss did not improve from 1.39777\n",
      "31873/31873 [==============================] - 22s 680us/sample - loss: 10.1443 - val_loss: 1.4063\n",
      "Epoch 12/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.1326\n",
      "Epoch 12: val_loss did not improve from 1.39777\n",
      "31873/31873 [==============================] - 23s 714us/sample - loss: 10.1326 - val_loss: 1.4100\n",
      "Epoch 13/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.1243\n",
      "Epoch 13: val_loss did not improve from 1.39777\n",
      "31873/31873 [==============================] - 22s 692us/sample - loss: 10.1243 - val_loss: 1.4207\n",
      "Epoch 14/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0835\n",
      "Epoch 14: val_loss improved from 1.39777 to 1.39221, saving model to ./checkpoints/unknown_person_few_shot_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 649us/sample - loss: 10.0835 - val_loss: 1.3922\n",
      "Epoch 15/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0637\n",
      "Epoch 15: val_loss did not improve from 1.39221\n",
      "31873/31873 [==============================] - 20s 634us/sample - loss: 10.0637 - val_loss: 1.3930\n",
      "Epoch 16/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0684\n",
      "Epoch 16: val_loss did not improve from 1.39221\n",
      "31873/31873 [==============================] - 23s 708us/sample - loss: 10.0684 - val_loss: 1.3993\n",
      "Epoch 17/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0598\n",
      "Epoch 17: val_loss did not improve from 1.39221\n",
      "31873/31873 [==============================] - 21s 647us/sample - loss: 10.0598 - val_loss: 1.4068\n",
      "Epoch 18/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0882\n",
      "Epoch 18: val_loss did not improve from 1.39221\n",
      "31873/31873 [==============================] - 22s 704us/sample - loss: 10.0882 - val_loss: 1.4125\n",
      "Epoch 19/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0573\n",
      "Epoch 19: val_loss did not improve from 1.39221\n",
      "31873/31873 [==============================] - 23s 716us/sample - loss: 10.0573 - val_loss: 1.4124\n",
      "Epoch 20/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.0415\n",
      "Epoch 20: val_loss did not improve from 1.39221\n",
      "31873/31873 [==============================] - 20s 622us/sample - loss: 10.0415 - val_loss: 1.3983\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:24:16.040986: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_173_2/lstm_cell_543/kernel/Assign' id:270208 op device:{requested: '', assigned: ''} def:{{{node lstm_173_2/lstm_cell_543/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_173_2/lstm_cell_543/kernel, lstm_173_2/lstm_cell_543/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:24:29.813170: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_164_2/lstm_cell_534/kernel/v/Assign' id:273701 op device:{requested: '', assigned: ''} def:{{{node lstm_164_2/lstm_cell_534/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_164_2/lstm_cell_534/kernel/v, lstm_164_2/lstm_cell_534/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31873 samples, validate on 3541 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:24:46.014148: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:25:58.376057: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:26:21.654139: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40001, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 49s 2ms/sample - loss: 1.4154 - val_loss: 1.4000\n",
      "Epoch 2/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4134\n",
      "Epoch 2: val_loss improved from 1.40001 to 1.39846, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 727us/sample - loss: 1.4134 - val_loss: 1.3985\n",
      "Epoch 3/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 3: val_loss improved from 1.39846 to 1.38096, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 664us/sample - loss: 1.4080 - val_loss: 1.3810\n",
      "Epoch 4/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4094\n",
      "Epoch 4: val_loss did not improve from 1.38096\n",
      "31873/31873 [==============================] - 22s 689us/sample - loss: 1.4094 - val_loss: 1.3861\n",
      "Epoch 5/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4052\n",
      "Epoch 5: val_loss improved from 1.38096 to 1.38093, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 663us/sample - loss: 1.4052 - val_loss: 1.3809\n",
      "Epoch 6/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4060\n",
      "Epoch 6: val_loss improved from 1.38093 to 1.38070, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 663us/sample - loss: 1.4060 - val_loss: 1.3807\n",
      "Epoch 7/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 7: val_loss did not improve from 1.38070\n",
      "31873/31873 [==============================] - 23s 710us/sample - loss: 1.4063 - val_loss: 1.3869\n",
      "Epoch 8/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4017\n",
      "Epoch 8: val_loss did not improve from 1.38070\n",
      "31873/31873 [==============================] - 20s 642us/sample - loss: 1.4017 - val_loss: 1.3847\n",
      "Epoch 9/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4020\n",
      "Epoch 9: val_loss improved from 1.38070 to 1.37493, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 709us/sample - loss: 1.4020 - val_loss: 1.3749\n",
      "Epoch 10/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 10: val_loss did not improve from 1.37493\n",
      "31873/31873 [==============================] - 23s 720us/sample - loss: 1.4008 - val_loss: 1.3811\n",
      "Epoch 11/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 11: val_loss did not improve from 1.37493\n",
      "31873/31873 [==============================] - 22s 698us/sample - loss: 1.3991 - val_loss: 1.3767\n",
      "Epoch 12/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3973\n",
      "Epoch 12: val_loss did not improve from 1.37493\n",
      "31873/31873 [==============================] - 23s 715us/sample - loss: 1.3973 - val_loss: 1.3757\n",
      "Epoch 13/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3967\n",
      "Epoch 13: val_loss did not improve from 1.37493\n",
      "31873/31873 [==============================] - 23s 722us/sample - loss: 1.3967 - val_loss: 1.3814\n",
      "Epoch 14/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3978\n",
      "Epoch 14: val_loss did not improve from 1.37493\n",
      "31873/31873 [==============================] - 23s 723us/sample - loss: 1.3978 - val_loss: 1.3806\n",
      "Epoch 15/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3941\n",
      "Epoch 15: val_loss improved from 1.37493 to 1.37423, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 23s 714us/sample - loss: 1.3941 - val_loss: 1.3742\n",
      "Epoch 16/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3900\n",
      "Epoch 16: val_loss did not improve from 1.37423\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.3900 - val_loss: 1.3861\n",
      "Epoch 17/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3908\n",
      "Epoch 17: val_loss did not improve from 1.37423\n",
      "31873/31873 [==============================] - 20s 643us/sample - loss: 1.3908 - val_loss: 1.3774\n",
      "Epoch 18/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 18: val_loss improved from 1.37423 to 1.37011, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 652us/sample - loss: 1.3936 - val_loss: 1.3701\n",
      "Epoch 19/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 19: val_loss improved from 1.37011 to 1.36458, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 650us/sample - loss: 1.3905 - val_loss: 1.3646\n",
      "Epoch 20/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3878\n",
      "Epoch 20: val_loss improved from 1.36458 to 1.36323, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_34.h5\n",
      "31873/31873 [==============================] - 21s 650us/sample - loss: 1.3878 - val_loss: 1.3632\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:33:46.763645: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_199/lstm_cell_569/recurrent_kernel/Assign' id:287558 op device:{requested: '', assigned: ''} def:{{{node lstm_199/lstm_cell_569/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_199/lstm_cell_569/recurrent_kernel, lstm_199/lstm_cell_569/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:33:54.368824: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_1' id:288846 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:34:00.427732: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_2' id:288847 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31873, 95)\n",
      "Train on 31873 samples, validate on 3541 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:34:17.840356: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_217/lstm_cell_587/bias/Assign' id:290766 op device:{requested: '', assigned: ''} def:{{{node lstm_217/lstm_cell_587/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_217/lstm_cell_587/bias, lstm_217/lstm_cell_587/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:35:34.738191: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 3.5451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:35:56.446727: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_31/mul' id:291687 op device:{requested: '', assigned: ''} def:{{{node loss_31/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_31/mul/x, loss_31/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.89344, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 90s 3ms/sample - loss: 3.5451 - val_loss: 1.8934\n",
      "Epoch 2/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.8498\n",
      "Epoch 2: val_loss improved from 1.89344 to 1.63933, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 21s 665us/sample - loss: 1.8498 - val_loss: 1.6393\n",
      "Epoch 3/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.6173\n",
      "Epoch 3: val_loss improved from 1.63933 to 1.55457, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 23s 716us/sample - loss: 1.6173 - val_loss: 1.5546\n",
      "Epoch 4/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5497\n",
      "Epoch 4: val_loss improved from 1.55457 to 1.52182, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 22s 699us/sample - loss: 1.5497 - val_loss: 1.5218\n",
      "Epoch 5/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5229\n",
      "Epoch 5: val_loss improved from 1.52182 to 1.49453, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.5229 - val_loss: 1.4945\n",
      "Epoch 6/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5088\n",
      "Epoch 6: val_loss improved from 1.49453 to 1.48916, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 21s 649us/sample - loss: 1.5088 - val_loss: 1.4892\n",
      "Epoch 7/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4954\n",
      "Epoch 7: val_loss improved from 1.48916 to 1.47280, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 619us/sample - loss: 1.4954 - val_loss: 1.4728\n",
      "Epoch 8/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4973\n",
      "Epoch 8: val_loss did not improve from 1.47280\n",
      "31873/31873 [==============================] - 20s 618us/sample - loss: 1.4973 - val_loss: 1.4770\n",
      "Epoch 9/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4945\n",
      "Epoch 9: val_loss did not improve from 1.47280\n",
      "31873/31873 [==============================] - 20s 626us/sample - loss: 1.4945 - val_loss: 1.4731\n",
      "Epoch 10/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4858\n",
      "Epoch 10: val_loss improved from 1.47280 to 1.45291, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 635us/sample - loss: 1.4858 - val_loss: 1.4529\n",
      "Epoch 11/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4990\n",
      "Epoch 11: val_loss did not improve from 1.45291\n",
      "31873/31873 [==============================] - 20s 629us/sample - loss: 1.4990 - val_loss: 1.4571\n",
      "Epoch 12/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4926\n",
      "Epoch 12: val_loss did not improve from 1.45291\n",
      "31873/31873 [==============================] - 20s 628us/sample - loss: 1.4926 - val_loss: 1.4721\n",
      "Epoch 13/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5133\n",
      "Epoch 13: val_loss improved from 1.45291 to 1.44738, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 22s 683us/sample - loss: 1.5133 - val_loss: 1.4474\n",
      "Epoch 14/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5312\n",
      "Epoch 14: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 22s 694us/sample - loss: 1.5312 - val_loss: 1.4654\n",
      "Epoch 15/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5792\n",
      "Epoch 15: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 22s 701us/sample - loss: 1.5792 - val_loss: 1.4688\n",
      "Epoch 16/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5596\n",
      "Epoch 16: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 19s 607us/sample - loss: 1.5596 - val_loss: 1.4559\n",
      "Epoch 17/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5122\n",
      "Epoch 17: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 19s 606us/sample - loss: 1.5122 - val_loss: 1.4518\n",
      "Epoch 18/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5216\n",
      "Epoch 18: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 19s 606us/sample - loss: 1.5216 - val_loss: 1.4588\n",
      "Epoch 19/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5424\n",
      "Epoch 19: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 19s 605us/sample - loss: 1.5424 - val_loss: 1.4709\n",
      "Epoch 20/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5192\n",
      "Epoch 20: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 716us/sample - loss: 1.5192 - val_loss: 1.4653\n",
      "Epoch 21/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5332\n",
      "Epoch 21: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 713us/sample - loss: 1.5332 - val_loss: 1.4758\n",
      "Epoch 22/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5775\n",
      "Epoch 22: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 712us/sample - loss: 1.5775 - val_loss: 1.4811\n",
      "Epoch 23/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5450\n",
      "Epoch 23: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 709us/sample - loss: 1.5450 - val_loss: 1.4819\n",
      "Epoch 24/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.5041\n",
      "Epoch 24: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 715us/sample - loss: 1.5041 - val_loss: 1.4622\n",
      "Epoch 25/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4872\n",
      "Epoch 25: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 711us/sample - loss: 1.4872 - val_loss: 1.4547\n",
      "Epoch 26/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4851\n",
      "Epoch 26: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 714us/sample - loss: 1.4851 - val_loss: 1.4535\n",
      "Epoch 27/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4724\n",
      "Epoch 27: val_loss did not improve from 1.44738\n",
      "31873/31873 [==============================] - 23s 714us/sample - loss: 1.4724 - val_loss: 1.4478\n",
      "Epoch 28/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4750\n",
      "Epoch 28: val_loss improved from 1.44738 to 1.43604, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 23s 721us/sample - loss: 1.4750 - val_loss: 1.4360\n",
      "Epoch 29/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4699\n",
      "Epoch 29: val_loss did not improve from 1.43604\n",
      "31873/31873 [==============================] - 20s 642us/sample - loss: 1.4699 - val_loss: 1.4513\n",
      "Epoch 30/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 30: val_loss did not improve from 1.43604\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4658 - val_loss: 1.4411\n",
      "Epoch 31/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4588\n",
      "Epoch 31: val_loss did not improve from 1.43604\n",
      "31873/31873 [==============================] - 20s 633us/sample - loss: 1.4588 - val_loss: 1.4378\n",
      "Epoch 32/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4573\n",
      "Epoch 32: val_loss improved from 1.43604 to 1.42999, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 639us/sample - loss: 1.4573 - val_loss: 1.4300\n",
      "Epoch 33/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4565\n",
      "Epoch 33: val_loss improved from 1.42999 to 1.42904, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 624us/sample - loss: 1.4565 - val_loss: 1.4290\n",
      "Epoch 34/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4518\n",
      "Epoch 34: val_loss improved from 1.42904 to 1.42825, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 621us/sample - loss: 1.4518 - val_loss: 1.4283\n",
      "Epoch 35/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4497\n",
      "Epoch 35: val_loss improved from 1.42825 to 1.42488, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 615us/sample - loss: 1.4497 - val_loss: 1.4249\n",
      "Epoch 36/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4500\n",
      "Epoch 36: val_loss did not improve from 1.42488\n",
      "31873/31873 [==============================] - 19s 607us/sample - loss: 1.4500 - val_loss: 1.4321\n",
      "Epoch 37/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4489\n",
      "Epoch 37: val_loss improved from 1.42488 to 1.41612, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 614us/sample - loss: 1.4489 - val_loss: 1.4161\n",
      "Epoch 38/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4442\n",
      "Epoch 38: val_loss improved from 1.41612 to 1.41402, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 21s 672us/sample - loss: 1.4442 - val_loss: 1.4140\n",
      "Epoch 39/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4465\n",
      "Epoch 39: val_loss did not improve from 1.41402\n",
      "31873/31873 [==============================] - 22s 689us/sample - loss: 1.4465 - val_loss: 1.4180\n",
      "Epoch 40/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4392\n",
      "Epoch 40: val_loss did not improve from 1.41402\n",
      "31873/31873 [==============================] - 20s 635us/sample - loss: 1.4392 - val_loss: 1.4151\n",
      "Epoch 41/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4386\n",
      "Epoch 41: val_loss did not improve from 1.41402\n",
      "31873/31873 [==============================] - 21s 671us/sample - loss: 1.4386 - val_loss: 1.4185\n",
      "Epoch 42/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4384\n",
      "Epoch 42: val_loss did not improve from 1.41402\n",
      "31873/31873 [==============================] - 23s 714us/sample - loss: 1.4384 - val_loss: 1.4160\n",
      "Epoch 43/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 43: val_loss improved from 1.41402 to 1.41120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 23s 713us/sample - loss: 1.4375 - val_loss: 1.4112\n",
      "Epoch 44/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 44: val_loss improved from 1.41120 to 1.41097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 22s 692us/sample - loss: 1.4312 - val_loss: 1.4110\n",
      "Epoch 45/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4336\n",
      "Epoch 45: val_loss improved from 1.41097 to 1.40804, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 22s 685us/sample - loss: 1.4336 - val_loss: 1.4080\n",
      "Epoch 46/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 46: val_loss did not improve from 1.40804\n",
      "31873/31873 [==============================] - 20s 616us/sample - loss: 1.4311 - val_loss: 1.4101\n",
      "Epoch 47/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4298\n",
      "Epoch 47: val_loss did not improve from 1.40804\n",
      "31873/31873 [==============================] - 19s 609us/sample - loss: 1.4298 - val_loss: 1.4089\n",
      "Epoch 48/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4282\n",
      "Epoch 48: val_loss improved from 1.40804 to 1.40505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 614us/sample - loss: 1.4282 - val_loss: 1.4051\n",
      "Epoch 49/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4259\n",
      "Epoch 49: val_loss did not improve from 1.40505\n",
      "31873/31873 [==============================] - 19s 608us/sample - loss: 1.4259 - val_loss: 1.4051\n",
      "Epoch 50/50\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 50: val_loss did not improve from 1.40505\n",
      "31873/31873 [==============================] - 19s 608us/sample - loss: 1.4237 - val_loss: 1.4120\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:54:17.869557: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_199_1/lstm_cell_606/kernel/Assign' id:306090 op device:{requested: '', assigned: ''} def:{{{node lstm_199_1/lstm_cell_606/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_199_1/lstm_cell_606/kernel, lstm_199_1/lstm_cell_606/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:54:33.518258: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_195_1/lstm_cell_602/kernel/v/Assign' id:311255 op device:{requested: '', assigned: ''} def:{{{node lstm_195_1/lstm_cell_602/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_195_1/lstm_cell_602/kernel/v, lstm_195_1/lstm_cell_602/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 13:54:48.976398: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_29_1/cond/Merge' id:309801 op device:{requested: '', assigned: ''} def:{{{node dropout_29_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_29_1/cond/Identity, dropout_29_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1587)\n",
      "(1514, 1587)\n",
      "(1644, 1587)\n",
      "(1764, 1587)\n",
      "(1836, 1587)\n",
      "(1699, 1587)\n",
      "(1369, 1587)\n",
      "(1594, 1587)\n",
      "(1764, 1587)\n",
      "(1560, 1587)\n",
      "(1896, 1587)\n",
      "(1727, 1587)\n",
      "(1800, 1587)\n",
      "(1824, 1587)\n",
      "(1728, 1587)\n",
      "(1824, 1587)\n",
      "(946, 1587)\n",
      "(1692, 1587)\n",
      "(1848, 1587)\n",
      "{1: 7.248705934476945, 2: 4.2647659992091995, 4: 9.19351737248351, 5: 7.6133735344764295, 6: 7.153978019883338, 8: 9.038061432532787, 9: 4.664863110471144, 11: 6.300035804948037, 12: 9.38001349769264, 13: 8.074706766491206, 17: 9.285784018886465, 19: 8.805189527954262, 21: 10.0, 22: 1.0, 25: 8.02301820256585, 26: 7.238420383576605, 27: 3.861531447176754, 28: 7.4848427866553155, 29: 2.8945428364988945}\n",
      "Train on 31873 samples, validate on 3541 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:59:45.416659: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 11.1062\n",
      "Epoch 1: val_loss improved from inf to 1.43338, saving model to ./checkpoints/unknown_person_few_shot_p10_35.h5\n",
      "31873/31873 [==============================] - 51s 2ms/sample - loss: 11.1062 - val_loss: 1.4334\n",
      "Epoch 2/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.9852\n",
      "Epoch 2: val_loss did not improve from 1.43338\n",
      "31873/31873 [==============================] - 20s 627us/sample - loss: 10.9852 - val_loss: 1.4681\n",
      "Epoch 3/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 11.0141\n",
      "Epoch 3: val_loss did not improve from 1.43338\n",
      "31873/31873 [==============================] - 20s 625us/sample - loss: 11.0141 - val_loss: 1.4413\n",
      "Epoch 4/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.9558\n",
      "Epoch 4: val_loss improved from 1.43338 to 1.39878, saving model to ./checkpoints/unknown_person_few_shot_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 630us/sample - loss: 10.9558 - val_loss: 1.3988\n",
      "Epoch 5/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.9114\n",
      "Epoch 5: val_loss did not improve from 1.39878\n",
      "31873/31873 [==============================] - 20s 627us/sample - loss: 10.9114 - val_loss: 1.4291\n",
      "Epoch 6/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.8676\n",
      "Epoch 6: val_loss did not improve from 1.39878\n",
      "31873/31873 [==============================] - 20s 628us/sample - loss: 10.8676 - val_loss: 1.4218\n",
      "Epoch 7/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.8488\n",
      "Epoch 7: val_loss did not improve from 1.39878\n",
      "31873/31873 [==============================] - 20s 622us/sample - loss: 10.8488 - val_loss: 1.4091\n",
      "Epoch 8/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.8231\n",
      "Epoch 8: val_loss did not improve from 1.39878\n",
      "31873/31873 [==============================] - 20s 617us/sample - loss: 10.8231 - val_loss: 1.4200\n",
      "Epoch 9/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7934\n",
      "Epoch 9: val_loss did not improve from 1.39878\n",
      "31873/31873 [==============================] - 20s 618us/sample - loss: 10.7934 - val_loss: 1.4079\n",
      "Epoch 10/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7872\n",
      "Epoch 10: val_loss improved from 1.39878 to 1.39598, saving model to ./checkpoints/unknown_person_few_shot_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 624us/sample - loss: 10.7872 - val_loss: 1.3960\n",
      "Epoch 11/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7590\n",
      "Epoch 11: val_loss improved from 1.39598 to 1.39560, saving model to ./checkpoints/unknown_person_few_shot_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 622us/sample - loss: 10.7590 - val_loss: 1.3956\n",
      "Epoch 12/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7600\n",
      "Epoch 12: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 22s 696us/sample - loss: 10.7600 - val_loss: 1.4151\n",
      "Epoch 13/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7245\n",
      "Epoch 13: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 22s 685us/sample - loss: 10.7245 - val_loss: 1.4123\n",
      "Epoch 14/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7074\n",
      "Epoch 14: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 21s 664us/sample - loss: 10.7074 - val_loss: 1.4085\n",
      "Epoch 15/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7239\n",
      "Epoch 15: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 23s 717us/sample - loss: 10.7239 - val_loss: 1.4250\n",
      "Epoch 16/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.7137\n",
      "Epoch 16: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 21s 651us/sample - loss: 10.7137 - val_loss: 1.4076\n",
      "Epoch 17/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6789\n",
      "Epoch 17: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 21s 645us/sample - loss: 10.6789 - val_loss: 1.3984\n",
      "Epoch 18/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6586\n",
      "Epoch 18: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 23s 721us/sample - loss: 10.6586 - val_loss: 1.4082\n",
      "Epoch 19/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6637\n",
      "Epoch 19: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 23s 726us/sample - loss: 10.6637 - val_loss: 1.4004\n",
      "Epoch 20/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 10.6538\n",
      "Epoch 20: val_loss did not improve from 1.39560\n",
      "31873/31873 [==============================] - 21s 656us/sample - loss: 10.6538 - val_loss: 1.4053\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:07:18.246214: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_207_2/lstm_cell_651/bias/Assign' id:326799 op device:{requested: '', assigned: ''} def:{{{node lstm_207_2/lstm_cell_651/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_207_2/lstm_cell_651/bias, lstm_207_2/lstm_cell_651/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 14:07:34.882188: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_205_2/lstm_cell_649/bias/m/Assign' id:330170 op device:{requested: '', assigned: ''} def:{{{node lstm_205_2/lstm_cell_649/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_205_2/lstm_cell_649/bias/m, lstm_205_2/lstm_cell_649/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31873 samples, validate on 3541 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:07:54.128196: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:09:50.191174: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:10:14.804267: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40369, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 55s 2ms/sample - loss: 1.4263 - val_loss: 1.4037\n",
      "Epoch 2/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4239\n",
      "Epoch 2: val_loss did not improve from 1.40369\n",
      "31873/31873 [==============================] - 23s 724us/sample - loss: 1.4239 - val_loss: 1.4065\n",
      "Epoch 3/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 3: val_loss did not improve from 1.40369\n",
      "31873/31873 [==============================] - 23s 724us/sample - loss: 1.4225 - val_loss: 1.4076\n",
      "Epoch 4/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 4: val_loss improved from 1.40369 to 1.39701, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 21s 645us/sample - loss: 1.4212 - val_loss: 1.3970\n",
      "Epoch 5/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4196\n",
      "Epoch 5: val_loss improved from 1.39701 to 1.39549, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 639us/sample - loss: 1.4196 - val_loss: 1.3955\n",
      "Epoch 6/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 6: val_loss did not improve from 1.39549\n",
      "31873/31873 [==============================] - 20s 637us/sample - loss: 1.4163 - val_loss: 1.4006\n",
      "Epoch 7/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4170\n",
      "Epoch 7: val_loss did not improve from 1.39549\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4170 - val_loss: 1.4079\n",
      "Epoch 8/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4154\n",
      "Epoch 8: val_loss did not improve from 1.39549\n",
      "31873/31873 [==============================] - 21s 672us/sample - loss: 1.4154 - val_loss: 1.3993\n",
      "Epoch 9/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 9: val_loss did not improve from 1.39549\n",
      "31873/31873 [==============================] - 23s 724us/sample - loss: 1.4155 - val_loss: 1.4014\n",
      "Epoch 10/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4130\n",
      "Epoch 10: val_loss improved from 1.39549 to 1.39282, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 23s 731us/sample - loss: 1.4130 - val_loss: 1.3928\n",
      "Epoch 11/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4104\n",
      "Epoch 11: val_loss improved from 1.39282 to 1.39226, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 22s 681us/sample - loss: 1.4104 - val_loss: 1.3923\n",
      "Epoch 12/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4094\n",
      "Epoch 12: val_loss improved from 1.39226 to 1.38889, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 639us/sample - loss: 1.4094 - val_loss: 1.3889\n",
      "Epoch 13/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 13: val_loss did not improve from 1.38889\n",
      "31873/31873 [==============================] - 20s 628us/sample - loss: 1.4069 - val_loss: 1.3913\n",
      "Epoch 14/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 14: val_loss improved from 1.38889 to 1.38888, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 631us/sample - loss: 1.4063 - val_loss: 1.3889\n",
      "Epoch 15/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 15: val_loss did not improve from 1.38888\n",
      "31873/31873 [==============================] - 20s 635us/sample - loss: 1.4065 - val_loss: 1.3950\n",
      "Epoch 16/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4044\n",
      "Epoch 16: val_loss did not improve from 1.38888\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.4044 - val_loss: 1.3929\n",
      "Epoch 17/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 17: val_loss did not improve from 1.38888\n",
      "31873/31873 [==============================] - 20s 636us/sample - loss: 1.4067 - val_loss: 1.3895\n",
      "Epoch 18/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4025\n",
      "Epoch 18: val_loss improved from 1.38888 to 1.38694, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 638us/sample - loss: 1.4025 - val_loss: 1.3869\n",
      "Epoch 19/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.4021\n",
      "Epoch 19: val_loss improved from 1.38694 to 1.38157, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 639us/sample - loss: 1.4021 - val_loss: 1.3816\n",
      "Epoch 20/20\n",
      "31873/31873 [==============================] - ETA: 0s - loss: 1.3989\n",
      "Epoch 20: val_loss improved from 1.38157 to 1.37717, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_35.h5\n",
      "31873/31873 [==============================] - 20s 634us/sample - loss: 1.3989 - val_loss: 1.3772\n",
      "35607\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:17:36.358403: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_242/lstm_cell_686/kernel/Assign' id:345570 op device:{requested: '', assigned: ''} def:{{{node lstm_242/lstm_cell_686/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_242/lstm_cell_686/kernel, lstm_242/lstm_cell_686/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 14:17:45.654455: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_1' id:345888 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 14:17:53.082363: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_2' id:345889 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32032, 95)\n",
      "Train on 32032 samples, validate on 3575 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:18:13.543122: W tensorflow/c/c_api.cc:304] Operation '{name:'training_36/Adam/lstm_244/lstm_cell_688/kernel/m/Assign' id:358976 op device:{requested: '', assigned: ''} def:{{{node training_36/Adam/lstm_244/lstm_cell_688/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_36/Adam/lstm_244/lstm_cell_688/kernel/m, training_36/Adam/lstm_244/lstm_cell_688/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:19:48.331377: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 3.1534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-22 14:20:10.746041: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_37/mul' id:348729 op device:{requested: '', assigned: ''} def:{{{node loss_37/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_37/mul/x, loss_37/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.74906, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 107s 3ms/sample - loss: 3.1534 - val_loss: 1.7491\n",
      "Epoch 2/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.7575\n",
      "Epoch 2: val_loss improved from 1.74906 to 1.54237, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 1.7575 - val_loss: 1.5424\n",
      "Epoch 3/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.6011\n",
      "Epoch 3: val_loss improved from 1.54237 to 1.48505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 725us/sample - loss: 1.6011 - val_loss: 1.4851\n",
      "Epoch 4/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5558\n",
      "Epoch 4: val_loss improved from 1.48505 to 1.46355, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.5558 - val_loss: 1.4635\n",
      "Epoch 5/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5256\n",
      "Epoch 5: val_loss improved from 1.46355 to 1.44790, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 22s 681us/sample - loss: 1.5256 - val_loss: 1.4479\n",
      "Epoch 6/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5134\n",
      "Epoch 6: val_loss improved from 1.44790 to 1.43817, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 633us/sample - loss: 1.5134 - val_loss: 1.4382\n",
      "Epoch 7/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5007\n",
      "Epoch 7: val_loss improved from 1.43817 to 1.43609, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 634us/sample - loss: 1.5007 - val_loss: 1.4361\n",
      "Epoch 8/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4970\n",
      "Epoch 8: val_loss improved from 1.43609 to 1.42912, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 631us/sample - loss: 1.4970 - val_loss: 1.4291\n",
      "Epoch 9/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4926\n",
      "Epoch 9: val_loss improved from 1.42912 to 1.42102, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 21s 641us/sample - loss: 1.4926 - val_loss: 1.4210\n",
      "Epoch 10/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4843\n",
      "Epoch 10: val_loss did not improve from 1.42102\n",
      "32032/32032 [==============================] - 20s 640us/sample - loss: 1.4843 - val_loss: 1.4229\n",
      "Epoch 11/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5029\n",
      "Epoch 11: val_loss improved from 1.42102 to 1.41999, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 1.5029 - val_loss: 1.4200\n",
      "Epoch 12/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5380\n",
      "Epoch 12: val_loss improved from 1.41999 to 1.41773, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 725us/sample - loss: 1.5380 - val_loss: 1.4177\n",
      "Epoch 13/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4835\n",
      "Epoch 13: val_loss improved from 1.41773 to 1.41384, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 702us/sample - loss: 1.4835 - val_loss: 1.4138\n",
      "Epoch 14/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4744\n",
      "Epoch 14: val_loss improved from 1.41384 to 1.40663, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 1.4744 - val_loss: 1.4066\n",
      "Epoch 15/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 15: val_loss did not improve from 1.40663\n",
      "32032/32032 [==============================] - 20s 635us/sample - loss: 1.4794 - val_loss: 1.4090\n",
      "Epoch 16/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4721\n",
      "Epoch 16: val_loss improved from 1.40663 to 1.40474, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 21s 643us/sample - loss: 1.4721 - val_loss: 1.4047\n",
      "Epoch 17/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4680\n",
      "Epoch 17: val_loss improved from 1.40474 to 1.40277, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 1.4680 - val_loss: 1.4028\n",
      "Epoch 18/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4701\n",
      "Epoch 18: val_loss improved from 1.40277 to 1.39950, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 637us/sample - loss: 1.4701 - val_loss: 1.3995\n",
      "Epoch 19/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4661\n",
      "Epoch 19: val_loss did not improve from 1.39950\n",
      "32032/32032 [==============================] - 20s 631us/sample - loss: 1.4661 - val_loss: 1.4004\n",
      "Epoch 20/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5278\n",
      "Epoch 20: val_loss did not improve from 1.39950\n",
      "32032/32032 [==============================] - 20s 635us/sample - loss: 1.5278 - val_loss: 1.4022\n",
      "Epoch 21/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4896\n",
      "Epoch 21: val_loss did not improve from 1.39950\n",
      "32032/32032 [==============================] - 21s 646us/sample - loss: 1.4896 - val_loss: 1.4005\n",
      "Epoch 22/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4675\n",
      "Epoch 22: val_loss improved from 1.39950 to 1.39717, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 722us/sample - loss: 1.4675 - val_loss: 1.3972\n",
      "Epoch 23/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 23: val_loss did not improve from 1.39717\n",
      "32032/32032 [==============================] - 20s 639us/sample - loss: 1.4623 - val_loss: 1.3972\n",
      "Epoch 24/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4544\n",
      "Epoch 24: val_loss improved from 1.39717 to 1.39210, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 718us/sample - loss: 1.4544 - val_loss: 1.3921\n",
      "Epoch 25/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4485\n",
      "Epoch 25: val_loss did not improve from 1.39210\n",
      "32032/32032 [==============================] - 22s 687us/sample - loss: 1.4485 - val_loss: 1.3921\n",
      "Epoch 26/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4482\n",
      "Epoch 26: val_loss improved from 1.39210 to 1.38898, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 21s 640us/sample - loss: 1.4482 - val_loss: 1.3890\n",
      "Epoch 27/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 27: val_loss improved from 1.38898 to 1.38564, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 640us/sample - loss: 1.4432 - val_loss: 1.3856\n",
      "Epoch 28/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4413\n",
      "Epoch 28: val_loss did not improve from 1.38564\n",
      "32032/32032 [==============================] - 21s 654us/sample - loss: 1.4413 - val_loss: 1.3864\n",
      "Epoch 29/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4360\n",
      "Epoch 29: val_loss improved from 1.38564 to 1.38434, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 1.4360 - val_loss: 1.3843\n",
      "Epoch 30/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4331\n",
      "Epoch 30: val_loss did not improve from 1.38434\n",
      "32032/32032 [==============================] - 23s 718us/sample - loss: 1.4331 - val_loss: 1.3859\n",
      "Epoch 31/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 31: val_loss improved from 1.38434 to 1.37868, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 714us/sample - loss: 1.4330 - val_loss: 1.3787\n",
      "Epoch 32/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4316\n",
      "Epoch 32: val_loss did not improve from 1.37868\n",
      "32032/32032 [==============================] - 22s 690us/sample - loss: 1.4316 - val_loss: 1.3808\n",
      "Epoch 33/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4261\n",
      "Epoch 33: val_loss improved from 1.37868 to 1.37587, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 729us/sample - loss: 1.4261 - val_loss: 1.3759\n",
      "Epoch 34/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4289\n",
      "Epoch 34: val_loss did not improve from 1.37587\n",
      "32032/32032 [==============================] - 22s 694us/sample - loss: 1.4289 - val_loss: 1.3773\n",
      "Epoch 35/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 35: val_loss did not improve from 1.37587\n",
      "32032/32032 [==============================] - 20s 629us/sample - loss: 1.4266 - val_loss: 1.3761\n",
      "Epoch 36/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4239\n",
      "Epoch 36: val_loss improved from 1.37587 to 1.37426, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 630us/sample - loss: 1.4239 - val_loss: 1.3743\n",
      "Epoch 37/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 37: val_loss did not improve from 1.37426\n",
      "32032/32032 [==============================] - 21s 663us/sample - loss: 1.4220 - val_loss: 1.3777\n",
      "Epoch 38/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4197\n",
      "Epoch 38: val_loss improved from 1.37426 to 1.37226, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 728us/sample - loss: 1.4197 - val_loss: 1.3723\n",
      "Epoch 39/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 39: val_loss did not improve from 1.37226\n",
      "32032/32032 [==============================] - 22s 700us/sample - loss: 1.4166 - val_loss: 1.3749\n",
      "Epoch 40/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4147\n",
      "Epoch 40: val_loss did not improve from 1.37226\n",
      "32032/32032 [==============================] - 20s 633us/sample - loss: 1.4147 - val_loss: 1.3737\n",
      "Epoch 41/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 41: val_loss improved from 1.37226 to 1.36797, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 635us/sample - loss: 1.4145 - val_loss: 1.3680\n",
      "Epoch 42/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4125\n",
      "Epoch 42: val_loss did not improve from 1.36797\n",
      "32032/32032 [==============================] - 20s 637us/sample - loss: 1.4125 - val_loss: 1.3768\n",
      "Epoch 43/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 43: val_loss improved from 1.36797 to 1.36549, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 636us/sample - loss: 1.4123 - val_loss: 1.3655\n",
      "Epoch 44/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4068\n",
      "Epoch 44: val_loss improved from 1.36549 to 1.36523, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 632us/sample - loss: 1.4068 - val_loss: 1.3652\n",
      "Epoch 45/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 45: val_loss improved from 1.36523 to 1.36465, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 633us/sample - loss: 1.4083 - val_loss: 1.3647\n",
      "Epoch 46/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4079\n",
      "Epoch 46: val_loss improved from 1.36465 to 1.36335, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 639us/sample - loss: 1.4079 - val_loss: 1.3634\n",
      "Epoch 47/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4038\n",
      "Epoch 47: val_loss improved from 1.36335 to 1.36251, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 727us/sample - loss: 1.4038 - val_loss: 1.3625\n",
      "Epoch 48/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 48: val_loss did not improve from 1.36251\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 1.4045 - val_loss: 1.3659\n",
      "Epoch 49/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4013\n",
      "Epoch 49: val_loss improved from 1.36251 to 1.35871, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 725us/sample - loss: 1.4013 - val_loss: 1.3587\n",
      "Epoch 50/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3989\n",
      "Epoch 50: val_loss did not improve from 1.35871\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.3989 - val_loss: 1.3653\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:39:18.384236: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_236_1/lstm_cell_717/bias/Assign' id:363161 op device:{requested: '', assigned: ''} def:{{{node lstm_236_1/lstm_cell_717/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_236_1/lstm_cell_717/bias, lstm_236_1/lstm_cell_717/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 14:39:37.730973: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_224_1/lstm_cell_705/bias/m/Assign' id:367544 op device:{requested: '', assigned: ''} def:{{{node lstm_224_1/lstm_cell_705/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_224_1/lstm_cell_705/bias/m, lstm_224_1/lstm_cell_705/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-22 14:39:56.816589: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_34_1/cond/Merge' id:366843 op device:{requested: '', assigned: ''} def:{{{node dropout_34_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_34_1/cond/Identity, dropout_34_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1394)\n",
      "(1514, 1394)\n",
      "(1644, 1394)\n",
      "(1764, 1394)\n",
      "(1836, 1394)\n",
      "(1699, 1394)\n",
      "(1369, 1394)\n",
      "(1606, 1394)\n",
      "(1752, 1394)\n",
      "(1502, 1394)\n",
      "(1932, 1394)\n",
      "(1715, 1394)\n",
      "(1776, 1394)\n",
      "(1860, 1394)\n",
      "(1740, 1394)\n",
      "(1812, 1394)\n",
      "(946, 1394)\n",
      "(1680, 1394)\n",
      "(1872, 1394)\n",
      "{1: 6.670165425221871, 2: 3.840497166293613, 4: 9.435214878119345, 5: 7.816463805880426, 6: 6.8151916941392185, 8: 9.488848196777862, 9: 5.212766420766542, 11: 6.879451714193903, 12: 9.33866619412303, 13: 7.892704788848001, 17: 9.352324948103348, 19: 8.892672412849516, 21: 10.0, 22: 1.0, 25: 7.761109144099578, 26: 6.063684395540684, 27: 3.877754912308859, 28: 7.058846776151309, 29: 3.1167740048153827}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916958/459382369.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32032 samples, validate on 3575 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:45:47.154860: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 11.1124\n",
      "Epoch 1: val_loss improved from inf to 1.38395, saving model to ./checkpoints/unknown_person_few_shot_p10_36.h5\n",
      "32032/32032 [==============================] - 59s 2ms/sample - loss: 11.1124 - val_loss: 1.3839\n",
      "Epoch 2/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 11.0252\n",
      "Epoch 2: val_loss improved from 1.38395 to 1.37786, saving model to ./checkpoints/unknown_person_few_shot_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 731us/sample - loss: 11.0252 - val_loss: 1.3779\n",
      "Epoch 3/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.9985\n",
      "Epoch 3: val_loss improved from 1.37786 to 1.36827, saving model to ./checkpoints/unknown_person_few_shot_p10_36.h5\n",
      "32032/32032 [==============================] - 22s 701us/sample - loss: 10.9985 - val_loss: 1.3683\n",
      "Epoch 4/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.9010\n",
      "Epoch 4: val_loss did not improve from 1.36827\n",
      "32032/32032 [==============================] - 21s 647us/sample - loss: 10.9010 - val_loss: 1.3689\n",
      "Epoch 5/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8736\n",
      "Epoch 5: val_loss did not improve from 1.36827\n",
      "32032/32032 [==============================] - 22s 678us/sample - loss: 10.8736 - val_loss: 1.3823\n",
      "Epoch 6/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8696\n",
      "Epoch 6: val_loss improved from 1.36827 to 1.36185, saving model to ./checkpoints/unknown_person_few_shot_p10_36.h5\n",
      "32032/32032 [==============================] - 24s 735us/sample - loss: 10.8696 - val_loss: 1.3618\n",
      "Epoch 7/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8496\n",
      "Epoch 7: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 22s 702us/sample - loss: 10.8496 - val_loss: 1.3624\n",
      "Epoch 8/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8000\n",
      "Epoch 8: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 715us/sample - loss: 10.8000 - val_loss: 1.3674\n",
      "Epoch 9/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8344\n",
      "Epoch 9: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 10.8344 - val_loss: 1.3768\n",
      "Epoch 10/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7694\n",
      "Epoch 10: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 22s 697us/sample - loss: 10.7694 - val_loss: 1.3689\n",
      "Epoch 11/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7676\n",
      "Epoch 11: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 21s 647us/sample - loss: 10.7676 - val_loss: 1.3655\n",
      "Epoch 12/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7243\n",
      "Epoch 12: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 715us/sample - loss: 10.7243 - val_loss: 1.3664\n",
      "Epoch 13/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7171\n",
      "Epoch 13: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 10.7171 - val_loss: 1.3636\n",
      "Epoch 14/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7147\n",
      "Epoch 14: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 715us/sample - loss: 10.7147 - val_loss: 1.3644\n",
      "Epoch 15/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7111\n",
      "Epoch 15: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 10.7111 - val_loss: 1.3673\n",
      "Epoch 16/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6860\n",
      "Epoch 16: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 718us/sample - loss: 10.6860 - val_loss: 1.3655\n",
      "Epoch 17/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6949\n",
      "Epoch 17: val_loss did not improve from 1.36185\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 10.6949 - val_loss: 1.3644\n",
      "Epoch 18/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6895\n",
      "Epoch 18: val_loss improved from 1.36185 to 1.35864, saving model to ./checkpoints/unknown_person_few_shot_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 726us/sample - loss: 10.6895 - val_loss: 1.3586\n",
      "Epoch 19/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6786\n",
      "Epoch 19: val_loss did not improve from 1.35864\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 10.6786 - val_loss: 1.3630\n",
      "Epoch 20/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6424\n",
      "Epoch 20: val_loss did not improve from 1.35864\n",
      "32032/32032 [==============================] - 23s 704us/sample - loss: 10.6424 - val_loss: 1.3596\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:54:04.535026: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_222_2/lstm_cell_740/recurrent_kernel/Assign' id:380310 op device:{requested: '', assigned: ''} def:{{{node lstm_222_2/lstm_cell_740/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_222_2/lstm_cell_740/recurrent_kernel, lstm_222_2/lstm_cell_740/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 14:54:24.215279: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_258_2/lstm_cell_776/bias/v/Assign' id:388095 op device:{requested: '', assigned: ''} def:{{{node lstm_258_2/lstm_cell_776/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_258_2/lstm_cell_776/bias/v, lstm_258_2/lstm_cell_776/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32032 samples, validate on 3575 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:54:46.396253: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:56:30.157147: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:56:55.030096: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36251, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 61s 2ms/sample - loss: 1.4003 - val_loss: 1.3625\n",
      "Epoch 2/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 2: val_loss did not improve from 1.36251\n",
      "32032/32032 [==============================] - 22s 698us/sample - loss: 1.3986 - val_loss: 1.3628\n",
      "Epoch 3/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 3: val_loss improved from 1.36251 to 1.36126, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 22s 680us/sample - loss: 1.3992 - val_loss: 1.3613\n",
      "Epoch 4/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 4: val_loss improved from 1.36126 to 1.35917, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 629us/sample - loss: 1.3949 - val_loss: 1.3592\n",
      "Epoch 5/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3968\n",
      "Epoch 5: val_loss improved from 1.35917 to 1.35721, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 632us/sample - loss: 1.3968 - val_loss: 1.3572\n",
      "Epoch 6/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3959\n",
      "Epoch 6: val_loss did not improve from 1.35721\n",
      "32032/32032 [==============================] - 21s 658us/sample - loss: 1.3959 - val_loss: 1.3609\n",
      "Epoch 7/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 7: val_loss did not improve from 1.35721\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 1.3948 - val_loss: 1.3680\n",
      "Epoch 8/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 8: val_loss improved from 1.35721 to 1.35456, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 22s 690us/sample - loss: 1.3914 - val_loss: 1.3546\n",
      "Epoch 9/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 9: val_loss did not improve from 1.35456\n",
      "32032/32032 [==============================] - 22s 672us/sample - loss: 1.3902 - val_loss: 1.3546\n",
      "Epoch 10/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3926\n",
      "Epoch 10: val_loss improved from 1.35456 to 1.35203, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 727us/sample - loss: 1.3926 - val_loss: 1.3520\n",
      "Epoch 11/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3886\n",
      "Epoch 11: val_loss did not improve from 1.35203\n",
      "32032/32032 [==============================] - 22s 690us/sample - loss: 1.3886 - val_loss: 1.3542\n",
      "Epoch 12/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3846\n",
      "Epoch 12: val_loss improved from 1.35203 to 1.35110, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 710us/sample - loss: 1.3846 - val_loss: 1.3511\n",
      "Epoch 13/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3849\n",
      "Epoch 13: val_loss improved from 1.35110 to 1.35051, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 21s 648us/sample - loss: 1.3849 - val_loss: 1.3505\n",
      "Epoch 14/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3832\n",
      "Epoch 14: val_loss improved from 1.35051 to 1.34847, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 20s 626us/sample - loss: 1.3832 - val_loss: 1.3485\n",
      "Epoch 15/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3833\n",
      "Epoch 15: val_loss improved from 1.34847 to 1.34706, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 711us/sample - loss: 1.3833 - val_loss: 1.3471\n",
      "Epoch 16/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3818\n",
      "Epoch 16: val_loss did not improve from 1.34706\n",
      "32032/32032 [==============================] - 23s 713us/sample - loss: 1.3818 - val_loss: 1.3507\n",
      "Epoch 17/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 17: val_loss improved from 1.34706 to 1.34615, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 724us/sample - loss: 1.3812 - val_loss: 1.3462\n",
      "Epoch 18/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 18: val_loss improved from 1.34615 to 1.34586, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 22s 698us/sample - loss: 1.3812 - val_loss: 1.3459\n",
      "Epoch 19/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3782\n",
      "Epoch 19: val_loss improved from 1.34586 to 1.34271, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_36.h5\n",
      "32032/32032 [==============================] - 23s 710us/sample - loss: 1.3782 - val_loss: 1.3427\n",
      "Epoch 20/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3773\n",
      "Epoch 20: val_loss did not improve from 1.34271\n",
      "32032/32032 [==============================] - 22s 689us/sample - loss: 1.3773 - val_loss: 1.3458\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:04:35.047070: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_273/lstm_cell_791/bias/Assign' id:401651 op device:{requested: '', assigned: ''} def:{{{node lstm_273/lstm_cell_791/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_273/lstm_cell_791/bias, lstm_273/lstm_cell_791/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:04:45.781109: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_1' id:402930 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:04:54.395879: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_2' id:402931 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32032, 95)\n",
      "Train on 32032 samples, validate on 3575 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:05:15.898391: W tensorflow/c/c_api.cc:304] Operation '{name:'training_42/Adam/lstm_287/lstm_cell_805/kernel/v/Assign' id:416751 op device:{requested: '', assigned: ''} def:{{{node training_42/Adam/lstm_287/lstm_cell_805/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_42/Adam/lstm_287/lstm_cell_805/kernel/v, training_42/Adam/lstm_287/lstm_cell_805/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:07:02.921621: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 3.3123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:07:25.908761: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_43/mul' id:405771 op device:{requested: '', assigned: ''} def:{{{node loss_43/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_43/mul/x, loss_43/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.79262, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 117s 4ms/sample - loss: 3.3123 - val_loss: 1.7926\n",
      "Epoch 2/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.7503\n",
      "Epoch 2: val_loss improved from 1.79262 to 1.53764, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 701us/sample - loss: 1.7503 - val_loss: 1.5376\n",
      "Epoch 3/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.6059\n",
      "Epoch 3: val_loss improved from 1.53764 to 1.48865, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 663us/sample - loss: 1.6059 - val_loss: 1.4886\n",
      "Epoch 4/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5634\n",
      "Epoch 4: val_loss improved from 1.48865 to 1.46782, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 643us/sample - loss: 1.5634 - val_loss: 1.4678\n",
      "Epoch 5/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5336\n",
      "Epoch 5: val_loss improved from 1.46782 to 1.45304, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 631us/sample - loss: 1.5336 - val_loss: 1.4530\n",
      "Epoch 6/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5166\n",
      "Epoch 6: val_loss improved from 1.45304 to 1.45225, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 626us/sample - loss: 1.5166 - val_loss: 1.4522\n",
      "Epoch 7/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5047\n",
      "Epoch 7: val_loss improved from 1.45225 to 1.43652, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 632us/sample - loss: 1.5047 - val_loss: 1.4365\n",
      "Epoch 8/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4974\n",
      "Epoch 8: val_loss improved from 1.43652 to 1.43008, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 628us/sample - loss: 1.4974 - val_loss: 1.4301\n",
      "Epoch 9/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4965\n",
      "Epoch 9: val_loss improved from 1.43008 to 1.42134, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 629us/sample - loss: 1.4965 - val_loss: 1.4213\n",
      "Epoch 10/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4931\n",
      "Epoch 10: val_loss did not improve from 1.42134\n",
      "32032/32032 [==============================] - 23s 719us/sample - loss: 1.4931 - val_loss: 1.4253\n",
      "Epoch 11/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5146\n",
      "Epoch 11: val_loss did not improve from 1.42134\n",
      "32032/32032 [==============================] - 21s 668us/sample - loss: 1.5146 - val_loss: 1.4251\n",
      "Epoch 12/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4871\n",
      "Epoch 12: val_loss improved from 1.42134 to 1.41839, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 649us/sample - loss: 1.4871 - val_loss: 1.4184\n",
      "Epoch 13/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4850\n",
      "Epoch 13: val_loss improved from 1.41839 to 1.41423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 653us/sample - loss: 1.4850 - val_loss: 1.4142\n",
      "Epoch 14/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 14: val_loss improved from 1.41423 to 1.41383, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 1.4829 - val_loss: 1.4138\n",
      "Epoch 15/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5181\n",
      "Epoch 15: val_loss improved from 1.41383 to 1.41355, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 636us/sample - loss: 1.5181 - val_loss: 1.4136\n",
      "Epoch 16/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5335\n",
      "Epoch 16: val_loss did not improve from 1.41355\n",
      "32032/32032 [==============================] - 20s 635us/sample - loss: 1.5335 - val_loss: 1.4204\n",
      "Epoch 17/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5267\n",
      "Epoch 17: val_loss improved from 1.41355 to 1.40786, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 641us/sample - loss: 1.5267 - val_loss: 1.4079\n",
      "Epoch 18/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5491\n",
      "Epoch 18: val_loss did not improve from 1.40786\n",
      "32032/32032 [==============================] - 20s 635us/sample - loss: 1.5491 - val_loss: 1.4126\n",
      "Epoch 19/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4922\n",
      "Epoch 19: val_loss improved from 1.40786 to 1.40673, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 653us/sample - loss: 1.4922 - val_loss: 1.4067\n",
      "Epoch 20/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4939\n",
      "Epoch 20: val_loss improved from 1.40673 to 1.40659, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 652us/sample - loss: 1.4939 - val_loss: 1.4066\n",
      "Epoch 21/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5274\n",
      "Epoch 21: val_loss did not improve from 1.40659\n",
      "32032/32032 [==============================] - 21s 647us/sample - loss: 1.5274 - val_loss: 1.4159\n",
      "Epoch 22/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4979\n",
      "Epoch 22: val_loss did not improve from 1.40659\n",
      "32032/32032 [==============================] - 23s 711us/sample - loss: 1.4979 - val_loss: 1.4153\n",
      "Epoch 23/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5646\n",
      "Epoch 23: val_loss did not improve from 1.40659\n",
      "32032/32032 [==============================] - 21s 653us/sample - loss: 1.5646 - val_loss: 1.4402\n",
      "Epoch 24/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4909\n",
      "Epoch 24: val_loss did not improve from 1.40659\n",
      "32032/32032 [==============================] - 23s 722us/sample - loss: 1.4909 - val_loss: 1.4133\n",
      "Epoch 25/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4720\n",
      "Epoch 25: val_loss did not improve from 1.40659\n",
      "32032/32032 [==============================] - 23s 714us/sample - loss: 1.4720 - val_loss: 1.4166\n",
      "Epoch 26/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4656\n",
      "Epoch 26: val_loss did not improve from 1.40659\n",
      "32032/32032 [==============================] - 23s 711us/sample - loss: 1.4656 - val_loss: 1.4117\n",
      "Epoch 27/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4592\n",
      "Epoch 27: val_loss improved from 1.40659 to 1.40617, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 700us/sample - loss: 1.4592 - val_loss: 1.4062\n",
      "Epoch 28/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4566\n",
      "Epoch 28: val_loss improved from 1.40617 to 1.40127, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 1.4566 - val_loss: 1.4013\n",
      "Epoch 29/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4541\n",
      "Epoch 29: val_loss improved from 1.40127 to 1.39988, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 711us/sample - loss: 1.4541 - val_loss: 1.3999\n",
      "Epoch 30/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4522\n",
      "Epoch 30: val_loss improved from 1.39988 to 1.39844, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 663us/sample - loss: 1.4522 - val_loss: 1.3984\n",
      "Epoch 31/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 31: val_loss improved from 1.39844 to 1.39660, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 650us/sample - loss: 1.4483 - val_loss: 1.3966\n",
      "Epoch 32/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4469\n",
      "Epoch 32: val_loss did not improve from 1.39660\n",
      "32032/32032 [==============================] - 21s 664us/sample - loss: 1.4469 - val_loss: 1.3979\n",
      "Epoch 33/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 33: val_loss improved from 1.39660 to 1.39367, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 683us/sample - loss: 1.4411 - val_loss: 1.3937\n",
      "Epoch 34/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4419\n",
      "Epoch 34: val_loss improved from 1.39367 to 1.39250, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 634us/sample - loss: 1.4419 - val_loss: 1.3925\n",
      "Epoch 35/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 35: val_loss improved from 1.39250 to 1.39048, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 1.4379 - val_loss: 1.3905\n",
      "Epoch 36/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 36: val_loss did not improve from 1.39048\n",
      "32032/32032 [==============================] - 21s 669us/sample - loss: 1.4375 - val_loss: 1.3909\n",
      "Epoch 37/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 37: val_loss improved from 1.39048 to 1.38887, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 658us/sample - loss: 1.4354 - val_loss: 1.3889\n",
      "Epoch 38/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 38: val_loss improved from 1.38887 to 1.38572, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 1.4346 - val_loss: 1.3857\n",
      "Epoch 39/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4332\n",
      "Epoch 39: val_loss did not improve from 1.38572\n",
      "32032/32032 [==============================] - 20s 636us/sample - loss: 1.4332 - val_loss: 1.3864\n",
      "Epoch 40/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 40: val_loss did not improve from 1.38572\n",
      "32032/32032 [==============================] - 21s 643us/sample - loss: 1.4324 - val_loss: 1.3916\n",
      "Epoch 41/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4288\n",
      "Epoch 41: val_loss improved from 1.38572 to 1.38543, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 20s 640us/sample - loss: 1.4288 - val_loss: 1.3854\n",
      "Epoch 42/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4276\n",
      "Epoch 42: val_loss improved from 1.38543 to 1.38393, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 678us/sample - loss: 1.4276 - val_loss: 1.3839\n",
      "Epoch 43/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4259\n",
      "Epoch 43: val_loss did not improve from 1.38393\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.4259 - val_loss: 1.3857\n",
      "Epoch 44/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4260\n",
      "Epoch 44: val_loss improved from 1.38393 to 1.38046, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 725us/sample - loss: 1.4260 - val_loss: 1.3805\n",
      "Epoch 45/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 45: val_loss did not improve from 1.38046\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 1.4255 - val_loss: 1.3831\n",
      "Epoch 46/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4227\n",
      "Epoch 46: val_loss did not improve from 1.38046\n",
      "32032/32032 [==============================] - 23s 724us/sample - loss: 1.4227 - val_loss: 1.3815\n",
      "Epoch 47/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 47: val_loss improved from 1.38046 to 1.37905, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.4212 - val_loss: 1.3790\n",
      "Epoch 48/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4180\n",
      "Epoch 48: val_loss did not improve from 1.37905\n",
      "32032/32032 [==============================] - 22s 672us/sample - loss: 1.4180 - val_loss: 1.3796\n",
      "Epoch 49/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4185\n",
      "Epoch 49: val_loss improved from 1.37905 to 1.37903, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 641us/sample - loss: 1.4185 - val_loss: 1.3790\n",
      "Epoch 50/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 50: val_loss improved from 1.37903 to 1.37644, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 667us/sample - loss: 1.4172 - val_loss: 1.3764\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:26:39.560008: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_290_1/lstm_cell_845/recurrent_kernel/Assign' id:422916 op device:{requested: '', assigned: ''} def:{{{node lstm_290_1/lstm_cell_845/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_290_1/lstm_cell_845/recurrent_kernel, lstm_290_1/lstm_cell_845/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:27:01.255439: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_265_1/lstm_cell_820/recurrent_kernel/m/Assign' id:424641 op device:{requested: '', assigned: ''} def:{{{node lstm_265_1/lstm_cell_820/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_265_1/lstm_cell_820/recurrent_kernel/m, lstm_265_1/lstm_cell_820/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:27:22.834214: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_39_1/cond/Merge' id:423885 op device:{requested: '', assigned: ''} def:{{{node dropout_39_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_39_1/cond/Identity, dropout_39_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1394)\n",
      "(1514, 1394)\n",
      "(1644, 1394)\n",
      "(1764, 1394)\n",
      "(1836, 1394)\n",
      "(1699, 1394)\n",
      "(1369, 1394)\n",
      "(1606, 1394)\n",
      "(1752, 1394)\n",
      "(1502, 1394)\n",
      "(1932, 1394)\n",
      "(1715, 1394)\n",
      "(1776, 1394)\n",
      "(1860, 1394)\n",
      "(1740, 1394)\n",
      "(1812, 1394)\n",
      "(946, 1394)\n",
      "(1680, 1394)\n",
      "(1872, 1394)\n",
      "{1: 6.84024723783602, 2: 3.908370025390992, 4: 8.957288061997442, 5: 6.9491452052328215, 6: 6.886381929238826, 8: 9.161197718782185, 9: 5.093727577688758, 11: 6.732586386297866, 12: 9.493493392781968, 13: 6.812534254010532, 17: 9.219806827237996, 19: 8.730945503358548, 21: 10.0, 22: 1.0, 25: 7.903581083048931, 26: 6.736810054726988, 27: 3.598396051819864, 28: 7.130945635741197, 29: 2.135402297633263}\n",
      "Train on 32032 samples, validate on 3575 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:33:24.477708: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 11.0051\n",
      "Epoch 1: val_loss improved from inf to 1.41704, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 62s 2ms/sample - loss: 11.0051 - val_loss: 1.4170\n",
      "Epoch 2/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8951\n",
      "Epoch 2: val_loss improved from 1.41704 to 1.39837, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 10.8951 - val_loss: 1.3984\n",
      "Epoch 3/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.8554\n",
      "Epoch 3: val_loss improved from 1.39837 to 1.39047, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 729us/sample - loss: 10.8554 - val_loss: 1.3905\n",
      "Epoch 4/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7710\n",
      "Epoch 4: val_loss improved from 1.39047 to 1.38102, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 733us/sample - loss: 10.7710 - val_loss: 1.3810\n",
      "Epoch 5/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7437\n",
      "Epoch 5: val_loss did not improve from 1.38102\n",
      "32032/32032 [==============================] - 23s 725us/sample - loss: 10.7437 - val_loss: 1.3819\n",
      "Epoch 6/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6997\n",
      "Epoch 6: val_loss did not improve from 1.38102\n",
      "32032/32032 [==============================] - 23s 729us/sample - loss: 10.6997 - val_loss: 1.3835\n",
      "Epoch 7/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6602\n",
      "Epoch 7: val_loss did not improve from 1.38102\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 10.6602 - val_loss: 1.3857\n",
      "Epoch 8/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6841\n",
      "Epoch 8: val_loss improved from 1.38102 to 1.38078, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 24s 736us/sample - loss: 10.6841 - val_loss: 1.3808\n",
      "Epoch 9/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6456\n",
      "Epoch 9: val_loss improved from 1.38078 to 1.37781, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 24s 735us/sample - loss: 10.6456 - val_loss: 1.3778\n",
      "Epoch 10/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6162\n",
      "Epoch 10: val_loss improved from 1.37781 to 1.37265, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 686us/sample - loss: 10.6162 - val_loss: 1.3726\n",
      "Epoch 11/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5901\n",
      "Epoch 11: val_loss did not improve from 1.37265\n",
      "32032/32032 [==============================] - 22s 678us/sample - loss: 10.5901 - val_loss: 1.3789\n",
      "Epoch 12/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5964\n",
      "Epoch 12: val_loss did not improve from 1.37265\n",
      "32032/32032 [==============================] - 22s 682us/sample - loss: 10.5964 - val_loss: 1.3790\n",
      "Epoch 13/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5703\n",
      "Epoch 13: val_loss improved from 1.37265 to 1.37042, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 734us/sample - loss: 10.5703 - val_loss: 1.3704\n",
      "Epoch 14/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5605\n",
      "Epoch 14: val_loss did not improve from 1.37042\n",
      "32032/32032 [==============================] - 23s 724us/sample - loss: 10.5605 - val_loss: 1.3740\n",
      "Epoch 15/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5725\n",
      "Epoch 15: val_loss did not improve from 1.37042\n",
      "32032/32032 [==============================] - 23s 725us/sample - loss: 10.5725 - val_loss: 1.3750\n",
      "Epoch 16/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5621\n",
      "Epoch 16: val_loss improved from 1.37042 to 1.36959, saving model to ./checkpoints/unknown_person_few_shot_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 728us/sample - loss: 10.5621 - val_loss: 1.3696\n",
      "Epoch 17/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5374\n",
      "Epoch 17: val_loss did not improve from 1.36959\n",
      "32032/32032 [==============================] - 21s 660us/sample - loss: 10.5374 - val_loss: 1.3753\n",
      "Epoch 18/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5621\n",
      "Epoch 18: val_loss did not improve from 1.36959\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 10.5621 - val_loss: 1.3800\n",
      "Epoch 19/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5013\n",
      "Epoch 19: val_loss did not improve from 1.36959\n",
      "32032/32032 [==============================] - 22s 702us/sample - loss: 10.5013 - val_loss: 1.3700\n",
      "Epoch 20/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.4966\n",
      "Epoch 20: val_loss did not improve from 1.36959\n",
      "32032/32032 [==============================] - 20s 637us/sample - loss: 10.4966 - val_loss: 1.3769\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:41:47.990759: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_281_2/lstm_cell_873/kernel/Assign' id:440854 op device:{requested: '', assigned: ''} def:{{{node lstm_281_2/lstm_cell_873/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_281_2/lstm_cell_873/kernel, lstm_281_2/lstm_cell_873/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:42:10.548349: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_261_2/lstm_cell_853/kernel/m/Assign' id:443974 op device:{requested: '', assigned: ''} def:{{{node lstm_261_2/lstm_cell_853/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_261_2/lstm_cell_853/kernel/m, lstm_261_2/lstm_cell_853/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32032 samples, validate on 3575 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:42:35.529506: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:44:33.199687: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:44:56.484591: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37533, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 64s 2ms/sample - loss: 1.4166 - val_loss: 1.3753\n",
      "Epoch 2/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 2: val_loss improved from 1.37533 to 1.37436, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 724us/sample - loss: 1.4145 - val_loss: 1.3744\n",
      "Epoch 3/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 3: val_loss did not improve from 1.37436\n",
      "32032/32032 [==============================] - 23s 714us/sample - loss: 1.4148 - val_loss: 1.3747\n",
      "Epoch 4/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4131\n",
      "Epoch 4: val_loss improved from 1.37436 to 1.37217, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 701us/sample - loss: 1.4131 - val_loss: 1.3722\n",
      "Epoch 5/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4101\n",
      "Epoch 5: val_loss improved from 1.37217 to 1.37031, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 648us/sample - loss: 1.4101 - val_loss: 1.3703\n",
      "Epoch 6/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4107\n",
      "Epoch 6: val_loss did not improve from 1.37031\n",
      "32032/32032 [==============================] - 21s 645us/sample - loss: 1.4107 - val_loss: 1.3730\n",
      "Epoch 7/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 7: val_loss did not improve from 1.37031\n",
      "32032/32032 [==============================] - 22s 674us/sample - loss: 1.4058 - val_loss: 1.3716\n",
      "Epoch 8/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 8: val_loss improved from 1.37031 to 1.36883, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.4066 - val_loss: 1.3688\n",
      "Epoch 9/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4076\n",
      "Epoch 9: val_loss improved from 1.36883 to 1.36717, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 685us/sample - loss: 1.4076 - val_loss: 1.3672\n",
      "Epoch 10/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 10: val_loss did not improve from 1.36717\n",
      "32032/32032 [==============================] - 20s 632us/sample - loss: 1.4026 - val_loss: 1.3711\n",
      "Epoch 11/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4021\n",
      "Epoch 11: val_loss improved from 1.36717 to 1.36182, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 21s 640us/sample - loss: 1.4021 - val_loss: 1.3618\n",
      "Epoch 12/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4028\n",
      "Epoch 12: val_loss did not improve from 1.36182\n",
      "32032/32032 [==============================] - 20s 631us/sample - loss: 1.4028 - val_loss: 1.3678\n",
      "Epoch 13/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 13: val_loss did not improve from 1.36182\n",
      "32032/32032 [==============================] - 22s 677us/sample - loss: 1.4011 - val_loss: 1.3628\n",
      "Epoch 14/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3978\n",
      "Epoch 14: val_loss improved from 1.36182 to 1.36182, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 728us/sample - loss: 1.3978 - val_loss: 1.3618\n",
      "Epoch 15/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3966\n",
      "Epoch 15: val_loss improved from 1.36182 to 1.36111, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 709us/sample - loss: 1.3966 - val_loss: 1.3611\n",
      "Epoch 16/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 16: val_loss improved from 1.36111 to 1.35752, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 694us/sample - loss: 1.3983 - val_loss: 1.3575\n",
      "Epoch 17/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3954\n",
      "Epoch 17: val_loss did not improve from 1.35752\n",
      "32032/32032 [==============================] - 23s 719us/sample - loss: 1.3954 - val_loss: 1.3602\n",
      "Epoch 18/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3955\n",
      "Epoch 18: val_loss did not improve from 1.35752\n",
      "32032/32032 [==============================] - 23s 715us/sample - loss: 1.3955 - val_loss: 1.3576\n",
      "Epoch 19/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 19: val_loss improved from 1.35752 to 1.35403, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 23s 719us/sample - loss: 1.3936 - val_loss: 1.3540\n",
      "Epoch 20/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.3923\n",
      "Epoch 20: val_loss improved from 1.35403 to 1.35365, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_37.h5\n",
      "32032/32032 [==============================] - 22s 678us/sample - loss: 1.3923 - val_loss: 1.3536\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:52:44.036955: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_299/lstm_cell_891/bias/Assign' id:456878 op device:{requested: '', assigned: ''} def:{{{node lstm_299/lstm_cell_891/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_299/lstm_cell_891/bias, lstm_299/lstm_cell_891/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:52:56.953200: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_1' id:459972 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 15:53:07.372781: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_2' id:459973 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32032, 95)\n",
      "Train on 32032 samples, validate on 3575 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:53:32.545525: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_35/kernel/Assign' id:460168 op device:{requested: '', assigned: ''} def:{{{node conv2d_35/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_35/kernel, conv2d_35/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:55:36.664272: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 3.1016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 15:56:01.429257: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_49/mul' id:462813 op device:{requested: '', assigned: ''} def:{{{node loss_49/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_49/mul/x, loss_49/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.78695, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 136s 4ms/sample - loss: 3.1016 - val_loss: 1.7869\n",
      "Epoch 2/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.7756\n",
      "Epoch 2: val_loss improved from 1.78695 to 1.54180, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 632us/sample - loss: 1.7756 - val_loss: 1.5418\n",
      "Epoch 3/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5960\n",
      "Epoch 3: val_loss improved from 1.54180 to 1.47752, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 661us/sample - loss: 1.5960 - val_loss: 1.4775\n",
      "Epoch 4/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5491\n",
      "Epoch 4: val_loss improved from 1.47752 to 1.45753, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 698us/sample - loss: 1.5491 - val_loss: 1.4575\n",
      "Epoch 5/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5302\n",
      "Epoch 5: val_loss improved from 1.45753 to 1.45222, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 671us/sample - loss: 1.5302 - val_loss: 1.4522\n",
      "Epoch 6/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5140\n",
      "Epoch 6: val_loss improved from 1.45222 to 1.43687, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 654us/sample - loss: 1.5140 - val_loss: 1.4369\n",
      "Epoch 7/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5015\n",
      "Epoch 7: val_loss improved from 1.43687 to 1.42794, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.5015 - val_loss: 1.4279\n",
      "Epoch 8/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5052\n",
      "Epoch 8: val_loss did not improve from 1.42794\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 1.5052 - val_loss: 1.4332\n",
      "Epoch 9/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4982\n",
      "Epoch 9: val_loss did not improve from 1.42794\n",
      "32032/32032 [==============================] - 20s 632us/sample - loss: 1.4982 - val_loss: 1.4309\n",
      "Epoch 10/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4890\n",
      "Epoch 10: val_loss improved from 1.42794 to 1.41726, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 657us/sample - loss: 1.4890 - val_loss: 1.4173\n",
      "Epoch 11/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.6211\n",
      "Epoch 11: val_loss did not improve from 1.41726\n",
      "32032/32032 [==============================] - 21s 667us/sample - loss: 1.6211 - val_loss: 1.4215\n",
      "Epoch 12/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5063\n",
      "Epoch 12: val_loss did not improve from 1.41726\n",
      "32032/32032 [==============================] - 20s 624us/sample - loss: 1.5063 - val_loss: 1.4205\n",
      "Epoch 13/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5012\n",
      "Epoch 13: val_loss improved from 1.41726 to 1.41174, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 710us/sample - loss: 1.5012 - val_loss: 1.4117\n",
      "Epoch 14/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4873\n",
      "Epoch 14: val_loss improved from 1.41174 to 1.41037, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 726us/sample - loss: 1.4873 - val_loss: 1.4104\n",
      "Epoch 15/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5924\n",
      "Epoch 15: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 1.5924 - val_loss: 1.4366\n",
      "Epoch 16/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5479\n",
      "Epoch 16: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 22s 702us/sample - loss: 1.5479 - val_loss: 1.4308\n",
      "Epoch 17/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4960\n",
      "Epoch 17: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 633us/sample - loss: 1.4960 - val_loss: 1.4219\n",
      "Epoch 18/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.6432\n",
      "Epoch 18: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 624us/sample - loss: 1.6432 - val_loss: 1.4482\n",
      "Epoch 19/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5447\n",
      "Epoch 19: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 621us/sample - loss: 1.5447 - val_loss: 1.4308\n",
      "Epoch 20/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5232\n",
      "Epoch 20: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 624us/sample - loss: 1.5232 - val_loss: 1.4265\n",
      "Epoch 21/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5292\n",
      "Epoch 21: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 619us/sample - loss: 1.5292 - val_loss: 1.4329\n",
      "Epoch 22/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5866\n",
      "Epoch 22: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 617us/sample - loss: 1.5866 - val_loss: 1.4432\n",
      "Epoch 23/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5345\n",
      "Epoch 23: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 20s 617us/sample - loss: 1.5345 - val_loss: 1.4415\n",
      "Epoch 24/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.5042\n",
      "Epoch 24: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 21s 641us/sample - loss: 1.5042 - val_loss: 1.4242\n",
      "Epoch 25/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4943\n",
      "Epoch 25: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 23s 711us/sample - loss: 1.4943 - val_loss: 1.4234\n",
      "Epoch 26/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4868\n",
      "Epoch 26: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 23s 713us/sample - loss: 1.4868 - val_loss: 1.4184\n",
      "Epoch 27/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4964\n",
      "Epoch 27: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 1.4964 - val_loss: 1.4150\n",
      "Epoch 28/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4852\n",
      "Epoch 28: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 1.4852 - val_loss: 1.4156\n",
      "Epoch 29/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 29: val_loss did not improve from 1.41037\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 1.4854 - val_loss: 1.4110\n",
      "Epoch 30/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4749\n",
      "Epoch 30: val_loss improved from 1.41037 to 1.40788, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 729us/sample - loss: 1.4749 - val_loss: 1.4079\n",
      "Epoch 31/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4702\n",
      "Epoch 31: val_loss improved from 1.40788 to 1.40743, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 723us/sample - loss: 1.4702 - val_loss: 1.4074\n",
      "Epoch 32/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4664\n",
      "Epoch 32: val_loss did not improve from 1.40743\n",
      "32032/32032 [==============================] - 23s 718us/sample - loss: 1.4664 - val_loss: 1.4082\n",
      "Epoch 33/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4666\n",
      "Epoch 33: val_loss improved from 1.40743 to 1.40650, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 682us/sample - loss: 1.4666 - val_loss: 1.4065\n",
      "Epoch 34/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 34: val_loss did not improve from 1.40650\n",
      "32032/32032 [==============================] - 21s 641us/sample - loss: 1.4597 - val_loss: 1.4071\n",
      "Epoch 35/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4660\n",
      "Epoch 35: val_loss improved from 1.40650 to 1.40567, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 637us/sample - loss: 1.4660 - val_loss: 1.4057\n",
      "Epoch 36/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4580\n",
      "Epoch 36: val_loss improved from 1.40567 to 1.40340, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 1.4580 - val_loss: 1.4034\n",
      "Epoch 37/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4585\n",
      "Epoch 37: val_loss improved from 1.40340 to 1.40074, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 714us/sample - loss: 1.4585 - val_loss: 1.4007\n",
      "Epoch 38/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4549\n",
      "Epoch 38: val_loss improved from 1.40074 to 1.40010, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 634us/sample - loss: 1.4549 - val_loss: 1.4001\n",
      "Epoch 39/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4556\n",
      "Epoch 39: val_loss improved from 1.40010 to 1.39803, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 637us/sample - loss: 1.4556 - val_loss: 1.3980\n",
      "Epoch 40/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4522\n",
      "Epoch 40: val_loss improved from 1.39803 to 1.39709, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 1.4522 - val_loss: 1.3971\n",
      "Epoch 41/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4510\n",
      "Epoch 41: val_loss improved from 1.39709 to 1.39424, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 716us/sample - loss: 1.4510 - val_loss: 1.3942\n",
      "Epoch 42/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4500\n",
      "Epoch 42: val_loss did not improve from 1.39424\n",
      "32032/32032 [==============================] - 22s 693us/sample - loss: 1.4500 - val_loss: 1.3996\n",
      "Epoch 43/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4438\n",
      "Epoch 43: val_loss improved from 1.39424 to 1.39390, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 721us/sample - loss: 1.4438 - val_loss: 1.3939\n",
      "Epoch 44/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4470\n",
      "Epoch 44: val_loss did not improve from 1.39390\n",
      "32032/32032 [==============================] - 22s 684us/sample - loss: 1.4470 - val_loss: 1.4026\n",
      "Epoch 45/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4447\n",
      "Epoch 45: val_loss did not improve from 1.39390\n",
      "32032/32032 [==============================] - 20s 624us/sample - loss: 1.4447 - val_loss: 1.3987\n",
      "Epoch 46/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4425\n",
      "Epoch 46: val_loss improved from 1.39390 to 1.39238, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 634us/sample - loss: 1.4425 - val_loss: 1.3924\n",
      "Epoch 47/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4430\n",
      "Epoch 47: val_loss improved from 1.39238 to 1.39034, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 686us/sample - loss: 1.4430 - val_loss: 1.3903\n",
      "Epoch 48/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4391\n",
      "Epoch 48: val_loss did not improve from 1.39034\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 1.4391 - val_loss: 1.3925\n",
      "Epoch 49/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 49: val_loss did not improve from 1.39034\n",
      "32032/32032 [==============================] - 23s 719us/sample - loss: 1.4404 - val_loss: 1.3915\n",
      "Epoch 50/50\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 50: val_loss did not improve from 1.39034\n",
      "32032/32032 [==============================] - 23s 719us/sample - loss: 1.4361 - val_loss: 1.3908\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:15:42.615346: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_308_1/lstm_cell_937/recurrent_kernel/Assign' id:476916 op device:{requested: '', assigned: ''} def:{{{node lstm_308_1/lstm_cell_937/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_308_1/lstm_cell_937/recurrent_kernel, lstm_308_1/lstm_cell_937/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 16:16:08.070852: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_323_1/lstm_cell_952/bias/m/Assign' id:482003 op device:{requested: '', assigned: ''} def:{{{node lstm_323_1/lstm_cell_952/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_323_1/lstm_cell_952/bias/m, lstm_323_1/lstm_cell_952/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 16:16:33.567196: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_44_1/cond/Merge' id:480927 op device:{requested: '', assigned: ''} def:{{{node dropout_44_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_44_1/cond/Identity, dropout_44_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1394)\n",
      "(1514, 1394)\n",
      "(1644, 1394)\n",
      "(1764, 1394)\n",
      "(1836, 1394)\n",
      "(1699, 1394)\n",
      "(1369, 1394)\n",
      "(1606, 1394)\n",
      "(1752, 1394)\n",
      "(1502, 1394)\n",
      "(1932, 1394)\n",
      "(1715, 1394)\n",
      "(1776, 1394)\n",
      "(1860, 1394)\n",
      "(1740, 1394)\n",
      "(1812, 1394)\n",
      "(946, 1394)\n",
      "(1680, 1394)\n",
      "(1872, 1394)\n",
      "{1: 7.210581490510092, 2: 3.0212292365682676, 4: 8.239108644932376, 5: 6.912810096125031, 6: 6.672652259717389, 8: 8.413732334124113, 9: 3.2644548792089436, 11: 5.682039188849017, 12: 9.280685744922678, 13: 8.047256987617406, 17: 8.519242114990426, 19: 8.31834396001129, 21: 10.0, 22: 1.0, 25: 7.849911132566672, 26: 7.365386052989182, 27: 2.4078602182292115, 28: 7.688213813627938, 29: 2.5164534974320527}\n",
      "Train on 32032 samples, validate on 3575 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:22:28.650178: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7664\n",
      "Epoch 1: val_loss improved from inf to 1.42621, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 69s 2ms/sample - loss: 10.7664 - val_loss: 1.4262\n",
      "Epoch 2/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.7083\n",
      "Epoch 2: val_loss improved from 1.42621 to 1.39556, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 685us/sample - loss: 10.7083 - val_loss: 1.3956\n",
      "Epoch 3/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.6588\n",
      "Epoch 3: val_loss improved from 1.39556 to 1.39339, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 638us/sample - loss: 10.6588 - val_loss: 1.3934\n",
      "Epoch 4/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5696\n",
      "Epoch 4: val_loss did not improve from 1.39339\n",
      "32032/32032 [==============================] - 22s 682us/sample - loss: 10.5696 - val_loss: 1.4025\n",
      "Epoch 5/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5491\n",
      "Epoch 5: val_loss improved from 1.39339 to 1.38910, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 24s 736us/sample - loss: 10.5491 - val_loss: 1.3891\n",
      "Epoch 6/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.5157\n",
      "Epoch 6: val_loss did not improve from 1.38910\n",
      "32032/32032 [==============================] - 23s 728us/sample - loss: 10.5157 - val_loss: 1.3986\n",
      "Epoch 7/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.4664\n",
      "Epoch 7: val_loss improved from 1.38910 to 1.38853, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 707us/sample - loss: 10.4664 - val_loss: 1.3885\n",
      "Epoch 8/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.4569\n",
      "Epoch 8: val_loss improved from 1.38853 to 1.38702, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 729us/sample - loss: 10.4569 - val_loss: 1.3870\n",
      "Epoch 9/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.4418\n",
      "Epoch 9: val_loss did not improve from 1.38702\n",
      "32032/32032 [==============================] - 21s 665us/sample - loss: 10.4418 - val_loss: 1.3921\n",
      "Epoch 10/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.4610\n",
      "Epoch 10: val_loss improved from 1.38702 to 1.38158, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 647us/sample - loss: 10.4610 - val_loss: 1.3816\n",
      "Epoch 11/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3942\n",
      "Epoch 11: val_loss did not improve from 1.38158\n",
      "32032/32032 [==============================] - 23s 710us/sample - loss: 10.3942 - val_loss: 1.3818\n",
      "Epoch 12/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3891\n",
      "Epoch 12: val_loss improved from 1.38158 to 1.37713, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 718us/sample - loss: 10.3891 - val_loss: 1.3771\n",
      "Epoch 13/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3878\n",
      "Epoch 13: val_loss did not improve from 1.37713\n",
      "32032/32032 [==============================] - 22s 682us/sample - loss: 10.3878 - val_loss: 1.3870\n",
      "Epoch 14/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3879\n",
      "Epoch 14: val_loss did not improve from 1.37713\n",
      "32032/32032 [==============================] - 23s 717us/sample - loss: 10.3879 - val_loss: 1.3873\n",
      "Epoch 15/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3835\n",
      "Epoch 15: val_loss improved from 1.37713 to 1.37362, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 660us/sample - loss: 10.3835 - val_loss: 1.3736\n",
      "Epoch 16/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3642\n",
      "Epoch 16: val_loss improved from 1.37362 to 1.37016, saving model to ./checkpoints/unknown_person_few_shot_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 655us/sample - loss: 10.3642 - val_loss: 1.3702\n",
      "Epoch 17/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3241\n",
      "Epoch 17: val_loss did not improve from 1.37016\n",
      "32032/32032 [==============================] - 23s 710us/sample - loss: 10.3241 - val_loss: 1.3792\n",
      "Epoch 18/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3148\n",
      "Epoch 18: val_loss did not improve from 1.37016\n",
      "32032/32032 [==============================] - 23s 703us/sample - loss: 10.3148 - val_loss: 1.3763\n",
      "Epoch 19/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.3250\n",
      "Epoch 19: val_loss did not improve from 1.37016\n",
      "32032/32032 [==============================] - 23s 730us/sample - loss: 10.3250 - val_loss: 1.3732\n",
      "Epoch 20/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 10.2970\n",
      "Epoch 20: val_loss did not improve from 1.37016\n",
      "32032/32032 [==============================] - 23s 729us/sample - loss: 10.2970 - val_loss: 1.3754\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:30:51.724799: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_32_2/kernel/Assign' id:500296 op device:{requested: '', assigned: ''} def:{{{node dense_32_2/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_32_2/kernel, dense_32_2/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 16:31:18.954186: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_313_2/lstm_cell_979/bias/v/Assign' id:501894 op device:{requested: '', assigned: ''} def:{{{node lstm_313_2/lstm_cell_979/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_313_2/lstm_cell_979/bias/v, lstm_313_2/lstm_cell_979/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32032 samples, validate on 3575 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:31:48.244416: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:34:04.333234: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:34:26.835510: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39158, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 70s 2ms/sample - loss: 1.4398 - val_loss: 1.3916\n",
      "Epoch 2/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 2: val_loss improved from 1.39158 to 1.38959, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 636us/sample - loss: 1.4375 - val_loss: 1.3896\n",
      "Epoch 3/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4374\n",
      "Epoch 3: val_loss improved from 1.38959 to 1.38495, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 658us/sample - loss: 1.4374 - val_loss: 1.3850\n",
      "Epoch 4/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4372\n",
      "Epoch 4: val_loss did not improve from 1.38495\n",
      "32032/32032 [==============================] - 23s 719us/sample - loss: 1.4372 - val_loss: 1.3889\n",
      "Epoch 5/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 5: val_loss improved from 1.38495 to 1.38292, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 701us/sample - loss: 1.4321 - val_loss: 1.3829\n",
      "Epoch 6/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4326\n",
      "Epoch 6: val_loss improved from 1.38292 to 1.38155, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 692us/sample - loss: 1.4326 - val_loss: 1.3815\n",
      "Epoch 7/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4263\n",
      "Epoch 7: val_loss improved from 1.38155 to 1.37977, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 22s 681us/sample - loss: 1.4263 - val_loss: 1.3798\n",
      "Epoch 8/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 8: val_loss did not improve from 1.37977\n",
      "32032/32032 [==============================] - 20s 624us/sample - loss: 1.4266 - val_loss: 1.3815\n",
      "Epoch 9/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 9: val_loss improved from 1.37977 to 1.37752, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 627us/sample - loss: 1.4262 - val_loss: 1.3775\n",
      "Epoch 10/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 10: val_loss improved from 1.37752 to 1.37461, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 20s 623us/sample - loss: 1.4249 - val_loss: 1.3746\n",
      "Epoch 11/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 11: val_loss did not improve from 1.37461\n",
      "32032/32032 [==============================] - 20s 616us/sample - loss: 1.4242 - val_loss: 1.3767\n",
      "Epoch 12/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 12: val_loss did not improve from 1.37461\n",
      "32032/32032 [==============================] - 20s 613us/sample - loss: 1.4246 - val_loss: 1.3760\n",
      "Epoch 13/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4179\n",
      "Epoch 13: val_loss did not improve from 1.37461\n",
      "32032/32032 [==============================] - 20s 615us/sample - loss: 1.4179 - val_loss: 1.3747\n",
      "Epoch 14/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 14: val_loss improved from 1.37461 to 1.36998, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 658us/sample - loss: 1.4207 - val_loss: 1.3700\n",
      "Epoch 15/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4208\n",
      "Epoch 15: val_loss did not improve from 1.36998\n",
      "32032/32032 [==============================] - 23s 720us/sample - loss: 1.4208 - val_loss: 1.3741\n",
      "Epoch 16/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4162\n",
      "Epoch 16: val_loss improved from 1.36998 to 1.36883, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 23s 727us/sample - loss: 1.4162 - val_loss: 1.3688\n",
      "Epoch 17/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4142\n",
      "Epoch 17: val_loss did not improve from 1.36883\n",
      "32032/32032 [==============================] - 23s 715us/sample - loss: 1.4142 - val_loss: 1.3696\n",
      "Epoch 18/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4161\n",
      "Epoch 18: val_loss improved from 1.36883 to 1.36707, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_38.h5\n",
      "32032/32032 [==============================] - 21s 666us/sample - loss: 1.4161 - val_loss: 1.3671\n",
      "Epoch 19/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 19: val_loss did not improve from 1.36707\n",
      "32032/32032 [==============================] - 20s 612us/sample - loss: 1.4149 - val_loss: 1.3721\n",
      "Epoch 20/20\n",
      "32032/32032 [==============================] - ETA: 0s - loss: 1.4131\n",
      "Epoch 20: val_loss did not improve from 1.36707\n",
      "32032/32032 [==============================] - 22s 690us/sample - loss: 1.4131 - val_loss: 1.3671\n",
      "35811\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:42:13.061720: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_339/lstm_cell_1005/recurrent_kernel/Assign' id:514406 op device:{requested: '', assigned: ''} def:{{{node lstm_339/lstm_cell_1005/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_339/lstm_cell_1005/recurrent_kernel, lstm_339/lstm_cell_1005/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 16:42:27.567321: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_1' id:517014 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 16:42:39.383195: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_2' id:517015 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32224, 95)\n",
      "Train on 32224 samples, validate on 3587 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:43:08.705543: W tensorflow/c/c_api.cc:304] Operation '{name:'training_54/Adam/lstm_352/lstm_cell_1018/kernel/m/Assign' id:530057 op device:{requested: '', assigned: ''} def:{{{node training_54/Adam/lstm_352/lstm_cell_1018/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_54/Adam/lstm_352/lstm_cell_1018/kernel/m, training_54/Adam/lstm_352/lstm_cell_1018/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:45:29.317640: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 3.1096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-22 16:45:54.297992: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_55/mul' id:519855 op device:{requested: '', assigned: ''} def:{{{node loss_55/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_55/mul/x, loss_55/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.81159, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 150s 5ms/sample - loss: 3.1096 - val_loss: 1.8116\n",
      "Epoch 2/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.7760\n",
      "Epoch 2: val_loss improved from 1.81159 to 1.58872, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 622us/sample - loss: 1.7760 - val_loss: 1.5887\n",
      "Epoch 3/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5999\n",
      "Epoch 3: val_loss improved from 1.58872 to 1.49264, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 1.5999 - val_loss: 1.4926\n",
      "Epoch 4/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5503\n",
      "Epoch 4: val_loss improved from 1.49264 to 1.46967, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 1.5503 - val_loss: 1.4697\n",
      "Epoch 5/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5265\n",
      "Epoch 5: val_loss improved from 1.46967 to 1.45175, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 630us/sample - loss: 1.5265 - val_loss: 1.4517\n",
      "Epoch 6/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5125\n",
      "Epoch 6: val_loss improved from 1.45175 to 1.43380, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 1.5125 - val_loss: 1.4338\n",
      "Epoch 7/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5013\n",
      "Epoch 7: val_loss did not improve from 1.43380\n",
      "32224/32224 [==============================] - 20s 622us/sample - loss: 1.5013 - val_loss: 1.4402\n",
      "Epoch 8/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 8: val_loss improved from 1.43380 to 1.42325, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 706us/sample - loss: 1.5028 - val_loss: 1.4232\n",
      "Epoch 9/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4897\n",
      "Epoch 9: val_loss improved from 1.42325 to 1.41644, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 649us/sample - loss: 1.4897 - val_loss: 1.4164\n",
      "Epoch 10/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4837\n",
      "Epoch 10: val_loss improved from 1.41644 to 1.41639, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 657us/sample - loss: 1.4837 - val_loss: 1.4164\n",
      "Epoch 11/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4996\n",
      "Epoch 11: val_loss improved from 1.41639 to 1.40494, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 731us/sample - loss: 1.4996 - val_loss: 1.4049\n",
      "Epoch 12/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5003\n",
      "Epoch 12: val_loss improved from 1.40494 to 1.40311, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 648us/sample - loss: 1.5003 - val_loss: 1.4031\n",
      "Epoch 13/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.6076\n",
      "Epoch 13: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 21s 666us/sample - loss: 1.6076 - val_loss: 1.4201\n",
      "Epoch 14/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5187\n",
      "Epoch 14: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 22s 681us/sample - loss: 1.5187 - val_loss: 1.4234\n",
      "Epoch 15/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5073\n",
      "Epoch 15: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 23s 704us/sample - loss: 1.5073 - val_loss: 1.4098\n",
      "Epoch 16/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5445\n",
      "Epoch 16: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 20s 629us/sample - loss: 1.5445 - val_loss: 1.4282\n",
      "Epoch 17/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4776\n",
      "Epoch 17: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 21s 664us/sample - loss: 1.4776 - val_loss: 1.4097\n",
      "Epoch 18/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4681\n",
      "Epoch 18: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 23s 716us/sample - loss: 1.4681 - val_loss: 1.4069\n",
      "Epoch 19/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5118\n",
      "Epoch 19: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 20s 623us/sample - loss: 1.5118 - val_loss: 1.4157\n",
      "Epoch 20/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5221\n",
      "Epoch 20: val_loss did not improve from 1.40311\n",
      "32224/32224 [==============================] - 22s 674us/sample - loss: 1.5221 - val_loss: 1.4146\n",
      "Epoch 21/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5422\n",
      "Epoch 21: val_loss improved from 1.40311 to 1.40019, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 732us/sample - loss: 1.5422 - val_loss: 1.4002\n",
      "Epoch 22/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5040\n",
      "Epoch 22: val_loss improved from 1.40019 to 1.39877, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 705us/sample - loss: 1.5040 - val_loss: 1.3988\n",
      "Epoch 23/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4660\n",
      "Epoch 23: val_loss improved from 1.39877 to 1.39315, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 648us/sample - loss: 1.4660 - val_loss: 1.3932\n",
      "Epoch 24/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4539\n",
      "Epoch 24: val_loss improved from 1.39315 to 1.39313, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 652us/sample - loss: 1.4539 - val_loss: 1.3931\n",
      "Epoch 25/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4497\n",
      "Epoch 25: val_loss improved from 1.39313 to 1.38434, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 650us/sample - loss: 1.4497 - val_loss: 1.3843\n",
      "Epoch 26/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 26: val_loss did not improve from 1.38434\n",
      "32224/32224 [==============================] - 23s 703us/sample - loss: 1.4432 - val_loss: 1.3855\n",
      "Epoch 27/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4434\n",
      "Epoch 27: val_loss did not improve from 1.38434\n",
      "32224/32224 [==============================] - 23s 723us/sample - loss: 1.4434 - val_loss: 1.3875\n",
      "Epoch 28/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4367\n",
      "Epoch 28: val_loss improved from 1.38434 to 1.37819, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 730us/sample - loss: 1.4367 - val_loss: 1.3782\n",
      "Epoch 29/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 29: val_loss improved from 1.37819 to 1.37668, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 730us/sample - loss: 1.4379 - val_loss: 1.3767\n",
      "Epoch 30/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4352\n",
      "Epoch 30: val_loss improved from 1.37668 to 1.37284, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 732us/sample - loss: 1.4352 - val_loss: 1.3728\n",
      "Epoch 31/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4297\n",
      "Epoch 31: val_loss did not improve from 1.37284\n",
      "32224/32224 [==============================] - 23s 724us/sample - loss: 1.4297 - val_loss: 1.3742\n",
      "Epoch 32/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 32: val_loss improved from 1.37284 to 1.36913, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 733us/sample - loss: 1.4275 - val_loss: 1.3691\n",
      "Epoch 33/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4268\n",
      "Epoch 33: val_loss improved from 1.36913 to 1.36897, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 22s 683us/sample - loss: 1.4268 - val_loss: 1.3690\n",
      "Epoch 34/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 34: val_loss improved from 1.36897 to 1.36849, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 22s 691us/sample - loss: 1.4250 - val_loss: 1.3685\n",
      "Epoch 35/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 35: val_loss improved from 1.36849 to 1.36465, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 727us/sample - loss: 1.4250 - val_loss: 1.3646\n",
      "Epoch 36/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 36: val_loss improved from 1.36465 to 1.35927, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 715us/sample - loss: 1.4220 - val_loss: 1.3593\n",
      "Epoch 37/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4171\n",
      "Epoch 37: val_loss did not improve from 1.35927\n",
      "32224/32224 [==============================] - 22s 687us/sample - loss: 1.4171 - val_loss: 1.3688\n",
      "Epoch 38/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4214\n",
      "Epoch 38: val_loss did not improve from 1.35927\n",
      "32224/32224 [==============================] - 21s 656us/sample - loss: 1.4214 - val_loss: 1.3651\n",
      "Epoch 39/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 39: val_loss did not improve from 1.35927\n",
      "32224/32224 [==============================] - 21s 636us/sample - loss: 1.4173 - val_loss: 1.3612\n",
      "Epoch 40/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4165\n",
      "Epoch 40: val_loss did not improve from 1.35927\n",
      "32224/32224 [==============================] - 22s 680us/sample - loss: 1.4165 - val_loss: 1.3646\n",
      "Epoch 41/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4146\n",
      "Epoch 41: val_loss improved from 1.35927 to 1.35603, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 706us/sample - loss: 1.4146 - val_loss: 1.3560\n",
      "Epoch 42/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 42: val_loss did not improve from 1.35603\n",
      "32224/32224 [==============================] - 24s 730us/sample - loss: 1.4159 - val_loss: 1.3619\n",
      "Epoch 43/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4135\n",
      "Epoch 43: val_loss did not improve from 1.35603\n",
      "32224/32224 [==============================] - 23s 725us/sample - loss: 1.4135 - val_loss: 1.3583\n",
      "Epoch 44/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 44: val_loss improved from 1.35603 to 1.35429, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 738us/sample - loss: 1.4124 - val_loss: 1.3543\n",
      "Epoch 45/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 45: val_loss did not improve from 1.35429\n",
      "32224/32224 [==============================] - 22s 691us/sample - loss: 1.4099 - val_loss: 1.3565\n",
      "Epoch 46/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 46: val_loss did not improve from 1.35429\n",
      "32224/32224 [==============================] - 23s 726us/sample - loss: 1.4100 - val_loss: 1.3561\n",
      "Epoch 47/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 47: val_loss did not improve from 1.35429\n",
      "32224/32224 [==============================] - 21s 667us/sample - loss: 1.4080 - val_loss: 1.3547\n",
      "Epoch 48/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 48: val_loss did not improve from 1.35429\n",
      "32224/32224 [==============================] - 23s 713us/sample - loss: 1.4050 - val_loss: 1.3567\n",
      "Epoch 49/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4036\n",
      "Epoch 49: val_loss improved from 1.35429 to 1.35062, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_39.h5\n",
      "32224/32224 [==============================] - 24s 734us/sample - loss: 1.4036 - val_loss: 1.3506\n",
      "Epoch 50/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 50: val_loss did not improve from 1.35062\n",
      "32224/32224 [==============================] - 21s 645us/sample - loss: 1.4055 - val_loss: 1.3561\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:06:10.702002: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_360_1/lstm_cell_1063/recurrent_kernel/Assign' id:536360 op device:{requested: '', assigned: ''} def:{{{node lstm_360_1/lstm_cell_1063/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_360_1/lstm_cell_1063/recurrent_kernel, lstm_360_1/lstm_cell_1063/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 17:06:39.367735: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_363_1/lstm_cell_1066/recurrent_kernel/v/Assign' id:539728 op device:{requested: '', assigned: ''} def:{{{node lstm_363_1/lstm_cell_1066/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_363_1/lstm_cell_1066/recurrent_kernel/v, lstm_363_1/lstm_cell_1066/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-22 17:07:07.641484: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_49_1/cond/Merge' id:537969 op device:{requested: '', assigned: ''} def:{{{node dropout_49_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_49_1/cond/Identity, dropout_49_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1190)\n",
      "(1514, 1190)\n",
      "(1644, 1190)\n",
      "(1764, 1190)\n",
      "(1836, 1190)\n",
      "(1699, 1190)\n",
      "(1369, 1190)\n",
      "(1606, 1190)\n",
      "(1740, 1190)\n",
      "(1526, 1190)\n",
      "(1908, 1190)\n",
      "(1715, 1190)\n",
      "(1764, 1190)\n",
      "(1872, 1190)\n",
      "(1728, 1190)\n",
      "(1812, 1190)\n",
      "(970, 1190)\n",
      "(1668, 1190)\n",
      "(1884, 1190)\n",
      "{1: 6.240497497338522, 2: 4.313364509192292, 4: 9.134866850680579, 5: 8.055833550508709, 6: 7.1898606040413, 8: 8.934469195891875, 9: 4.373643282259026, 11: 6.697601629828539, 12: 9.035162146355624, 13: 6.994788026622795, 17: 9.165479153284657, 19: 8.499424583435637, 21: 10.0, 22: 1.0, 25: 7.554211686375823, 26: 6.450667337122003, 27: 3.2281620931024944, 28: 6.805354390155052, 29: 3.413019259253674}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916958/459382369.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32224 samples, validate on 3587 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:13:28.786586: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 11.1841\n",
      "Epoch 1: val_loss improved from inf to 1.38981, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 77s 2ms/sample - loss: 11.1841 - val_loss: 1.3898\n",
      "Epoch 2/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.1179\n",
      "Epoch 2: val_loss improved from 1.38981 to 1.37926, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 645us/sample - loss: 11.1179 - val_loss: 1.3793\n",
      "Epoch 3/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0013\n",
      "Epoch 3: val_loss did not improve from 1.37926\n",
      "32224/32224 [==============================] - 20s 621us/sample - loss: 11.0013 - val_loss: 1.4086\n",
      "Epoch 4/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9541\n",
      "Epoch 4: val_loss improved from 1.37926 to 1.37608, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 22s 673us/sample - loss: 10.9541 - val_loss: 1.3761\n",
      "Epoch 5/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9173\n",
      "Epoch 5: val_loss improved from 1.37608 to 1.36922, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 722us/sample - loss: 10.9173 - val_loss: 1.3692\n",
      "Epoch 6/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9022\n",
      "Epoch 6: val_loss did not improve from 1.36922\n",
      "32224/32224 [==============================] - 22s 682us/sample - loss: 10.9022 - val_loss: 1.3824\n",
      "Epoch 7/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8556\n",
      "Epoch 7: val_loss did not improve from 1.36922\n",
      "32224/32224 [==============================] - 20s 623us/sample - loss: 10.8556 - val_loss: 1.3746\n",
      "Epoch 8/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8501\n",
      "Epoch 8: val_loss improved from 1.36922 to 1.36836, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 634us/sample - loss: 10.8501 - val_loss: 1.3684\n",
      "Epoch 9/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8338\n",
      "Epoch 9: val_loss did not improve from 1.36836\n",
      "32224/32224 [==============================] - 20s 625us/sample - loss: 10.8338 - val_loss: 1.3809\n",
      "Epoch 10/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8156\n",
      "Epoch 10: val_loss did not improve from 1.36836\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 10.8156 - val_loss: 1.3712\n",
      "Epoch 11/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8183\n",
      "Epoch 11: val_loss did not improve from 1.36836\n",
      "32224/32224 [==============================] - 22s 672us/sample - loss: 10.8183 - val_loss: 1.3725\n",
      "Epoch 12/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7646\n",
      "Epoch 12: val_loss did not improve from 1.36836\n",
      "32224/32224 [==============================] - 22s 692us/sample - loss: 10.7646 - val_loss: 1.3823\n",
      "Epoch 13/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7576\n",
      "Epoch 13: val_loss improved from 1.36836 to 1.35969, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 22s 670us/sample - loss: 10.7576 - val_loss: 1.3597\n",
      "Epoch 14/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7690\n",
      "Epoch 14: val_loss did not improve from 1.35969\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 10.7690 - val_loss: 1.3635\n",
      "Epoch 15/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7594\n",
      "Epoch 15: val_loss did not improve from 1.35969\n",
      "32224/32224 [==============================] - 20s 627us/sample - loss: 10.7594 - val_loss: 1.3704\n",
      "Epoch 16/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7309\n",
      "Epoch 16: val_loss did not improve from 1.35969\n",
      "32224/32224 [==============================] - 20s 633us/sample - loss: 10.7309 - val_loss: 1.3664\n",
      "Epoch 17/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7292\n",
      "Epoch 17: val_loss did not improve from 1.35969\n",
      "32224/32224 [==============================] - 22s 686us/sample - loss: 10.7292 - val_loss: 1.3684\n",
      "Epoch 18/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7199\n",
      "Epoch 18: val_loss did not improve from 1.35969\n",
      "32224/32224 [==============================] - 22s 673us/sample - loss: 10.7199 - val_loss: 1.3690\n",
      "Epoch 19/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7368\n",
      "Epoch 19: val_loss did not improve from 1.35969\n",
      "32224/32224 [==============================] - 20s 631us/sample - loss: 10.7368 - val_loss: 1.3711\n",
      "Epoch 20/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.6945\n",
      "Epoch 20: val_loss improved from 1.35969 to 1.35968, saving model to ./checkpoints/unknown_person_few_shot_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 634us/sample - loss: 10.6945 - val_loss: 1.3597\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:21:36.877346: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_344_2/lstm_cell_1084/kernel/Assign' id:553176 op device:{requested: '', assigned: ''} def:{{{node lstm_344_2/lstm_cell_1084/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_344_2/lstm_cell_1084/kernel, lstm_344_2/lstm_cell_1084/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 17:22:05.750809: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_340_2/lstm_cell_1080/recurrent_kernel/m/Assign' id:558138 op device:{requested: '', assigned: ''} def:{{{node lstm_340_2/lstm_cell_1080/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_340_2/lstm_cell_1080/recurrent_kernel/m, lstm_340_2/lstm_cell_1080/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32224 samples, validate on 3587 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:22:37.120007: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:25:05.871885: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:25:28.415934: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.35376, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 74s 2ms/sample - loss: 1.4045 - val_loss: 1.3538\n",
      "Epoch 2/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4016\n",
      "Epoch 2: val_loss improved from 1.35376 to 1.35196, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 633us/sample - loss: 1.4016 - val_loss: 1.3520\n",
      "Epoch 3/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 3: val_loss did not improve from 1.35196\n",
      "32224/32224 [==============================] - 20s 632us/sample - loss: 1.4010 - val_loss: 1.3570\n",
      "Epoch 4/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 4: val_loss did not improve from 1.35196\n",
      "32224/32224 [==============================] - 20s 623us/sample - loss: 1.3997 - val_loss: 1.3536\n",
      "Epoch 5/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4003\n",
      "Epoch 5: val_loss improved from 1.35196 to 1.35160, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 659us/sample - loss: 1.4003 - val_loss: 1.3516\n",
      "Epoch 6/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 6: val_loss improved from 1.35160 to 1.35137, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 727us/sample - loss: 1.3991 - val_loss: 1.3514\n",
      "Epoch 7/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3966\n",
      "Epoch 7: val_loss improved from 1.35137 to 1.34520, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 725us/sample - loss: 1.3966 - val_loss: 1.3452\n",
      "Epoch 8/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3942\n",
      "Epoch 8: val_loss improved from 1.34520 to 1.34333, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 23s 702us/sample - loss: 1.3942 - val_loss: 1.3433\n",
      "Epoch 9/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 9: val_loss did not improve from 1.34333\n",
      "32224/32224 [==============================] - 21s 651us/sample - loss: 1.3935 - val_loss: 1.3444\n",
      "Epoch 10/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3930\n",
      "Epoch 10: val_loss did not improve from 1.34333\n",
      "32224/32224 [==============================] - 20s 625us/sample - loss: 1.3930 - val_loss: 1.3434\n",
      "Epoch 11/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 11: val_loss did not improve from 1.34333\n",
      "32224/32224 [==============================] - 20s 627us/sample - loss: 1.3914 - val_loss: 1.3439\n",
      "Epoch 12/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 12: val_loss improved from 1.34333 to 1.34009, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 21s 642us/sample - loss: 1.3912 - val_loss: 1.3401\n",
      "Epoch 13/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3895\n",
      "Epoch 13: val_loss did not improve from 1.34009\n",
      "32224/32224 [==============================] - 22s 675us/sample - loss: 1.3895 - val_loss: 1.3506\n",
      "Epoch 14/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3883\n",
      "Epoch 14: val_loss did not improve from 1.34009\n",
      "32224/32224 [==============================] - 21s 643us/sample - loss: 1.3883 - val_loss: 1.3449\n",
      "Epoch 15/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3867\n",
      "Epoch 15: val_loss did not improve from 1.34009\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 1.3867 - val_loss: 1.3412\n",
      "Epoch 16/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3883\n",
      "Epoch 16: val_loss improved from 1.34009 to 1.33939, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_39.h5\n",
      "32224/32224 [==============================] - 20s 634us/sample - loss: 1.3883 - val_loss: 1.3394\n",
      "Epoch 17/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3879\n",
      "Epoch 17: val_loss did not improve from 1.33939\n",
      "32224/32224 [==============================] - 20s 618us/sample - loss: 1.3879 - val_loss: 1.3470\n",
      "Epoch 18/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3824\n",
      "Epoch 18: val_loss did not improve from 1.33939\n",
      "32224/32224 [==============================] - 20s 622us/sample - loss: 1.3824 - val_loss: 1.3426\n",
      "Epoch 19/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3816\n",
      "Epoch 19: val_loss did not improve from 1.33939\n",
      "32224/32224 [==============================] - 20s 626us/sample - loss: 1.3816 - val_loss: 1.3410\n",
      "Epoch 20/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3829\n",
      "Epoch 20: val_loss did not improve from 1.33939\n",
      "32224/32224 [==============================] - 21s 640us/sample - loss: 1.3829 - val_loss: 1.3418\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:33:08.028904: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_377/lstm_cell_1117/recurrent_kernel/Assign' id:571613 op device:{requested: '', assigned: ''} def:{{{node lstm_377/lstm_cell_1117/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_377/lstm_cell_1117/recurrent_kernel, lstm_377/lstm_cell_1117/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 17:33:23.944222: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_1' id:574056 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 17:33:36.849854: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_2' id:574057 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32224, 95)\n",
      "Train on 32224 samples, validate on 3587 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:34:06.861033: W tensorflow/c/c_api.cc:304] Operation '{name:'training_60/Adam/lstm_406/lstm_cell_1146/kernel/m/Assign' id:587354 op device:{requested: '', assigned: ''} def:{{{node training_60/Adam/lstm_406/lstm_cell_1146/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_60/Adam/lstm_406/lstm_cell_1146/kernel/m, training_60/Adam/lstm_406/lstm_cell_1146/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:36:40.663275: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 3.1778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:37:03.758339: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_61/mul' id:576897 op device:{requested: '', assigned: ''} def:{{{node loss_61/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_61/mul/x, loss_61/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.89351, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 162s 5ms/sample - loss: 3.1778 - val_loss: 1.8935\n",
      "Epoch 2/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.8422\n",
      "Epoch 2: val_loss improved from 1.89351 to 1.60839, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 22s 678us/sample - loss: 1.8422 - val_loss: 1.6084\n",
      "Epoch 3/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.6187\n",
      "Epoch 3: val_loss improved from 1.60839 to 1.50688, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 646us/sample - loss: 1.6187 - val_loss: 1.5069\n",
      "Epoch 4/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5490\n",
      "Epoch 4: val_loss improved from 1.50688 to 1.46824, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 608us/sample - loss: 1.5490 - val_loss: 1.4682\n",
      "Epoch 5/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5231\n",
      "Epoch 5: val_loss improved from 1.46824 to 1.44583, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 612us/sample - loss: 1.5231 - val_loss: 1.4458\n",
      "Epoch 6/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5067\n",
      "Epoch 6: val_loss did not improve from 1.44583\n",
      "32224/32224 [==============================] - 23s 708us/sample - loss: 1.5067 - val_loss: 1.4468\n",
      "Epoch 7/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4915\n",
      "Epoch 7: val_loss improved from 1.44583 to 1.43752, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 721us/sample - loss: 1.4915 - val_loss: 1.4375\n",
      "Epoch 8/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4893\n",
      "Epoch 8: val_loss improved from 1.43752 to 1.41393, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 665us/sample - loss: 1.4893 - val_loss: 1.4139\n",
      "Epoch 9/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4966\n",
      "Epoch 9: val_loss improved from 1.41393 to 1.41327, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 22s 668us/sample - loss: 1.4966 - val_loss: 1.4133\n",
      "Epoch 10/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4760\n",
      "Epoch 10: val_loss improved from 1.41327 to 1.41063, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 642us/sample - loss: 1.4760 - val_loss: 1.4106\n",
      "Epoch 11/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4753\n",
      "Epoch 11: val_loss improved from 1.41063 to 1.41036, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 642us/sample - loss: 1.4753 - val_loss: 1.4104\n",
      "Epoch 12/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4759\n",
      "Epoch 12: val_loss improved from 1.41036 to 1.39775, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 613us/sample - loss: 1.4759 - val_loss: 1.3977\n",
      "Epoch 13/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4878\n",
      "Epoch 13: val_loss did not improve from 1.39775\n",
      "32224/32224 [==============================] - 20s 606us/sample - loss: 1.4878 - val_loss: 1.4012\n",
      "Epoch 14/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4882\n",
      "Epoch 14: val_loss did not improve from 1.39775\n",
      "32224/32224 [==============================] - 22s 672us/sample - loss: 1.4882 - val_loss: 1.4045\n",
      "Epoch 15/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4704\n",
      "Epoch 15: val_loss improved from 1.39775 to 1.39099, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 667us/sample - loss: 1.4704 - val_loss: 1.3910\n",
      "Epoch 16/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4590\n",
      "Epoch 16: val_loss improved from 1.39099 to 1.39064, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 615us/sample - loss: 1.4590 - val_loss: 1.3906\n",
      "Epoch 17/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4754\n",
      "Epoch 17: val_loss did not improve from 1.39064\n",
      "32224/32224 [==============================] - 20s 606us/sample - loss: 1.4754 - val_loss: 1.3969\n",
      "Epoch 18/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4737\n",
      "Epoch 18: val_loss did not improve from 1.39064\n",
      "32224/32224 [==============================] - 21s 664us/sample - loss: 1.4737 - val_loss: 1.3958\n",
      "Epoch 19/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4916\n",
      "Epoch 19: val_loss did not improve from 1.39064\n",
      "32224/32224 [==============================] - 20s 621us/sample - loss: 1.4916 - val_loss: 1.3954\n",
      "Epoch 20/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4839\n",
      "Epoch 20: val_loss did not improve from 1.39064\n",
      "32224/32224 [==============================] - 20s 623us/sample - loss: 1.4839 - val_loss: 1.3923\n",
      "Epoch 21/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4725\n",
      "Epoch 21: val_loss improved from 1.39064 to 1.38850, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 718us/sample - loss: 1.4725 - val_loss: 1.3885\n",
      "Epoch 22/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5531\n",
      "Epoch 22: val_loss did not improve from 1.38850\n",
      "32224/32224 [==============================] - 23s 713us/sample - loss: 1.5531 - val_loss: 1.4256\n",
      "Epoch 23/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4934\n",
      "Epoch 23: val_loss did not improve from 1.38850\n",
      "32224/32224 [==============================] - 23s 710us/sample - loss: 1.4934 - val_loss: 1.4119\n",
      "Epoch 24/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4733\n",
      "Epoch 24: val_loss did not improve from 1.38850\n",
      "32224/32224 [==============================] - 20s 621us/sample - loss: 1.4733 - val_loss: 1.4029\n",
      "Epoch 25/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4586\n",
      "Epoch 25: val_loss did not improve from 1.38850\n",
      "32224/32224 [==============================] - 21s 657us/sample - loss: 1.4586 - val_loss: 1.3948\n",
      "Epoch 26/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4543\n",
      "Epoch 26: val_loss improved from 1.38850 to 1.38528, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 703us/sample - loss: 1.4543 - val_loss: 1.3853\n",
      "Epoch 27/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4496\n",
      "Epoch 27: val_loss improved from 1.38528 to 1.37703, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 629us/sample - loss: 1.4496 - val_loss: 1.3770\n",
      "Epoch 28/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4463\n",
      "Epoch 28: val_loss did not improve from 1.37703\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 1.4463 - val_loss: 1.3787\n",
      "Epoch 29/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4431\n",
      "Epoch 29: val_loss did not improve from 1.37703\n",
      "32224/32224 [==============================] - 20s 636us/sample - loss: 1.4431 - val_loss: 1.3784\n",
      "Epoch 30/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4380\n",
      "Epoch 30: val_loss improved from 1.37703 to 1.37196, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 720us/sample - loss: 1.4380 - val_loss: 1.3720\n",
      "Epoch 31/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4363\n",
      "Epoch 31: val_loss did not improve from 1.37196\n",
      "32224/32224 [==============================] - 23s 713us/sample - loss: 1.4363 - val_loss: 1.3760\n",
      "Epoch 32/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4347\n",
      "Epoch 32: val_loss did not improve from 1.37196\n",
      "32224/32224 [==============================] - 20s 623us/sample - loss: 1.4347 - val_loss: 1.3787\n",
      "Epoch 33/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4340\n",
      "Epoch 33: val_loss improved from 1.37196 to 1.36759, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 1.4340 - val_loss: 1.3676\n",
      "Epoch 34/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4317\n",
      "Epoch 34: val_loss did not improve from 1.36759\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 1.4317 - val_loss: 1.3687\n",
      "Epoch 35/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4265\n",
      "Epoch 35: val_loss improved from 1.36759 to 1.36539, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 634us/sample - loss: 1.4265 - val_loss: 1.3654\n",
      "Epoch 36/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4276\n",
      "Epoch 36: val_loss improved from 1.36539 to 1.36525, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 619us/sample - loss: 1.4276 - val_loss: 1.3652\n",
      "Epoch 37/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4251\n",
      "Epoch 37: val_loss improved from 1.36525 to 1.36249, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 718us/sample - loss: 1.4251 - val_loss: 1.3625\n",
      "Epoch 38/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 38: val_loss did not improve from 1.36249\n",
      "32224/32224 [==============================] - 23s 714us/sample - loss: 1.4211 - val_loss: 1.3642\n",
      "Epoch 39/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4205\n",
      "Epoch 39: val_loss did not improve from 1.36249\n",
      "32224/32224 [==============================] - 21s 648us/sample - loss: 1.4205 - val_loss: 1.3636\n",
      "Epoch 40/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 40: val_loss improved from 1.36249 to 1.35735, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 702us/sample - loss: 1.4202 - val_loss: 1.3574\n",
      "Epoch 41/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4169\n",
      "Epoch 41: val_loss did not improve from 1.35735\n",
      "32224/32224 [==============================] - 20s 615us/sample - loss: 1.4169 - val_loss: 1.3615\n",
      "Epoch 42/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 42: val_loss did not improve from 1.35735\n",
      "32224/32224 [==============================] - 20s 611us/sample - loss: 1.4186 - val_loss: 1.3623\n",
      "Epoch 43/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 43: val_loss improved from 1.35735 to 1.35557, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 22s 688us/sample - loss: 1.4159 - val_loss: 1.3556\n",
      "Epoch 44/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 44: val_loss did not improve from 1.35557\n",
      "32224/32224 [==============================] - 21s 661us/sample - loss: 1.4145 - val_loss: 1.3580\n",
      "Epoch 45/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4110\n",
      "Epoch 45: val_loss did not improve from 1.35557\n",
      "32224/32224 [==============================] - 23s 710us/sample - loss: 1.4110 - val_loss: 1.3564\n",
      "Epoch 46/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4092\n",
      "Epoch 46: val_loss did not improve from 1.35557\n",
      "32224/32224 [==============================] - 22s 674us/sample - loss: 1.4092 - val_loss: 1.3601\n",
      "Epoch 47/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 47: val_loss did not improve from 1.35557\n",
      "32224/32224 [==============================] - 22s 689us/sample - loss: 1.4126 - val_loss: 1.3724\n",
      "Epoch 48/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 48: val_loss improved from 1.35557 to 1.35249, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 641us/sample - loss: 1.4099 - val_loss: 1.3525\n",
      "Epoch 49/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 49: val_loss did not improve from 1.35249\n",
      "32224/32224 [==============================] - 21s 655us/sample - loss: 1.4088 - val_loss: 1.3589\n",
      "Epoch 50/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4076\n",
      "Epoch 50: val_loss did not improve from 1.35249\n",
      "32224/32224 [==============================] - 20s 612us/sample - loss: 1.4076 - val_loss: 1.3622\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:56:53.149039: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_385_1/lstm_cell_1162/kernel/Assign' id:591460 op device:{requested: '', assigned: ''} def:{{{node lstm_385_1/lstm_cell_1162/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_385_1/lstm_cell_1162/kernel, lstm_385_1/lstm_cell_1162/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 17:57:25.635429: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_392_1/lstm_cell_1169/bias/m/Assign' id:596012 op device:{requested: '', assigned: ''} def:{{{node lstm_392_1/lstm_cell_1169/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_392_1/lstm_cell_1169/bias/m, lstm_392_1/lstm_cell_1169/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 17:57:57.091999: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_54_1/cond/Merge' id:595011 op device:{requested: '', assigned: ''} def:{{{node dropout_54_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_54_1/cond/Identity, dropout_54_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1190)\n",
      "(1514, 1190)\n",
      "(1644, 1190)\n",
      "(1764, 1190)\n",
      "(1836, 1190)\n",
      "(1699, 1190)\n",
      "(1369, 1190)\n",
      "(1606, 1190)\n",
      "(1740, 1190)\n",
      "(1526, 1190)\n",
      "(1908, 1190)\n",
      "(1715, 1190)\n",
      "(1764, 1190)\n",
      "(1872, 1190)\n",
      "(1728, 1190)\n",
      "(1812, 1190)\n",
      "(970, 1190)\n",
      "(1668, 1190)\n",
      "(1884, 1190)\n",
      "{1: 6.258860402046695, 2: 4.482402177517352, 4: 9.725230193306045, 5: 6.882424215161693, 6: 7.3604875766906925, 8: 9.20450356182395, 9: 5.2840864890875485, 11: 7.34938766094135, 12: 9.515044922334843, 13: 6.760031719351012, 17: 9.566761578481355, 19: 9.048237473363441, 21: 10.0, 22: 1.0, 25: 8.105257195610712, 26: 6.986815793562573, 27: 4.288778567689306, 28: 6.863522601894701, 29: 2.4847051938889697}\n",
      "Train on 32224 samples, validate on 3587 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:04:17.485706: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 11.4329\n",
      "Epoch 1: val_loss improved from inf to 1.38635, saving model to ./checkpoints/unknown_person_few_shot_p10_40.h5\n",
      "32224/32224 [==============================] - 79s 2ms/sample - loss: 11.4329 - val_loss: 1.3864\n",
      "Epoch 2/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.3863\n",
      "Epoch 2: val_loss improved from 1.38635 to 1.36969, saving model to ./checkpoints/unknown_person_few_shot_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 729us/sample - loss: 11.3863 - val_loss: 1.3697\n",
      "Epoch 3/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.2467\n",
      "Epoch 3: val_loss did not improve from 1.36969\n",
      "32224/32224 [==============================] - 23s 705us/sample - loss: 11.2467 - val_loss: 1.4018\n",
      "Epoch 4/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.1865\n",
      "Epoch 4: val_loss did not improve from 1.36969\n",
      "32224/32224 [==============================] - 23s 721us/sample - loss: 11.1865 - val_loss: 1.3810\n",
      "Epoch 5/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.2077\n",
      "Epoch 5: val_loss did not improve from 1.36969\n",
      "32224/32224 [==============================] - 22s 696us/sample - loss: 11.2077 - val_loss: 1.3897\n",
      "Epoch 6/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.1394\n",
      "Epoch 6: val_loss improved from 1.36969 to 1.36580, saving model to ./checkpoints/unknown_person_few_shot_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 615us/sample - loss: 11.1394 - val_loss: 1.3658\n",
      "Epoch 7/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.1238\n",
      "Epoch 7: val_loss did not improve from 1.36580\n",
      "32224/32224 [==============================] - 20s 609us/sample - loss: 11.1238 - val_loss: 1.3779\n",
      "Epoch 8/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0938\n",
      "Epoch 8: val_loss improved from 1.36580 to 1.36564, saving model to ./checkpoints/unknown_person_few_shot_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 625us/sample - loss: 11.0938 - val_loss: 1.3656\n",
      "Epoch 9/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0992\n",
      "Epoch 9: val_loss did not improve from 1.36564\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 11.0992 - val_loss: 1.3983\n",
      "Epoch 10/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0753\n",
      "Epoch 10: val_loss did not improve from 1.36564\n",
      "32224/32224 [==============================] - 20s 606us/sample - loss: 11.0753 - val_loss: 1.3814\n",
      "Epoch 11/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0384\n",
      "Epoch 11: val_loss improved from 1.36564 to 1.35830, saving model to ./checkpoints/unknown_person_few_shot_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 621us/sample - loss: 11.0384 - val_loss: 1.3583\n",
      "Epoch 12/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0116\n",
      "Epoch 12: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 20s 612us/sample - loss: 11.0116 - val_loss: 1.3775\n",
      "Epoch 13/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0330\n",
      "Epoch 13: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 21s 645us/sample - loss: 11.0330 - val_loss: 1.3779\n",
      "Epoch 14/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0137\n",
      "Epoch 14: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 22s 675us/sample - loss: 11.0137 - val_loss: 1.3629\n",
      "Epoch 15/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9908\n",
      "Epoch 15: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 20s 632us/sample - loss: 10.9908 - val_loss: 1.3724\n",
      "Epoch 16/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9998\n",
      "Epoch 16: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 20s 616us/sample - loss: 10.9998 - val_loss: 1.3882\n",
      "Epoch 17/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9777\n",
      "Epoch 17: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 22s 696us/sample - loss: 10.9777 - val_loss: 1.3639\n",
      "Epoch 18/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9691\n",
      "Epoch 18: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 22s 683us/sample - loss: 10.9691 - val_loss: 1.3766\n",
      "Epoch 19/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9591\n",
      "Epoch 19: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 23s 707us/sample - loss: 10.9591 - val_loss: 1.3678\n",
      "Epoch 20/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9422\n",
      "Epoch 20: val_loss did not improve from 1.35830\n",
      "32224/32224 [==============================] - 22s 684us/sample - loss: 10.9422 - val_loss: 1.3775\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:12:31.864256: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_370_2/lstm_cell_1184/recurrent_kernel/Assign' id:608478 op device:{requested: '', assigned: ''} def:{{{node lstm_370_2/lstm_cell_1184/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_370_2/lstm_cell_1184/recurrent_kernel, lstm_370_2/lstm_cell_1184/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 18:13:03.513137: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_387_2/lstm_cell_1201/bias/v/Assign' id:615978 op device:{requested: '', assigned: ''} def:{{{node lstm_387_2/lstm_cell_1201/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_387_2/lstm_cell_1201/bias/v, lstm_387_2/lstm_cell_1201/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32224 samples, validate on 3587 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:13:39.258015: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:16:19.708395: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:16:42.267723: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.34932, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_40.h5\n",
      "32224/32224 [==============================] - 77s 2ms/sample - loss: 1.4084 - val_loss: 1.3493\n",
      "Epoch 2/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 2: val_loss did not improve from 1.34932\n",
      "32224/32224 [==============================] - 20s 607us/sample - loss: 1.4042 - val_loss: 1.3528\n",
      "Epoch 3/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4038\n",
      "Epoch 3: val_loss did not improve from 1.34932\n",
      "32224/32224 [==============================] - 20s 608us/sample - loss: 1.4038 - val_loss: 1.3595\n",
      "Epoch 4/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3999\n",
      "Epoch 4: val_loss did not improve from 1.34932\n",
      "32224/32224 [==============================] - 20s 610us/sample - loss: 1.3999 - val_loss: 1.3647\n",
      "Epoch 5/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4023\n",
      "Epoch 5: val_loss did not improve from 1.34932\n",
      "32224/32224 [==============================] - 20s 626us/sample - loss: 1.4023 - val_loss: 1.3634\n",
      "Epoch 6/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 6: val_loss improved from 1.34932 to 1.34804, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 617us/sample - loss: 1.3995 - val_loss: 1.3480\n",
      "Epoch 7/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 7: val_loss did not improve from 1.34804\n",
      "32224/32224 [==============================] - 20s 609us/sample - loss: 1.3975 - val_loss: 1.3487\n",
      "Epoch 8/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 8: val_loss did not improve from 1.34804\n",
      "32224/32224 [==============================] - 20s 607us/sample - loss: 1.3972 - val_loss: 1.3496\n",
      "Epoch 9/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3960\n",
      "Epoch 9: val_loss did not improve from 1.34804\n",
      "32224/32224 [==============================] - 20s 612us/sample - loss: 1.3960 - val_loss: 1.3491\n",
      "Epoch 10/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 10: val_loss did not improve from 1.34804\n",
      "32224/32224 [==============================] - 21s 652us/sample - loss: 1.3957 - val_loss: 1.3535\n",
      "Epoch 11/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3937\n",
      "Epoch 11: val_loss improved from 1.34804 to 1.34541, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 716us/sample - loss: 1.3937 - val_loss: 1.3454\n",
      "Epoch 12/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3923\n",
      "Epoch 12: val_loss improved from 1.34541 to 1.34421, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_40.h5\n",
      "32224/32224 [==============================] - 20s 635us/sample - loss: 1.3923 - val_loss: 1.3442\n",
      "Epoch 13/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3893\n",
      "Epoch 13: val_loss did not improve from 1.34421\n",
      "32224/32224 [==============================] - 20s 610us/sample - loss: 1.3893 - val_loss: 1.3445\n",
      "Epoch 14/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 14: val_loss did not improve from 1.34421\n",
      "32224/32224 [==============================] - 20s 615us/sample - loss: 1.3887 - val_loss: 1.3467\n",
      "Epoch 15/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 15: val_loss did not improve from 1.34421\n",
      "32224/32224 [==============================] - 20s 610us/sample - loss: 1.3896 - val_loss: 1.3508\n",
      "Epoch 16/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3875\n",
      "Epoch 16: val_loss did not improve from 1.34421\n",
      "32224/32224 [==============================] - 20s 613us/sample - loss: 1.3875 - val_loss: 1.3596\n",
      "Epoch 17/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 17: val_loss did not improve from 1.34421\n",
      "32224/32224 [==============================] - 20s 617us/sample - loss: 1.3862 - val_loss: 1.3448\n",
      "Epoch 18/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3853\n",
      "Epoch 18: val_loss improved from 1.34421 to 1.34341, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_40.h5\n",
      "32224/32224 [==============================] - 21s 660us/sample - loss: 1.3853 - val_loss: 1.3434\n",
      "Epoch 19/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3855\n",
      "Epoch 19: val_loss improved from 1.34341 to 1.33945, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_40.h5\n",
      "32224/32224 [==============================] - 23s 725us/sample - loss: 1.3855 - val_loss: 1.3395\n",
      "Epoch 20/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3834\n",
      "Epoch 20: val_loss did not improve from 1.33945\n",
      "32224/32224 [==============================] - 20s 621us/sample - loss: 1.3834 - val_loss: 1.3491\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:24:13.603139: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_424/lstm_cell_1238/kernel/Assign' id:630285 op device:{requested: '', assigned: ''} def:{{{node lstm_424/lstm_cell_1238/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_424/lstm_cell_1238/kernel, lstm_424/lstm_cell_1238/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 18:24:30.778721: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_1' id:631098 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 18:24:44.706947: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_2' id:631099 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32224, 95)\n",
      "Train on 32224 samples, validate on 3587 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:25:16.899985: W tensorflow/c/c_api.cc:304] Operation '{name:'training_66/Adam/lstm_438/lstm_cell_1252/kernel/m/Assign' id:644321 op device:{requested: '', assigned: ''} def:{{{node training_66/Adam/lstm_438/lstm_cell_1252/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_66/Adam/lstm_438/lstm_cell_1252/kernel/m, training_66/Adam/lstm_438/lstm_cell_1252/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:28:03.460807: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 3.0880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:28:26.238449: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_67/mul' id:633939 op device:{requested: '', assigned: ''} def:{{{node loss_67/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_67/mul/x, loss_67/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.93983, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 173s 5ms/sample - loss: 3.0880 - val_loss: 1.9398\n",
      "Epoch 2/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.7730\n",
      "Epoch 2: val_loss improved from 1.93983 to 1.57118, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 638us/sample - loss: 1.7730 - val_loss: 1.5712\n",
      "Epoch 3/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5978\n",
      "Epoch 3: val_loss improved from 1.57118 to 1.49573, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 646us/sample - loss: 1.5978 - val_loss: 1.4957\n",
      "Epoch 4/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5464\n",
      "Epoch 4: val_loss improved from 1.49573 to 1.46355, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 658us/sample - loss: 1.5464 - val_loss: 1.4635\n",
      "Epoch 5/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5230\n",
      "Epoch 5: val_loss improved from 1.46355 to 1.45003, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 22s 688us/sample - loss: 1.5230 - val_loss: 1.4500\n",
      "Epoch 6/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5076\n",
      "Epoch 6: val_loss improved from 1.45003 to 1.44398, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 652us/sample - loss: 1.5076 - val_loss: 1.4440\n",
      "Epoch 7/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4979\n",
      "Epoch 7: val_loss improved from 1.44398 to 1.42493, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 649us/sample - loss: 1.4979 - val_loss: 1.4249\n",
      "Epoch 8/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4960\n",
      "Epoch 8: val_loss improved from 1.42493 to 1.42143, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 651us/sample - loss: 1.4960 - val_loss: 1.4214\n",
      "Epoch 9/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4940\n",
      "Epoch 9: val_loss improved from 1.42143 to 1.41618, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 649us/sample - loss: 1.4940 - val_loss: 1.4162\n",
      "Epoch 10/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5102\n",
      "Epoch 10: val_loss did not improve from 1.41618\n",
      "32224/32224 [==============================] - 20s 631us/sample - loss: 1.5102 - val_loss: 1.4240\n",
      "Epoch 11/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5013\n",
      "Epoch 11: val_loss improved from 1.41618 to 1.41133, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 643us/sample - loss: 1.5013 - val_loss: 1.4113\n",
      "Epoch 12/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4877\n",
      "Epoch 12: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 20s 635us/sample - loss: 1.4877 - val_loss: 1.4136\n",
      "Epoch 13/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5131\n",
      "Epoch 13: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 21s 643us/sample - loss: 1.5131 - val_loss: 1.4166\n",
      "Epoch 14/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5430\n",
      "Epoch 14: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 21s 639us/sample - loss: 1.5430 - val_loss: 1.4313\n",
      "Epoch 15/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4988\n",
      "Epoch 15: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 20s 629us/sample - loss: 1.4988 - val_loss: 1.4426\n",
      "Epoch 16/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5008\n",
      "Epoch 16: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 20s 630us/sample - loss: 1.5008 - val_loss: 1.4178\n",
      "Epoch 17/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 17: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 22s 679us/sample - loss: 1.4987 - val_loss: 1.4152\n",
      "Epoch 18/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5217\n",
      "Epoch 18: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 20s 635us/sample - loss: 1.5217 - val_loss: 1.4238\n",
      "Epoch 19/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5105\n",
      "Epoch 19: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 21s 641us/sample - loss: 1.5105 - val_loss: 1.4115\n",
      "Epoch 20/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5627\n",
      "Epoch 20: val_loss did not improve from 1.41133\n",
      "32224/32224 [==============================] - 21s 664us/sample - loss: 1.5627 - val_loss: 1.4126\n",
      "Epoch 21/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5347\n",
      "Epoch 21: val_loss improved from 1.41133 to 1.40820, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 726us/sample - loss: 1.5347 - val_loss: 1.4082\n",
      "Epoch 22/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5111\n",
      "Epoch 22: val_loss did not improve from 1.40820\n",
      "32224/32224 [==============================] - 23s 716us/sample - loss: 1.5111 - val_loss: 1.4114\n",
      "Epoch 23/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5436\n",
      "Epoch 23: val_loss improved from 1.40820 to 1.40813, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 707us/sample - loss: 1.5436 - val_loss: 1.4081\n",
      "Epoch 24/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.5383\n",
      "Epoch 24: val_loss did not improve from 1.40813\n",
      "32224/32224 [==============================] - 20s 621us/sample - loss: 1.5383 - val_loss: 1.4165\n",
      "Epoch 25/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4960\n",
      "Epoch 25: val_loss did not improve from 1.40813\n",
      "32224/32224 [==============================] - 22s 681us/sample - loss: 1.4960 - val_loss: 1.4188\n",
      "Epoch 26/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4888\n",
      "Epoch 26: val_loss did not improve from 1.40813\n",
      "32224/32224 [==============================] - 23s 715us/sample - loss: 1.4888 - val_loss: 1.4115\n",
      "Epoch 27/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4798\n",
      "Epoch 27: val_loss improved from 1.40813 to 1.40678, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 725us/sample - loss: 1.4798 - val_loss: 1.4068\n",
      "Epoch 28/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4758\n",
      "Epoch 28: val_loss did not improve from 1.40678\n",
      "32224/32224 [==============================] - 23s 707us/sample - loss: 1.4758 - val_loss: 1.4127\n",
      "Epoch 29/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4672\n",
      "Epoch 29: val_loss improved from 1.40678 to 1.40415, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 712us/sample - loss: 1.4672 - val_loss: 1.4041\n",
      "Epoch 30/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4643\n",
      "Epoch 30: val_loss improved from 1.40415 to 1.40123, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 22s 676us/sample - loss: 1.4643 - val_loss: 1.4012\n",
      "Epoch 31/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4604\n",
      "Epoch 31: val_loss improved from 1.40123 to 1.39883, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 1.4604 - val_loss: 1.3988\n",
      "Epoch 32/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4588\n",
      "Epoch 32: val_loss improved from 1.39883 to 1.39505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 701us/sample - loss: 1.4588 - val_loss: 1.3951\n",
      "Epoch 33/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4559\n",
      "Epoch 33: val_loss improved from 1.39505 to 1.38844, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 624us/sample - loss: 1.4559 - val_loss: 1.3884\n",
      "Epoch 34/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4574\n",
      "Epoch 34: val_loss did not improve from 1.38844\n",
      "32224/32224 [==============================] - 20s 617us/sample - loss: 1.4574 - val_loss: 1.3917\n",
      "Epoch 35/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4510\n",
      "Epoch 35: val_loss improved from 1.38844 to 1.38509, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 637us/sample - loss: 1.4510 - val_loss: 1.3851\n",
      "Epoch 36/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4481\n",
      "Epoch 36: val_loss did not improve from 1.38509\n",
      "32224/32224 [==============================] - 20s 620us/sample - loss: 1.4481 - val_loss: 1.3872\n",
      "Epoch 37/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4475\n",
      "Epoch 37: val_loss improved from 1.38509 to 1.38095, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 633us/sample - loss: 1.4475 - val_loss: 1.3809\n",
      "Epoch 38/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4465\n",
      "Epoch 38: val_loss improved from 1.38095 to 1.38091, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 636us/sample - loss: 1.4465 - val_loss: 1.3809\n",
      "Epoch 39/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4421\n",
      "Epoch 39: val_loss improved from 1.38091 to 1.37948, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 640us/sample - loss: 1.4421 - val_loss: 1.3795\n",
      "Epoch 40/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 40: val_loss improved from 1.37948 to 1.37933, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 24s 731us/sample - loss: 1.4412 - val_loss: 1.3793\n",
      "Epoch 41/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 41: val_loss did not improve from 1.37933\n",
      "32224/32224 [==============================] - 22s 696us/sample - loss: 1.4354 - val_loss: 1.3821\n",
      "Epoch 42/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 42: val_loss improved from 1.37933 to 1.37432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 633us/sample - loss: 1.4346 - val_loss: 1.3743\n",
      "Epoch 43/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4344\n",
      "Epoch 43: val_loss did not improve from 1.37432\n",
      "32224/32224 [==============================] - 21s 643us/sample - loss: 1.4344 - val_loss: 1.3780\n",
      "Epoch 44/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 44: val_loss improved from 1.37432 to 1.37418, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 635us/sample - loss: 1.4321 - val_loss: 1.3742\n",
      "Epoch 45/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4319\n",
      "Epoch 45: val_loss did not improve from 1.37418\n",
      "32224/32224 [==============================] - 20s 631us/sample - loss: 1.4319 - val_loss: 1.3779\n",
      "Epoch 46/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4295\n",
      "Epoch 46: val_loss improved from 1.37418 to 1.37145, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 636us/sample - loss: 1.4295 - val_loss: 1.3715\n",
      "Epoch 47/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 47: val_loss did not improve from 1.37145\n",
      "32224/32224 [==============================] - 20s 629us/sample - loss: 1.4266 - val_loss: 1.3754\n",
      "Epoch 48/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4279\n",
      "Epoch 48: val_loss improved from 1.37145 to 1.36826, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 720us/sample - loss: 1.4279 - val_loss: 1.3683\n",
      "Epoch 49/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4260\n",
      "Epoch 49: val_loss did not improve from 1.36826\n",
      "32224/32224 [==============================] - 21s 655us/sample - loss: 1.4260 - val_loss: 1.3694\n",
      "Epoch 50/50\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 50: val_loss did not improve from 1.36826\n",
      "32224/32224 [==============================] - 21s 638us/sample - loss: 1.4232 - val_loss: 1.3723\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:48:29.422300: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_418_1/lstm_cell_1269/kernel/Assign' id:647862 op device:{requested: '', assigned: ''} def:{{{node lstm_418_1/lstm_cell_1269/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_418_1/lstm_cell_1269/kernel, lstm_418_1/lstm_cell_1269/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 18:49:02.789804: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_429_1/lstm_cell_1280/bias/v/Assign' id:653697 op device:{requested: '', assigned: ''} def:{{{node lstm_429_1/lstm_cell_1280/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_429_1/lstm_cell_1280/bias/v, lstm_429_1/lstm_cell_1280/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 18:49:35.994328: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_59_1/cond/Merge' id:652053 op device:{requested: '', assigned: ''} def:{{{node dropout_59_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_59_1/cond/Identity, dropout_59_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1190)\n",
      "(1514, 1190)\n",
      "(1644, 1190)\n",
      "(1764, 1190)\n",
      "(1836, 1190)\n",
      "(1699, 1190)\n",
      "(1369, 1190)\n",
      "(1606, 1190)\n",
      "(1740, 1190)\n",
      "(1526, 1190)\n",
      "(1908, 1190)\n",
      "(1715, 1190)\n",
      "(1764, 1190)\n",
      "(1872, 1190)\n",
      "(1728, 1190)\n",
      "(1812, 1190)\n",
      "(970, 1190)\n",
      "(1668, 1190)\n",
      "(1884, 1190)\n",
      "{1: 7.210416602856749, 2: 3.2685380574285285, 4: 9.341694454642981, 5: 7.0726158194764706, 6: 7.103856558751333, 8: 9.098498912281219, 9: 4.283293761239661, 11: 6.504497256737035, 12: 9.4835263011555, 13: 7.338155838339015, 17: 9.014798862519426, 19: 8.780560442677082, 21: 10.0, 22: 1.0, 25: 7.660277520438731, 26: 6.469893121536116, 27: 3.5609118540066196, 28: 7.174239064239649, 29: 2.84023580963549}\n",
      "Train on 32224 samples, validate on 3587 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:56:22.042189: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 11.2277\n",
      "Epoch 1: val_loss improved from inf to 1.41036, saving model to ./checkpoints/unknown_person_few_shot_p10_41.h5\n",
      "32224/32224 [==============================] - 82s 3ms/sample - loss: 11.2277 - val_loss: 1.4104\n",
      "Epoch 2/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.1602\n",
      "Epoch 2: val_loss improved from 1.41036 to 1.39820, saving model to ./checkpoints/unknown_person_few_shot_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 647us/sample - loss: 11.1602 - val_loss: 1.3982\n",
      "Epoch 3/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0578\n",
      "Epoch 3: val_loss improved from 1.39820 to 1.39548, saving model to ./checkpoints/unknown_person_few_shot_p10_41.h5\n",
      "32224/32224 [==============================] - 22s 697us/sample - loss: 11.0578 - val_loss: 1.3955\n",
      "Epoch 4/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 11.0728\n",
      "Epoch 4: val_loss improved from 1.39548 to 1.38348, saving model to ./checkpoints/unknown_person_few_shot_p10_41.h5\n",
      "32224/32224 [==============================] - 24s 736us/sample - loss: 11.0728 - val_loss: 1.3835\n",
      "Epoch 5/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9999\n",
      "Epoch 5: val_loss improved from 1.38348 to 1.37343, saving model to ./checkpoints/unknown_person_few_shot_p10_41.h5\n",
      "32224/32224 [==============================] - 24s 734us/sample - loss: 10.9999 - val_loss: 1.3734\n",
      "Epoch 6/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9689\n",
      "Epoch 6: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 21s 656us/sample - loss: 10.9689 - val_loss: 1.3754\n",
      "Epoch 7/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9393\n",
      "Epoch 7: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 625us/sample - loss: 10.9393 - val_loss: 1.3784\n",
      "Epoch 8/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9336\n",
      "Epoch 8: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 10.9336 - val_loss: 1.3927\n",
      "Epoch 9/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8939\n",
      "Epoch 9: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 627us/sample - loss: 10.8939 - val_loss: 1.3796\n",
      "Epoch 10/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.9050\n",
      "Epoch 10: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 627us/sample - loss: 10.9050 - val_loss: 1.3779\n",
      "Epoch 11/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8821\n",
      "Epoch 11: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 21s 656us/sample - loss: 10.8821 - val_loss: 1.3781\n",
      "Epoch 12/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8744\n",
      "Epoch 12: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 23s 721us/sample - loss: 10.8744 - val_loss: 1.3744\n",
      "Epoch 13/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8448\n",
      "Epoch 13: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 22s 687us/sample - loss: 10.8448 - val_loss: 1.3954\n",
      "Epoch 14/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8170\n",
      "Epoch 14: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 21s 647us/sample - loss: 10.8170 - val_loss: 1.3784\n",
      "Epoch 15/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.8110\n",
      "Epoch 15: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 629us/sample - loss: 10.8110 - val_loss: 1.3750\n",
      "Epoch 16/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7994\n",
      "Epoch 16: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 628us/sample - loss: 10.7994 - val_loss: 1.3954\n",
      "Epoch 17/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7965\n",
      "Epoch 17: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 625us/sample - loss: 10.7965 - val_loss: 1.3817\n",
      "Epoch 18/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7956\n",
      "Epoch 18: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 627us/sample - loss: 10.7956 - val_loss: 1.3851\n",
      "Epoch 19/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7803\n",
      "Epoch 19: val_loss did not improve from 1.37343\n",
      "32224/32224 [==============================] - 20s 629us/sample - loss: 10.7803 - val_loss: 1.3810\n",
      "Epoch 20/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 10.7879\n",
      "Epoch 20: val_loss improved from 1.37343 to 1.37111, saving model to ./checkpoints/unknown_person_few_shot_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 638us/sample - loss: 10.7879 - val_loss: 1.3711\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:04:40.381563: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_422_2/lstm_cell_1310/kernel/Assign' id:667900 op device:{requested: '', assigned: ''} def:{{{node lstm_422_2/lstm_cell_1310/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_422_2/lstm_cell_1310/kernel, lstm_422_2/lstm_cell_1310/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 19:05:15.409612: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_415_2/lstm_cell_1303/kernel/m/Assign' id:672232 op device:{requested: '', assigned: ''} def:{{{node lstm_415_2/lstm_cell_1303/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_415_2/lstm_cell_1303/kernel/m, lstm_415_2/lstm_cell_1303/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32224 samples, validate on 3587 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:05:53.605437: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:08:48.950715: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:09:11.904456: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36692, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 83s 3ms/sample - loss: 1.4235 - val_loss: 1.3669\n",
      "Epoch 2/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4194\n",
      "Epoch 2: val_loss improved from 1.36692 to 1.36669, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 661us/sample - loss: 1.4194 - val_loss: 1.3667\n",
      "Epoch 3/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 3: val_loss did not improve from 1.36669\n",
      "32224/32224 [==============================] - 22s 677us/sample - loss: 1.4204 - val_loss: 1.3737\n",
      "Epoch 4/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4156\n",
      "Epoch 4: val_loss improved from 1.36669 to 1.36399, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 716us/sample - loss: 1.4156 - val_loss: 1.3640\n",
      "Epoch 5/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4169\n",
      "Epoch 5: val_loss improved from 1.36399 to 1.36228, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 652us/sample - loss: 1.4169 - val_loss: 1.3623\n",
      "Epoch 6/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 6: val_loss improved from 1.36228 to 1.35733, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 21s 656us/sample - loss: 1.4149 - val_loss: 1.3573\n",
      "Epoch 7/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 7: val_loss did not improve from 1.35733\n",
      "32224/32224 [==============================] - 20s 630us/sample - loss: 1.4132 - val_loss: 1.3589\n",
      "Epoch 8/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4110\n",
      "Epoch 8: val_loss did not improve from 1.35733\n",
      "32224/32224 [==============================] - 22s 692us/sample - loss: 1.4110 - val_loss: 1.3605\n",
      "Epoch 9/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4092\n",
      "Epoch 9: val_loss did not improve from 1.35733\n",
      "32224/32224 [==============================] - 21s 649us/sample - loss: 1.4092 - val_loss: 1.3601\n",
      "Epoch 10/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 10: val_loss did not improve from 1.35733\n",
      "32224/32224 [==============================] - 22s 680us/sample - loss: 1.4082 - val_loss: 1.3620\n",
      "Epoch 11/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4085\n",
      "Epoch 11: val_loss did not improve from 1.35733\n",
      "32224/32224 [==============================] - 23s 714us/sample - loss: 1.4085 - val_loss: 1.3611\n",
      "Epoch 12/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 12: val_loss improved from 1.35733 to 1.35125, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 23s 720us/sample - loss: 1.4050 - val_loss: 1.3512\n",
      "Epoch 13/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4031\n",
      "Epoch 13: val_loss did not improve from 1.35125\n",
      "32224/32224 [==============================] - 22s 667us/sample - loss: 1.4031 - val_loss: 1.3555\n",
      "Epoch 14/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 14: val_loss did not improve from 1.35125\n",
      "32224/32224 [==============================] - 20s 619us/sample - loss: 1.4053 - val_loss: 1.3543\n",
      "Epoch 15/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4027\n",
      "Epoch 15: val_loss improved from 1.35125 to 1.34931, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 20s 623us/sample - loss: 1.4027 - val_loss: 1.3493\n",
      "Epoch 16/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 16: val_loss did not improve from 1.34931\n",
      "32224/32224 [==============================] - 20s 617us/sample - loss: 1.4015 - val_loss: 1.3497\n",
      "Epoch 17/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.4000\n",
      "Epoch 17: val_loss improved from 1.34931 to 1.34616, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_41.h5\n",
      "32224/32224 [==============================] - 22s 686us/sample - loss: 1.4000 - val_loss: 1.3462\n",
      "Epoch 18/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 18: val_loss did not improve from 1.34616\n",
      "32224/32224 [==============================] - 23s 710us/sample - loss: 1.3977 - val_loss: 1.3481\n",
      "Epoch 19/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 19: val_loss did not improve from 1.34616\n",
      "32224/32224 [==============================] - 23s 714us/sample - loss: 1.3980 - val_loss: 1.3499\n",
      "Epoch 20/20\n",
      "32224/32224 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 20: val_loss did not improve from 1.34616\n",
      "32224/32224 [==============================] - 21s 665us/sample - loss: 1.3975 - val_loss: 1.3499\n",
      "36006\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:17:21.076669: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_450/lstm_cell_1338/bias/Assign' id:685541 op device:{requested: '', assigned: ''} def:{{{node lstm_450/lstm_cell_1338/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_450/lstm_cell_1338/bias, lstm_450/lstm_cell_1338/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 19:17:40.039162: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_1' id:688140 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 19:17:55.411195: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_2' id:688141 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32405, 95)\n",
      "Train on 32405 samples, validate on 3601 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:18:30.508835: W tensorflow/c/c_api.cc:304] Operation '{name:'training_72/Adam/lstm_455/lstm_cell_1343/bias/m/Assign' id:701073 op device:{requested: '', assigned: ''} def:{{{node training_72/Adam/lstm_455/lstm_cell_1343/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_72/Adam/lstm_455/lstm_cell_1343/bias/m, training_72/Adam/lstm_455/lstm_cell_1343/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:21:32.249272: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 3.2742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-22 19:21:57.567665: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_73/mul' id:690981 op device:{requested: '', assigned: ''} def:{{{node loss_73/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_73/mul/x, loss_73/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.85418, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 190s 6ms/sample - loss: 3.2742 - val_loss: 1.8542\n",
      "Epoch 2/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.8227\n",
      "Epoch 2: val_loss improved from 1.85418 to 1.58964, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 640us/sample - loss: 1.8227 - val_loss: 1.5896\n",
      "Epoch 3/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.6062\n",
      "Epoch 3: val_loss improved from 1.58964 to 1.52629, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 655us/sample - loss: 1.6062 - val_loss: 1.5263\n",
      "Epoch 4/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5497\n",
      "Epoch 4: val_loss improved from 1.52629 to 1.49502, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 655us/sample - loss: 1.5497 - val_loss: 1.4950\n",
      "Epoch 5/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5216\n",
      "Epoch 5: val_loss improved from 1.49502 to 1.47877, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 626us/sample - loss: 1.5216 - val_loss: 1.4788\n",
      "Epoch 6/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5089\n",
      "Epoch 6: val_loss improved from 1.47877 to 1.46035, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 629us/sample - loss: 1.5089 - val_loss: 1.4604\n",
      "Epoch 7/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4939\n",
      "Epoch 7: val_loss improved from 1.46035 to 1.45129, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 22s 684us/sample - loss: 1.4939 - val_loss: 1.4513\n",
      "Epoch 8/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4973\n",
      "Epoch 8: val_loss did not improve from 1.45129\n",
      "32405/32405 [==============================] - 23s 707us/sample - loss: 1.4973 - val_loss: 1.4571\n",
      "Epoch 9/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 9: val_loss improved from 1.45129 to 1.44676, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 695us/sample - loss: 1.4829 - val_loss: 1.4468\n",
      "Epoch 10/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4807\n",
      "Epoch 10: val_loss did not improve from 1.44676\n",
      "32405/32405 [==============================] - 21s 640us/sample - loss: 1.4807 - val_loss: 1.4582\n",
      "Epoch 11/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4732\n",
      "Epoch 11: val_loss improved from 1.44676 to 1.43834, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 719us/sample - loss: 1.4732 - val_loss: 1.4383\n",
      "Epoch 12/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 12: val_loss improved from 1.43834 to 1.43504, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 22s 688us/sample - loss: 1.4781 - val_loss: 1.4350\n",
      "Epoch 13/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4761\n",
      "Epoch 13: val_loss did not improve from 1.43504\n",
      "32405/32405 [==============================] - 20s 627us/sample - loss: 1.4761 - val_loss: 1.4380\n",
      "Epoch 14/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4694\n",
      "Epoch 14: val_loss did not improve from 1.43504\n",
      "32405/32405 [==============================] - 21s 636us/sample - loss: 1.4694 - val_loss: 1.4425\n",
      "Epoch 15/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4611\n",
      "Epoch 15: val_loss improved from 1.43504 to 1.42697, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 639us/sample - loss: 1.4611 - val_loss: 1.4270\n",
      "Epoch 16/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4664\n",
      "Epoch 16: val_loss did not improve from 1.42697\n",
      "32405/32405 [==============================] - 20s 618us/sample - loss: 1.4664 - val_loss: 1.4315\n",
      "Epoch 17/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4615\n",
      "Epoch 17: val_loss improved from 1.42697 to 1.42423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 626us/sample - loss: 1.4615 - val_loss: 1.4242\n",
      "Epoch 18/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4782\n",
      "Epoch 18: val_loss did not improve from 1.42423\n",
      "32405/32405 [==============================] - 20s 620us/sample - loss: 1.4782 - val_loss: 1.4247\n",
      "Epoch 19/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4627\n",
      "Epoch 19: val_loss improved from 1.42423 to 1.41608, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 624us/sample - loss: 1.4627 - val_loss: 1.4161\n",
      "Epoch 20/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 20: val_loss did not improve from 1.41608\n",
      "32405/32405 [==============================] - 20s 620us/sample - loss: 1.4745 - val_loss: 1.4168\n",
      "Epoch 21/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4603\n",
      "Epoch 21: val_loss did not improve from 1.41608\n",
      "32405/32405 [==============================] - 21s 651us/sample - loss: 1.4603 - val_loss: 1.4175\n",
      "Epoch 22/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4601\n",
      "Epoch 22: val_loss did not improve from 1.41608\n",
      "32405/32405 [==============================] - 20s 616us/sample - loss: 1.4601 - val_loss: 1.4235\n",
      "Epoch 23/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4504\n",
      "Epoch 23: val_loss did not improve from 1.41608\n",
      "32405/32405 [==============================] - 20s 614us/sample - loss: 1.4504 - val_loss: 1.4170\n",
      "Epoch 24/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4403\n",
      "Epoch 24: val_loss improved from 1.41608 to 1.41487, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 649us/sample - loss: 1.4403 - val_loss: 1.4149\n",
      "Epoch 25/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4376\n",
      "Epoch 25: val_loss improved from 1.41487 to 1.40657, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 646us/sample - loss: 1.4376 - val_loss: 1.4066\n",
      "Epoch 26/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4362\n",
      "Epoch 26: val_loss improved from 1.40657 to 1.40500, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 720us/sample - loss: 1.4362 - val_loss: 1.4050\n",
      "Epoch 27/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4329\n",
      "Epoch 27: val_loss improved from 1.40500 to 1.40418, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 699us/sample - loss: 1.4329 - val_loss: 1.4042\n",
      "Epoch 28/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4314\n",
      "Epoch 28: val_loss improved from 1.40418 to 1.40056, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 722us/sample - loss: 1.4314 - val_loss: 1.4006\n",
      "Epoch 29/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4264\n",
      "Epoch 29: val_loss improved from 1.40056 to 1.39804, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 719us/sample - loss: 1.4264 - val_loss: 1.3980\n",
      "Epoch 30/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4270\n",
      "Epoch 30: val_loss did not improve from 1.39804\n",
      "32405/32405 [==============================] - 22s 681us/sample - loss: 1.4270 - val_loss: 1.4010\n",
      "Epoch 31/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 31: val_loss improved from 1.39804 to 1.39801, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 706us/sample - loss: 1.4225 - val_loss: 1.3980\n",
      "Epoch 32/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 32: val_loss improved from 1.39801 to 1.38935, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 626us/sample - loss: 1.4206 - val_loss: 1.3893\n",
      "Epoch 33/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 33: val_loss did not improve from 1.38935\n",
      "32405/32405 [==============================] - 20s 623us/sample - loss: 1.4204 - val_loss: 1.3962\n",
      "Epoch 34/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 34: val_loss did not improve from 1.38935\n",
      "32405/32405 [==============================] - 23s 696us/sample - loss: 1.4166 - val_loss: 1.3900\n",
      "Epoch 35/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 35: val_loss improved from 1.38935 to 1.38553, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 22s 684us/sample - loss: 1.4174 - val_loss: 1.3855\n",
      "Epoch 36/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 36: val_loss did not improve from 1.38553\n",
      "32405/32405 [==============================] - 20s 617us/sample - loss: 1.4155 - val_loss: 1.3874\n",
      "Epoch 37/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4142\n",
      "Epoch 37: val_loss did not improve from 1.38553\n",
      "32405/32405 [==============================] - 20s 619us/sample - loss: 1.4142 - val_loss: 1.3919\n",
      "Epoch 38/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 38: val_loss improved from 1.38553 to 1.38320, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 656us/sample - loss: 1.4100 - val_loss: 1.3832\n",
      "Epoch 39/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4105\n",
      "Epoch 39: val_loss did not improve from 1.38320\n",
      "32405/32405 [==============================] - 23s 699us/sample - loss: 1.4105 - val_loss: 1.3836\n",
      "Epoch 40/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 40: val_loss did not improve from 1.38320\n",
      "32405/32405 [==============================] - 23s 695us/sample - loss: 1.4069 - val_loss: 1.3844\n",
      "Epoch 41/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4061\n",
      "Epoch 41: val_loss improved from 1.38320 to 1.37874, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 724us/sample - loss: 1.4061 - val_loss: 1.3787\n",
      "Epoch 42/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 42: val_loss improved from 1.37874 to 1.37721, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 708us/sample - loss: 1.4050 - val_loss: 1.3772\n",
      "Epoch 43/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4020\n",
      "Epoch 43: val_loss improved from 1.37721 to 1.37577, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 24s 726us/sample - loss: 1.4020 - val_loss: 1.3758\n",
      "Epoch 44/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4041\n",
      "Epoch 44: val_loss did not improve from 1.37577\n",
      "32405/32405 [==============================] - 23s 714us/sample - loss: 1.4041 - val_loss: 1.3819\n",
      "Epoch 45/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 45: val_loss did not improve from 1.37577\n",
      "32405/32405 [==============================] - 23s 714us/sample - loss: 1.3996 - val_loss: 1.3795\n",
      "Epoch 46/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 46: val_loss did not improve from 1.37577\n",
      "32405/32405 [==============================] - 23s 714us/sample - loss: 1.4001 - val_loss: 1.3779\n",
      "Epoch 47/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 47: val_loss did not improve from 1.37577\n",
      "32405/32405 [==============================] - 23s 714us/sample - loss: 1.3986 - val_loss: 1.3769\n",
      "Epoch 48/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3968\n",
      "Epoch 48: val_loss improved from 1.37577 to 1.37339, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 725us/sample - loss: 1.3968 - val_loss: 1.3734\n",
      "Epoch 49/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3968\n",
      "Epoch 49: val_loss improved from 1.37339 to 1.37094, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_42.h5\n",
      "32405/32405 [==============================] - 24s 726us/sample - loss: 1.3968 - val_loss: 1.3709\n",
      "Epoch 50/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3958\n",
      "Epoch 50: val_loss did not improve from 1.37094\n",
      "32405/32405 [==============================] - 22s 684us/sample - loss: 1.3958 - val_loss: 1.3776\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:42:40.459462: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_461_1/lstm_cell_1386/kernel/Assign' id:705864 op device:{requested: '', assigned: ''} def:{{{node lstm_461_1/lstm_cell_1386/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_461_1/lstm_cell_1386/kernel, lstm_461_1/lstm_cell_1386/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 19:43:17.983125: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_476_1/lstm_cell_1401/bias/m/Assign' id:710246 op device:{requested: '', assigned: ''} def:{{{node lstm_476_1/lstm_cell_1401/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_476_1/lstm_cell_1401/bias/m, lstm_476_1/lstm_cell_1401/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-22 19:43:54.608967: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_64_1/cond/Merge' id:709095 op device:{requested: '', assigned: ''} def:{{{node dropout_64_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_64_1/cond/Identity, dropout_64_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 995)\n",
      "(1514, 995)\n",
      "(1644, 995)\n",
      "(1764, 995)\n",
      "(1836, 995)\n",
      "(1699, 995)\n",
      "(1369, 995)\n",
      "(1594, 995)\n",
      "(1740, 995)\n",
      "(1526, 995)\n",
      "(1884, 995)\n",
      "(1740, 995)\n",
      "(1764, 995)\n",
      "(1860, 995)\n",
      "(1752, 995)\n",
      "(1788, 995)\n",
      "(982, 995)\n",
      "(1656, 995)\n",
      "(1884, 995)\n",
      "{1: 6.303930855077363, 2: 4.4258145351336236, 4: 9.971950676667188, 5: 6.400948294596948, 6: 6.329324681528798, 8: 9.222435831867266, 9: 5.980553557195612, 11: 7.4801935690620445, 12: 8.821789014935895, 13: 7.26035854874772, 17: 9.293054708279273, 19: 9.354586753173379, 21: 10.0, 22: 1.0, 25: 7.715730362229382, 26: 6.289830540650891, 27: 4.579957458781288, 28: 6.302484102294999, 29: 1.4873321295005246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916958/459382369.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32405 samples, validate on 3601 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:50:53.876437: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 11.3420\n",
      "Epoch 1: val_loss improved from inf to 1.40723, saving model to ./checkpoints/unknown_person_few_shot_p10_42.h5\n",
      "32405/32405 [==============================] - 90s 3ms/sample - loss: 11.3420 - val_loss: 1.4072\n",
      "Epoch 2/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.2218\n",
      "Epoch 2: val_loss improved from 1.40723 to 1.40608, saving model to ./checkpoints/unknown_person_few_shot_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 659us/sample - loss: 11.2218 - val_loss: 1.4061\n",
      "Epoch 3/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.1022\n",
      "Epoch 3: val_loss improved from 1.40608 to 1.38439, saving model to ./checkpoints/unknown_person_few_shot_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 619us/sample - loss: 11.1022 - val_loss: 1.3844\n",
      "Epoch 4/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.0647\n",
      "Epoch 4: val_loss did not improve from 1.38439\n",
      "32405/32405 [==============================] - 20s 612us/sample - loss: 11.0647 - val_loss: 1.3934\n",
      "Epoch 5/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.0431\n",
      "Epoch 5: val_loss did not improve from 1.38439\n",
      "32405/32405 [==============================] - 23s 703us/sample - loss: 11.0431 - val_loss: 1.3880\n",
      "Epoch 6/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.0459\n",
      "Epoch 6: val_loss did not improve from 1.38439\n",
      "32405/32405 [==============================] - 23s 714us/sample - loss: 11.0459 - val_loss: 1.3849\n",
      "Epoch 7/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.9621\n",
      "Epoch 7: val_loss did not improve from 1.38439\n",
      "32405/32405 [==============================] - 23s 715us/sample - loss: 10.9621 - val_loss: 1.3949\n",
      "Epoch 8/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.9795\n",
      "Epoch 8: val_loss did not improve from 1.38439\n",
      "32405/32405 [==============================] - 23s 719us/sample - loss: 10.9795 - val_loss: 1.3903\n",
      "Epoch 9/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.9268\n",
      "Epoch 9: val_loss improved from 1.38439 to 1.38423, saving model to ./checkpoints/unknown_person_few_shot_p10_42.h5\n",
      "32405/32405 [==============================] - 24s 732us/sample - loss: 10.9268 - val_loss: 1.3842\n",
      "Epoch 10/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.9207\n",
      "Epoch 10: val_loss did not improve from 1.38423\n",
      "32405/32405 [==============================] - 23s 715us/sample - loss: 10.9207 - val_loss: 1.3861\n",
      "Epoch 11/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8895\n",
      "Epoch 11: val_loss did not improve from 1.38423\n",
      "32405/32405 [==============================] - 23s 715us/sample - loss: 10.8895 - val_loss: 1.3849\n",
      "Epoch 12/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8832\n",
      "Epoch 12: val_loss did not improve from 1.38423\n",
      "32405/32405 [==============================] - 23s 713us/sample - loss: 10.8832 - val_loss: 1.3852\n",
      "Epoch 13/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8923\n",
      "Epoch 13: val_loss improved from 1.38423 to 1.38024, saving model to ./checkpoints/unknown_person_few_shot_p10_42.h5\n",
      "32405/32405 [==============================] - 23s 724us/sample - loss: 10.8923 - val_loss: 1.3802\n",
      "Epoch 14/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8406\n",
      "Epoch 14: val_loss did not improve from 1.38024\n",
      "32405/32405 [==============================] - 23s 698us/sample - loss: 10.8406 - val_loss: 1.3831\n",
      "Epoch 15/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8566\n",
      "Epoch 15: val_loss did not improve from 1.38024\n",
      "32405/32405 [==============================] - 20s 624us/sample - loss: 10.8566 - val_loss: 1.3861\n",
      "Epoch 16/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8303\n",
      "Epoch 16: val_loss did not improve from 1.38024\n",
      "32405/32405 [==============================] - 21s 634us/sample - loss: 10.8303 - val_loss: 1.3912\n",
      "Epoch 17/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8148\n",
      "Epoch 17: val_loss did not improve from 1.38024\n",
      "32405/32405 [==============================] - 23s 712us/sample - loss: 10.8148 - val_loss: 1.3902\n",
      "Epoch 18/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.8077\n",
      "Epoch 18: val_loss did not improve from 1.38024\n",
      "32405/32405 [==============================] - 23s 712us/sample - loss: 10.8077 - val_loss: 1.3853\n",
      "Epoch 19/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.7753\n",
      "Epoch 19: val_loss did not improve from 1.38024\n",
      "32405/32405 [==============================] - 22s 678us/sample - loss: 10.7753 - val_loss: 1.3902\n",
      "Epoch 20/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.7852\n",
      "Epoch 20: val_loss improved from 1.38024 to 1.37584, saving model to ./checkpoints/unknown_person_few_shot_p10_42.h5\n",
      "32405/32405 [==============================] - 22s 691us/sample - loss: 10.7852 - val_loss: 1.3758\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 19:59:42.596343: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_48_2/bias/Assign' id:728469 op device:{requested: '', assigned: ''} def:{{{node dense_48_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_48_2/bias, dense_48_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 20:00:20.802136: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_472_2/lstm_cell_1434/recurrent_kernel/v/Assign' id:730222 op device:{requested: '', assigned: ''} def:{{{node lstm_472_2/lstm_cell_1434/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_472_2/lstm_cell_1434/recurrent_kernel/v, lstm_472_2/lstm_cell_1434/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32405 samples, validate on 3601 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:01:03.652855: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:04:18.524098: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:04:41.034035: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37005, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 89s 3ms/sample - loss: 1.3987 - val_loss: 1.3700\n",
      "Epoch 2/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3943\n",
      "Epoch 2: val_loss improved from 1.37005 to 1.36911, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 663us/sample - loss: 1.3943 - val_loss: 1.3691\n",
      "Epoch 3/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3929\n",
      "Epoch 3: val_loss did not improve from 1.36911\n",
      "32405/32405 [==============================] - 21s 653us/sample - loss: 1.3929 - val_loss: 1.3718\n",
      "Epoch 4/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 4: val_loss did not improve from 1.36911\n",
      "32405/32405 [==============================] - 23s 702us/sample - loss: 1.3905 - val_loss: 1.3785\n",
      "Epoch 5/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3916\n",
      "Epoch 5: val_loss did not improve from 1.36911\n",
      "32405/32405 [==============================] - 21s 649us/sample - loss: 1.3916 - val_loss: 1.3844\n",
      "Epoch 6/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3858\n",
      "Epoch 6: val_loss did not improve from 1.36911\n",
      "32405/32405 [==============================] - 23s 700us/sample - loss: 1.3858 - val_loss: 1.3724\n",
      "Epoch 7/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3868\n",
      "Epoch 7: val_loss improved from 1.36911 to 1.36550, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 22s 680us/sample - loss: 1.3868 - val_loss: 1.3655\n",
      "Epoch 8/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3839\n",
      "Epoch 8: val_loss did not improve from 1.36550\n",
      "32405/32405 [==============================] - 23s 704us/sample - loss: 1.3839 - val_loss: 1.3690\n",
      "Epoch 9/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3811\n",
      "Epoch 9: val_loss did not improve from 1.36550\n",
      "32405/32405 [==============================] - 20s 604us/sample - loss: 1.3811 - val_loss: 1.3684\n",
      "Epoch 10/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3834\n",
      "Epoch 10: val_loss improved from 1.36550 to 1.36294, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 613us/sample - loss: 1.3834 - val_loss: 1.3629\n",
      "Epoch 11/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3810\n",
      "Epoch 11: val_loss improved from 1.36294 to 1.36251, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 610us/sample - loss: 1.3810 - val_loss: 1.3625\n",
      "Epoch 12/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3785\n",
      "Epoch 12: val_loss improved from 1.36251 to 1.35950, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 611us/sample - loss: 1.3785 - val_loss: 1.3595\n",
      "Epoch 13/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3794\n",
      "Epoch 13: val_loss improved from 1.35950 to 1.35605, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 20s 607us/sample - loss: 1.3794 - val_loss: 1.3561\n",
      "Epoch 14/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3744\n",
      "Epoch 14: val_loss did not improve from 1.35605\n",
      "32405/32405 [==============================] - 19s 597us/sample - loss: 1.3744 - val_loss: 1.3613\n",
      "Epoch 15/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3767\n",
      "Epoch 15: val_loss did not improve from 1.35605\n",
      "32405/32405 [==============================] - 19s 593us/sample - loss: 1.3767 - val_loss: 1.3573\n",
      "Epoch 16/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3749\n",
      "Epoch 16: val_loss did not improve from 1.35605\n",
      "32405/32405 [==============================] - 19s 594us/sample - loss: 1.3749 - val_loss: 1.3606\n",
      "Epoch 17/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3719\n",
      "Epoch 17: val_loss did not improve from 1.35605\n",
      "32405/32405 [==============================] - 21s 646us/sample - loss: 1.3719 - val_loss: 1.3620\n",
      "Epoch 18/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3701\n",
      "Epoch 18: val_loss did not improve from 1.35605\n",
      "32405/32405 [==============================] - 23s 699us/sample - loss: 1.3701 - val_loss: 1.3570\n",
      "Epoch 19/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3683\n",
      "Epoch 19: val_loss improved from 1.35605 to 1.35579, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 634us/sample - loss: 1.3683 - val_loss: 1.3558\n",
      "Epoch 20/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3704\n",
      "Epoch 20: val_loss improved from 1.35579 to 1.35013, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_42.h5\n",
      "32405/32405 [==============================] - 21s 649us/sample - loss: 1.3704 - val_loss: 1.3501\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:12:37.445116: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_492/lstm_cell_1454/bias/Assign' id:743408 op device:{requested: '', assigned: ''} def:{{{node lstm_492/lstm_cell_1454/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_492/lstm_cell_1454/bias, lstm_492/lstm_cell_1454/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 20:12:58.696095: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_1' id:745182 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 20:13:15.939780: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_2' id:745183 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32405, 95)\n",
      "Train on 32405 samples, validate on 3601 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:13:55.106637: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_517/lstm_cell_1479/kernel/Assign' id:747733 op device:{requested: '', assigned: ''} def:{{{node lstm_517/lstm_cell_1479/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_517/lstm_cell_1479/kernel, lstm_517/lstm_cell_1479/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:17:19.038069: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 3.4713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:17:41.914501: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_79/mul' id:748023 op device:{requested: '', assigned: ''} def:{{{node loss_79/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_79/mul/x, loss_79/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.00097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 203s 6ms/sample - loss: 3.4713 - val_loss: 2.0010\n",
      "Epoch 2/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.8075\n",
      "Epoch 2: val_loss improved from 2.00097 to 1.58423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 623us/sample - loss: 1.8075 - val_loss: 1.5842\n",
      "Epoch 3/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5973\n",
      "Epoch 3: val_loss improved from 1.58423 to 1.51618, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 620us/sample - loss: 1.5973 - val_loss: 1.5162\n",
      "Epoch 4/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5420\n",
      "Epoch 4: val_loss improved from 1.51618 to 1.48756, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 631us/sample - loss: 1.5420 - val_loss: 1.4876\n",
      "Epoch 5/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5186\n",
      "Epoch 5: val_loss improved from 1.48756 to 1.46992, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 19s 592us/sample - loss: 1.5186 - val_loss: 1.4699\n",
      "Epoch 6/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5066\n",
      "Epoch 6: val_loss improved from 1.46992 to 1.45859, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 19s 594us/sample - loss: 1.5066 - val_loss: 1.4586\n",
      "Epoch 7/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4972\n",
      "Epoch 7: val_loss improved from 1.45859 to 1.45371, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 19s 599us/sample - loss: 1.4972 - val_loss: 1.4537\n",
      "Epoch 8/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4919\n",
      "Epoch 8: val_loss improved from 1.45371 to 1.44580, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 602us/sample - loss: 1.4919 - val_loss: 1.4458\n",
      "Epoch 9/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4901\n",
      "Epoch 9: val_loss improved from 1.44580 to 1.44119, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 648us/sample - loss: 1.4901 - val_loss: 1.4412\n",
      "Epoch 10/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4881\n",
      "Epoch 10: val_loss improved from 1.44119 to 1.43843, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 22s 669us/sample - loss: 1.4881 - val_loss: 1.4384\n",
      "Epoch 11/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4840\n",
      "Epoch 11: val_loss did not improve from 1.43843\n",
      "32405/32405 [==============================] - 23s 700us/sample - loss: 1.4840 - val_loss: 1.4406\n",
      "Epoch 12/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4738\n",
      "Epoch 12: val_loss improved from 1.43843 to 1.43450, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 699us/sample - loss: 1.4738 - val_loss: 1.4345\n",
      "Epoch 13/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4784\n",
      "Epoch 13: val_loss improved from 1.43450 to 1.43258, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 617us/sample - loss: 1.4784 - val_loss: 1.4326\n",
      "Epoch 14/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4969\n",
      "Epoch 14: val_loss did not improve from 1.43258\n",
      "32405/32405 [==============================] - 21s 653us/sample - loss: 1.4969 - val_loss: 1.4337\n",
      "Epoch 15/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4816\n",
      "Epoch 15: val_loss did not improve from 1.43258\n",
      "32405/32405 [==============================] - 19s 599us/sample - loss: 1.4816 - val_loss: 1.4437\n",
      "Epoch 16/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5128\n",
      "Epoch 16: val_loss did not improve from 1.43258\n",
      "32405/32405 [==============================] - 22s 680us/sample - loss: 1.5128 - val_loss: 1.4349\n",
      "Epoch 17/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4832\n",
      "Epoch 17: val_loss improved from 1.43258 to 1.42436, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 648us/sample - loss: 1.4832 - val_loss: 1.4244\n",
      "Epoch 18/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4795\n",
      "Epoch 18: val_loss did not improve from 1.42436\n",
      "32405/32405 [==============================] - 21s 649us/sample - loss: 1.4795 - val_loss: 1.4264\n",
      "Epoch 19/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4871\n",
      "Epoch 19: val_loss improved from 1.42436 to 1.42070, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 609us/sample - loss: 1.4871 - val_loss: 1.4207\n",
      "Epoch 20/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4880\n",
      "Epoch 20: val_loss did not improve from 1.42070\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 1.4880 - val_loss: 1.4217\n",
      "Epoch 21/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5383\n",
      "Epoch 21: val_loss did not improve from 1.42070\n",
      "32405/32405 [==============================] - 20s 606us/sample - loss: 1.5383 - val_loss: 1.4249\n",
      "Epoch 22/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5655\n",
      "Epoch 22: val_loss did not improve from 1.42070\n",
      "32405/32405 [==============================] - 20s 605us/sample - loss: 1.5655 - val_loss: 1.4520\n",
      "Epoch 23/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5003\n",
      "Epoch 23: val_loss did not improve from 1.42070\n",
      "32405/32405 [==============================] - 22s 665us/sample - loss: 1.5003 - val_loss: 1.4310\n",
      "Epoch 24/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4647\n",
      "Epoch 24: val_loss did not improve from 1.42070\n",
      "32405/32405 [==============================] - 22s 689us/sample - loss: 1.4647 - val_loss: 1.4211\n",
      "Epoch 25/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4569\n",
      "Epoch 25: val_loss improved from 1.42070 to 1.42032, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 603us/sample - loss: 1.4569 - val_loss: 1.4203\n",
      "Epoch 26/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4492\n",
      "Epoch 26: val_loss did not improve from 1.42032\n",
      "32405/32405 [==============================] - 22s 685us/sample - loss: 1.4492 - val_loss: 1.4221\n",
      "Epoch 27/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4464\n",
      "Epoch 27: val_loss improved from 1.42032 to 1.41363, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 703us/sample - loss: 1.4464 - val_loss: 1.4136\n",
      "Epoch 28/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4430\n",
      "Epoch 28: val_loss improved from 1.41363 to 1.41317, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 703us/sample - loss: 1.4430 - val_loss: 1.4132\n",
      "Epoch 29/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4408\n",
      "Epoch 29: val_loss improved from 1.41317 to 1.41181, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 701us/sample - loss: 1.4408 - val_loss: 1.4118\n",
      "Epoch 30/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 30: val_loss improved from 1.41181 to 1.40900, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 708us/sample - loss: 1.4379 - val_loss: 1.4090\n",
      "Epoch 31/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4365\n",
      "Epoch 31: val_loss improved from 1.40900 to 1.40718, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 706us/sample - loss: 1.4365 - val_loss: 1.4072\n",
      "Epoch 32/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4320\n",
      "Epoch 32: val_loss did not improve from 1.40718\n",
      "32405/32405 [==============================] - 20s 606us/sample - loss: 1.4320 - val_loss: 1.4086\n",
      "Epoch 33/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4345\n",
      "Epoch 33: val_loss improved from 1.40718 to 1.40324, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 19s 600us/sample - loss: 1.4345 - val_loss: 1.4032\n",
      "Epoch 34/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 34: val_loss improved from 1.40324 to 1.39973, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 19s 599us/sample - loss: 1.4262 - val_loss: 1.3997\n",
      "Epoch 35/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 35: val_loss did not improve from 1.39973\n",
      "32405/32405 [==============================] - 19s 592us/sample - loss: 1.4266 - val_loss: 1.4010\n",
      "Epoch 36/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 36: val_loss improved from 1.39973 to 1.39706, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 1.4246 - val_loss: 1.3971\n",
      "Epoch 37/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4233\n",
      "Epoch 37: val_loss improved from 1.39706 to 1.39033, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 645us/sample - loss: 1.4233 - val_loss: 1.3903\n",
      "Epoch 38/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4227\n",
      "Epoch 38: val_loss did not improve from 1.39033\n",
      "32405/32405 [==============================] - 22s 694us/sample - loss: 1.4227 - val_loss: 1.3907\n",
      "Epoch 39/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 39: val_loss did not improve from 1.39033\n",
      "32405/32405 [==============================] - 23s 698us/sample - loss: 1.4212 - val_loss: 1.3932\n",
      "Epoch 40/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4182\n",
      "Epoch 40: val_loss improved from 1.39033 to 1.38969, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 709us/sample - loss: 1.4182 - val_loss: 1.3897\n",
      "Epoch 41/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 41: val_loss improved from 1.38969 to 1.38636, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 705us/sample - loss: 1.4173 - val_loss: 1.3864\n",
      "Epoch 42/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 42: val_loss improved from 1.38636 to 1.38515, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 697us/sample - loss: 1.4145 - val_loss: 1.3851\n",
      "Epoch 43/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4121\n",
      "Epoch 43: val_loss improved from 1.38515 to 1.38480, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 708us/sample - loss: 1.4121 - val_loss: 1.3848\n",
      "Epoch 44/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4120\n",
      "Epoch 44: val_loss did not improve from 1.38480\n",
      "32405/32405 [==============================] - 20s 604us/sample - loss: 1.4120 - val_loss: 1.3871\n",
      "Epoch 45/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 45: val_loss improved from 1.38480 to 1.38410, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 618us/sample - loss: 1.4123 - val_loss: 1.3841\n",
      "Epoch 46/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4102\n",
      "Epoch 46: val_loss improved from 1.38410 to 1.38280, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 659us/sample - loss: 1.4102 - val_loss: 1.3828\n",
      "Epoch 47/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 47: val_loss improved from 1.38280 to 1.38206, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 615us/sample - loss: 1.4078 - val_loss: 1.3821\n",
      "Epoch 48/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 48: val_loss improved from 1.38206 to 1.37663, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 638us/sample - loss: 1.4062 - val_loss: 1.3766\n",
      "Epoch 49/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 49: val_loss did not improve from 1.37663\n",
      "32405/32405 [==============================] - 23s 697us/sample - loss: 1.4049 - val_loss: 1.3776\n",
      "Epoch 50/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4040\n",
      "Epoch 50: val_loss did not improve from 1.37663\n",
      "32405/32405 [==============================] - 23s 697us/sample - loss: 1.4040 - val_loss: 1.3816\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:38:07.872491: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_508_1/lstm_cell_1507/kernel/Assign' id:764508 op device:{requested: '', assigned: ''} def:{{{node lstm_508_1/lstm_cell_1507/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_508_1/lstm_cell_1507/kernel, lstm_508_1/lstm_cell_1507/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 20:38:48.177956: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_501_1/lstm_cell_1500/bias/m/Assign' id:767108 op device:{requested: '', assigned: ''} def:{{{node lstm_501_1/lstm_cell_1500/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_501_1/lstm_cell_1500/bias/m, lstm_501_1/lstm_cell_1500/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 20:39:28.028691: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_69_1/cond/Merge' id:766137 op device:{requested: '', assigned: ''} def:{{{node dropout_69_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_69_1/cond/Identity, dropout_69_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 995)\n",
      "(1514, 995)\n",
      "(1644, 995)\n",
      "(1764, 995)\n",
      "(1836, 995)\n",
      "(1699, 995)\n",
      "(1369, 995)\n",
      "(1594, 995)\n",
      "(1740, 995)\n",
      "(1526, 995)\n",
      "(1884, 995)\n",
      "(1740, 995)\n",
      "(1764, 995)\n",
      "(1860, 995)\n",
      "(1752, 995)\n",
      "(1788, 995)\n",
      "(982, 995)\n",
      "(1656, 995)\n",
      "(1884, 995)\n",
      "{1: 6.3037086094142705, 2: 2.029390495199748, 4: 8.394289920549044, 5: 7.337005640888575, 6: 6.075662432587394, 8: 8.480512583686473, 9: 2.3713736759970168, 11: 4.859284402522773, 12: 9.436493660736225, 13: 6.994241637819172, 17: 8.794698976578566, 19: 7.8221242137890306, 21: 10.0, 22: 1.0, 25: 7.09314660059405, 26: 6.595571245047787, 27: 1.1994443175106804, 28: 6.516118941487367, 29: 2.1805620519298}\n",
      "Train on 32405 samples, validate on 3601 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:47:01.477359: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 10.4430\n",
      "Epoch 1: val_loss improved from inf to 1.41334, saving model to ./checkpoints/unknown_person_few_shot_p10_43.h5\n",
      "32405/32405 [==============================] - 93s 3ms/sample - loss: 10.4430 - val_loss: 1.4133\n",
      "Epoch 2/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.2915\n",
      "Epoch 2: val_loss improved from 1.41334 to 1.40919, saving model to ./checkpoints/unknown_person_few_shot_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 640us/sample - loss: 10.2915 - val_loss: 1.4092\n",
      "Epoch 3/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.2294\n",
      "Epoch 3: val_loss improved from 1.40919 to 1.40528, saving model to ./checkpoints/unknown_person_few_shot_p10_43.h5\n",
      "32405/32405 [==============================] - 21s 652us/sample - loss: 10.2294 - val_loss: 1.4053\n",
      "Epoch 4/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.1895\n",
      "Epoch 4: val_loss improved from 1.40528 to 1.39333, saving model to ./checkpoints/unknown_person_few_shot_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 630us/sample - loss: 10.1895 - val_loss: 1.3933\n",
      "Epoch 5/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.1499\n",
      "Epoch 5: val_loss did not improve from 1.39333\n",
      "32405/32405 [==============================] - 21s 662us/sample - loss: 10.1499 - val_loss: 1.4119\n",
      "Epoch 6/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.1542\n",
      "Epoch 6: val_loss improved from 1.39333 to 1.38359, saving model to ./checkpoints/unknown_person_few_shot_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 627us/sample - loss: 10.1542 - val_loss: 1.3836\n",
      "Epoch 7/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0884\n",
      "Epoch 7: val_loss did not improve from 1.38359\n",
      "32405/32405 [==============================] - 22s 689us/sample - loss: 10.0884 - val_loss: 1.4036\n",
      "Epoch 8/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0726\n",
      "Epoch 8: val_loss did not improve from 1.38359\n",
      "32405/32405 [==============================] - 21s 641us/sample - loss: 10.0726 - val_loss: 1.3846\n",
      "Epoch 9/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0952\n",
      "Epoch 9: val_loss did not improve from 1.38359\n",
      "32405/32405 [==============================] - 22s 665us/sample - loss: 10.0952 - val_loss: 1.3923\n",
      "Epoch 10/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0642\n",
      "Epoch 10: val_loss did not improve from 1.38359\n",
      "32405/32405 [==============================] - 23s 707us/sample - loss: 10.0642 - val_loss: 1.3890\n",
      "Epoch 11/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0220\n",
      "Epoch 11: val_loss did not improve from 1.38359\n",
      "32405/32405 [==============================] - 23s 710us/sample - loss: 10.0220 - val_loss: 1.3872\n",
      "Epoch 12/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0076\n",
      "Epoch 12: val_loss improved from 1.38359 to 1.38146, saving model to ./checkpoints/unknown_person_few_shot_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 632us/sample - loss: 10.0076 - val_loss: 1.3815\n",
      "Epoch 13/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0162\n",
      "Epoch 13: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 21s 645us/sample - loss: 10.0162 - val_loss: 1.3956\n",
      "Epoch 14/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 10.0250\n",
      "Epoch 14: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 23s 707us/sample - loss: 10.0250 - val_loss: 1.3868\n",
      "Epoch 15/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 9.9696\n",
      "Epoch 15: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 23s 703us/sample - loss: 9.9696 - val_loss: 1.3889\n",
      "Epoch 16/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 9.9819\n",
      "Epoch 16: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 23s 704us/sample - loss: 9.9819 - val_loss: 1.3927\n",
      "Epoch 17/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 9.9716\n",
      "Epoch 17: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 23s 702us/sample - loss: 9.9716 - val_loss: 1.3934\n",
      "Epoch 18/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 9.9682\n",
      "Epoch 18: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 22s 664us/sample - loss: 9.9682 - val_loss: 1.3900\n",
      "Epoch 19/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 9.9500\n",
      "Epoch 19: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 21s 637us/sample - loss: 9.9500 - val_loss: 1.3847\n",
      "Epoch 20/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 9.9165\n",
      "Epoch 20: val_loss did not improve from 1.38146\n",
      "32405/32405 [==============================] - 20s 624us/sample - loss: 9.9165 - val_loss: 1.3879\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:55:40.309303: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_501_2/lstm_cell_1537/kernel/Assign' id:782784 op device:{requested: '', assigned: ''} def:{{{node lstm_501_2/lstm_cell_1537/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_501_2/lstm_cell_1537/kernel, lstm_501_2/lstm_cell_1537/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 20:56:21.756155: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_513_2/lstm_cell_1549/kernel/v/Assign' id:787319 op device:{requested: '', assigned: ''} def:{{{node lstm_513_2/lstm_cell_1549/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_513_2/lstm_cell_1549/kernel/v, lstm_513_2/lstm_cell_1549/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32405 samples, validate on 3601 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:57:05.695751: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:00:36.758323: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:00:59.943285: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37791, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 96s 3ms/sample - loss: 1.4038 - val_loss: 1.3779\n",
      "Epoch 2/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 2: val_loss improved from 1.37791 to 1.37437, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 621us/sample - loss: 1.4051 - val_loss: 1.3744\n",
      "Epoch 3/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4018\n",
      "Epoch 3: val_loss improved from 1.37437 to 1.37189, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 610us/sample - loss: 1.4018 - val_loss: 1.3719\n",
      "Epoch 4/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 4: val_loss improved from 1.37189 to 1.37083, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 623us/sample - loss: 1.3996 - val_loss: 1.3708\n",
      "Epoch 5/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 5: val_loss did not improve from 1.37083\n",
      "32405/32405 [==============================] - 20s 630us/sample - loss: 1.3992 - val_loss: 1.3734\n",
      "Epoch 6/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 6: val_loss improved from 1.37083 to 1.36908, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 713us/sample - loss: 1.3984 - val_loss: 1.3691\n",
      "Epoch 7/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 7: val_loss improved from 1.36908 to 1.36618, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 711us/sample - loss: 1.3947 - val_loss: 1.3662\n",
      "Epoch 8/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 8: val_loss did not improve from 1.36618\n",
      "32405/32405 [==============================] - 20s 616us/sample - loss: 1.3957 - val_loss: 1.3731\n",
      "Epoch 9/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3934\n",
      "Epoch 9: val_loss did not improve from 1.36618\n",
      "32405/32405 [==============================] - 20s 605us/sample - loss: 1.3934 - val_loss: 1.3712\n",
      "Epoch 10/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 10: val_loss did not improve from 1.36618\n",
      "32405/32405 [==============================] - 20s 610us/sample - loss: 1.3918 - val_loss: 1.3668\n",
      "Epoch 11/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3899\n",
      "Epoch 11: val_loss improved from 1.36618 to 1.35992, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 20s 617us/sample - loss: 1.3899 - val_loss: 1.3599\n",
      "Epoch 12/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3909\n",
      "Epoch 12: val_loss did not improve from 1.35992\n",
      "32405/32405 [==============================] - 22s 693us/sample - loss: 1.3909 - val_loss: 1.3658\n",
      "Epoch 13/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3900\n",
      "Epoch 13: val_loss did not improve from 1.35992\n",
      "32405/32405 [==============================] - 23s 707us/sample - loss: 1.3900 - val_loss: 1.3605\n",
      "Epoch 14/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3864\n",
      "Epoch 14: val_loss did not improve from 1.35992\n",
      "32405/32405 [==============================] - 23s 713us/sample - loss: 1.3864 - val_loss: 1.3690\n",
      "Epoch 15/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3860\n",
      "Epoch 15: val_loss did not improve from 1.35992\n",
      "32405/32405 [==============================] - 23s 716us/sample - loss: 1.3860 - val_loss: 1.3737\n",
      "Epoch 16/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3845\n",
      "Epoch 16: val_loss did not improve from 1.35992\n",
      "32405/32405 [==============================] - 23s 705us/sample - loss: 1.3845 - val_loss: 1.3618\n",
      "Epoch 17/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3825\n",
      "Epoch 17: val_loss improved from 1.35992 to 1.35882, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_43.h5\n",
      "32405/32405 [==============================] - 23s 709us/sample - loss: 1.3825 - val_loss: 1.3588\n",
      "Epoch 18/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 18: val_loss did not improve from 1.35882\n",
      "32405/32405 [==============================] - 23s 701us/sample - loss: 1.3830 - val_loss: 1.3648\n",
      "Epoch 19/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3803\n",
      "Epoch 19: val_loss did not improve from 1.35882\n",
      "32405/32405 [==============================] - 23s 704us/sample - loss: 1.3803 - val_loss: 1.3646\n",
      "Epoch 20/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.3818\n",
      "Epoch 20: val_loss did not improve from 1.35882\n",
      "32405/32405 [==============================] - 20s 621us/sample - loss: 1.3818 - val_loss: 1.3623\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:09:17.635124: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_520/lstm_cell_1556/recurrent_kernel/Assign' id:798956 op device:{requested: '', assigned: ''} def:{{{node lstm_520/lstm_cell_1556/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_520/lstm_cell_1556/recurrent_kernel, lstm_520/lstm_cell_1556/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 21:09:40.577944: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_1' id:802224 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 21:09:58.995046: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_2' id:802225 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32405, 95)\n",
      "Train on 32405 samples, validate on 3601 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:10:40.422802: W tensorflow/c/c_api.cc:304] Operation '{name:'training_84/Adam/lstm_532/lstm_cell_1568/bias/m/Assign' id:815202 op device:{requested: '', assigned: ''} def:{{{node training_84/Adam/lstm_532/lstm_cell_1568/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_84/Adam/lstm_532/lstm_cell_1568/bias/m, training_84/Adam/lstm_532/lstm_cell_1568/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:14:21.551275: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 3.5507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:14:43.987157: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_85/mul' id:805065 op device:{requested: '', assigned: ''} def:{{{node loss_85/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_85/mul/x, loss_85/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.87362, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 219s 7ms/sample - loss: 3.5507 - val_loss: 1.8736\n",
      "Epoch 2/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.8767\n",
      "Epoch 2: val_loss improved from 1.87362 to 1.61312, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 22s 678us/sample - loss: 1.8767 - val_loss: 1.6131\n",
      "Epoch 3/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.6221\n",
      "Epoch 3: val_loss improved from 1.61312 to 1.53224, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 643us/sample - loss: 1.6221 - val_loss: 1.5322\n",
      "Epoch 4/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5549\n",
      "Epoch 4: val_loss improved from 1.53224 to 1.49376, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 633us/sample - loss: 1.5549 - val_loss: 1.4938\n",
      "Epoch 5/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5265\n",
      "Epoch 5: val_loss improved from 1.49376 to 1.47783, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 637us/sample - loss: 1.5265 - val_loss: 1.4778\n",
      "Epoch 6/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5132\n",
      "Epoch 6: val_loss improved from 1.47783 to 1.46315, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 617us/sample - loss: 1.5132 - val_loss: 1.4632\n",
      "Epoch 7/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4988\n",
      "Epoch 7: val_loss improved from 1.46315 to 1.45900, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 22s 676us/sample - loss: 1.4988 - val_loss: 1.4590\n",
      "Epoch 8/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5056\n",
      "Epoch 8: val_loss did not improve from 1.45900\n",
      "32405/32405 [==============================] - 20s 616us/sample - loss: 1.5056 - val_loss: 1.4590\n",
      "Epoch 9/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.6208\n",
      "Epoch 9: val_loss did not improve from 1.45900\n",
      "32405/32405 [==============================] - 20s 628us/sample - loss: 1.6208 - val_loss: 1.4717\n",
      "Epoch 10/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5740\n",
      "Epoch 10: val_loss did not improve from 1.45900\n",
      "32405/32405 [==============================] - 20s 602us/sample - loss: 1.5740 - val_loss: 1.4676\n",
      "Epoch 11/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5157\n",
      "Epoch 11: val_loss improved from 1.45900 to 1.45763, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 611us/sample - loss: 1.5157 - val_loss: 1.4576\n",
      "Epoch 12/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5000\n",
      "Epoch 12: val_loss improved from 1.45763 to 1.45477, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 615us/sample - loss: 1.5000 - val_loss: 1.4548\n",
      "Epoch 13/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4974\n",
      "Epoch 13: val_loss did not improve from 1.45477\n",
      "32405/32405 [==============================] - 20s 618us/sample - loss: 1.4974 - val_loss: 1.4552\n",
      "Epoch 14/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4966\n",
      "Epoch 14: val_loss did not improve from 1.45477\n",
      "32405/32405 [==============================] - 20s 602us/sample - loss: 1.4966 - val_loss: 1.4558\n",
      "Epoch 15/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4880\n",
      "Epoch 15: val_loss improved from 1.45477 to 1.44962, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 610us/sample - loss: 1.4880 - val_loss: 1.4496\n",
      "Epoch 16/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5110\n",
      "Epoch 16: val_loss did not improve from 1.44962\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 1.5110 - val_loss: 1.4505\n",
      "Epoch 17/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4928\n",
      "Epoch 17: val_loss improved from 1.44962 to 1.44804, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 608us/sample - loss: 1.4928 - val_loss: 1.4480\n",
      "Epoch 18/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.6223\n",
      "Epoch 18: val_loss did not improve from 1.44804\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 1.6223 - val_loss: 1.4787\n",
      "Epoch 19/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5064\n",
      "Epoch 19: val_loss did not improve from 1.44804\n",
      "32405/32405 [==============================] - 19s 602us/sample - loss: 1.5064 - val_loss: 1.4641\n",
      "Epoch 20/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5027\n",
      "Epoch 20: val_loss did not improve from 1.44804\n",
      "32405/32405 [==============================] - 20s 603us/sample - loss: 1.5027 - val_loss: 1.4551\n",
      "Epoch 21/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5033\n",
      "Epoch 21: val_loss did not improve from 1.44804\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 1.5033 - val_loss: 1.4559\n",
      "Epoch 22/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.5208\n",
      "Epoch 22: val_loss did not improve from 1.44804\n",
      "32405/32405 [==============================] - 19s 600us/sample - loss: 1.5208 - val_loss: 1.4583\n",
      "Epoch 23/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4944\n",
      "Epoch 23: val_loss improved from 1.44804 to 1.44391, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 610us/sample - loss: 1.4944 - val_loss: 1.4439\n",
      "Epoch 24/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4876\n",
      "Epoch 24: val_loss did not improve from 1.44391\n",
      "32405/32405 [==============================] - 22s 678us/sample - loss: 1.4876 - val_loss: 1.4494\n",
      "Epoch 25/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4976\n",
      "Epoch 25: val_loss did not improve from 1.44391\n",
      "32405/32405 [==============================] - 22s 687us/sample - loss: 1.4976 - val_loss: 1.4491\n",
      "Epoch 26/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4826\n",
      "Epoch 26: val_loss improved from 1.44391 to 1.43805, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 24s 727us/sample - loss: 1.4826 - val_loss: 1.4381\n",
      "Epoch 27/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4758\n",
      "Epoch 27: val_loss did not improve from 1.43805\n",
      "32405/32405 [==============================] - 23s 715us/sample - loss: 1.4758 - val_loss: 1.4386\n",
      "Epoch 28/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4725\n",
      "Epoch 28: val_loss improved from 1.43805 to 1.43107, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 24s 727us/sample - loss: 1.4725 - val_loss: 1.4311\n",
      "Epoch 29/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4690\n",
      "Epoch 29: val_loss improved from 1.43107 to 1.42857, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 23s 721us/sample - loss: 1.4690 - val_loss: 1.4286\n",
      "Epoch 30/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4645\n",
      "Epoch 30: val_loss improved from 1.42857 to 1.42608, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 23s 696us/sample - loss: 1.4645 - val_loss: 1.4261\n",
      "Epoch 31/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4630\n",
      "Epoch 31: val_loss did not improve from 1.42608\n",
      "32405/32405 [==============================] - 23s 708us/sample - loss: 1.4630 - val_loss: 1.4289\n",
      "Epoch 32/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4615\n",
      "Epoch 32: val_loss improved from 1.42608 to 1.41912, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 24s 726us/sample - loss: 1.4615 - val_loss: 1.4191\n",
      "Epoch 33/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4602\n",
      "Epoch 33: val_loss improved from 1.41912 to 1.41860, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 24s 725us/sample - loss: 1.4602 - val_loss: 1.4186\n",
      "Epoch 34/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4581\n",
      "Epoch 34: val_loss did not improve from 1.41860\n",
      "32405/32405 [==============================] - 23s 701us/sample - loss: 1.4581 - val_loss: 1.4202\n",
      "Epoch 35/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4554\n",
      "Epoch 35: val_loss improved from 1.41860 to 1.41770, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 630us/sample - loss: 1.4554 - val_loss: 1.4177\n",
      "Epoch 36/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4519\n",
      "Epoch 36: val_loss improved from 1.41770 to 1.41571, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 611us/sample - loss: 1.4519 - val_loss: 1.4157\n",
      "Epoch 37/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4515\n",
      "Epoch 37: val_loss improved from 1.41571 to 1.41149, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 615us/sample - loss: 1.4515 - val_loss: 1.4115\n",
      "Epoch 38/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4536\n",
      "Epoch 38: val_loss did not improve from 1.41149\n",
      "32405/32405 [==============================] - 20s 605us/sample - loss: 1.4536 - val_loss: 1.4132\n",
      "Epoch 39/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4467\n",
      "Epoch 39: val_loss improved from 1.41149 to 1.40930, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 613us/sample - loss: 1.4467 - val_loss: 1.4093\n",
      "Epoch 40/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4458\n",
      "Epoch 40: val_loss did not improve from 1.40930\n",
      "32405/32405 [==============================] - 20s 610us/sample - loss: 1.4458 - val_loss: 1.4162\n",
      "Epoch 41/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4421\n",
      "Epoch 41: val_loss improved from 1.40930 to 1.40534, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 619us/sample - loss: 1.4421 - val_loss: 1.4053\n",
      "Epoch 42/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4421\n",
      "Epoch 42: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 23s 697us/sample - loss: 1.4421 - val_loss: 1.4057\n",
      "Epoch 43/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 43: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 20s 619us/sample - loss: 1.4412 - val_loss: 1.4129\n",
      "Epoch 44/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4403\n",
      "Epoch 44: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 20s 603us/sample - loss: 1.4403 - val_loss: 1.4131\n",
      "Epoch 45/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4373\n",
      "Epoch 45: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 20s 603us/sample - loss: 1.4373 - val_loss: 1.4074\n",
      "Epoch 46/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 46: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 19s 602us/sample - loss: 1.4379 - val_loss: 1.4083\n",
      "Epoch 47/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 47: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 1.4379 - val_loss: 1.4067\n",
      "Epoch 48/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4343\n",
      "Epoch 48: val_loss did not improve from 1.40534\n",
      "32405/32405 [==============================] - 22s 670us/sample - loss: 1.4343 - val_loss: 1.4064\n",
      "Epoch 49/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4351\n",
      "Epoch 49: val_loss improved from 1.40534 to 1.40019, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_44.h5\n",
      "32405/32405 [==============================] - 24s 730us/sample - loss: 1.4351 - val_loss: 1.4002\n",
      "Epoch 50/50\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4385\n",
      "Epoch 50: val_loss did not improve from 1.40019\n",
      "32405/32405 [==============================] - 22s 683us/sample - loss: 1.4385 - val_loss: 1.4036\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:35:20.808791: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_552_1/lstm_cell_1625/bias/Assign' id:822699 op device:{requested: '', assigned: ''} def:{{{node lstm_552_1/lstm_cell_1625/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_552_1/lstm_cell_1625/bias, lstm_552_1/lstm_cell_1625/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 21:36:06.615662: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_533_1/lstm_cell_1606/recurrent_kernel/m/Assign' id:824070 op device:{requested: '', assigned: ''} def:{{{node lstm_533_1/lstm_cell_1606/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_533_1/lstm_cell_1606/recurrent_kernel/m, lstm_533_1/lstm_cell_1606/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 21:36:51.287593: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_74_1/cond/Merge' id:823179 op device:{requested: '', assigned: ''} def:{{{node dropout_74_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_74_1/cond/Identity, dropout_74_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 995)\n",
      "(1514, 995)\n",
      "(1644, 995)\n",
      "(1764, 995)\n",
      "(1836, 995)\n",
      "(1699, 995)\n",
      "(1369, 995)\n",
      "(1594, 995)\n",
      "(1740, 995)\n",
      "(1526, 995)\n",
      "(1884, 995)\n",
      "(1740, 995)\n",
      "(1764, 995)\n",
      "(1860, 995)\n",
      "(1752, 995)\n",
      "(1788, 995)\n",
      "(982, 995)\n",
      "(1656, 995)\n",
      "(1884, 995)\n",
      "{1: 7.7586356911825956, 2: 5.571465977200777, 4: 8.712172995832844, 5: 6.980579580199063, 6: 7.136717844671318, 8: 9.328643677314961, 9: 6.1286483833654914, 11: 6.799316844228666, 12: 9.202228368001828, 13: 8.307843995486436, 17: 8.925020053790512, 19: 8.561204840933723, 21: 10.0, 22: 1.0, 25: 7.927985042543758, 26: 7.219595640569552, 27: 5.000072536869075, 28: 7.197614315451875, 29: 3.3789732954631906}\n",
      "Train on 32405 samples, validate on 3601 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:45:09.276461: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 11.9979\n",
      "Epoch 1: val_loss improved from inf to 1.42496, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 101s 3ms/sample - loss: 11.9979 - val_loss: 1.4250\n",
      "Epoch 2/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.8125\n",
      "Epoch 2: val_loss improved from 1.42496 to 1.42280, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 22s 692us/sample - loss: 11.8125 - val_loss: 1.4228\n",
      "Epoch 3/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.7916\n",
      "Epoch 3: val_loss improved from 1.42280 to 1.41887, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 650us/sample - loss: 11.7916 - val_loss: 1.4189\n",
      "Epoch 4/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.7174\n",
      "Epoch 4: val_loss did not improve from 1.41887\n",
      "32405/32405 [==============================] - 20s 625us/sample - loss: 11.7174 - val_loss: 1.4239\n",
      "Epoch 5/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6911\n",
      "Epoch 5: val_loss improved from 1.41887 to 1.41681, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 647us/sample - loss: 11.6911 - val_loss: 1.4168\n",
      "Epoch 6/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6599\n",
      "Epoch 6: val_loss did not improve from 1.41681\n",
      "32405/32405 [==============================] - 20s 615us/sample - loss: 11.6599 - val_loss: 1.4230\n",
      "Epoch 7/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6582\n",
      "Epoch 7: val_loss improved from 1.41681 to 1.41116, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 22s 675us/sample - loss: 11.6582 - val_loss: 1.4112\n",
      "Epoch 8/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6631\n",
      "Epoch 8: val_loss improved from 1.41116 to 1.40741, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 23s 713us/sample - loss: 11.6631 - val_loss: 1.4074\n",
      "Epoch 9/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6626\n",
      "Epoch 9: val_loss did not improve from 1.40741\n",
      "32405/32405 [==============================] - 22s 675us/sample - loss: 11.6626 - val_loss: 1.4129\n",
      "Epoch 10/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6225\n",
      "Epoch 10: val_loss did not improve from 1.40741\n",
      "32405/32405 [==============================] - 21s 636us/sample - loss: 11.6225 - val_loss: 1.4087\n",
      "Epoch 11/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.6058\n",
      "Epoch 11: val_loss improved from 1.40741 to 1.40179, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 23s 706us/sample - loss: 11.6058 - val_loss: 1.4018\n",
      "Epoch 12/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.5495\n",
      "Epoch 12: val_loss did not improve from 1.40179\n",
      "32405/32405 [==============================] - 19s 601us/sample - loss: 11.5495 - val_loss: 1.4018\n",
      "Epoch 13/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.5519\n",
      "Epoch 13: val_loss improved from 1.40179 to 1.40175, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 609us/sample - loss: 11.5519 - val_loss: 1.4018\n",
      "Epoch 14/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.5296\n",
      "Epoch 14: val_loss improved from 1.40175 to 1.39993, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 612us/sample - loss: 11.5296 - val_loss: 1.3999\n",
      "Epoch 15/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.5094\n",
      "Epoch 15: val_loss did not improve from 1.39993\n",
      "32405/32405 [==============================] - 22s 673us/sample - loss: 11.5094 - val_loss: 1.4072\n",
      "Epoch 16/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.4832\n",
      "Epoch 16: val_loss did not improve from 1.39993\n",
      "32405/32405 [==============================] - 20s 616us/sample - loss: 11.4832 - val_loss: 1.4033\n",
      "Epoch 17/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.4811\n",
      "Epoch 17: val_loss did not improve from 1.39993\n",
      "32405/32405 [==============================] - 20s 615us/sample - loss: 11.4811 - val_loss: 1.4037\n",
      "Epoch 18/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.4981\n",
      "Epoch 18: val_loss improved from 1.39993 to 1.39806, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 20s 626us/sample - loss: 11.4981 - val_loss: 1.3981\n",
      "Epoch 19/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.4694\n",
      "Epoch 19: val_loss improved from 1.39806 to 1.39685, saving model to ./checkpoints/unknown_person_few_shot_p10_44.h5\n",
      "32405/32405 [==============================] - 23s 703us/sample - loss: 11.4694 - val_loss: 1.3969\n",
      "Epoch 20/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 11.4599\n",
      "Epoch 20: val_loss did not improve from 1.39685\n",
      "32405/32405 [==============================] - 21s 662us/sample - loss: 11.4599 - val_loss: 1.3989\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:53:48.007262: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_526_2/lstm_cell_1636/bias/Assign' id:837935 op device:{requested: '', assigned: ''} def:{{{node lstm_526_2/lstm_cell_1636/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_526_2/lstm_cell_1636/bias, lstm_526_2/lstm_cell_1636/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 21:54:32.385232: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_540_2/lstm_cell_1650/recurrent_kernel/v/Assign' id:844216 op device:{requested: '', assigned: ''} def:{{{node lstm_540_2/lstm_cell_1650/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_540_2/lstm_cell_1650/recurrent_kernel/v, lstm_540_2/lstm_cell_1650/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32405 samples, validate on 3601 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:55:19.168150: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:59:05.224776: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:59:30.569146: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40695, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 104s 3ms/sample - loss: 1.4355 - val_loss: 1.4069\n",
      "Epoch 2/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 2: val_loss improved from 1.40695 to 1.39280, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 23s 723us/sample - loss: 1.4308 - val_loss: 1.3928\n",
      "Epoch 3/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4300\n",
      "Epoch 3: val_loss did not improve from 1.39280\n",
      "32405/32405 [==============================] - 23s 703us/sample - loss: 1.4300 - val_loss: 1.4005\n",
      "Epoch 4/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4261\n",
      "Epoch 4: val_loss improved from 1.39280 to 1.39157, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 659us/sample - loss: 1.4261 - val_loss: 1.3916\n",
      "Epoch 5/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4261\n",
      "Epoch 5: val_loss did not improve from 1.39157\n",
      "32405/32405 [==============================] - 21s 636us/sample - loss: 1.4261 - val_loss: 1.3990\n",
      "Epoch 6/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4236\n",
      "Epoch 6: val_loss did not improve from 1.39157\n",
      "32405/32405 [==============================] - 21s 644us/sample - loss: 1.4236 - val_loss: 1.3923\n",
      "Epoch 7/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 7: val_loss did not improve from 1.39157\n",
      "32405/32405 [==============================] - 21s 647us/sample - loss: 1.4207 - val_loss: 1.4001\n",
      "Epoch 8/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 8: val_loss did not improve from 1.39157\n",
      "32405/32405 [==============================] - 21s 647us/sample - loss: 1.4176 - val_loss: 1.3935\n",
      "Epoch 9/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4185\n",
      "Epoch 9: val_loss improved from 1.39157 to 1.38450, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 656us/sample - loss: 1.4185 - val_loss: 1.3845\n",
      "Epoch 10/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 10: val_loss did not improve from 1.38450\n",
      "32405/32405 [==============================] - 21s 649us/sample - loss: 1.4164 - val_loss: 1.3865\n",
      "Epoch 11/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 11: val_loss did not improve from 1.38450\n",
      "32405/32405 [==============================] - 21s 650us/sample - loss: 1.4155 - val_loss: 1.3924\n",
      "Epoch 12/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4150\n",
      "Epoch 12: val_loss did not improve from 1.38450\n",
      "32405/32405 [==============================] - 23s 705us/sample - loss: 1.4150 - val_loss: 1.3868\n",
      "Epoch 13/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4135\n",
      "Epoch 13: val_loss did not improve from 1.38450\n",
      "32405/32405 [==============================] - 23s 719us/sample - loss: 1.4135 - val_loss: 1.3846\n",
      "Epoch 14/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 14: val_loss did not improve from 1.38450\n",
      "32405/32405 [==============================] - 23s 699us/sample - loss: 1.4141 - val_loss: 1.3921\n",
      "Epoch 15/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 15: val_loss improved from 1.38450 to 1.38272, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 655us/sample - loss: 1.4117 - val_loss: 1.3827\n",
      "Epoch 16/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4090\n",
      "Epoch 16: val_loss improved from 1.38272 to 1.38202, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 658us/sample - loss: 1.4090 - val_loss: 1.3820\n",
      "Epoch 17/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4074\n",
      "Epoch 17: val_loss did not improve from 1.38202\n",
      "32405/32405 [==============================] - 21s 638us/sample - loss: 1.4074 - val_loss: 1.3886\n",
      "Epoch 18/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4095\n",
      "Epoch 18: val_loss improved from 1.38202 to 1.38046, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_44.h5\n",
      "32405/32405 [==============================] - 21s 645us/sample - loss: 1.4095 - val_loss: 1.3805\n",
      "Epoch 19/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 19: val_loss did not improve from 1.38046\n",
      "32405/32405 [==============================] - 21s 639us/sample - loss: 1.4083 - val_loss: 1.3838\n",
      "Epoch 20/20\n",
      "32405/32405 [==============================] - ETA: 0s - loss: 1.4075\n",
      "Epoch 20: val_loss did not improve from 1.38046\n",
      "32405/32405 [==============================] - 21s 635us/sample - loss: 1.4075 - val_loss: 1.3806\n",
      "36207\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:08:00.266665: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_574/lstm_cell_1684/kernel/Assign' id:858783 op device:{requested: '', assigned: ''} def:{{{node lstm_574/lstm_cell_1684/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_574/lstm_cell_1684/kernel, lstm_574/lstm_cell_1684/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 22:08:25.461838: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_1' id:859266 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 22:08:45.899916: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_2' id:859267 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32573, 95)\n",
      "Train on 32573 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:09:31.558789: W tensorflow/c/c_api.cc:304] Operation '{name:'training_90/Adam/conv2d_62/bias/m/Assign' id:872009 op device:{requested: '', assigned: ''} def:{{{node training_90/Adam/conv2d_62/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_90/Adam/conv2d_62/bias/m, training_90/Adam/conv2d_62/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:13:32.789087: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 3.1807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-22 22:13:57.900940: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_91/mul' id:862107 op device:{requested: '', assigned: ''} def:{{{node loss_91/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_91/mul/x, loss_91/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95085, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 237s 7ms/sample - loss: 3.1807 - val_loss: 1.9508\n",
      "Epoch 2/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.7849\n",
      "Epoch 2: val_loss improved from 1.95085 to 1.58388, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 696us/sample - loss: 1.7849 - val_loss: 1.5839\n",
      "Epoch 3/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.6032\n",
      "Epoch 3: val_loss improved from 1.58388 to 1.51716, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 718us/sample - loss: 1.6032 - val_loss: 1.5172\n",
      "Epoch 4/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5480\n",
      "Epoch 4: val_loss improved from 1.51716 to 1.48971, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 24s 722us/sample - loss: 1.5480 - val_loss: 1.4897\n",
      "Epoch 5/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5243\n",
      "Epoch 5: val_loss improved from 1.48971 to 1.47208, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 716us/sample - loss: 1.5243 - val_loss: 1.4721\n",
      "Epoch 6/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5084\n",
      "Epoch 6: val_loss improved from 1.47208 to 1.46258, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 708us/sample - loss: 1.5084 - val_loss: 1.4626\n",
      "Epoch 7/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4970\n",
      "Epoch 7: val_loss improved from 1.46258 to 1.45389, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 714us/sample - loss: 1.4970 - val_loss: 1.4539\n",
      "Epoch 8/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4889\n",
      "Epoch 8: val_loss improved from 1.45389 to 1.45075, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 717us/sample - loss: 1.4889 - val_loss: 1.4507\n",
      "Epoch 9/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5121\n",
      "Epoch 9: val_loss improved from 1.45075 to 1.44510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 25s 780us/sample - loss: 1.5121 - val_loss: 1.4451\n",
      "Epoch 10/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4842\n",
      "Epoch 10: val_loss improved from 1.44510 to 1.44121, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 676us/sample - loss: 1.4842 - val_loss: 1.4412\n",
      "Epoch 11/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 11: val_loss improved from 1.44121 to 1.43781, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 628us/sample - loss: 1.4836 - val_loss: 1.4378\n",
      "Epoch 12/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4706\n",
      "Epoch 12: val_loss improved from 1.43781 to 1.43449, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 710us/sample - loss: 1.4706 - val_loss: 1.4345\n",
      "Epoch 13/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4700\n",
      "Epoch 13: val_loss improved from 1.43449 to 1.43204, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 711us/sample - loss: 1.4700 - val_loss: 1.4320\n",
      "Epoch 14/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4703\n",
      "Epoch 14: val_loss improved from 1.43204 to 1.42858, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 694us/sample - loss: 1.4703 - val_loss: 1.4286\n",
      "Epoch 15/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4711\n",
      "Epoch 15: val_loss did not improve from 1.42858\n",
      "32573/32573 [==============================] - 23s 700us/sample - loss: 1.4711 - val_loss: 1.4317\n",
      "Epoch 16/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4857\n",
      "Epoch 16: val_loss improved from 1.42858 to 1.42424, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 707us/sample - loss: 1.4857 - val_loss: 1.4242\n",
      "Epoch 17/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4808\n",
      "Epoch 17: val_loss did not improve from 1.42424\n",
      "32573/32573 [==============================] - 23s 705us/sample - loss: 1.4808 - val_loss: 1.4288\n",
      "Epoch 18/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4645\n",
      "Epoch 18: val_loss improved from 1.42424 to 1.41973, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 668us/sample - loss: 1.4645 - val_loss: 1.4197\n",
      "Epoch 19/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4917\n",
      "Epoch 19: val_loss improved from 1.41973 to 1.41953, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.4917 - val_loss: 1.4195\n",
      "Epoch 20/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 20: val_loss improved from 1.41953 to 1.41898, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 700us/sample - loss: 1.4752 - val_loss: 1.4190\n",
      "Epoch 21/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4767\n",
      "Epoch 21: val_loss improved from 1.41898 to 1.41793, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 659us/sample - loss: 1.4767 - val_loss: 1.4179\n",
      "Epoch 22/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4653\n",
      "Epoch 22: val_loss did not improve from 1.41793\n",
      "32573/32573 [==============================] - 20s 599us/sample - loss: 1.4653 - val_loss: 1.4205\n",
      "Epoch 23/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4601\n",
      "Epoch 23: val_loss improved from 1.41793 to 1.41562, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 608us/sample - loss: 1.4601 - val_loss: 1.4156\n",
      "Epoch 24/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4447\n",
      "Epoch 24: val_loss improved from 1.41562 to 1.40881, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 19s 597us/sample - loss: 1.4447 - val_loss: 1.4088\n",
      "Epoch 25/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4413\n",
      "Epoch 25: val_loss improved from 1.40881 to 1.40874, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 19s 595us/sample - loss: 1.4413 - val_loss: 1.4087\n",
      "Epoch 26/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4343\n",
      "Epoch 26: val_loss improved from 1.40874 to 1.40036, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 19s 596us/sample - loss: 1.4343 - val_loss: 1.4004\n",
      "Epoch 27/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4317\n",
      "Epoch 27: val_loss improved from 1.40036 to 1.39872, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 19s 597us/sample - loss: 1.4317 - val_loss: 1.3987\n",
      "Epoch 28/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 28: val_loss improved from 1.39872 to 1.39358, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 622us/sample - loss: 1.4269 - val_loss: 1.3936\n",
      "Epoch 29/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4251\n",
      "Epoch 29: val_loss did not improve from 1.39358\n",
      "32573/32573 [==============================] - 20s 605us/sample - loss: 1.4251 - val_loss: 1.3939\n",
      "Epoch 30/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4257\n",
      "Epoch 30: val_loss improved from 1.39358 to 1.39047, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 628us/sample - loss: 1.4257 - val_loss: 1.3905\n",
      "Epoch 31/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 31: val_loss improved from 1.39047 to 1.38821, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 626us/sample - loss: 1.4202 - val_loss: 1.3882\n",
      "Epoch 32/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4183\n",
      "Epoch 32: val_loss improved from 1.38821 to 1.38426, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 662us/sample - loss: 1.4183 - val_loss: 1.3843\n",
      "Epoch 33/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 33: val_loss did not improve from 1.38426\n",
      "32573/32573 [==============================] - 21s 645us/sample - loss: 1.4176 - val_loss: 1.3849\n",
      "Epoch 34/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4137\n",
      "Epoch 34: val_loss improved from 1.38426 to 1.38274, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 620us/sample - loss: 1.4137 - val_loss: 1.3827\n",
      "Epoch 35/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4131\n",
      "Epoch 35: val_loss improved from 1.38274 to 1.38097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 627us/sample - loss: 1.4131 - val_loss: 1.3810\n",
      "Epoch 36/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 36: val_loss improved from 1.38097 to 1.37819, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 662us/sample - loss: 1.4096 - val_loss: 1.3782\n",
      "Epoch 37/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4114\n",
      "Epoch 37: val_loss improved from 1.37819 to 1.37532, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 638us/sample - loss: 1.4114 - val_loss: 1.3753\n",
      "Epoch 38/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 38: val_loss did not improve from 1.37532\n",
      "32573/32573 [==============================] - 23s 713us/sample - loss: 1.4042 - val_loss: 1.3779\n",
      "Epoch 39/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 39: val_loss improved from 1.37532 to 1.37471, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 24s 726us/sample - loss: 1.4083 - val_loss: 1.3747\n",
      "Epoch 40/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4048\n",
      "Epoch 40: val_loss improved from 1.37471 to 1.37438, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 24s 726us/sample - loss: 1.4048 - val_loss: 1.3744\n",
      "Epoch 41/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4059\n",
      "Epoch 41: val_loss improved from 1.37438 to 1.37072, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 651us/sample - loss: 1.4059 - val_loss: 1.3707\n",
      "Epoch 42/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4048\n",
      "Epoch 42: val_loss did not improve from 1.37072\n",
      "32573/32573 [==============================] - 20s 606us/sample - loss: 1.4048 - val_loss: 1.3747\n",
      "Epoch 43/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4032\n",
      "Epoch 43: val_loss improved from 1.37072 to 1.36910, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 617us/sample - loss: 1.4032 - val_loss: 1.3691\n",
      "Epoch 44/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 44: val_loss improved from 1.36910 to 1.36406, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 619us/sample - loss: 1.3991 - val_loss: 1.3641\n",
      "Epoch 45/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3967\n",
      "Epoch 45: val_loss did not improve from 1.36406\n",
      "32573/32573 [==============================] - 20s 618us/sample - loss: 1.3967 - val_loss: 1.3690\n",
      "Epoch 46/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3981\n",
      "Epoch 46: val_loss improved from 1.36406 to 1.36406, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_45.h5\n",
      "32573/32573 [==============================] - 23s 704us/sample - loss: 1.3981 - val_loss: 1.3641\n",
      "Epoch 47/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3937\n",
      "Epoch 47: val_loss did not improve from 1.36406\n",
      "32573/32573 [==============================] - 23s 703us/sample - loss: 1.3937 - val_loss: 1.3652\n",
      "Epoch 48/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3942\n",
      "Epoch 48: val_loss did not improve from 1.36406\n",
      "32573/32573 [==============================] - 22s 679us/sample - loss: 1.3942 - val_loss: 1.3645\n",
      "Epoch 49/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 49: val_loss did not improve from 1.36406\n",
      "32573/32573 [==============================] - 20s 623us/sample - loss: 1.3957 - val_loss: 1.3650\n",
      "Epoch 50/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3922\n",
      "Epoch 50: val_loss did not improve from 1.36406\n",
      "32573/32573 [==============================] - 20s 606us/sample - loss: 1.3922 - val_loss: 1.3670\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:35:26.952004: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_583_1/lstm_cell_1730/recurrent_kernel/Assign' id:878772 op device:{requested: '', assigned: ''} def:{{{node lstm_583_1/lstm_cell_1730/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_583_1/lstm_cell_1730/recurrent_kernel, lstm_583_1/lstm_cell_1730/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 22:36:14.601663: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_62_1/bias/v/Assign' id:882111 op device:{requested: '', assigned: ''} def:{{{node dense_62_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_62_1/bias/v, dense_62_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-22 22:37:02.205833: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_79_1/cond/Merge' id:880221 op device:{requested: '', assigned: ''} def:{{{node dropout_79_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_79_1/cond/Identity, dropout_79_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 794)\n",
      "(1514, 794)\n",
      "(1644, 794)\n",
      "(1764, 794)\n",
      "(1836, 794)\n",
      "(1699, 794)\n",
      "(1369, 794)\n",
      "(1582, 794)\n",
      "(1716, 794)\n",
      "(1538, 794)\n",
      "(1908, 794)\n",
      "(1727, 794)\n",
      "(1776, 794)\n",
      "(1848, 794)\n",
      "(1752, 794)\n",
      "(1812, 794)\n",
      "(959, 794)\n",
      "(1656, 794)\n",
      "(1896, 794)\n",
      "{1: 6.29718847439895, 2: 3.804599675884139, 4: 9.176466213998523, 5: 8.013533888569787, 6: 7.704400052309838, 8: 9.318514349306637, 9: 4.6324220993681795, 11: 6.588260031180766, 12: 8.941393108435218, 13: 6.420853163206695, 17: 9.086062505128416, 19: 8.770649565110364, 21: 10.0, 22: 1.0, 25: 7.521856024862559, 26: 5.682786345080824, 27: 3.1548364804709936, 28: 6.319929791991466, 29: 3.2564964203659637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2916958/459382369.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32573 samples, validate on 3634 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:44:52.526584: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 11.5658\n",
      "Epoch 1: val_loss improved from inf to 1.39557, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 103s 3ms/sample - loss: 11.5658 - val_loss: 1.3956\n",
      "Epoch 2/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4551\n",
      "Epoch 2: val_loss improved from 1.39557 to 1.37770, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 611us/sample - loss: 11.4551 - val_loss: 1.3777\n",
      "Epoch 3/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.3354\n",
      "Epoch 3: val_loss did not improve from 1.37770\n",
      "32573/32573 [==============================] - 20s 613us/sample - loss: 11.3354 - val_loss: 1.3868\n",
      "Epoch 4/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.2971\n",
      "Epoch 4: val_loss improved from 1.37770 to 1.37397, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 614us/sample - loss: 11.2971 - val_loss: 1.3740\n",
      "Epoch 5/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.2704\n",
      "Epoch 5: val_loss improved from 1.37397 to 1.36904, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 668us/sample - loss: 11.2704 - val_loss: 1.3690\n",
      "Epoch 6/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.2541\n",
      "Epoch 6: val_loss did not improve from 1.36904\n",
      "32573/32573 [==============================] - 23s 709us/sample - loss: 11.2541 - val_loss: 1.3768\n",
      "Epoch 7/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.2426\n",
      "Epoch 7: val_loss improved from 1.36904 to 1.36382, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 20s 628us/sample - loss: 11.2426 - val_loss: 1.3638\n",
      "Epoch 8/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1971\n",
      "Epoch 8: val_loss did not improve from 1.36382\n",
      "32573/32573 [==============================] - 21s 649us/sample - loss: 11.1971 - val_loss: 1.3776\n",
      "Epoch 9/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1727\n",
      "Epoch 9: val_loss improved from 1.36382 to 1.36364, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 672us/sample - loss: 11.1727 - val_loss: 1.3636\n",
      "Epoch 10/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1523\n",
      "Epoch 10: val_loss improved from 1.36364 to 1.36088, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 689us/sample - loss: 11.1523 - val_loss: 1.3609\n",
      "Epoch 11/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0980\n",
      "Epoch 11: val_loss did not improve from 1.36088\n",
      "32573/32573 [==============================] - 22s 676us/sample - loss: 11.0980 - val_loss: 1.3671\n",
      "Epoch 12/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1272\n",
      "Epoch 12: val_loss improved from 1.36088 to 1.35740, saving model to ./checkpoints/unknown_person_few_shot_p10_45.h5\n",
      "32573/32573 [==============================] - 24s 723us/sample - loss: 11.1272 - val_loss: 1.3574\n",
      "Epoch 13/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1264\n",
      "Epoch 13: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 23s 716us/sample - loss: 11.1264 - val_loss: 1.3631\n",
      "Epoch 14/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0735\n",
      "Epoch 14: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 23s 721us/sample - loss: 11.0735 - val_loss: 1.3741\n",
      "Epoch 15/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0617\n",
      "Epoch 15: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 23s 714us/sample - loss: 11.0617 - val_loss: 1.3660\n",
      "Epoch 16/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0607\n",
      "Epoch 16: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 23s 719us/sample - loss: 11.0607 - val_loss: 1.3692\n",
      "Epoch 17/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0466\n",
      "Epoch 17: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 22s 687us/sample - loss: 11.0466 - val_loss: 1.3601\n",
      "Epoch 18/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0385\n",
      "Epoch 18: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 20s 624us/sample - loss: 11.0385 - val_loss: 1.3643\n",
      "Epoch 19/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0232\n",
      "Epoch 19: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 20s 624us/sample - loss: 11.0232 - val_loss: 1.3626\n",
      "Epoch 20/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.9913\n",
      "Epoch 20: val_loss did not improve from 1.35740\n",
      "32573/32573 [==============================] - 21s 639us/sample - loss: 10.9913 - val_loss: 1.3592\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:53:48.053301: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_60_2/bias/Assign' id:893373 op device:{requested: '', assigned: ''} def:{{{node conv2d_60_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_60_2/bias, conv2d_60_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 22:54:36.021076: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_563_2/lstm_cell_1747/bias/m/Assign' id:900410 op device:{requested: '', assigned: ''} def:{{{node lstm_563_2/lstm_cell_1747/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_563_2/lstm_cell_1747/bias/m, lstm_563_2/lstm_cell_1747/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32573 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:55:26.516969: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:59:31.724508: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 22:59:57.478285: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36622, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 109s 3ms/sample - loss: 1.3952 - val_loss: 1.3662\n",
      "Epoch 2/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3931\n",
      "Epoch 2: val_loss improved from 1.36622 to 1.36319, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.3931 - val_loss: 1.3632\n",
      "Epoch 3/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 3: val_loss improved from 1.36319 to 1.36285, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 674us/sample - loss: 1.3935 - val_loss: 1.3629\n",
      "Epoch 4/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 4: val_loss improved from 1.36285 to 1.35992, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.3918 - val_loss: 1.3599\n",
      "Epoch 5/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3889\n",
      "Epoch 5: val_loss improved from 1.35992 to 1.35584, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 642us/sample - loss: 1.3889 - val_loss: 1.3558\n",
      "Epoch 6/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3906\n",
      "Epoch 6: val_loss did not improve from 1.35584\n",
      "32573/32573 [==============================] - 21s 645us/sample - loss: 1.3906 - val_loss: 1.3621\n",
      "Epoch 7/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 7: val_loss did not improve from 1.35584\n",
      "32573/32573 [==============================] - 22s 673us/sample - loss: 1.3887 - val_loss: 1.3565\n",
      "Epoch 8/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3851\n",
      "Epoch 8: val_loss did not improve from 1.35584\n",
      "32573/32573 [==============================] - 23s 717us/sample - loss: 1.3851 - val_loss: 1.3580\n",
      "Epoch 9/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3856\n",
      "Epoch 9: val_loss improved from 1.35584 to 1.35491, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 658us/sample - loss: 1.3856 - val_loss: 1.3549\n",
      "Epoch 10/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 10: val_loss did not improve from 1.35491\n",
      "32573/32573 [==============================] - 20s 612us/sample - loss: 1.3862 - val_loss: 1.3600\n",
      "Epoch 11/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3821\n",
      "Epoch 11: val_loss improved from 1.35491 to 1.35172, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 683us/sample - loss: 1.3821 - val_loss: 1.3517\n",
      "Epoch 12/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3822\n",
      "Epoch 12: val_loss did not improve from 1.35172\n",
      "32573/32573 [==============================] - 21s 634us/sample - loss: 1.3822 - val_loss: 1.3540\n",
      "Epoch 13/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3808\n",
      "Epoch 13: val_loss did not improve from 1.35172\n",
      "32573/32573 [==============================] - 21s 635us/sample - loss: 1.3808 - val_loss: 1.3541\n",
      "Epoch 14/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3799\n",
      "Epoch 14: val_loss did not improve from 1.35172\n",
      "32573/32573 [==============================] - 21s 647us/sample - loss: 1.3799 - val_loss: 1.3548\n",
      "Epoch 15/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3779\n",
      "Epoch 15: val_loss improved from 1.35172 to 1.34594, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 22s 672us/sample - loss: 1.3779 - val_loss: 1.3459\n",
      "Epoch 16/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3782\n",
      "Epoch 16: val_loss did not improve from 1.34594\n",
      "32573/32573 [==============================] - 21s 636us/sample - loss: 1.3782 - val_loss: 1.3508\n",
      "Epoch 17/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3756\n",
      "Epoch 17: val_loss improved from 1.34594 to 1.34556, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_45.h5\n",
      "32573/32573 [==============================] - 21s 648us/sample - loss: 1.3756 - val_loss: 1.3456\n",
      "Epoch 18/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3723\n",
      "Epoch 18: val_loss did not improve from 1.34556\n",
      "32573/32573 [==============================] - 21s 647us/sample - loss: 1.3723 - val_loss: 1.3489\n",
      "Epoch 19/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3744\n",
      "Epoch 19: val_loss did not improve from 1.34556\n",
      "32573/32573 [==============================] - 21s 641us/sample - loss: 1.3744 - val_loss: 1.3496\n",
      "Epoch 20/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3719\n",
      "Epoch 20: val_loss did not improve from 1.34556\n",
      "32573/32573 [==============================] - 21s 641us/sample - loss: 1.3719 - val_loss: 1.3464\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:08:22.433382: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_597/lstm_cell_1781/bias/Assign' id:913544 op device:{requested: '', assigned: ''} def:{{{node lstm_597/lstm_cell_1781/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_597/lstm_cell_1781/bias, lstm_597/lstm_cell_1781/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 23:08:48.868871: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_1' id:916308 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 23:09:10.312815: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_2' id:916309 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32573, 95)\n",
      "Train on 32573 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:09:58.972476: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_615/lstm_cell_1799/bias/Assign' id:916743 op device:{requested: '', assigned: ''} def:{{{node lstm_615/lstm_cell_1799/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_615/lstm_cell_1799/bias, lstm_615/lstm_cell_1799/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:14:16.294303: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 3.0887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:14:39.454243: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_97/mul' id:919149 op device:{requested: '', assigned: ''} def:{{{node loss_97/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_97/mul/x, loss_97/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.87337, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 265s 8ms/sample - loss: 3.0887 - val_loss: 1.8734\n",
      "Epoch 2/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.7754\n",
      "Epoch 2: val_loss improved from 1.87337 to 1.57861, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 641us/sample - loss: 1.7754 - val_loss: 1.5786\n",
      "Epoch 3/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5957\n",
      "Epoch 3: val_loss improved from 1.57861 to 1.51195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.5957 - val_loss: 1.5120\n",
      "Epoch 4/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5424\n",
      "Epoch 4: val_loss improved from 1.51195 to 1.48469, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 628us/sample - loss: 1.5424 - val_loss: 1.4847\n",
      "Epoch 5/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5163\n",
      "Epoch 5: val_loss improved from 1.48469 to 1.47411, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 630us/sample - loss: 1.5163 - val_loss: 1.4741\n",
      "Epoch 6/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4981\n",
      "Epoch 6: val_loss improved from 1.47411 to 1.45831, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 614us/sample - loss: 1.4981 - val_loss: 1.4583\n",
      "Epoch 7/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 7: val_loss improved from 1.45831 to 1.45374, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 615us/sample - loss: 1.4854 - val_loss: 1.4537\n",
      "Epoch 8/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4936\n",
      "Epoch 8: val_loss improved from 1.45374 to 1.44715, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 613us/sample - loss: 1.4936 - val_loss: 1.4472\n",
      "Epoch 9/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4788\n",
      "Epoch 9: val_loss improved from 1.44715 to 1.44224, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 613us/sample - loss: 1.4788 - val_loss: 1.4422\n",
      "Epoch 10/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4768\n",
      "Epoch 10: val_loss improved from 1.44224 to 1.43772, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 615us/sample - loss: 1.4768 - val_loss: 1.4377\n",
      "Epoch 11/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4746\n",
      "Epoch 11: val_loss improved from 1.43772 to 1.43256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 616us/sample - loss: 1.4746 - val_loss: 1.4326\n",
      "Epoch 12/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4900\n",
      "Epoch 12: val_loss did not improve from 1.43256\n",
      "32573/32573 [==============================] - 20s 606us/sample - loss: 1.4900 - val_loss: 1.4405\n",
      "Epoch 13/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4843\n",
      "Epoch 13: val_loss did not improve from 1.43256\n",
      "32573/32573 [==============================] - 20s 608us/sample - loss: 1.4843 - val_loss: 1.4366\n",
      "Epoch 14/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4659\n",
      "Epoch 14: val_loss improved from 1.43256 to 1.42601, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 22s 671us/sample - loss: 1.4659 - val_loss: 1.4260\n",
      "Epoch 15/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4819\n",
      "Epoch 15: val_loss did not improve from 1.42601\n",
      "32573/32573 [==============================] - 23s 720us/sample - loss: 1.4819 - val_loss: 1.4293\n",
      "Epoch 16/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4925\n",
      "Epoch 16: val_loss improved from 1.42601 to 1.42317, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 24s 728us/sample - loss: 1.4925 - val_loss: 1.4232\n",
      "Epoch 17/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4910\n",
      "Epoch 17: val_loss improved from 1.42317 to 1.42082, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 24s 731us/sample - loss: 1.4910 - val_loss: 1.4208\n",
      "Epoch 18/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 18: val_loss improved from 1.42082 to 1.41779, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 24s 727us/sample - loss: 1.4745 - val_loss: 1.4178\n",
      "Epoch 19/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5098\n",
      "Epoch 19: val_loss did not improve from 1.41779\n",
      "32573/32573 [==============================] - 23s 706us/sample - loss: 1.5098 - val_loss: 1.4225\n",
      "Epoch 20/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5434\n",
      "Epoch 20: val_loss did not improve from 1.41779\n",
      "32573/32573 [==============================] - 23s 718us/sample - loss: 1.5434 - val_loss: 1.4387\n",
      "Epoch 21/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5022\n",
      "Epoch 21: val_loss did not improve from 1.41779\n",
      "32573/32573 [==============================] - 23s 714us/sample - loss: 1.5022 - val_loss: 1.4288\n",
      "Epoch 22/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5149\n",
      "Epoch 22: val_loss did not improve from 1.41779\n",
      "32573/32573 [==============================] - 23s 713us/sample - loss: 1.5149 - val_loss: 1.4274\n",
      "Epoch 23/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 23: val_loss did not improve from 1.41779\n",
      "32573/32573 [==============================] - 23s 719us/sample - loss: 1.4827 - val_loss: 1.4237\n",
      "Epoch 24/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4653\n",
      "Epoch 24: val_loss improved from 1.41779 to 1.41558, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 24s 723us/sample - loss: 1.4653 - val_loss: 1.4156\n",
      "Epoch 25/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4563\n",
      "Epoch 25: val_loss did not improve from 1.41558\n",
      "32573/32573 [==============================] - 23s 715us/sample - loss: 1.4563 - val_loss: 1.4210\n",
      "Epoch 26/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4541\n",
      "Epoch 26: val_loss improved from 1.41558 to 1.41405, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 24s 723us/sample - loss: 1.4541 - val_loss: 1.4140\n",
      "Epoch 27/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4526\n",
      "Epoch 27: val_loss did not improve from 1.41405\n",
      "32573/32573 [==============================] - 23s 711us/sample - loss: 1.4526 - val_loss: 1.4189\n",
      "Epoch 28/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4480\n",
      "Epoch 28: val_loss did not improve from 1.41405\n",
      "32573/32573 [==============================] - 23s 703us/sample - loss: 1.4480 - val_loss: 1.4183\n",
      "Epoch 29/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 29: val_loss improved from 1.41405 to 1.40689, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 618us/sample - loss: 1.4432 - val_loss: 1.4069\n",
      "Epoch 30/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4431\n",
      "Epoch 30: val_loss improved from 1.40689 to 1.40175, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 617us/sample - loss: 1.4431 - val_loss: 1.4017\n",
      "Epoch 31/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4387\n",
      "Epoch 31: val_loss improved from 1.40175 to 1.40103, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 645us/sample - loss: 1.4387 - val_loss: 1.4010\n",
      "Epoch 32/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4351\n",
      "Epoch 32: val_loss improved from 1.40103 to 1.39880, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 645us/sample - loss: 1.4351 - val_loss: 1.3988\n",
      "Epoch 33/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4318\n",
      "Epoch 33: val_loss improved from 1.39880 to 1.39807, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 619us/sample - loss: 1.4318 - val_loss: 1.3981\n",
      "Epoch 34/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 34: val_loss improved from 1.39807 to 1.39508, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 631us/sample - loss: 1.4305 - val_loss: 1.3951\n",
      "Epoch 35/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4289\n",
      "Epoch 35: val_loss improved from 1.39508 to 1.39415, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 22s 690us/sample - loss: 1.4289 - val_loss: 1.3942\n",
      "Epoch 36/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4260\n",
      "Epoch 36: val_loss improved from 1.39415 to 1.39059, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 22s 682us/sample - loss: 1.4260 - val_loss: 1.3906\n",
      "Epoch 37/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4263\n",
      "Epoch 37: val_loss improved from 1.39059 to 1.38858, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 655us/sample - loss: 1.4263 - val_loss: 1.3886\n",
      "Epoch 38/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4245\n",
      "Epoch 38: val_loss improved from 1.38858 to 1.38551, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 720us/sample - loss: 1.4245 - val_loss: 1.3855\n",
      "Epoch 39/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 39: val_loss improved from 1.38551 to 1.38356, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 22s 676us/sample - loss: 1.4174 - val_loss: 1.3836\n",
      "Epoch 40/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4188\n",
      "Epoch 40: val_loss improved from 1.38356 to 1.37964, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 651us/sample - loss: 1.4188 - val_loss: 1.3796\n",
      "Epoch 41/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4161\n",
      "Epoch 41: val_loss did not improve from 1.37964\n",
      "32573/32573 [==============================] - 23s 712us/sample - loss: 1.4161 - val_loss: 1.3847\n",
      "Epoch 42/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 42: val_loss did not improve from 1.37964\n",
      "32573/32573 [==============================] - 23s 710us/sample - loss: 1.4174 - val_loss: 1.3803\n",
      "Epoch 43/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4133\n",
      "Epoch 43: val_loss improved from 1.37964 to 1.37956, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 24s 723us/sample - loss: 1.4133 - val_loss: 1.3796\n",
      "Epoch 44/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4134\n",
      "Epoch 44: val_loss improved from 1.37956 to 1.37458, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 702us/sample - loss: 1.4134 - val_loss: 1.3746\n",
      "Epoch 45/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4128\n",
      "Epoch 45: val_loss did not improve from 1.37458\n",
      "32573/32573 [==============================] - 21s 648us/sample - loss: 1.4128 - val_loss: 1.3751\n",
      "Epoch 46/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4104\n",
      "Epoch 46: val_loss improved from 1.37458 to 1.37385, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 648us/sample - loss: 1.4104 - val_loss: 1.3739\n",
      "Epoch 47/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4091\n",
      "Epoch 47: val_loss improved from 1.37385 to 1.37025, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 641us/sample - loss: 1.4091 - val_loss: 1.3703\n",
      "Epoch 48/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 48: val_loss did not improve from 1.37025\n",
      "32573/32573 [==============================] - 22s 687us/sample - loss: 1.4082 - val_loss: 1.3743\n",
      "Epoch 49/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 49: val_loss improved from 1.37025 to 1.36974, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 22s 680us/sample - loss: 1.4058 - val_loss: 1.3697\n",
      "Epoch 50/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4040\n",
      "Epoch 50: val_loss improved from 1.36974 to 1.36937, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 633us/sample - loss: 1.4040 - val_loss: 1.3694\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:36:50.536796: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_603_1/lstm_cell_1824/recurrent_kernel/Assign' id:933092 op device:{requested: '', assigned: ''} def:{{{node lstm_603_1/lstm_cell_1824/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_603_1/lstm_cell_1824/recurrent_kernel, lstm_603_1/lstm_cell_1824/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 23:37:44.508568: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_628_1/lstm_cell_1849/recurrent_kernel/v/Assign' id:939112 op device:{requested: '', assigned: ''} def:{{{node lstm_628_1/lstm_cell_1849/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_628_1/lstm_cell_1849/recurrent_kernel/v, lstm_628_1/lstm_cell_1849/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 23:38:38.285487: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_84_1/cond/Merge' id:937263 op device:{requested: '', assigned: ''} def:{{{node dropout_84_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_84_1/cond/Identity, dropout_84_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 794)\n",
      "(1514, 794)\n",
      "(1644, 794)\n",
      "(1764, 794)\n",
      "(1836, 794)\n",
      "(1699, 794)\n",
      "(1369, 794)\n",
      "(1582, 794)\n",
      "(1716, 794)\n",
      "(1538, 794)\n",
      "(1908, 794)\n",
      "(1727, 794)\n",
      "(1776, 794)\n",
      "(1848, 794)\n",
      "(1752, 794)\n",
      "(1812, 794)\n",
      "(959, 794)\n",
      "(1656, 794)\n",
      "(1896, 794)\n",
      "{1: 7.452223610311451, 2: 4.442430339043812, 4: 7.983185773413142, 5: 6.85074011710645, 6: 6.493675165393849, 8: 9.1472697250497, 9: 4.6387383355241, 11: 5.385480321119355, 12: 9.152371351286758, 13: 7.194011710644954, 17: 8.484218656643456, 19: 7.613711883371536, 21: 10.0, 22: 1.0, 25: 7.476179157659175, 26: 7.160367179776868, 27: 2.772632287921089, 28: 6.810625183318305, 29: 3.084433750122212}\n",
      "Train on 32573 samples, validate on 3634 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:47:31.194822: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 11.3002\n",
      "Epoch 1: val_loss improved from inf to 1.39556, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 111s 3ms/sample - loss: 11.3002 - val_loss: 1.3956\n",
      "Epoch 2/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1478\n",
      "Epoch 2: val_loss improved from 1.39556 to 1.38688, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 617us/sample - loss: 11.1478 - val_loss: 1.3869\n",
      "Epoch 3/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.1121\n",
      "Epoch 3: val_loss improved from 1.38688 to 1.38104, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 701us/sample - loss: 11.1121 - val_loss: 1.3810\n",
      "Epoch 4/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0773\n",
      "Epoch 4: val_loss did not improve from 1.38104\n",
      "32573/32573 [==============================] - 21s 644us/sample - loss: 11.0773 - val_loss: 1.3833\n",
      "Epoch 5/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.0193\n",
      "Epoch 5: val_loss did not improve from 1.38104\n",
      "32573/32573 [==============================] - 20s 603us/sample - loss: 11.0193 - val_loss: 1.3906\n",
      "Epoch 6/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.9766\n",
      "Epoch 6: val_loss improved from 1.38104 to 1.37841, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 614us/sample - loss: 10.9766 - val_loss: 1.3784\n",
      "Epoch 7/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.9652\n",
      "Epoch 7: val_loss did not improve from 1.37841\n",
      "32573/32573 [==============================] - 21s 648us/sample - loss: 10.9652 - val_loss: 1.3786\n",
      "Epoch 8/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.9263\n",
      "Epoch 8: val_loss improved from 1.37841 to 1.37735, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 711us/sample - loss: 10.9263 - val_loss: 1.3773\n",
      "Epoch 9/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8960\n",
      "Epoch 9: val_loss improved from 1.37735 to 1.37326, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 721us/sample - loss: 10.8960 - val_loss: 1.3733\n",
      "Epoch 10/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.9078\n",
      "Epoch 10: val_loss did not improve from 1.37326\n",
      "32573/32573 [==============================] - 23s 709us/sample - loss: 10.9078 - val_loss: 1.3772\n",
      "Epoch 11/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.9134\n",
      "Epoch 11: val_loss improved from 1.37326 to 1.37170, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 718us/sample - loss: 10.9134 - val_loss: 1.3717\n",
      "Epoch 12/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8773\n",
      "Epoch 12: val_loss improved from 1.37170 to 1.36882, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 720us/sample - loss: 10.8773 - val_loss: 1.3688\n",
      "Epoch 13/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8544\n",
      "Epoch 13: val_loss improved from 1.36882 to 1.36786, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 718us/sample - loss: 10.8544 - val_loss: 1.3679\n",
      "Epoch 14/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8175\n",
      "Epoch 14: val_loss improved from 1.36786 to 1.36360, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 23s 718us/sample - loss: 10.8175 - val_loss: 1.3636\n",
      "Epoch 15/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8841\n",
      "Epoch 15: val_loss did not improve from 1.36360\n",
      "32573/32573 [==============================] - 23s 711us/sample - loss: 10.8841 - val_loss: 1.3661\n",
      "Epoch 16/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8352\n",
      "Epoch 16: val_loss did not improve from 1.36360\n",
      "32573/32573 [==============================] - 23s 715us/sample - loss: 10.8352 - val_loss: 1.3674\n",
      "Epoch 17/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.7979\n",
      "Epoch 17: val_loss did not improve from 1.36360\n",
      "32573/32573 [==============================] - 23s 702us/sample - loss: 10.7979 - val_loss: 1.3643\n",
      "Epoch 18/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.8228\n",
      "Epoch 18: val_loss did not improve from 1.36360\n",
      "32573/32573 [==============================] - 23s 711us/sample - loss: 10.8228 - val_loss: 1.3705\n",
      "Epoch 19/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.7514\n",
      "Epoch 19: val_loss improved from 1.36360 to 1.36097, saving model to ./checkpoints/unknown_person_few_shot_p10_46.h5\n",
      "32573/32573 [==============================] - 22s 678us/sample - loss: 10.7514 - val_loss: 1.3610\n",
      "Epoch 20/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 10.7751\n",
      "Epoch 20: val_loss did not improve from 1.36097\n",
      "32573/32573 [==============================] - 20s 606us/sample - loss: 10.7751 - val_loss: 1.3622\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:56:45.416427: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_619_2/lstm_cell_1877/kernel/Assign' id:955032 op device:{requested: '', assigned: ''} def:{{{node lstm_619_2/lstm_cell_1877/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_619_2/lstm_cell_1877/kernel, lstm_619_2/lstm_cell_1877/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-22 23:57:40.225771: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_620_2/lstm_cell_1878/recurrent_kernel/m/Assign' id:957747 op device:{requested: '', assigned: ''} def:{{{node lstm_620_2/lstm_cell_1878/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_620_2/lstm_cell_1878/recurrent_kernel/m, lstm_620_2/lstm_cell_1878/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32573 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 23:58:37.973689: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:03:04.992076: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:03:28.000553: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36658, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 113s 3ms/sample - loss: 1.4037 - val_loss: 1.3666\n",
      "Epoch 2/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 2: val_loss did not improve from 1.36658\n",
      "32573/32573 [==============================] - 20s 611us/sample - loss: 1.4001 - val_loss: 1.3667\n",
      "Epoch 3/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4007\n",
      "Epoch 3: val_loss improved from 1.36658 to 1.36521, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 621us/sample - loss: 1.4007 - val_loss: 1.3652\n",
      "Epoch 4/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3976\n",
      "Epoch 4: val_loss improved from 1.36521 to 1.36514, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 624us/sample - loss: 1.3976 - val_loss: 1.3651\n",
      "Epoch 5/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3981\n",
      "Epoch 5: val_loss improved from 1.36514 to 1.36477, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 622us/sample - loss: 1.3981 - val_loss: 1.3648\n",
      "Epoch 6/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3952\n",
      "Epoch 6: val_loss did not improve from 1.36477\n",
      "32573/32573 [==============================] - 20s 617us/sample - loss: 1.3952 - val_loss: 1.3666\n",
      "Epoch 7/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3942\n",
      "Epoch 7: val_loss improved from 1.36477 to 1.36013, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 625us/sample - loss: 1.3942 - val_loss: 1.3601\n",
      "Epoch 8/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3944\n",
      "Epoch 8: val_loss improved from 1.36013 to 1.35981, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 624us/sample - loss: 1.3944 - val_loss: 1.3598\n",
      "Epoch 9/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 9: val_loss did not improve from 1.35981\n",
      "32573/32573 [==============================] - 20s 616us/sample - loss: 1.3912 - val_loss: 1.3666\n",
      "Epoch 10/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 10: val_loss improved from 1.35981 to 1.35568, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 623us/sample - loss: 1.3896 - val_loss: 1.3557\n",
      "Epoch 11/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3909\n",
      "Epoch 11: val_loss did not improve from 1.35568\n",
      "32573/32573 [==============================] - 20s 615us/sample - loss: 1.3909 - val_loss: 1.3595\n",
      "Epoch 12/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3857\n",
      "Epoch 12: val_loss improved from 1.35568 to 1.35196, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 20s 628us/sample - loss: 1.3857 - val_loss: 1.3520\n",
      "Epoch 13/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3858\n",
      "Epoch 13: val_loss did not improve from 1.35196\n",
      "32573/32573 [==============================] - 20s 616us/sample - loss: 1.3858 - val_loss: 1.3573\n",
      "Epoch 14/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 14: val_loss did not improve from 1.35196\n",
      "32573/32573 [==============================] - 20s 611us/sample - loss: 1.3862 - val_loss: 1.3528\n",
      "Epoch 15/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3858\n",
      "Epoch 15: val_loss did not improve from 1.35196\n",
      "32573/32573 [==============================] - 21s 651us/sample - loss: 1.3858 - val_loss: 1.3553\n",
      "Epoch 16/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 16: val_loss did not improve from 1.35196\n",
      "32573/32573 [==============================] - 21s 634us/sample - loss: 1.3812 - val_loss: 1.3520\n",
      "Epoch 17/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3845\n",
      "Epoch 17: val_loss did not improve from 1.35196\n",
      "32573/32573 [==============================] - 20s 625us/sample - loss: 1.3845 - val_loss: 1.3539\n",
      "Epoch 18/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3826\n",
      "Epoch 18: val_loss did not improve from 1.35196\n",
      "32573/32573 [==============================] - 20s 619us/sample - loss: 1.3826 - val_loss: 1.3577\n",
      "Epoch 19/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3802\n",
      "Epoch 19: val_loss improved from 1.35196 to 1.35156, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_46.h5\n",
      "32573/32573 [==============================] - 21s 633us/sample - loss: 1.3802 - val_loss: 1.3516\n",
      "Epoch 20/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3799\n",
      "Epoch 20: val_loss did not improve from 1.35156\n",
      "32573/32573 [==============================] - 20s 622us/sample - loss: 1.3799 - val_loss: 1.3520\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:11:44.655856: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_638/lstm_cell_1896/recurrent_kernel/Assign' id:971237 op device:{requested: '', assigned: ''} def:{{{node lstm_638/lstm_cell_1896/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_638/lstm_cell_1896/recurrent_kernel, lstm_638/lstm_cell_1896/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 00:12:14.892203: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_1' id:973350 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 00:12:39.702936: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_2' id:973351 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32573, 95)\n",
      "Train on 32573 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:13:34.334205: W tensorflow/c/c_api.cc:304] Operation '{name:'training_102/Adam/lstm_647/lstm_cell_1905/kernel/v/Assign' id:987021 op device:{requested: '', assigned: ''} def:{{{node training_102/Adam/lstm_647/lstm_cell_1905/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_102/Adam/lstm_647/lstm_cell_1905/kernel/v, training_102/Adam/lstm_647/lstm_cell_1905/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:18:15.847613: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 3.5451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:18:39.744514: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_103/mul' id:976191 op device:{requested: '', assigned: ''} def:{{{node loss_103/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_103/mul/x, loss_103/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.08512, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 282s 9ms/sample - loss: 3.5451 - val_loss: 2.0851\n",
      "Epoch 2/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.8500\n",
      "Epoch 2: val_loss improved from 2.08512 to 1.58490, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 623us/sample - loss: 1.8500 - val_loss: 1.5849\n",
      "Epoch 3/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5987\n",
      "Epoch 3: val_loss improved from 1.58490 to 1.51603, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 623us/sample - loss: 1.5987 - val_loss: 1.5160\n",
      "Epoch 4/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5451\n",
      "Epoch 4: val_loss improved from 1.51603 to 1.48638, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 620us/sample - loss: 1.5451 - val_loss: 1.4864\n",
      "Epoch 5/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5227\n",
      "Epoch 5: val_loss improved from 1.48638 to 1.47309, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 622us/sample - loss: 1.5227 - val_loss: 1.4731\n",
      "Epoch 6/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5086\n",
      "Epoch 6: val_loss improved from 1.47309 to 1.46212, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 622us/sample - loss: 1.5086 - val_loss: 1.4621\n",
      "Epoch 7/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4962\n",
      "Epoch 7: val_loss improved from 1.46212 to 1.45502, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 623us/sample - loss: 1.4962 - val_loss: 1.4550\n",
      "Epoch 8/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4982\n",
      "Epoch 8: val_loss improved from 1.45502 to 1.45244, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 626us/sample - loss: 1.4982 - val_loss: 1.4524\n",
      "Epoch 9/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4864\n",
      "Epoch 9: val_loss improved from 1.45244 to 1.43963, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 630us/sample - loss: 1.4864 - val_loss: 1.4396\n",
      "Epoch 10/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5212\n",
      "Epoch 10: val_loss did not improve from 1.43963\n",
      "32573/32573 [==============================] - 20s 623us/sample - loss: 1.5212 - val_loss: 1.4531\n",
      "Epoch 11/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4897\n",
      "Epoch 11: val_loss did not improve from 1.43963\n",
      "32573/32573 [==============================] - 20s 620us/sample - loss: 1.4897 - val_loss: 1.4412\n",
      "Epoch 12/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4848\n",
      "Epoch 12: val_loss improved from 1.43963 to 1.43940, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 633us/sample - loss: 1.4848 - val_loss: 1.4394\n",
      "Epoch 13/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4986\n",
      "Epoch 13: val_loss did not improve from 1.43940\n",
      "32573/32573 [==============================] - 20s 619us/sample - loss: 1.4986 - val_loss: 1.4425\n",
      "Epoch 14/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 14: val_loss improved from 1.43940 to 1.42885, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 673us/sample - loss: 1.4903 - val_loss: 1.4289\n",
      "Epoch 15/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4881\n",
      "Epoch 15: val_loss improved from 1.42885 to 1.42792, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 671us/sample - loss: 1.4881 - val_loss: 1.4279\n",
      "Epoch 16/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4748\n",
      "Epoch 16: val_loss improved from 1.42792 to 1.42627, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 722us/sample - loss: 1.4748 - val_loss: 1.4263\n",
      "Epoch 17/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5161\n",
      "Epoch 17: val_loss did not improve from 1.42627\n",
      "32573/32573 [==============================] - 23s 713us/sample - loss: 1.5161 - val_loss: 1.4308\n",
      "Epoch 18/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4983\n",
      "Epoch 18: val_loss improved from 1.42627 to 1.42450, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 711us/sample - loss: 1.4983 - val_loss: 1.4245\n",
      "Epoch 19/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5141\n",
      "Epoch 19: val_loss did not improve from 1.42450\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.5141 - val_loss: 1.4269\n",
      "Epoch 20/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.5145\n",
      "Epoch 20: val_loss did not improve from 1.42450\n",
      "32573/32573 [==============================] - 22s 668us/sample - loss: 1.5145 - val_loss: 1.4309\n",
      "Epoch 21/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4948\n",
      "Epoch 21: val_loss did not improve from 1.42450\n",
      "32573/32573 [==============================] - 21s 633us/sample - loss: 1.4948 - val_loss: 1.4334\n",
      "Epoch 22/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4918\n",
      "Epoch 22: val_loss did not improve from 1.42450\n",
      "32573/32573 [==============================] - 23s 696us/sample - loss: 1.4918 - val_loss: 1.4290\n",
      "Epoch 23/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4833\n",
      "Epoch 23: val_loss did not improve from 1.42450\n",
      "32573/32573 [==============================] - 22s 677us/sample - loss: 1.4833 - val_loss: 1.4253\n",
      "Epoch 24/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4768\n",
      "Epoch 24: val_loss improved from 1.42450 to 1.42332, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 706us/sample - loss: 1.4768 - val_loss: 1.4233\n",
      "Epoch 25/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 25: val_loss improved from 1.42332 to 1.42124, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 660us/sample - loss: 1.4752 - val_loss: 1.4212\n",
      "Epoch 26/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4655\n",
      "Epoch 26: val_loss improved from 1.42124 to 1.41943, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 671us/sample - loss: 1.4655 - val_loss: 1.4194\n",
      "Epoch 27/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4595\n",
      "Epoch 27: val_loss improved from 1.41943 to 1.41738, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 729us/sample - loss: 1.4595 - val_loss: 1.4174\n",
      "Epoch 28/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4550\n",
      "Epoch 28: val_loss did not improve from 1.41738\n",
      "32573/32573 [==============================] - 23s 716us/sample - loss: 1.4550 - val_loss: 1.4175\n",
      "Epoch 29/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 29: val_loss improved from 1.41738 to 1.41346, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 713us/sample - loss: 1.4535 - val_loss: 1.4135\n",
      "Epoch 30/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4514\n",
      "Epoch 30: val_loss improved from 1.41346 to 1.41204, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 640us/sample - loss: 1.4514 - val_loss: 1.4120\n",
      "Epoch 31/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4496\n",
      "Epoch 31: val_loss improved from 1.41204 to 1.40960, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 630us/sample - loss: 1.4496 - val_loss: 1.4096\n",
      "Epoch 32/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4486\n",
      "Epoch 32: val_loss improved from 1.40960 to 1.40751, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 635us/sample - loss: 1.4486 - val_loss: 1.4075\n",
      "Epoch 33/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4485\n",
      "Epoch 33: val_loss did not improve from 1.40751\n",
      "32573/32573 [==============================] - 20s 617us/sample - loss: 1.4485 - val_loss: 1.4163\n",
      "Epoch 34/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4441\n",
      "Epoch 34: val_loss improved from 1.40751 to 1.40697, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 622us/sample - loss: 1.4441 - val_loss: 1.4070\n",
      "Epoch 35/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4406\n",
      "Epoch 35: val_loss did not improve from 1.40697\n",
      "32573/32573 [==============================] - 20s 621us/sample - loss: 1.4406 - val_loss: 1.4108\n",
      "Epoch 36/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4425\n",
      "Epoch 36: val_loss did not improve from 1.40697\n",
      "32573/32573 [==============================] - 23s 705us/sample - loss: 1.4425 - val_loss: 1.4081\n",
      "Epoch 37/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4388\n",
      "Epoch 37: val_loss improved from 1.40697 to 1.40518, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 708us/sample - loss: 1.4388 - val_loss: 1.4052\n",
      "Epoch 38/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4377\n",
      "Epoch 38: val_loss improved from 1.40518 to 1.40304, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 727us/sample - loss: 1.4377 - val_loss: 1.4030\n",
      "Epoch 39/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4356\n",
      "Epoch 39: val_loss did not improve from 1.40304\n",
      "32573/32573 [==============================] - 21s 653us/sample - loss: 1.4356 - val_loss: 1.4048\n",
      "Epoch 40/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4327\n",
      "Epoch 40: val_loss improved from 1.40304 to 1.40081, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 632us/sample - loss: 1.4327 - val_loss: 1.4008\n",
      "Epoch 41/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4310\n",
      "Epoch 41: val_loss improved from 1.40081 to 1.39614, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.4310 - val_loss: 1.3961\n",
      "Epoch 42/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4292\n",
      "Epoch 42: val_loss improved from 1.39614 to 1.39614, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 722us/sample - loss: 1.4292 - val_loss: 1.3961\n",
      "Epoch 43/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 43: val_loss improved from 1.39614 to 1.39485, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 654us/sample - loss: 1.4269 - val_loss: 1.3949\n",
      "Epoch 44/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4241\n",
      "Epoch 44: val_loss improved from 1.39485 to 1.39195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 634us/sample - loss: 1.4241 - val_loss: 1.3919\n",
      "Epoch 45/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4238\n",
      "Epoch 45: val_loss improved from 1.39195 to 1.39122, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 631us/sample - loss: 1.4238 - val_loss: 1.3912\n",
      "Epoch 46/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4235\n",
      "Epoch 46: val_loss did not improve from 1.39122\n",
      "32573/32573 [==============================] - 22s 673us/sample - loss: 1.4235 - val_loss: 1.3931\n",
      "Epoch 47/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4201\n",
      "Epoch 47: val_loss improved from 1.39122 to 1.38719, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 649us/sample - loss: 1.4201 - val_loss: 1.3872\n",
      "Epoch 48/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4183\n",
      "Epoch 48: val_loss did not improve from 1.38719\n",
      "32573/32573 [==============================] - 21s 642us/sample - loss: 1.4183 - val_loss: 1.3943\n",
      "Epoch 49/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4165\n",
      "Epoch 49: val_loss improved from 1.38719 to 1.38502, saving model to ./checkpoints/unknown_person_few_shot_baseline_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 659us/sample - loss: 1.4165 - val_loss: 1.3850\n",
      "Epoch 50/50\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4181\n",
      "Epoch 50: val_loss did not improve from 1.38502\n",
      "32573/32573 [==============================] - 23s 714us/sample - loss: 1.4181 - val_loss: 1.3916\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:40:52.861703: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_630_1/lstm_cell_1925/bias/Assign' id:988543 op device:{requested: '', assigned: ''} def:{{{node lstm_630_1/lstm_cell_1925/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_630_1/lstm_cell_1925/bias, lstm_630_1/lstm_cell_1925/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 00:41:50.376109: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_649_1/lstm_cell_1944/recurrent_kernel/v/Assign' id:995914 op device:{requested: '', assigned: ''} def:{{{node lstm_649_1/lstm_cell_1944/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_649_1/lstm_cell_1944/recurrent_kernel/v, lstm_649_1/lstm_cell_1944/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 00:42:47.860726: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_89_1/cond/Merge' id:994305 op device:{requested: '', assigned: ''} def:{{{node dropout_89_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_89_1/cond/Identity, dropout_89_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 794)\n",
      "(1514, 794)\n",
      "(1644, 794)\n",
      "(1764, 794)\n",
      "(1836, 794)\n",
      "(1699, 794)\n",
      "(1369, 794)\n",
      "(1582, 794)\n",
      "(1716, 794)\n",
      "(1538, 794)\n",
      "(1908, 794)\n",
      "(1727, 794)\n",
      "(1776, 794)\n",
      "(1848, 794)\n",
      "(1752, 794)\n",
      "(1812, 794)\n",
      "(959, 794)\n",
      "(1656, 794)\n",
      "(1896, 794)\n",
      "{1: 6.324892128720601, 2: 4.378035250364537, 4: 9.695985880875682, 5: 6.95302158197969, 6: 7.22293066722131, 8: 9.198457224162063, 9: 5.604308672128136, 11: 7.213536307698928, 12: 9.163038039211576, 13: 7.3353584427033995, 17: 9.291439205065496, 19: 9.295269111326029, 21: 10.0, 22: 1.0, 25: 8.090101551547878, 26: 6.677749965932482, 27: 4.353791314796558, 28: 7.1788221962432495, 29: 2.2705043702970964}\n",
      "Train on 32573 samples, validate on 3634 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 00:52:22.218136: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 11.9397\n",
      "Epoch 1: val_loss improved from inf to 1.40917, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 121s 4ms/sample - loss: 11.9397 - val_loss: 1.4092\n",
      "Epoch 2/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.8771\n",
      "Epoch 2: val_loss improved from 1.40917 to 1.39876, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 663us/sample - loss: 11.8771 - val_loss: 1.3988\n",
      "Epoch 3/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.8001\n",
      "Epoch 3: val_loss improved from 1.39876 to 1.39677, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 666us/sample - loss: 11.8001 - val_loss: 1.3968\n",
      "Epoch 4/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.7648\n",
      "Epoch 4: val_loss improved from 1.39677 to 1.38578, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 671us/sample - loss: 11.7648 - val_loss: 1.3858\n",
      "Epoch 5/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.7279\n",
      "Epoch 5: val_loss improved from 1.38578 to 1.38408, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 725us/sample - loss: 11.7279 - val_loss: 1.3841\n",
      "Epoch 6/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.6334\n",
      "Epoch 6: val_loss improved from 1.38408 to 1.37571, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 682us/sample - loss: 11.6334 - val_loss: 1.3757\n",
      "Epoch 7/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.6093\n",
      "Epoch 7: val_loss did not improve from 1.37571\n",
      "32573/32573 [==============================] - 21s 635us/sample - loss: 11.6093 - val_loss: 1.3808\n",
      "Epoch 8/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.6136\n",
      "Epoch 8: val_loss improved from 1.37571 to 1.37560, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 22s 661us/sample - loss: 11.6136 - val_loss: 1.3756\n",
      "Epoch 9/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.5972\n",
      "Epoch 9: val_loss did not improve from 1.37560\n",
      "32573/32573 [==============================] - 22s 690us/sample - loss: 11.5972 - val_loss: 1.3789\n",
      "Epoch 10/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.5328\n",
      "Epoch 10: val_loss did not improve from 1.37560\n",
      "32573/32573 [==============================] - 23s 712us/sample - loss: 11.5328 - val_loss: 1.3800\n",
      "Epoch 11/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.5449\n",
      "Epoch 11: val_loss did not improve from 1.37560\n",
      "32573/32573 [==============================] - 23s 707us/sample - loss: 11.5449 - val_loss: 1.3801\n",
      "Epoch 12/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.5296\n",
      "Epoch 12: val_loss did not improve from 1.37560\n",
      "32573/32573 [==============================] - 23s 715us/sample - loss: 11.5296 - val_loss: 1.3818\n",
      "Epoch 13/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.5159\n",
      "Epoch 13: val_loss improved from 1.37560 to 1.37319, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 726us/sample - loss: 11.5159 - val_loss: 1.3732\n",
      "Epoch 14/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4848\n",
      "Epoch 14: val_loss did not improve from 1.37319\n",
      "32573/32573 [==============================] - 23s 697us/sample - loss: 11.4848 - val_loss: 1.3762\n",
      "Epoch 15/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4882\n",
      "Epoch 15: val_loss improved from 1.37319 to 1.36925, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 725us/sample - loss: 11.4882 - val_loss: 1.3692\n",
      "Epoch 16/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4861\n",
      "Epoch 16: val_loss did not improve from 1.36925\n",
      "32573/32573 [==============================] - 23s 712us/sample - loss: 11.4861 - val_loss: 1.3809\n",
      "Epoch 17/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4629\n",
      "Epoch 17: val_loss did not improve from 1.36925\n",
      "32573/32573 [==============================] - 23s 719us/sample - loss: 11.4629 - val_loss: 1.3704\n",
      "Epoch 18/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4545\n",
      "Epoch 18: val_loss did not improve from 1.36925\n",
      "32573/32573 [==============================] - 22s 674us/sample - loss: 11.4545 - val_loss: 1.3712\n",
      "Epoch 19/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4763\n",
      "Epoch 19: val_loss did not improve from 1.36925\n",
      "32573/32573 [==============================] - 21s 642us/sample - loss: 11.4763 - val_loss: 1.3700\n",
      "Epoch 20/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 11.4483\n",
      "Epoch 20: val_loss improved from 1.36925 to 1.36748, saving model to ./checkpoints/unknown_person_few_shot_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 693us/sample - loss: 11.4483 - val_loss: 1.3675\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 01:01:53.187294: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_651_2/lstm_cell_1983/recurrent_kernel/Assign' id:1011294 op device:{requested: '', assigned: ''} def:{{{node lstm_651_2/lstm_cell_1983/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_651_2/lstm_cell_1983/recurrent_kernel, lstm_651_2/lstm_cell_1983/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 01:02:51.790881: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_657_2/lstm_cell_1989/bias/v/Assign' id:1015437 op device:{requested: '', assigned: ''} def:{{{node lstm_657_2/lstm_cell_1989/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_657_2/lstm_cell_1989/bias/v, lstm_657_2/lstm_cell_1989/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32573 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 01:03:57.131535: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 01:08:46.945205: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 01:09:13.890824: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38626, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 126s 4ms/sample - loss: 1.4151 - val_loss: 1.3863\n",
      "Epoch 2/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4104\n",
      "Epoch 2: val_loss improved from 1.38626 to 1.38128, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 709us/sample - loss: 1.4104 - val_loss: 1.3813\n",
      "Epoch 3/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4125\n",
      "Epoch 3: val_loss improved from 1.38128 to 1.38117, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 720us/sample - loss: 1.4125 - val_loss: 1.3812\n",
      "Epoch 4/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 4: val_loss improved from 1.38117 to 1.37867, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 23s 720us/sample - loss: 1.4124 - val_loss: 1.3787\n",
      "Epoch 5/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 5: val_loss did not improve from 1.37867\n",
      "32573/32573 [==============================] - 23s 710us/sample - loss: 1.4096 - val_loss: 1.3802\n",
      "Epoch 6/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 6: val_loss improved from 1.37867 to 1.37151, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 24s 722us/sample - loss: 1.4070 - val_loss: 1.3715\n",
      "Epoch 7/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4033\n",
      "Epoch 7: val_loss did not improve from 1.37151\n",
      "32573/32573 [==============================] - 23s 709us/sample - loss: 1.4033 - val_loss: 1.3732\n",
      "Epoch 8/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 8: val_loss did not improve from 1.37151\n",
      "32573/32573 [==============================] - 23s 704us/sample - loss: 1.4015 - val_loss: 1.3772\n",
      "Epoch 9/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 9: val_loss did not improve from 1.37151\n",
      "32573/32573 [==============================] - 22s 673us/sample - loss: 1.4008 - val_loss: 1.3774\n",
      "Epoch 10/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 10: val_loss did not improve from 1.37151\n",
      "32573/32573 [==============================] - 20s 609us/sample - loss: 1.3991 - val_loss: 1.3766\n",
      "Epoch 11/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 11: val_loss did not improve from 1.37151\n",
      "32573/32573 [==============================] - 20s 612us/sample - loss: 1.4001 - val_loss: 1.3731\n",
      "Epoch 12/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 12: val_loss improved from 1.37151 to 1.36911, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 626us/sample - loss: 1.3986 - val_loss: 1.3691\n",
      "Epoch 13/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 13: val_loss improved from 1.36911 to 1.36575, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 618us/sample - loss: 1.3953 - val_loss: 1.3658\n",
      "Epoch 14/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 14: val_loss did not improve from 1.36575\n",
      "32573/32573 [==============================] - 21s 643us/sample - loss: 1.3947 - val_loss: 1.3704\n",
      "Epoch 15/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3945\n",
      "Epoch 15: val_loss did not improve from 1.36575\n",
      "32573/32573 [==============================] - 23s 707us/sample - loss: 1.3945 - val_loss: 1.3675\n",
      "Epoch 16/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3908\n",
      "Epoch 16: val_loss did not improve from 1.36575\n",
      "32573/32573 [==============================] - 23s 691us/sample - loss: 1.3908 - val_loss: 1.3686\n",
      "Epoch 17/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 17: val_loss improved from 1.36575 to 1.36223, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 20s 619us/sample - loss: 1.3935 - val_loss: 1.3622\n",
      "Epoch 18/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 18: val_loss improved from 1.36223 to 1.36112, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 21s 658us/sample - loss: 1.3914 - val_loss: 1.3611\n",
      "Epoch 19/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3879\n",
      "Epoch 19: val_loss improved from 1.36112 to 1.36071, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p10_47.h5\n",
      "32573/32573 [==============================] - 25s 754us/sample - loss: 1.3879 - val_loss: 1.3607\n",
      "Epoch 20/20\n",
      "32573/32573 [==============================] - ETA: 0s - loss: 1.3886\n",
      "Epoch 20: val_loss did not improve from 1.36071\n",
      "32573/32573 [==============================] - 24s 729us/sample - loss: 1.3886 - val_loss: 1.3693\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "\n",
    "test_person_id = [10]\n",
    "ra_all = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "idx = 30\n",
    "for ra in ra_all:\n",
    "    flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "    ## Data Normalization before training ans testing\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalers = []\n",
    "    X_train_normalized = []\n",
    "    X_val_normalized = []\n",
    "    X_test_normalized = []\n",
    "    train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "    np.random.shuffle(train_idx)\n",
    "    val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "    test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "    \n",
    "    for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "        scaler = StandardScaler()\n",
    "        if len(feature.shape)==2:\n",
    "            X_train_i = feature[train_idx,:]\n",
    "            X_val_i = feature[val_idx,:]\n",
    "            X_test_i = feature[test_idx,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i)\n",
    "            scalers.append(scaler)\n",
    "        else:\n",
    "            X_train_i = feature[train_idx,:,:]\n",
    "            X_val_i = feature[val_idx,:,:]\n",
    "            X_test_i = feature[test_idx,:,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "            scalers.append(scaler)\n",
    "        X_train_normalized.append(X_train_normalized_i)\n",
    "        X_val_normalized.append(X_val_normalized_i)\n",
    "        X_test_normalized.append(X_test_normalized_i)\n",
    "    y_train = gts[train_idx,:]\n",
    "    y_val = gts[val_idx,:]\n",
    "    y_test = gts[test_idx,:]\n",
    "    X_train_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "    for feature in X_train_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_train_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_train_normalized_new.append(feature)\n",
    "    X_train_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_val_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "    for feature in X_val_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_val_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_val_normalized_new.append(feature)\n",
    "    X_val_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_test_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "    for feature in X_test_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_test_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_test_normalized_new.append(feature)\n",
    "    X_test_normalized_new.append(combined_feature)\n",
    "    \n",
    "    \n",
    "    num_epochs = 50\n",
    "    \n",
    "    \n",
    "    # Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    \n",
    "    \n",
    "    rates = [0.4, 0.5, 0.6]\n",
    "    \n",
    "    for r in rates:\n",
    "        model = individual_model(X_train_normalized)\n",
    "        model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=20, frequency=1)\n",
    "        model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import tensorflow as tf\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        from tensorflow.keras.models import Model\n",
    "        layers = model.layers\n",
    "        second_last_layer_output = layers[-4].output\n",
    "        feature_extractor_model = Model(inputs=model.input, outputs=second_last_layer_output)\n",
    "        train_features = feature_extractor_model.predict(X_train_normalized_new)\n",
    "        test_features = feature_extractor_model.predict(X_test_normalized_new)\n",
    "        \n",
    "        p_train = people_nums[train_idx,:]\n",
    "        p_val = people_nums[val_idx,:]\n",
    "        p_test = people_nums[test_idx,:]\n",
    "        ## Calculate the distance between test person and training person\n",
    "        def euclidean_distance(a, b):\n",
    "            return np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "        \n",
    "        distance_dict = {}\n",
    "        for ii in range(len(person_nums)):\n",
    "            if person_nums[ii] == test_person_id[0]:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                ind = np.where(p_train ==person_nums[ii])[0]\n",
    "                tmp_train_features = train_features[ind, :]\n",
    "                distances = np.array([euclidean_distance(train_sample, test_features) for train_sample in tmp_train_features])\n",
    "                print(distances.shape)\n",
    "                average_distances = np.mean(distances, axis=1)\n",
    "        \n",
    "                # Step 4: Find the overall average distance\n",
    "                overall_average_distance = np.mean(average_distances)\n",
    "                distance_dict[person_nums[ii]] = overall_average_distance\n",
    "        \n",
    "        \n",
    "        def normalize_to_weights(distance_dict):\n",
    "            distances = np.array(list(distance_dict.values()))\n",
    "            # Handle the case where a distance is zero to avoid division by zero\n",
    "            distances = np.clip(distances, a_min=1e-10, a_max=None)\n",
    "            weights = 1 / distances\n",
    "            normalized_weights = weights\n",
    "            # normalized_weights = weights / sum(weights)\n",
    "            # print(sum(weights))\n",
    "            # print(sum(normalized_weights))\n",
    "            # Assign the normalized weights back to the dictionary\n",
    "            normalized_weight_dict = dict(zip(distance_dict.keys(), normalized_weights))\n",
    "            return normalized_weight_dict\n",
    "        def scale_dict_values(my_dict):\n",
    "            scaled_dict = my_dict.copy()\n",
    "            min_val = min(scaled_dict.values())\n",
    "            max_val = max(scaled_dict.values())\n",
    "            \n",
    "            for key in scaled_dict:\n",
    "                scaled_dict[key] = 1 + 9 * (scaled_dict[key] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            return scaled_dict\n",
    "        weights_dict = normalize_to_weights(distance_dict)\n",
    "        weights_dict = scale_dict_values(weights_dict)\n",
    "        print(weights_dict)\n",
    "        \n",
    "        w_train = np.zeros_like(p_train)\n",
    "        for i in range(len(w_train)):\n",
    "            if p_train[i] == test_person_id[0]:\n",
    "                w_train[i] = 50\n",
    "            else:\n",
    "                w_train[i] = weights_dict[int(p_train[i])]\n",
    "        \n",
    "        w_train = np.squeeze(w_train)\n",
    "        \n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,sample_weight= w_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_2_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        idx += 1\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508e9a1-9544-41f8-af41-e3d3b02a8d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b59e4-6581-4ea8-994d-a02a6654ab6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
