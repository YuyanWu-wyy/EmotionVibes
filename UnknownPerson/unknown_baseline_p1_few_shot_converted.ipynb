{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f8da1-2837-4bf7-b3f4-dfcaa7ab42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe25376-b856-4296-ba02-5e3771ff9451",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-17T18:04:28.248347Z",
     "iopub.status.busy": "2023-11-17T18:04:28.248185Z",
     "iopub.status.idle": "2023-11-18T09:22:11.025304Z",
     "shell.execute_reply": "2023-11-18T09:22:11.024739Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:04:28.429037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35564\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:06:08.071152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.083108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.083331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.086860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.090230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.090398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.156987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.157186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.157351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:08.157605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-17 13:06:08.157891: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:06:09.085764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:09.086008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:09.086182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:09.086393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:09.086565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-17 13:06:09.086701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-17 13:06:09.086732: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-17 13:06:09.108424: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-17 13:06:09.334286: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_20/lstm_cell_20/kernel/Assign' id:3316 op device:{requested: '', assigned: ''} def:{{{node lstm_20/lstm_cell_20/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_20/lstm_cell_20/kernel, lstm_20/lstm_cell_20/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:06:09.467262: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:06:09.500597: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32022, 95)\n",
      "Train on 32022 samples, validate on 3542 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:06:13.896073: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign' id:17397 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_24/lstm_cell_24/kernel/v, training/Adam/lstm_24/lstm_cell_24/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:06:17.741572: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-17 13:06:19.939941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-11-17 13:06:20.419476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 4.9106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-17 13:06:32.285828: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.54971, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 19s 600us/sample - loss: 4.9106 - val_loss: 4.5497\n",
      "Epoch 2/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 4.3021\n",
      "Epoch 2: val_loss improved from 4.54971 to 3.75632, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 4.3021 - val_loss: 3.7563\n",
      "Epoch 3/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 3.2030\n",
      "Epoch 3: val_loss improved from 3.75632 to 2.26407, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 218us/sample - loss: 3.2030 - val_loss: 2.2641\n",
      "Epoch 4/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 2.1818\n",
      "Epoch 4: val_loss improved from 2.26407 to 1.94228, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 2.1818 - val_loss: 1.9423\n",
      "Epoch 5/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 2.0778\n",
      "Epoch 5: val_loss improved from 1.94228 to 1.74423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 208us/sample - loss: 2.0778 - val_loss: 1.7442\n",
      "Epoch 6/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.8403\n",
      "Epoch 6: val_loss improved from 1.74423 to 1.65842, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 215us/sample - loss: 1.8403 - val_loss: 1.6584\n",
      "Epoch 7/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.7368\n",
      "Epoch 7: val_loss improved from 1.65842 to 1.55489, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.7368 - val_loss: 1.5549\n",
      "Epoch 8/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6499\n",
      "Epoch 8: val_loss improved from 1.55489 to 1.51327, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.6499 - val_loss: 1.5133\n",
      "Epoch 9/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6075\n",
      "Epoch 9: val_loss improved from 1.51327 to 1.46664, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.6075 - val_loss: 1.4666\n",
      "Epoch 10/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5766\n",
      "Epoch 10: val_loss improved from 1.46664 to 1.44680, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 220us/sample - loss: 1.5766 - val_loss: 1.4468\n",
      "Epoch 11/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6678\n",
      "Epoch 11: val_loss did not improve from 1.44680\n",
      "32022/32022 [==============================] - 6s 198us/sample - loss: 1.6678 - val_loss: 1.5292\n",
      "Epoch 12/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6144\n",
      "Epoch 12: val_loss did not improve from 1.44680\n",
      "32022/32022 [==============================] - 7s 216us/sample - loss: 1.6144 - val_loss: 1.5133\n",
      "Epoch 13/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6021\n",
      "Epoch 13: val_loss did not improve from 1.44680\n",
      "32022/32022 [==============================] - 7s 220us/sample - loss: 1.6021 - val_loss: 1.4894\n",
      "Epoch 14/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5608\n",
      "Epoch 14: val_loss improved from 1.44680 to 1.43294, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.5608 - val_loss: 1.4329\n",
      "Epoch 15/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5465\n",
      "Epoch 15: val_loss did not improve from 1.43294\n",
      "32022/32022 [==============================] - 7s 221us/sample - loss: 1.5465 - val_loss: 1.4584\n",
      "Epoch 16/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5158\n",
      "Epoch 16: val_loss improved from 1.43294 to 1.43171, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.5158 - val_loss: 1.4317\n",
      "Epoch 17/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5297\n",
      "Epoch 17: val_loss did not improve from 1.43171\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.5297 - val_loss: 1.4435\n",
      "Epoch 18/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5057\n",
      "Epoch 18: val_loss improved from 1.43171 to 1.42354, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.5057 - val_loss: 1.4235\n",
      "Epoch 19/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5066\n",
      "Epoch 19: val_loss did not improve from 1.42354\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.5066 - val_loss: 1.4239\n",
      "Epoch 20/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5093\n",
      "Epoch 20: val_loss did not improve from 1.42354\n",
      "32022/32022 [==============================] - 7s 207us/sample - loss: 1.5093 - val_loss: 1.4352\n",
      "Epoch 21/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5452\n",
      "Epoch 21: val_loss did not improve from 1.42354\n",
      "32022/32022 [==============================] - 6s 202us/sample - loss: 1.5452 - val_loss: 1.4713\n",
      "Epoch 22/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5171\n",
      "Epoch 22: val_loss did not improve from 1.42354\n",
      "32022/32022 [==============================] - 7s 207us/sample - loss: 1.5171 - val_loss: 1.4365\n",
      "Epoch 23/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5003\n",
      "Epoch 23: val_loss improved from 1.42354 to 1.41682, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.5003 - val_loss: 1.4168\n",
      "Epoch 24/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4943\n",
      "Epoch 24: val_loss improved from 1.41682 to 1.41462, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 213us/sample - loss: 1.4943 - val_loss: 1.4146\n",
      "Epoch 25/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4913\n",
      "Epoch 25: val_loss improved from 1.41462 to 1.40929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.4913 - val_loss: 1.4093\n",
      "Epoch 26/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4860\n",
      "Epoch 26: val_loss improved from 1.40929 to 1.40618, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 6s 202us/sample - loss: 1.4860 - val_loss: 1.4062\n",
      "Epoch 27/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4863\n",
      "Epoch 27: val_loss improved from 1.40618 to 1.40476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.4863 - val_loss: 1.4048\n",
      "Epoch 28/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4815\n",
      "Epoch 28: val_loss improved from 1.40476 to 1.40380, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.4815 - val_loss: 1.4038\n",
      "Epoch 29/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4780\n",
      "Epoch 29: val_loss improved from 1.40380 to 1.40279, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 210us/sample - loss: 1.4780 - val_loss: 1.4028\n",
      "Epoch 30/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4770\n",
      "Epoch 30: val_loss improved from 1.40279 to 1.40239, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 6s 203us/sample - loss: 1.4770 - val_loss: 1.4024\n",
      "Epoch 31/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4748\n",
      "Epoch 31: val_loss improved from 1.40239 to 1.40018, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.4748 - val_loss: 1.4002\n",
      "Epoch 32/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 32: val_loss did not improve from 1.40018\n",
      "32022/32022 [==============================] - 7s 221us/sample - loss: 1.4745 - val_loss: 1.4003\n",
      "Epoch 33/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4727\n",
      "Epoch 33: val_loss improved from 1.40018 to 1.39792, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.4727 - val_loss: 1.3979\n",
      "Epoch 34/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4686\n",
      "Epoch 34: val_loss did not improve from 1.39792\n",
      "32022/32022 [==============================] - 6s 200us/sample - loss: 1.4686 - val_loss: 1.3985\n",
      "Epoch 35/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4710\n",
      "Epoch 35: val_loss did not improve from 1.39792\n",
      "32022/32022 [==============================] - 6s 200us/sample - loss: 1.4710 - val_loss: 1.3986\n",
      "Epoch 36/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4663\n",
      "Epoch 36: val_loss improved from 1.39792 to 1.39563, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 6s 203us/sample - loss: 1.4663 - val_loss: 1.3956\n",
      "Epoch 37/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 37: val_loss improved from 1.39563 to 1.39552, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 204us/sample - loss: 1.4658 - val_loss: 1.3955\n",
      "Epoch 38/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4644\n",
      "Epoch 38: val_loss improved from 1.39552 to 1.39498, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 6s 201us/sample - loss: 1.4644 - val_loss: 1.3950\n",
      "Epoch 39/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4647\n",
      "Epoch 39: val_loss improved from 1.39498 to 1.39497, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.4647 - val_loss: 1.3950\n",
      "Epoch 40/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 40: val_loss improved from 1.39497 to 1.39469, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4623 - val_loss: 1.3947\n",
      "Epoch 41/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4594\n",
      "Epoch 41: val_loss improved from 1.39469 to 1.39357, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4594 - val_loss: 1.3936\n",
      "Epoch 42/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4596\n",
      "Epoch 42: val_loss did not improve from 1.39357\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.4596 - val_loss: 1.3939\n",
      "Epoch 43/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4565\n",
      "Epoch 43: val_loss improved from 1.39357 to 1.39292, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.4565 - val_loss: 1.3929\n",
      "Epoch 44/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4579\n",
      "Epoch 44: val_loss improved from 1.39292 to 1.39045, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 219us/sample - loss: 1.4579 - val_loss: 1.3905\n",
      "Epoch 45/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4552\n",
      "Epoch 45: val_loss improved from 1.39045 to 1.38956, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4552 - val_loss: 1.3896\n",
      "Epoch 46/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4554\n",
      "Epoch 46: val_loss improved from 1.38956 to 1.38910, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.4554 - val_loss: 1.3891\n",
      "Epoch 47/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4547\n",
      "Epoch 47: val_loss improved from 1.38910 to 1.38705, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.4547 - val_loss: 1.3870\n",
      "Epoch 48/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4523\n",
      "Epoch 48: val_loss did not improve from 1.38705\n",
      "32022/32022 [==============================] - 6s 201us/sample - loss: 1.4523 - val_loss: 1.3878\n",
      "Epoch 49/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4504\n",
      "Epoch 49: val_loss improved from 1.38705 to 1.38478, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_30.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.4504 - val_loss: 1.3848\n",
      "Epoch 50/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4488\n",
      "Epoch 50: val_loss did not improve from 1.38478\n",
      "32022/32022 [==============================] - 6s 198us/sample - loss: 1.4488 - val_loss: 1.3858\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:12:18.122968: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_13_1/lstm_cell_50/kernel/Assign' id:20720 op device:{requested: '', assigned: ''} def:{{{node lstm_13_1/lstm_cell_50/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_13_1/lstm_cell_50/kernel, lstm_13_1/lstm_cell_50/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:12:19.835665: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_2_1/bias/v/Assign' id:26481 op device:{requested: '', assigned: ''} def:{{{node dense_2_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_2_1/bias/v, dense_2_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-17 13:12:21.178726: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_4_1/cond/Merge' id:24591 op device:{requested: '', assigned: ''} def:{{{node dropout_4_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_4_1/cond/Identity, dropout_4_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1571, 1437)\n",
      "(1632, 1437)\n",
      "(1728, 1437)\n",
      "(1872, 1437)\n",
      "(1713, 1437)\n",
      "(1345, 1437)\n",
      "(1823, 1437)\n",
      "(1606, 1437)\n",
      "(1752, 1437)\n",
      "(1502, 1437)\n",
      "(1932, 1437)\n",
      "(1728, 1437)\n",
      "(1776, 1437)\n",
      "(1848, 1437)\n",
      "(1740, 1437)\n",
      "(1812, 1437)\n",
      "(946, 1437)\n",
      "(1680, 1437)\n",
      "(1872, 1437)\n",
      "{2: 5.113285607209674, 4: 7.526434600291585, 5: 5.55432981516793, 6: 4.98967963903357, 8: 9.122852207720069, 9: 5.987688784754395, 10: 8.023160714818955, 11: 6.462329550554583, 12: 8.393189007482373, 13: 8.48839748871011, 17: 8.201497249967915, 19: 7.07857562969212, 21: 10.0, 22: 1.7860086661752, 25: 7.017233252525256, 26: 6.563593308312515, 27: 5.436500063907118, 28: 6.750024157859655, 29: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2905707/2131643591.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32022 samples, validate on 3542 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:16:06.990726: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 10.1315\n",
      "Epoch 1: val_loss improved from inf to 1.41079, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 27s 844us/sample - loss: 10.1315 - val_loss: 1.4108\n",
      "Epoch 2/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.0239\n",
      "Epoch 2: val_loss improved from 1.41079 to 1.39840, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 614us/sample - loss: 10.0239 - val_loss: 1.3984\n",
      "Epoch 3/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9730\n",
      "Epoch 3: val_loss improved from 1.39840 to 1.39730, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 19s 607us/sample - loss: 9.9730 - val_loss: 1.3973\n",
      "Epoch 4/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9335\n",
      "Epoch 4: val_loss improved from 1.39730 to 1.39160, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 616us/sample - loss: 9.9335 - val_loss: 1.3916\n",
      "Epoch 5/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9215\n",
      "Epoch 5: val_loss improved from 1.39160 to 1.38986, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 21s 643us/sample - loss: 9.9215 - val_loss: 1.3899\n",
      "Epoch 6/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8905\n",
      "Epoch 6: val_loss improved from 1.38986 to 1.38786, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 614us/sample - loss: 9.8905 - val_loss: 1.3879\n",
      "Epoch 7/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8495\n",
      "Epoch 7: val_loss did not improve from 1.38786\n",
      "32022/32022 [==============================] - 19s 609us/sample - loss: 9.8495 - val_loss: 1.3965\n",
      "Epoch 8/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8173\n",
      "Epoch 8: val_loss did not improve from 1.38786\n",
      "32022/32022 [==============================] - 20s 629us/sample - loss: 9.8173 - val_loss: 1.3905\n",
      "Epoch 9/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7972\n",
      "Epoch 9: val_loss did not improve from 1.38786\n",
      "32022/32022 [==============================] - 20s 610us/sample - loss: 9.7972 - val_loss: 1.3965\n",
      "Epoch 10/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7778\n",
      "Epoch 10: val_loss improved from 1.38786 to 1.38781, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 626us/sample - loss: 9.7778 - val_loss: 1.3878\n",
      "Epoch 11/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7328\n",
      "Epoch 11: val_loss improved from 1.38781 to 1.38096, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 630us/sample - loss: 9.7328 - val_loss: 1.3810\n",
      "Epoch 12/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7263\n",
      "Epoch 12: val_loss did not improve from 1.38096\n",
      "32022/32022 [==============================] - 21s 666us/sample - loss: 9.7263 - val_loss: 1.3883\n",
      "Epoch 13/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7207\n",
      "Epoch 13: val_loss improved from 1.38096 to 1.38016, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 22s 680us/sample - loss: 9.7207 - val_loss: 1.3802\n",
      "Epoch 14/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7032\n",
      "Epoch 14: val_loss improved from 1.38016 to 1.37967, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 21s 653us/sample - loss: 9.7032 - val_loss: 1.3797\n",
      "Epoch 15/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6771\n",
      "Epoch 15: val_loss did not improve from 1.37967\n",
      "32022/32022 [==============================] - 22s 688us/sample - loss: 9.6771 - val_loss: 1.3822\n",
      "Epoch 16/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6578\n",
      "Epoch 16: val_loss improved from 1.37967 to 1.37819, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 21s 665us/sample - loss: 9.6578 - val_loss: 1.3782\n",
      "Epoch 17/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6440\n",
      "Epoch 17: val_loss improved from 1.37819 to 1.37281, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 633us/sample - loss: 9.6440 - val_loss: 1.3728\n",
      "Epoch 18/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6251\n",
      "Epoch 18: val_loss improved from 1.37281 to 1.36973, saving model to ./checkpoints/unknown_person_few_shot_p1_30.h5\n",
      "32022/32022 [==============================] - 22s 692us/sample - loss: 9.6251 - val_loss: 1.3697\n",
      "Epoch 19/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6206\n",
      "Epoch 19: val_loss did not improve from 1.36973\n",
      "32022/32022 [==============================] - 20s 627us/sample - loss: 9.6206 - val_loss: 1.3776\n",
      "Epoch 20/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6104\n",
      "Epoch 20: val_loss did not improve from 1.36973\n",
      "32022/32022 [==============================] - 23s 714us/sample - loss: 9.6104 - val_loss: 1.3804\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:23:06.724654: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_21_2/lstm_cell_95/recurrent_kernel/Assign' id:41418 op device:{requested: '', assigned: ''} def:{{{node lstm_21_2/lstm_cell_95/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_21_2/lstm_cell_95/recurrent_kernel, lstm_21_2/lstm_cell_95/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:23:09.114205: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_36_2/lstm_cell_110/bias/v/Assign' id:45843 op device:{requested: '', assigned: ''} def:{{{node lstm_36_2/lstm_cell_110/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_36_2/lstm_cell_110/bias/v, lstm_36_2/lstm_cell_110/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32022 samples, validate on 3542 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:23:14.246685: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:23:26.930919: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_6/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:23:50.871586: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39111, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 30s 947us/sample - loss: 1.4517 - val_loss: 1.3911\n",
      "Epoch 2/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 2: val_loss improved from 1.39111 to 1.38072, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 23s 714us/sample - loss: 1.4483 - val_loss: 1.3807\n",
      "Epoch 3/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4447\n",
      "Epoch 3: val_loss did not improve from 1.38072\n",
      "32022/32022 [==============================] - 22s 675us/sample - loss: 1.4447 - val_loss: 1.3866\n",
      "Epoch 4/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 4: val_loss improved from 1.38072 to 1.37785, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 23s 703us/sample - loss: 1.4420 - val_loss: 1.3779\n",
      "Epoch 5/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 5: val_loss improved from 1.37785 to 1.37528, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 23s 708us/sample - loss: 1.4383 - val_loss: 1.3753\n",
      "Epoch 6/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 6: val_loss improved from 1.37528 to 1.37158, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 23s 710us/sample - loss: 1.4354 - val_loss: 1.3716\n",
      "Epoch 7/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4333\n",
      "Epoch 7: val_loss did not improve from 1.37158\n",
      "32022/32022 [==============================] - 22s 697us/sample - loss: 1.4333 - val_loss: 1.3728\n",
      "Epoch 8/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4313\n",
      "Epoch 8: val_loss improved from 1.37158 to 1.37052, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 23s 714us/sample - loss: 1.4313 - val_loss: 1.3705\n",
      "Epoch 9/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4273\n",
      "Epoch 9: val_loss improved from 1.37052 to 1.36931, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 22s 681us/sample - loss: 1.4273 - val_loss: 1.3693\n",
      "Epoch 10/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 10: val_loss improved from 1.36931 to 1.36773, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 22s 686us/sample - loss: 1.4249 - val_loss: 1.3677\n",
      "Epoch 11/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4235\n",
      "Epoch 11: val_loss improved from 1.36773 to 1.36500, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 21s 664us/sample - loss: 1.4235 - val_loss: 1.3650\n",
      "Epoch 12/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 12: val_loss did not improve from 1.36500\n",
      "32022/32022 [==============================] - 21s 663us/sample - loss: 1.4206 - val_loss: 1.3664\n",
      "Epoch 13/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4209\n",
      "Epoch 13: val_loss did not improve from 1.36500\n",
      "32022/32022 [==============================] - 22s 674us/sample - loss: 1.4209 - val_loss: 1.3654\n",
      "Epoch 14/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4192\n",
      "Epoch 14: val_loss improved from 1.36500 to 1.36287, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 626us/sample - loss: 1.4192 - val_loss: 1.3629\n",
      "Epoch 15/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 15: val_loss improved from 1.36287 to 1.35788, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 22s 679us/sample - loss: 1.4178 - val_loss: 1.3579\n",
      "Epoch 16/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 16: val_loss improved from 1.35788 to 1.35553, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 21s 643us/sample - loss: 1.4172 - val_loss: 1.3555\n",
      "Epoch 17/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4136\n",
      "Epoch 17: val_loss improved from 1.35553 to 1.35214, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 23s 720us/sample - loss: 1.4136 - val_loss: 1.3521\n",
      "Epoch 18/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 18: val_loss did not improve from 1.35214\n",
      "32022/32022 [==============================] - 23s 717us/sample - loss: 1.4099 - val_loss: 1.3543\n",
      "Epoch 19/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4095\n",
      "Epoch 19: val_loss improved from 1.35214 to 1.34985, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_30.h5\n",
      "32022/32022 [==============================] - 20s 632us/sample - loss: 1.4095 - val_loss: 1.3498\n",
      "Epoch 20/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4075\n",
      "Epoch 20: val_loss did not improve from 1.34985\n",
      "32022/32022 [==============================] - 20s 620us/sample - loss: 1.4075 - val_loss: 1.3522\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:30:52.196415: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_55/lstm_cell_129/bias/Assign' id:60059 op device:{requested: '', assigned: ''} def:{{{node lstm_55/lstm_cell_129/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_55/lstm_cell_129/bias, lstm_55/lstm_cell_129/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:30:53.606998: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_1' id:60678 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:30:54.697137: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_2' id:60679 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32022, 95)\n",
      "Train on 32022 samples, validate on 3542 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:31:01.129837: W tensorflow/c/c_api.cc:304] Operation '{name:'training_6/Adam/lstm_38_1/lstm_cell_112/recurrent_kernel/v/Assign' id:74099 op device:{requested: '', assigned: ''} def:{{{node training_6/Adam/lstm_38_1/lstm_cell_112/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_6/Adam/lstm_38_1/lstm_cell_112/recurrent_kernel/v, training_6/Adam/lstm_38_1/lstm_cell_112/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:31:18.296875: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 4.6767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:31:26.618023: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_7/mul' id:63519 op device:{requested: '', assigned: ''} def:{{{node loss_7/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_7/mul/x, loss_7/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.19289, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 25s 774us/sample - loss: 4.6767 - val_loss: 4.1929\n",
      "Epoch 2/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 3.8258\n",
      "Epoch 2: val_loss improved from 4.19289 to 3.12530, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 212us/sample - loss: 3.8258 - val_loss: 3.1253\n",
      "Epoch 3/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 2.7187\n",
      "Epoch 3: val_loss improved from 3.12530 to 2.19969, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 217us/sample - loss: 2.7187 - val_loss: 2.1997\n",
      "Epoch 4/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 2.1668\n",
      "Epoch 4: val_loss improved from 2.19969 to 1.97573, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 2.1668 - val_loss: 1.9757\n",
      "Epoch 5/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.9445\n",
      "Epoch 5: val_loss improved from 1.97573 to 1.74531, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.9445 - val_loss: 1.7453\n",
      "Epoch 6/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.7989\n",
      "Epoch 6: val_loss improved from 1.74531 to 1.63476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.7989 - val_loss: 1.6348\n",
      "Epoch 7/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6952\n",
      "Epoch 7: val_loss improved from 1.63476 to 1.57041, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 221us/sample - loss: 1.6952 - val_loss: 1.5704\n",
      "Epoch 8/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6436\n",
      "Epoch 8: val_loss improved from 1.57041 to 1.53330, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 6s 202us/sample - loss: 1.6436 - val_loss: 1.5333\n",
      "Epoch 9/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6047\n",
      "Epoch 9: val_loss improved from 1.53330 to 1.49728, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 220us/sample - loss: 1.6047 - val_loss: 1.4973\n",
      "Epoch 10/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5801\n",
      "Epoch 10: val_loss improved from 1.49728 to 1.47621, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.5801 - val_loss: 1.4762\n",
      "Epoch 11/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5758\n",
      "Epoch 11: val_loss did not improve from 1.47621\n",
      "32022/32022 [==============================] - 7s 222us/sample - loss: 1.5758 - val_loss: 1.4770\n",
      "Epoch 12/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6002\n",
      "Epoch 12: val_loss did not improve from 1.47621\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.6002 - val_loss: 1.5122\n",
      "Epoch 13/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5425\n",
      "Epoch 13: val_loss improved from 1.47621 to 1.45262, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.5425 - val_loss: 1.4526\n",
      "Epoch 14/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6023\n",
      "Epoch 14: val_loss did not improve from 1.45262\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.6023 - val_loss: 1.4809\n",
      "Epoch 15/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5924\n",
      "Epoch 15: val_loss did not improve from 1.45262\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.5924 - val_loss: 1.5103\n",
      "Epoch 16/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5478\n",
      "Epoch 16: val_loss did not improve from 1.45262\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.5478 - val_loss: 1.4556\n",
      "Epoch 17/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5385\n",
      "Epoch 17: val_loss improved from 1.45262 to 1.44309, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 229us/sample - loss: 1.5385 - val_loss: 1.4431\n",
      "Epoch 18/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6157\n",
      "Epoch 18: val_loss did not improve from 1.44309\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.6157 - val_loss: 1.5146\n",
      "Epoch 19/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6105\n",
      "Epoch 19: val_loss did not improve from 1.44309\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.6105 - val_loss: 1.5557\n",
      "Epoch 20/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5880\n",
      "Epoch 20: val_loss did not improve from 1.44309\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.5880 - val_loss: 1.5113\n",
      "Epoch 21/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5835\n",
      "Epoch 21: val_loss did not improve from 1.44309\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.5835 - val_loss: 1.4955\n",
      "Epoch 22/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5505\n",
      "Epoch 22: val_loss did not improve from 1.44309\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.5505 - val_loss: 1.4950\n",
      "Epoch 23/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5289\n",
      "Epoch 23: val_loss did not improve from 1.44309\n",
      "32022/32022 [==============================] - 7s 211us/sample - loss: 1.5289 - val_loss: 1.4550\n",
      "Epoch 24/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5095\n",
      "Epoch 24: val_loss improved from 1.44309 to 1.43028, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.5095 - val_loss: 1.4303\n",
      "Epoch 25/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5050\n",
      "Epoch 25: val_loss improved from 1.43028 to 1.42439, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.5050 - val_loss: 1.4244\n",
      "Epoch 26/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4989\n",
      "Epoch 26: val_loss improved from 1.42439 to 1.41943, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4989 - val_loss: 1.4194\n",
      "Epoch 27/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4945\n",
      "Epoch 27: val_loss improved from 1.41943 to 1.41475, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 203us/sample - loss: 1.4945 - val_loss: 1.4148\n",
      "Epoch 28/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4925\n",
      "Epoch 28: val_loss improved from 1.41475 to 1.41150, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 204us/sample - loss: 1.4925 - val_loss: 1.4115\n",
      "Epoch 29/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4905\n",
      "Epoch 29: val_loss did not improve from 1.41150\n",
      "32022/32022 [==============================] - 6s 200us/sample - loss: 1.4905 - val_loss: 1.4137\n",
      "Epoch 30/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4852\n",
      "Epoch 30: val_loss improved from 1.41150 to 1.40848, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 204us/sample - loss: 1.4852 - val_loss: 1.4085\n",
      "Epoch 31/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4846\n",
      "Epoch 31: val_loss improved from 1.40848 to 1.40591, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 203us/sample - loss: 1.4846 - val_loss: 1.4059\n",
      "Epoch 32/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4815\n",
      "Epoch 32: val_loss improved from 1.40591 to 1.40544, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.4815 - val_loss: 1.4054\n",
      "Epoch 33/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4784\n",
      "Epoch 33: val_loss improved from 1.40544 to 1.40249, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 204us/sample - loss: 1.4784 - val_loss: 1.4025\n",
      "Epoch 34/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4767\n",
      "Epoch 34: val_loss did not improve from 1.40249\n",
      "32022/32022 [==============================] - 6s 199us/sample - loss: 1.4767 - val_loss: 1.4033\n",
      "Epoch 35/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4760\n",
      "Epoch 35: val_loss improved from 1.40249 to 1.40015, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 203us/sample - loss: 1.4760 - val_loss: 1.4002\n",
      "Epoch 36/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4726\n",
      "Epoch 36: val_loss did not improve from 1.40015\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.4726 - val_loss: 1.4003\n",
      "Epoch 37/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4716\n",
      "Epoch 37: val_loss improved from 1.40015 to 1.39778, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.4716 - val_loss: 1.3978\n",
      "Epoch 38/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 38: val_loss improved from 1.39778 to 1.39574, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.4689 - val_loss: 1.3957\n",
      "Epoch 39/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4662\n",
      "Epoch 39: val_loss improved from 1.39574 to 1.39461, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.4662 - val_loss: 1.3946\n",
      "Epoch 40/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4648\n",
      "Epoch 40: val_loss improved from 1.39461 to 1.39342, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 218us/sample - loss: 1.4648 - val_loss: 1.3934\n",
      "Epoch 41/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4635\n",
      "Epoch 41: val_loss did not improve from 1.39342\n",
      "32022/32022 [==============================] - 6s 197us/sample - loss: 1.4635 - val_loss: 1.3935\n",
      "Epoch 42/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4601\n",
      "Epoch 42: val_loss improved from 1.39342 to 1.39067, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.4601 - val_loss: 1.3907\n",
      "Epoch 43/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4599\n",
      "Epoch 43: val_loss did not improve from 1.39067\n",
      "32022/32022 [==============================] - 6s 201us/sample - loss: 1.4599 - val_loss: 1.3908\n",
      "Epoch 44/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4586\n",
      "Epoch 44: val_loss improved from 1.39067 to 1.38886, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 206us/sample - loss: 1.4586 - val_loss: 1.3889\n",
      "Epoch 45/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4583\n",
      "Epoch 45: val_loss improved from 1.38886 to 1.38849, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 209us/sample - loss: 1.4583 - val_loss: 1.3885\n",
      "Epoch 46/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4573\n",
      "Epoch 46: val_loss improved from 1.38849 to 1.38714, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 208us/sample - loss: 1.4573 - val_loss: 1.3871\n",
      "Epoch 47/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4564\n",
      "Epoch 47: val_loss improved from 1.38714 to 1.38613, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 208us/sample - loss: 1.4564 - val_loss: 1.3861\n",
      "Epoch 48/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4542\n",
      "Epoch 48: val_loss did not improve from 1.38613\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.4542 - val_loss: 1.3866\n",
      "Epoch 49/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4524\n",
      "Epoch 49: val_loss improved from 1.38613 to 1.38368, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 217us/sample - loss: 1.4524 - val_loss: 1.3837\n",
      "Epoch 50/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4514\n",
      "Epoch 50: val_loss improved from 1.38368 to 1.38343, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_31.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.4514 - val_loss: 1.3834\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:37:23.777508: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_57_1/lstm_cell_168/bias/Assign' id:78911 op device:{requested: '', assigned: ''} def:{{{node lstm_57_1/lstm_cell_168/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_57_1/lstm_cell_168/bias, lstm_57_1/lstm_cell_168/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:37:28.088865: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_7_1/kernel/m/Assign' id:82885 op device:{requested: '', assigned: ''} def:{{{node dense_7_1/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_7_1/kernel/m, dense_7_1/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:37:32.196016: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_9_1/cond/Merge' id:81633 op device:{requested: '', assigned: ''} def:{{{node dropout_9_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_9_1/cond/Identity, dropout_9_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1571, 1437)\n",
      "(1632, 1437)\n",
      "(1728, 1437)\n",
      "(1872, 1437)\n",
      "(1713, 1437)\n",
      "(1345, 1437)\n",
      "(1823, 1437)\n",
      "(1606, 1437)\n",
      "(1752, 1437)\n",
      "(1502, 1437)\n",
      "(1932, 1437)\n",
      "(1728, 1437)\n",
      "(1776, 1437)\n",
      "(1848, 1437)\n",
      "(1740, 1437)\n",
      "(1812, 1437)\n",
      "(946, 1437)\n",
      "(1680, 1437)\n",
      "(1872, 1437)\n",
      "{2: 4.932217391520911, 4: 7.993734887660214, 5: 5.789940252585804, 6: 4.148315525823181, 8: 9.233639378871882, 9: 5.9009606407198545, 10: 7.684344856606759, 11: 6.613533646223066, 12: 8.954269531733537, 13: 8.629488366069548, 17: 8.602142952149862, 19: 7.47095765030523, 21: 10.0, 22: 2.02099839262908, 25: 7.292144876272287, 26: 6.570993015048187, 27: 5.476427655487263, 28: 7.044357570942099, 29: 1.0}\n",
      "Train on 32022 samples, validate on 3542 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:41:28.034297: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 10.2824\n",
      "Epoch 1: val_loss improved from inf to 1.40303, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 31s 956us/sample - loss: 10.2824 - val_loss: 1.4030\n",
      "Epoch 2/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.1551\n",
      "Epoch 2: val_loss improved from 1.40303 to 1.39294, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 21s 644us/sample - loss: 10.1551 - val_loss: 1.3929\n",
      "Epoch 3/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.1550\n",
      "Epoch 3: val_loss did not improve from 1.39294\n",
      "32022/32022 [==============================] - 22s 694us/sample - loss: 10.1550 - val_loss: 1.4086\n",
      "Epoch 4/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.0729\n",
      "Epoch 4: val_loss did not improve from 1.39294\n",
      "32022/32022 [==============================] - 23s 705us/sample - loss: 10.0729 - val_loss: 1.3931\n",
      "Epoch 5/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.0493\n",
      "Epoch 5: val_loss improved from 1.39294 to 1.38642, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 21s 655us/sample - loss: 10.0493 - val_loss: 1.3864\n",
      "Epoch 6/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.0487\n",
      "Epoch 6: val_loss improved from 1.38642 to 1.38422, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 23s 711us/sample - loss: 10.0487 - val_loss: 1.3842\n",
      "Epoch 7/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 10.0133\n",
      "Epoch 7: val_loss did not improve from 1.38422\n",
      "32022/32022 [==============================] - 22s 700us/sample - loss: 10.0133 - val_loss: 1.3907\n",
      "Epoch 8/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9817\n",
      "Epoch 8: val_loss improved from 1.38422 to 1.37997, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 23s 713us/sample - loss: 9.9817 - val_loss: 1.3800\n",
      "Epoch 9/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9922\n",
      "Epoch 9: val_loss improved from 1.37997 to 1.37503, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 23s 713us/sample - loss: 9.9922 - val_loss: 1.3750\n",
      "Epoch 10/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9652\n",
      "Epoch 10: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 23s 705us/sample - loss: 9.9652 - val_loss: 1.3842\n",
      "Epoch 11/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9477\n",
      "Epoch 11: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 23s 705us/sample - loss: 9.9477 - val_loss: 1.3805\n",
      "Epoch 12/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9522\n",
      "Epoch 12: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 21s 662us/sample - loss: 9.9522 - val_loss: 1.3803\n",
      "Epoch 13/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9103\n",
      "Epoch 13: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 19s 606us/sample - loss: 9.9103 - val_loss: 1.3816\n",
      "Epoch 14/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9068\n",
      "Epoch 14: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 22s 676us/sample - loss: 9.9068 - val_loss: 1.3925\n",
      "Epoch 15/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8968\n",
      "Epoch 15: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 22s 698us/sample - loss: 9.8968 - val_loss: 1.3873\n",
      "Epoch 16/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9017\n",
      "Epoch 16: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 22s 690us/sample - loss: 9.9017 - val_loss: 1.3758\n",
      "Epoch 17/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8557\n",
      "Epoch 17: val_loss did not improve from 1.37503\n",
      "32022/32022 [==============================] - 20s 633us/sample - loss: 9.8557 - val_loss: 1.3806\n",
      "Epoch 18/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8520\n",
      "Epoch 18: val_loss improved from 1.37503 to 1.37453, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 20s 627us/sample - loss: 9.8520 - val_loss: 1.3745\n",
      "Epoch 19/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8261\n",
      "Epoch 19: val_loss did not improve from 1.37453\n",
      "32022/32022 [==============================] - 20s 621us/sample - loss: 9.8261 - val_loss: 1.3805\n",
      "Epoch 20/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8358\n",
      "Epoch 20: val_loss improved from 1.37453 to 1.36701, saving model to ./checkpoints/unknown_person_few_shot_p1_31.h5\n",
      "32022/32022 [==============================] - 23s 712us/sample - loss: 9.8358 - val_loss: 1.3670\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:48:53.729196: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_58_2/lstm_cell_206/bias/Assign' id:98469 op device:{requested: '', assigned: ''} def:{{{node lstm_58_2/lstm_cell_206/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_58_2/lstm_cell_206/bias, lstm_58_2/lstm_cell_206/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:48:58.910079: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_55_2/lstm_cell_203/kernel/m/Assign' id:101962 op device:{requested: '', assigned: ''} def:{{{node lstm_55_2/lstm_cell_203/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_55_2/lstm_cell_203/kernel/m, lstm_55_2/lstm_cell_203/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32022 samples, validate on 3542 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:49:06.660607: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:49:34.221601: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_3/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:49:58.810299: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38377, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 36s 1ms/sample - loss: 1.4501 - val_loss: 1.3838\n",
      "Epoch 2/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4448\n",
      "Epoch 2: val_loss improved from 1.38377 to 1.37776, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 23s 716us/sample - loss: 1.4448 - val_loss: 1.3778\n",
      "Epoch 3/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4440\n",
      "Epoch 3: val_loss improved from 1.37776 to 1.36962, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 20s 639us/sample - loss: 1.4440 - val_loss: 1.3696\n",
      "Epoch 4/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4393\n",
      "Epoch 4: val_loss did not improve from 1.36962\n",
      "32022/32022 [==============================] - 20s 635us/sample - loss: 1.4393 - val_loss: 1.3698\n",
      "Epoch 5/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4341\n",
      "Epoch 5: val_loss improved from 1.36962 to 1.36675, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 20s 636us/sample - loss: 1.4341 - val_loss: 1.3667\n",
      "Epoch 6/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4327\n",
      "Epoch 6: val_loss improved from 1.36675 to 1.36546, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 21s 647us/sample - loss: 1.4327 - val_loss: 1.3655\n",
      "Epoch 7/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 7: val_loss improved from 1.36546 to 1.35824, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 22s 684us/sample - loss: 1.4294 - val_loss: 1.3582\n",
      "Epoch 8/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4293\n",
      "Epoch 8: val_loss did not improve from 1.35824\n",
      "32022/32022 [==============================] - 23s 714us/sample - loss: 1.4293 - val_loss: 1.3627\n",
      "Epoch 9/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4254\n",
      "Epoch 9: val_loss did not improve from 1.35824\n",
      "32022/32022 [==============================] - 22s 686us/sample - loss: 1.4254 - val_loss: 1.3613\n",
      "Epoch 10/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4215\n",
      "Epoch 10: val_loss did not improve from 1.35824\n",
      "32022/32022 [==============================] - 23s 717us/sample - loss: 1.4215 - val_loss: 1.3611\n",
      "Epoch 11/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 11: val_loss did not improve from 1.35824\n",
      "32022/32022 [==============================] - 23s 722us/sample - loss: 1.4206 - val_loss: 1.3588\n",
      "Epoch 12/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4218\n",
      "Epoch 12: val_loss did not improve from 1.35824\n",
      "32022/32022 [==============================] - 23s 716us/sample - loss: 1.4218 - val_loss: 1.3712\n",
      "Epoch 13/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 13: val_loss improved from 1.35824 to 1.35144, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 23s 718us/sample - loss: 1.4176 - val_loss: 1.3514\n",
      "Epoch 14/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 14: val_loss did not improve from 1.35144\n",
      "32022/32022 [==============================] - 22s 682us/sample - loss: 1.4155 - val_loss: 1.3541\n",
      "Epoch 15/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 15: val_loss did not improve from 1.35144\n",
      "32022/32022 [==============================] - 23s 715us/sample - loss: 1.4164 - val_loss: 1.3576\n",
      "Epoch 16/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4133\n",
      "Epoch 16: val_loss did not improve from 1.35144\n",
      "32022/32022 [==============================] - 22s 692us/sample - loss: 1.4133 - val_loss: 1.3516\n",
      "Epoch 17/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4137\n",
      "Epoch 17: val_loss did not improve from 1.35144\n",
      "32022/32022 [==============================] - 23s 717us/sample - loss: 1.4137 - val_loss: 1.3588\n",
      "Epoch 18/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 18: val_loss did not improve from 1.35144\n",
      "32022/32022 [==============================] - 21s 649us/sample - loss: 1.4096 - val_loss: 1.3533\n",
      "Epoch 19/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 19: val_loss did not improve from 1.35144\n",
      "32022/32022 [==============================] - 20s 637us/sample - loss: 1.4087 - val_loss: 1.3547\n",
      "Epoch 20/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4085\n",
      "Epoch 20: val_loss improved from 1.35144 to 1.34739, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_31.h5\n",
      "32022/32022 [==============================] - 22s 697us/sample - loss: 1.4085 - val_loss: 1.3474\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:57:08.849627: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_82/lstm_cell_230/recurrent_kernel/Assign' id:115442 op device:{requested: '', assigned: ''} def:{{{node lstm_82/lstm_cell_230/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_82/lstm_cell_230/recurrent_kernel, lstm_82/lstm_cell_230/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:57:11.748166: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_1' id:117720 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 13:57:14.021275: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_2' id:117721 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32022, 95)\n",
      "Train on 32022 samples, validate on 3542 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:57:23.414907: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_9/bias/Assign' id:120476 op device:{requested: '', assigned: ''} def:{{{node dense_9/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_9/bias, dense_9/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:57:55.394364: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 4.5214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 13:58:04.712881: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_13/mul' id:120561 op device:{requested: '', assigned: ''} def:{{{node loss_13/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_13/mul/x, loss_13/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.94141, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 39s 1ms/sample - loss: 4.5214 - val_loss: 3.9414\n",
      "Epoch 2/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 3.4883\n",
      "Epoch 2: val_loss improved from 3.94141 to 2.72136, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 8s 234us/sample - loss: 3.4883 - val_loss: 2.7214\n",
      "Epoch 3/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 2.3113\n",
      "Epoch 3: val_loss improved from 2.72136 to 1.96267, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 2.3113 - val_loss: 1.9627\n",
      "Epoch 4/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 2.0602\n",
      "Epoch 4: val_loss improved from 1.96267 to 1.79021, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 2.0602 - val_loss: 1.7902\n",
      "Epoch 5/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.8217\n",
      "Epoch 5: val_loss improved from 1.79021 to 1.69585, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.8217 - val_loss: 1.6959\n",
      "Epoch 6/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.7330\n",
      "Epoch 6: val_loss improved from 1.69585 to 1.56701, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.7330 - val_loss: 1.5670\n",
      "Epoch 7/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6610\n",
      "Epoch 7: val_loss improved from 1.56701 to 1.53159, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.6610 - val_loss: 1.5316\n",
      "Epoch 8/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6229\n",
      "Epoch 8: val_loss improved from 1.53159 to 1.50472, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.6229 - val_loss: 1.5047\n",
      "Epoch 9/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5996\n",
      "Epoch 9: val_loss improved from 1.50472 to 1.48848, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 231us/sample - loss: 1.5996 - val_loss: 1.4885\n",
      "Epoch 10/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5833\n",
      "Epoch 10: val_loss improved from 1.48848 to 1.48319, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.5833 - val_loss: 1.4832\n",
      "Epoch 11/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5642\n",
      "Epoch 11: val_loss improved from 1.48319 to 1.46631, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 232us/sample - loss: 1.5642 - val_loss: 1.4663\n",
      "Epoch 12/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5446\n",
      "Epoch 12: val_loss improved from 1.46631 to 1.44813, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.5446 - val_loss: 1.4481\n",
      "Epoch 13/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5440\n",
      "Epoch 13: val_loss improved from 1.44813 to 1.44811, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 229us/sample - loss: 1.5440 - val_loss: 1.4481\n",
      "Epoch 14/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5289\n",
      "Epoch 14: val_loss improved from 1.44811 to 1.43991, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 232us/sample - loss: 1.5289 - val_loss: 1.4399\n",
      "Epoch 15/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5310\n",
      "Epoch 15: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.5310 - val_loss: 1.4412\n",
      "Epoch 16/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6000\n",
      "Epoch 16: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 213us/sample - loss: 1.6000 - val_loss: 1.5091\n",
      "Epoch 17/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5340\n",
      "Epoch 17: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.5340 - val_loss: 1.4470\n",
      "Epoch 18/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5584\n",
      "Epoch 18: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.5584 - val_loss: 1.4857\n",
      "Epoch 19/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5438\n",
      "Epoch 19: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 6s 202us/sample - loss: 1.5438 - val_loss: 1.4611\n",
      "Epoch 20/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6950\n",
      "Epoch 20: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 6s 202us/sample - loss: 1.6950 - val_loss: 1.4862\n",
      "Epoch 21/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.7902\n",
      "Epoch 21: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 6s 200us/sample - loss: 1.7902 - val_loss: 1.6787\n",
      "Epoch 22/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.6221\n",
      "Epoch 22: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 214us/sample - loss: 1.6221 - val_loss: 1.5899\n",
      "Epoch 23/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5419\n",
      "Epoch 23: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 219us/sample - loss: 1.5419 - val_loss: 1.4605\n",
      "Epoch 24/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5290\n",
      "Epoch 24: val_loss did not improve from 1.43991\n",
      "32022/32022 [==============================] - 7s 203us/sample - loss: 1.5290 - val_loss: 1.4439\n",
      "Epoch 25/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5266\n",
      "Epoch 25: val_loss improved from 1.43991 to 1.43961, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 206us/sample - loss: 1.5266 - val_loss: 1.4396\n",
      "Epoch 26/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5209\n",
      "Epoch 26: val_loss improved from 1.43961 to 1.43564, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 206us/sample - loss: 1.5209 - val_loss: 1.4356\n",
      "Epoch 27/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5160\n",
      "Epoch 27: val_loss improved from 1.43564 to 1.42802, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.5160 - val_loss: 1.4280\n",
      "Epoch 28/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5116\n",
      "Epoch 28: val_loss improved from 1.42802 to 1.42543, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 206us/sample - loss: 1.5116 - val_loss: 1.4254\n",
      "Epoch 29/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5059\n",
      "Epoch 29: val_loss improved from 1.42543 to 1.42004, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.5059 - val_loss: 1.4200\n",
      "Epoch 30/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5034\n",
      "Epoch 30: val_loss improved from 1.42004 to 1.41687, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 205us/sample - loss: 1.5034 - val_loss: 1.4169\n",
      "Epoch 31/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5017\n",
      "Epoch 31: val_loss improved from 1.41687 to 1.41548, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 204us/sample - loss: 1.5017 - val_loss: 1.4155\n",
      "Epoch 32/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4997\n",
      "Epoch 32: val_loss improved from 1.41548 to 1.41314, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 204us/sample - loss: 1.4997 - val_loss: 1.4131\n",
      "Epoch 33/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.5038\n",
      "Epoch 33: val_loss did not improve from 1.41314\n",
      "32022/32022 [==============================] - 6s 196us/sample - loss: 1.5038 - val_loss: 1.4173\n",
      "Epoch 34/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4968\n",
      "Epoch 34: val_loss improved from 1.41314 to 1.41133, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 6s 201us/sample - loss: 1.4968 - val_loss: 1.4113\n",
      "Epoch 35/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4941\n",
      "Epoch 35: val_loss did not improve from 1.41133\n",
      "32022/32022 [==============================] - 6s 198us/sample - loss: 1.4941 - val_loss: 1.4117\n",
      "Epoch 36/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 36: val_loss improved from 1.41133 to 1.40672, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 224us/sample - loss: 1.4903 - val_loss: 1.4067\n",
      "Epoch 37/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4869\n",
      "Epoch 37: val_loss did not improve from 1.40672\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.4869 - val_loss: 1.4070\n",
      "Epoch 38/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4899\n",
      "Epoch 38: val_loss improved from 1.40672 to 1.40391, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.4899 - val_loss: 1.4039\n",
      "Epoch 39/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4886\n",
      "Epoch 39: val_loss did not improve from 1.40391\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.4886 - val_loss: 1.4056\n",
      "Epoch 40/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4860\n",
      "Epoch 40: val_loss did not improve from 1.40391\n",
      "32022/32022 [==============================] - 7s 208us/sample - loss: 1.4860 - val_loss: 1.4041\n",
      "Epoch 41/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4825\n",
      "Epoch 41: val_loss improved from 1.40391 to 1.40336, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4825 - val_loss: 1.4034\n",
      "Epoch 42/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 42: val_loss improved from 1.40336 to 1.39972, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 230us/sample - loss: 1.4836 - val_loss: 1.3997\n",
      "Epoch 43/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4820\n",
      "Epoch 43: val_loss did not improve from 1.39972\n",
      "32022/32022 [==============================] - 7s 225us/sample - loss: 1.4820 - val_loss: 1.4001\n",
      "Epoch 44/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 44: val_loss did not improve from 1.39972\n",
      "32022/32022 [==============================] - 7s 226us/sample - loss: 1.4829 - val_loss: 1.4004\n",
      "Epoch 45/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4814\n",
      "Epoch 45: val_loss improved from 1.39972 to 1.39924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 229us/sample - loss: 1.4814 - val_loss: 1.3992\n",
      "Epoch 46/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 46: val_loss improved from 1.39924 to 1.39923, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 228us/sample - loss: 1.4787 - val_loss: 1.3992\n",
      "Epoch 47/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4780\n",
      "Epoch 47: val_loss improved from 1.39923 to 1.39603, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4780 - val_loss: 1.3960\n",
      "Epoch 48/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4778\n",
      "Epoch 48: val_loss did not improve from 1.39603\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.4778 - val_loss: 1.3965\n",
      "Epoch 49/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4762\n",
      "Epoch 49: val_loss did not improve from 1.39603\n",
      "32022/32022 [==============================] - 7s 223us/sample - loss: 1.4762 - val_loss: 1.3974\n",
      "Epoch 50/50\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4728\n",
      "Epoch 50: val_loss improved from 1.39603 to 1.39592, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_32.h5\n",
      "32022/32022 [==============================] - 7s 227us/sample - loss: 1.4728 - val_loss: 1.3959\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:04:20.968196: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_84_1/lstm_cell_269/bias/Assign' id:134353 op device:{requested: '', assigned: ''} def:{{{node lstm_84_1/lstm_cell_269/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_84_1/lstm_cell_269/bias, lstm_84_1/lstm_cell_269/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:04:27.972474: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_104_1/lstm_cell_289/bias/v/Assign' id:140439 op device:{requested: '', assigned: ''} def:{{{node lstm_104_1/lstm_cell_289/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_104_1/lstm_cell_289/bias/v, lstm_104_1/lstm_cell_289/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:04:34.816469: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_14_1/cond/Merge' id:138675 op device:{requested: '', assigned: ''} def:{{{node dropout_14_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_14_1/cond/Identity, dropout_14_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1571, 1437)\n",
      "(1632, 1437)\n",
      "(1728, 1437)\n",
      "(1872, 1437)\n",
      "(1713, 1437)\n",
      "(1345, 1437)\n",
      "(1823, 1437)\n",
      "(1606, 1437)\n",
      "(1752, 1437)\n",
      "(1502, 1437)\n",
      "(1932, 1437)\n",
      "(1728, 1437)\n",
      "(1776, 1437)\n",
      "(1848, 1437)\n",
      "(1740, 1437)\n",
      "(1812, 1437)\n",
      "(946, 1437)\n",
      "(1680, 1437)\n",
      "(1872, 1437)\n",
      "{2: 2.978179034290447, 4: 7.129070959154684, 5: 6.472676221866117, 6: 5.852024798996874, 8: 9.283374307690172, 9: 4.397792435835545, 10: 8.311414687224792, 11: 5.443922903945722, 12: 8.446363050281242, 13: 8.06068574724734, 17: 7.9027280593115385, 19: 7.280891554706936, 21: 10.0, 22: 1.0, 25: 6.697682121248109, 26: 6.4083955146189, 27: 4.081221187495469, 28: 7.162466666563845, 29: 1.6997482544769755}\n",
      "Train on 32022 samples, validate on 3542 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:08:40.240575: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 10.0254\n",
      "Epoch 1: val_loss improved from inf to 1.41737, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 36s 1ms/sample - loss: 10.0254 - val_loss: 1.4174\n",
      "Epoch 2/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.9369\n",
      "Epoch 2: val_loss improved from 1.41737 to 1.40913, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 21s 663us/sample - loss: 9.9369 - val_loss: 1.4091\n",
      "Epoch 3/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8629\n",
      "Epoch 3: val_loss improved from 1.40913 to 1.40822, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 23s 722us/sample - loss: 9.8629 - val_loss: 1.4082\n",
      "Epoch 4/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8020\n",
      "Epoch 4: val_loss did not improve from 1.40822\n",
      "32022/32022 [==============================] - 22s 698us/sample - loss: 9.8020 - val_loss: 1.4167\n",
      "Epoch 5/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.8083\n",
      "Epoch 5: val_loss did not improve from 1.40822\n",
      "32022/32022 [==============================] - 23s 715us/sample - loss: 9.8083 - val_loss: 1.4200\n",
      "Epoch 6/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7463\n",
      "Epoch 6: val_loss improved from 1.40822 to 1.39462, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 21s 642us/sample - loss: 9.7463 - val_loss: 1.3946\n",
      "Epoch 7/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7261\n",
      "Epoch 7: val_loss improved from 1.39462 to 1.39251, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 621us/sample - loss: 9.7261 - val_loss: 1.3925\n",
      "Epoch 8/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7128\n",
      "Epoch 8: val_loss improved from 1.39251 to 1.38707, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 22s 682us/sample - loss: 9.7128 - val_loss: 1.3871\n",
      "Epoch 9/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.7174\n",
      "Epoch 9: val_loss did not improve from 1.38707\n",
      "32022/32022 [==============================] - 23s 712us/sample - loss: 9.7174 - val_loss: 1.3953\n",
      "Epoch 10/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6814\n",
      "Epoch 10: val_loss did not improve from 1.38707\n",
      "32022/32022 [==============================] - 22s 696us/sample - loss: 9.6814 - val_loss: 1.3960\n",
      "Epoch 11/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6558\n",
      "Epoch 11: val_loss improved from 1.38707 to 1.38091, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 21s 665us/sample - loss: 9.6558 - val_loss: 1.3809\n",
      "Epoch 12/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6373\n",
      "Epoch 12: val_loss did not improve from 1.38091\n",
      "32022/32022 [==============================] - 22s 673us/sample - loss: 9.6373 - val_loss: 1.3876\n",
      "Epoch 13/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.6137\n",
      "Epoch 13: val_loss did not improve from 1.38091\n",
      "32022/32022 [==============================] - 23s 721us/sample - loss: 9.6137 - val_loss: 1.3854\n",
      "Epoch 14/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5847\n",
      "Epoch 14: val_loss improved from 1.38091 to 1.38016, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 23s 723us/sample - loss: 9.5847 - val_loss: 1.3802\n",
      "Epoch 15/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5766\n",
      "Epoch 15: val_loss did not improve from 1.38016\n",
      "32022/32022 [==============================] - 23s 720us/sample - loss: 9.5766 - val_loss: 1.3813\n",
      "Epoch 16/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5774\n",
      "Epoch 16: val_loss did not improve from 1.38016\n",
      "32022/32022 [==============================] - 23s 722us/sample - loss: 9.5774 - val_loss: 1.3891\n",
      "Epoch 17/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5644\n",
      "Epoch 17: val_loss did not improve from 1.38016\n",
      "32022/32022 [==============================] - 21s 654us/sample - loss: 9.5644 - val_loss: 1.3862\n",
      "Epoch 18/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5547\n",
      "Epoch 18: val_loss did not improve from 1.38016\n",
      "32022/32022 [==============================] - 20s 636us/sample - loss: 9.5547 - val_loss: 1.3955\n",
      "Epoch 19/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5553\n",
      "Epoch 19: val_loss did not improve from 1.38016\n",
      "32022/32022 [==============================] - 20s 627us/sample - loss: 9.5553 - val_loss: 1.3817\n",
      "Epoch 20/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 9.5397\n",
      "Epoch 20: val_loss improved from 1.38016 to 1.37552, saving model to ./checkpoints/unknown_person_few_shot_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 631us/sample - loss: 9.5397 - val_loss: 1.3755\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:16:14.373072: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_76_2/lstm_cell_298/kernel/Assign' id:152442 op device:{requested: '', assigned: ''} def:{{{node lstm_76_2/lstm_cell_298/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_76_2/lstm_cell_298/kernel, lstm_76_2/lstm_cell_298/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:16:22.327816: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_110_2/lstm_cell_332/recurrent_kernel/v/Assign' id:159922 op device:{requested: '', assigned: ''} def:{{{node lstm_110_2/lstm_cell_332/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_110_2/lstm_cell_332/recurrent_kernel/v, lstm_110_2/lstm_cell_332/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32022 samples, validate on 3542 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:16:32.794084: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:17:14.896805: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:17:37.001018: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39140, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 38s 1ms/sample - loss: 1.4714 - val_loss: 1.3914\n",
      "Epoch 2/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4613\n",
      "Epoch 2: val_loss improved from 1.39140 to 1.38943, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 23s 706us/sample - loss: 1.4613 - val_loss: 1.3894\n",
      "Epoch 3/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4592\n",
      "Epoch 3: val_loss improved from 1.38943 to 1.38624, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 21s 646us/sample - loss: 1.4592 - val_loss: 1.3862\n",
      "Epoch 4/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4553\n",
      "Epoch 4: val_loss improved from 1.38624 to 1.37979, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 632us/sample - loss: 1.4553 - val_loss: 1.3798\n",
      "Epoch 5/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 5: val_loss improved from 1.37979 to 1.37378, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 629us/sample - loss: 1.4535 - val_loss: 1.3738\n",
      "Epoch 6/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4467\n",
      "Epoch 6: val_loss did not improve from 1.37378\n",
      "32022/32022 [==============================] - 20s 640us/sample - loss: 1.4467 - val_loss: 1.3767\n",
      "Epoch 7/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4460\n",
      "Epoch 7: val_loss improved from 1.37378 to 1.37098, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 21s 655us/sample - loss: 1.4460 - val_loss: 1.3710\n",
      "Epoch 8/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4440\n",
      "Epoch 8: val_loss did not improve from 1.37098\n",
      "32022/32022 [==============================] - 23s 710us/sample - loss: 1.4440 - val_loss: 1.3722\n",
      "Epoch 9/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4405\n",
      "Epoch 9: val_loss did not improve from 1.37098\n",
      "32022/32022 [==============================] - 21s 646us/sample - loss: 1.4405 - val_loss: 1.3787\n",
      "Epoch 10/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4376\n",
      "Epoch 10: val_loss improved from 1.37098 to 1.36641, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 620us/sample - loss: 1.4376 - val_loss: 1.3664\n",
      "Epoch 11/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 11: val_loss improved from 1.36641 to 1.36437, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 628us/sample - loss: 1.4383 - val_loss: 1.3644\n",
      "Epoch 12/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4336\n",
      "Epoch 12: val_loss improved from 1.36437 to 1.36039, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 23s 708us/sample - loss: 1.4336 - val_loss: 1.3604\n",
      "Epoch 13/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 13: val_loss did not improve from 1.36039\n",
      "32022/32022 [==============================] - 20s 617us/sample - loss: 1.4349 - val_loss: 1.3665\n",
      "Epoch 14/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 14: val_loss did not improve from 1.36039\n",
      "32022/32022 [==============================] - 20s 618us/sample - loss: 1.4312 - val_loss: 1.3647\n",
      "Epoch 15/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 15: val_loss improved from 1.36039 to 1.35797, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 19s 608us/sample - loss: 1.4294 - val_loss: 1.3580\n",
      "Epoch 16/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4288\n",
      "Epoch 16: val_loss improved from 1.35797 to 1.35742, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 20s 619us/sample - loss: 1.4288 - val_loss: 1.3574\n",
      "Epoch 17/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4291\n",
      "Epoch 17: val_loss did not improve from 1.35742\n",
      "32022/32022 [==============================] - 20s 634us/sample - loss: 1.4291 - val_loss: 1.3620\n",
      "Epoch 18/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4238\n",
      "Epoch 18: val_loss did not improve from 1.35742\n",
      "32022/32022 [==============================] - 19s 607us/sample - loss: 1.4238 - val_loss: 1.3582\n",
      "Epoch 19/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 19: val_loss improved from 1.35742 to 1.35151, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_32.h5\n",
      "32022/32022 [==============================] - 21s 665us/sample - loss: 1.4237 - val_loss: 1.3515\n",
      "Epoch 20/20\n",
      "32022/32022 [==============================] - ETA: 0s - loss: 1.4216\n",
      "Epoch 20: val_loss did not improve from 1.35151\n",
      "32022/32022 [==============================] - 23s 717us/sample - loss: 1.4216 - val_loss: 1.3550\n",
      "35720\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:24:35.680898: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_117/lstm_cell_339/kernel/Assign' id:172134 op device:{requested: '', assigned: ''} def:{{{node lstm_117/lstm_cell_339/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_117/lstm_cell_339/kernel, lstm_117/lstm_cell_339/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:24:40.151055: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_1' id:174762 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:24:43.688444: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_2' id:174763 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32135, 95)\n",
      "Train on 32135 samples, validate on 3585 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:24:55.122653: W tensorflow/c/c_api.cc:304] Operation '{name:'training_18/Adam/lstm_118/lstm_cell_340/recurrent_kernel/m/Assign' id:187630 op device:{requested: '', assigned: ''} def:{{{node training_18/Adam/lstm_118/lstm_cell_340/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_18/Adam/lstm_118/lstm_cell_340/recurrent_kernel/m, training_18/Adam/lstm_118/lstm_cell_340/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:25:41.689870: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 4.5237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-17 14:25:53.564006: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_19/mul' id:177603 op device:{requested: '', assigned: ''} def:{{{node loss_19/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_19/mul/x, loss_19/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.84081, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 53s 2ms/sample - loss: 4.5237 - val_loss: 3.8408\n",
      "Epoch 2/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 3.3857\n",
      "Epoch 2: val_loss improved from 3.84081 to 2.76100, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 204us/sample - loss: 3.3857 - val_loss: 2.7610\n",
      "Epoch 3/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 2.4427\n",
      "Epoch 3: val_loss improved from 2.76100 to 1.99940, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 214us/sample - loss: 2.4427 - val_loss: 1.9994\n",
      "Epoch 4/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 2.0546\n",
      "Epoch 4: val_loss improved from 1.99940 to 1.85920, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 228us/sample - loss: 2.0546 - val_loss: 1.8592\n",
      "Epoch 5/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.8748\n",
      "Epoch 5: val_loss improved from 1.85920 to 1.78303, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.8748 - val_loss: 1.7830\n",
      "Epoch 6/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.7435\n",
      "Epoch 6: val_loss improved from 1.78303 to 1.63306, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.7435 - val_loss: 1.6331\n",
      "Epoch 7/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6731\n",
      "Epoch 7: val_loss improved from 1.63306 to 1.58356, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.6731 - val_loss: 1.5836\n",
      "Epoch 8/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6234\n",
      "Epoch 8: val_loss improved from 1.58356 to 1.55816, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.6234 - val_loss: 1.5582\n",
      "Epoch 9/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5851\n",
      "Epoch 9: val_loss improved from 1.55816 to 1.53487, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 228us/sample - loss: 1.5851 - val_loss: 1.5349\n",
      "Epoch 10/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5599\n",
      "Epoch 10: val_loss improved from 1.53487 to 1.52287, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.5599 - val_loss: 1.5229\n",
      "Epoch 11/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5579\n",
      "Epoch 11: val_loss improved from 1.52287 to 1.51749, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 209us/sample - loss: 1.5579 - val_loss: 1.5175\n",
      "Epoch 12/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5345\n",
      "Epoch 12: val_loss improved from 1.51749 to 1.50855, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.5345 - val_loss: 1.5086\n",
      "Epoch 13/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6086\n",
      "Epoch 13: val_loss did not improve from 1.50855\n",
      "32135/32135 [==============================] - 6s 199us/sample - loss: 1.6086 - val_loss: 1.5376\n",
      "Epoch 14/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5475\n",
      "Epoch 14: val_loss did not improve from 1.50855\n",
      "32135/32135 [==============================] - 6s 199us/sample - loss: 1.5475 - val_loss: 1.5196\n",
      "Epoch 15/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5301\n",
      "Epoch 15: val_loss improved from 1.50855 to 1.50354, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.5301 - val_loss: 1.5035\n",
      "Epoch 16/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6081\n",
      "Epoch 16: val_loss did not improve from 1.50354\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.6081 - val_loss: 1.5786\n",
      "Epoch 17/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6042\n",
      "Epoch 17: val_loss did not improve from 1.50354\n",
      "32135/32135 [==============================] - 7s 224us/sample - loss: 1.6042 - val_loss: 1.5909\n",
      "Epoch 18/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5344\n",
      "Epoch 18: val_loss did not improve from 1.50354\n",
      "32135/32135 [==============================] - 7s 224us/sample - loss: 1.5344 - val_loss: 1.5222\n",
      "Epoch 19/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5181\n",
      "Epoch 19: val_loss improved from 1.50354 to 1.49502, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.5181 - val_loss: 1.4950\n",
      "Epoch 20/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5355\n",
      "Epoch 20: val_loss did not improve from 1.49502\n",
      "32135/32135 [==============================] - 7s 221us/sample - loss: 1.5355 - val_loss: 1.5104\n",
      "Epoch 21/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5133\n",
      "Epoch 21: val_loss improved from 1.49502 to 1.49114, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.5133 - val_loss: 1.4911\n",
      "Epoch 22/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5307\n",
      "Epoch 22: val_loss did not improve from 1.49114\n",
      "32135/32135 [==============================] - 7s 221us/sample - loss: 1.5307 - val_loss: 1.5141\n",
      "Epoch 23/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5014\n",
      "Epoch 23: val_loss improved from 1.49114 to 1.48554, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 217us/sample - loss: 1.5014 - val_loss: 1.4855\n",
      "Epoch 24/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4937\n",
      "Epoch 24: val_loss improved from 1.48554 to 1.47754, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.4937 - val_loss: 1.4775\n",
      "Epoch 25/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4893\n",
      "Epoch 25: val_loss improved from 1.47754 to 1.47266, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.4893 - val_loss: 1.4727\n",
      "Epoch 26/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4875\n",
      "Epoch 26: val_loss improved from 1.47266 to 1.47018, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4875 - val_loss: 1.4702\n",
      "Epoch 27/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4822\n",
      "Epoch 27: val_loss improved from 1.47018 to 1.46723, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4822 - val_loss: 1.4672\n",
      "Epoch 28/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4809\n",
      "Epoch 28: val_loss improved from 1.46723 to 1.46564, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.4809 - val_loss: 1.4656\n",
      "Epoch 29/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4804\n",
      "Epoch 29: val_loss improved from 1.46564 to 1.46247, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.4804 - val_loss: 1.4625\n",
      "Epoch 30/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4775\n",
      "Epoch 30: val_loss improved from 1.46247 to 1.46053, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4775 - val_loss: 1.4605\n",
      "Epoch 31/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4750\n",
      "Epoch 31: val_loss did not improve from 1.46053\n",
      "32135/32135 [==============================] - 7s 209us/sample - loss: 1.4750 - val_loss: 1.4611\n",
      "Epoch 32/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4736\n",
      "Epoch 32: val_loss improved from 1.46053 to 1.45636, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 206us/sample - loss: 1.4736 - val_loss: 1.4564\n",
      "Epoch 33/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4707\n",
      "Epoch 33: val_loss did not improve from 1.45636\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4707 - val_loss: 1.4567\n",
      "Epoch 34/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4660\n",
      "Epoch 34: val_loss improved from 1.45636 to 1.45331, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4660 - val_loss: 1.4533\n",
      "Epoch 35/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4664\n",
      "Epoch 35: val_loss improved from 1.45331 to 1.45206, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.4664 - val_loss: 1.4521\n",
      "Epoch 36/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4626\n",
      "Epoch 36: val_loss improved from 1.45206 to 1.45071, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4626 - val_loss: 1.4507\n",
      "Epoch 37/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4607\n",
      "Epoch 37: val_loss improved from 1.45071 to 1.44956, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.4607 - val_loss: 1.4496\n",
      "Epoch 38/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4576\n",
      "Epoch 38: val_loss improved from 1.44956 to 1.44732, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 211us/sample - loss: 1.4576 - val_loss: 1.4473\n",
      "Epoch 39/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4561\n",
      "Epoch 39: val_loss did not improve from 1.44732\n",
      "32135/32135 [==============================] - 6s 199us/sample - loss: 1.4561 - val_loss: 1.4475\n",
      "Epoch 40/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4532\n",
      "Epoch 40: val_loss did not improve from 1.44732\n",
      "32135/32135 [==============================] - 6s 200us/sample - loss: 1.4532 - val_loss: 1.4480\n",
      "Epoch 41/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4531\n",
      "Epoch 41: val_loss improved from 1.44732 to 1.44621, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.4531 - val_loss: 1.4462\n",
      "Epoch 42/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 42: val_loss improved from 1.44621 to 1.44303, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.4525 - val_loss: 1.4430\n",
      "Epoch 43/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4501\n",
      "Epoch 43: val_loss did not improve from 1.44303\n",
      "32135/32135 [==============================] - 6s 200us/sample - loss: 1.4501 - val_loss: 1.4453\n",
      "Epoch 44/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4493\n",
      "Epoch 44: val_loss improved from 1.44303 to 1.44093, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 210us/sample - loss: 1.4493 - val_loss: 1.4409\n",
      "Epoch 45/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4455\n",
      "Epoch 45: val_loss did not improve from 1.44093\n",
      "32135/32135 [==============================] - 7s 222us/sample - loss: 1.4455 - val_loss: 1.4419\n",
      "Epoch 46/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4442\n",
      "Epoch 46: val_loss improved from 1.44093 to 1.43998, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.4442 - val_loss: 1.4400\n",
      "Epoch 47/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4439\n",
      "Epoch 47: val_loss improved from 1.43998 to 1.43851, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4439 - val_loss: 1.4385\n",
      "Epoch 48/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4425\n",
      "Epoch 48: val_loss improved from 1.43851 to 1.43567, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_33.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4425 - val_loss: 1.4357\n",
      "Epoch 49/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 49: val_loss did not improve from 1.43567\n",
      "32135/32135 [==============================] - 7s 215us/sample - loss: 1.4411 - val_loss: 1.4400\n",
      "Epoch 50/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4389\n",
      "Epoch 50: val_loss did not improve from 1.43567\n",
      "32135/32135 [==============================] - 6s 198us/sample - loss: 1.4389 - val_loss: 1.4364\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:32:21.826603: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_135_1/lstm_cell_394/recurrent_kernel/Assign' id:193628 op device:{requested: '', assigned: ''} def:{{{node lstm_135_1/lstm_cell_394/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_135_1/lstm_cell_394/recurrent_kernel, lstm_135_1/lstm_cell_394/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:32:32.336990: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_124_1/lstm_cell_383/recurrent_kernel/v/Assign' id:197221 op device:{requested: '', assigned: ''} def:{{{node lstm_124_1/lstm_cell_383/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_124_1/lstm_cell_383/recurrent_kernel/v, lstm_124_1/lstm_cell_383/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-17 14:32:42.108998: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_19_1/cond/Merge' id:195717 op device:{requested: '', assigned: ''} def:{{{node dropout_19_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_19_1/cond/Identity, dropout_19_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1281)\n",
      "(1656, 1281)\n",
      "(1704, 1281)\n",
      "(1872, 1281)\n",
      "(1712, 1281)\n",
      "(1369, 1281)\n",
      "(1802, 1281)\n",
      "(1595, 1281)\n",
      "(1752, 1281)\n",
      "(1514, 1281)\n",
      "(1908, 1281)\n",
      "(1727, 1281)\n",
      "(1776, 1281)\n",
      "(1872, 1281)\n",
      "(1704, 1281)\n",
      "(1824, 1281)\n",
      "(958, 1281)\n",
      "(1668, 1281)\n",
      "(1884, 1281)\n",
      "{2: 5.922634688400161, 4: 7.934214936660233, 5: 5.895461162342301, 6: 4.66858701137931, 8: 9.106313761355082, 9: 6.537820810511438, 10: 7.635700037200456, 11: 6.636050332806877, 12: 8.606059853483696, 13: 8.362646956561608, 17: 8.409375730506145, 19: 7.584668202155125, 21: 10.0, 22: 1.0, 25: 7.829894230525422, 26: 7.225035142447179, 27: 5.66314900640744, 28: 6.348712763507569, 29: 1.0258847959897144}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2905707/2131643591.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32135 samples, validate on 3585 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:37:34.017665: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 10.6797\n",
      "Epoch 1: val_loss improved from inf to 1.48066, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 44s 1ms/sample - loss: 10.6797 - val_loss: 1.4807\n",
      "Epoch 2/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.5790\n",
      "Epoch 2: val_loss improved from 1.48066 to 1.47290, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 723us/sample - loss: 10.5790 - val_loss: 1.4729\n",
      "Epoch 3/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.4807\n",
      "Epoch 3: val_loss improved from 1.47290 to 1.45226, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 715us/sample - loss: 10.4807 - val_loss: 1.4523\n",
      "Epoch 4/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.4092\n",
      "Epoch 4: val_loss did not improve from 1.45226\n",
      "32135/32135 [==============================] - 20s 626us/sample - loss: 10.4092 - val_loss: 1.4559\n",
      "Epoch 5/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.3794\n",
      "Epoch 5: val_loss did not improve from 1.45226\n",
      "32135/32135 [==============================] - 20s 622us/sample - loss: 10.3794 - val_loss: 1.4578\n",
      "Epoch 6/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.3223\n",
      "Epoch 6: val_loss did not improve from 1.45226\n",
      "32135/32135 [==============================] - 22s 697us/sample - loss: 10.3223 - val_loss: 1.4563\n",
      "Epoch 7/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2877\n",
      "Epoch 7: val_loss improved from 1.45226 to 1.44475, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 720us/sample - loss: 10.2877 - val_loss: 1.4447\n",
      "Epoch 8/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2793\n",
      "Epoch 8: val_loss did not improve from 1.44475\n",
      "32135/32135 [==============================] - 23s 717us/sample - loss: 10.2793 - val_loss: 1.4562\n",
      "Epoch 9/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2163\n",
      "Epoch 9: val_loss did not improve from 1.44475\n",
      "32135/32135 [==============================] - 23s 723us/sample - loss: 10.2163 - val_loss: 1.4452\n",
      "Epoch 10/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2222\n",
      "Epoch 10: val_loss improved from 1.44475 to 1.43990, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 22s 681us/sample - loss: 10.2222 - val_loss: 1.4399\n",
      "Epoch 11/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2030\n",
      "Epoch 11: val_loss did not improve from 1.43990\n",
      "32135/32135 [==============================] - 21s 661us/sample - loss: 10.2030 - val_loss: 1.4505\n",
      "Epoch 12/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1534\n",
      "Epoch 12: val_loss did not improve from 1.43990\n",
      "32135/32135 [==============================] - 22s 676us/sample - loss: 10.1534 - val_loss: 1.4495\n",
      "Epoch 13/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1561\n",
      "Epoch 13: val_loss did not improve from 1.43990\n",
      "32135/32135 [==============================] - 22s 689us/sample - loss: 10.1561 - val_loss: 1.4439\n",
      "Epoch 14/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1540\n",
      "Epoch 14: val_loss improved from 1.43990 to 1.43982, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 711us/sample - loss: 10.1540 - val_loss: 1.4398\n",
      "Epoch 15/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1297\n",
      "Epoch 15: val_loss improved from 1.43982 to 1.43918, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 22s 697us/sample - loss: 10.1297 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1067\n",
      "Epoch 16: val_loss improved from 1.43918 to 1.43427, saving model to ./checkpoints/unknown_person_few_shot_p1_33.h5\n",
      "32135/32135 [==============================] - 21s 645us/sample - loss: 10.1067 - val_loss: 1.4343\n",
      "Epoch 17/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0769\n",
      "Epoch 17: val_loss did not improve from 1.43427\n",
      "32135/32135 [==============================] - 21s 656us/sample - loss: 10.0769 - val_loss: 1.4440\n",
      "Epoch 18/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0651\n",
      "Epoch 18: val_loss did not improve from 1.43427\n",
      "32135/32135 [==============================] - 23s 715us/sample - loss: 10.0651 - val_loss: 1.4470\n",
      "Epoch 19/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0684\n",
      "Epoch 19: val_loss did not improve from 1.43427\n",
      "32135/32135 [==============================] - 23s 712us/sample - loss: 10.0684 - val_loss: 1.4492\n",
      "Epoch 20/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0217\n",
      "Epoch 20: val_loss did not improve from 1.43427\n",
      "32135/32135 [==============================] - 22s 692us/sample - loss: 10.0217 - val_loss: 1.4356\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:45:23.380773: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_13_2/kernel/Assign' id:215125 op device:{requested: '', assigned: ''} def:{{{node dense_13_2/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_13_2/kernel, dense_13_2/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:45:34.131178: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_14_2/bias/m/Assign' id:216362 op device:{requested: '', assigned: ''} def:{{{node dense_14_2/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_14_2/bias/m, dense_14_2/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32135 samples, validate on 3585 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:45:47.323715: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:46:44.081431: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:47:06.402067: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.43398, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 43s 1ms/sample - loss: 1.4401 - val_loss: 1.4340\n",
      "Epoch 2/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4353\n",
      "Epoch 2: val_loss improved from 1.43398 to 1.43365, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 719us/sample - loss: 1.4353 - val_loss: 1.4337\n",
      "Epoch 3/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4304\n",
      "Epoch 3: val_loss improved from 1.43365 to 1.43315, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 726us/sample - loss: 1.4304 - val_loss: 1.4332\n",
      "Epoch 4/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4266\n",
      "Epoch 4: val_loss improved from 1.43315 to 1.43217, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 22s 677us/sample - loss: 1.4266 - val_loss: 1.4322\n",
      "Epoch 5/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4284\n",
      "Epoch 5: val_loss improved from 1.43217 to 1.42907, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 21s 661us/sample - loss: 1.4284 - val_loss: 1.4291\n",
      "Epoch 6/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 6: val_loss improved from 1.42907 to 1.42454, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 707us/sample - loss: 1.4225 - val_loss: 1.4245\n",
      "Epoch 7/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4217\n",
      "Epoch 7: val_loss did not improve from 1.42454\n",
      "32135/32135 [==============================] - 21s 659us/sample - loss: 1.4217 - val_loss: 1.4306\n",
      "Epoch 8/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4160\n",
      "Epoch 8: val_loss did not improve from 1.42454\n",
      "32135/32135 [==============================] - 23s 713us/sample - loss: 1.4160 - val_loss: 1.4267\n",
      "Epoch 9/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4165\n",
      "Epoch 9: val_loss did not improve from 1.42454\n",
      "32135/32135 [==============================] - 23s 715us/sample - loss: 1.4165 - val_loss: 1.4335\n",
      "Epoch 10/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4179\n",
      "Epoch 10: val_loss did not improve from 1.42454\n",
      "32135/32135 [==============================] - 23s 714us/sample - loss: 1.4179 - val_loss: 1.4246\n",
      "Epoch 11/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4112\n",
      "Epoch 11: val_loss improved from 1.42454 to 1.42276, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 23s 722us/sample - loss: 1.4112 - val_loss: 1.4228\n",
      "Epoch 12/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 12: val_loss did not improve from 1.42276\n",
      "32135/32135 [==============================] - 23s 711us/sample - loss: 1.4093 - val_loss: 1.4334\n",
      "Epoch 13/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4076\n",
      "Epoch 13: val_loss improved from 1.42276 to 1.42258, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 22s 686us/sample - loss: 1.4076 - val_loss: 1.4226\n",
      "Epoch 14/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4037\n",
      "Epoch 14: val_loss did not improve from 1.42258\n",
      "32135/32135 [==============================] - 22s 681us/sample - loss: 1.4037 - val_loss: 1.4251\n",
      "Epoch 15/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4035\n",
      "Epoch 15: val_loss improved from 1.42258 to 1.42059, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_33.h5\n",
      "32135/32135 [==============================] - 22s 686us/sample - loss: 1.4035 - val_loss: 1.4206\n",
      "Epoch 16/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4028\n",
      "Epoch 16: val_loss did not improve from 1.42059\n",
      "32135/32135 [==============================] - 21s 653us/sample - loss: 1.4028 - val_loss: 1.4311\n",
      "Epoch 17/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 17: val_loss did not improve from 1.42059\n",
      "32135/32135 [==============================] - 20s 615us/sample - loss: 1.4011 - val_loss: 1.4294\n",
      "Epoch 18/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4012\n",
      "Epoch 18: val_loss did not improve from 1.42059\n",
      "32135/32135 [==============================] - 20s 628us/sample - loss: 1.4012 - val_loss: 1.4211\n",
      "Epoch 19/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 19: val_loss did not improve from 1.42059\n",
      "32135/32135 [==============================] - 23s 702us/sample - loss: 1.3977 - val_loss: 1.4210\n",
      "Epoch 20/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.3959\n",
      "Epoch 20: val_loss did not improve from 1.42059\n",
      "32135/32135 [==============================] - 23s 720us/sample - loss: 1.3959 - val_loss: 1.4210\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:54:32.452247: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_149/lstm_cell_445/recurrent_kernel/Assign' id:228371 op device:{requested: '', assigned: ''} def:{{{node lstm_149/lstm_cell_445/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_149/lstm_cell_445/recurrent_kernel, lstm_149/lstm_cell_445/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:54:38.856707: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_1' id:231804 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 14:54:44.011591: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_2' id:231805 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32135, 95)\n",
      "Train on 32135 samples, validate on 3585 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:54:59.223353: W tensorflow/c/c_api.cc:304] Operation '{name:'training_24/Adam/lstm_163/lstm_cell_459/recurrent_kernel/m/Assign' id:244792 op device:{requested: '', assigned: ''} def:{{{node training_24/Adam/lstm_163/lstm_cell_459/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_24/Adam/lstm_163/lstm_cell_459/recurrent_kernel/m, training_24/Adam/lstm_163/lstm_cell_459/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:56:02.674889: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 4.7127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:56:12.283398: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_25/mul' id:234645 op device:{requested: '', assigned: ''} def:{{{node loss_25/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_25/mul/x, loss_25/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.21346, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 66s 2ms/sample - loss: 4.7127 - val_loss: 4.2135\n",
      "Epoch 2/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 3.7910\n",
      "Epoch 2: val_loss improved from 4.21346 to 3.17646, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 3.7910 - val_loss: 3.1765\n",
      "Epoch 3/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 2.8042\n",
      "Epoch 3: val_loss improved from 3.17646 to 2.24700, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 232us/sample - loss: 2.8042 - val_loss: 2.2470\n",
      "Epoch 4/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 2.2143\n",
      "Epoch 4: val_loss improved from 2.24700 to 1.85005, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 219us/sample - loss: 2.2143 - val_loss: 1.8500\n",
      "Epoch 5/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.9591\n",
      "Epoch 5: val_loss did not improve from 1.85005\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.9591 - val_loss: 1.8594\n",
      "Epoch 6/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.8309\n",
      "Epoch 6: val_loss improved from 1.85005 to 1.72090, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 215us/sample - loss: 1.8309 - val_loss: 1.7209\n",
      "Epoch 7/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.7119\n",
      "Epoch 7: val_loss improved from 1.72090 to 1.61562, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.7119 - val_loss: 1.6156\n",
      "Epoch 8/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6541\n",
      "Epoch 8: val_loss improved from 1.61562 to 1.58449, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 220us/sample - loss: 1.6541 - val_loss: 1.5845\n",
      "Epoch 9/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6175\n",
      "Epoch 9: val_loss improved from 1.58449 to 1.55001, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 1.6175 - val_loss: 1.5500\n",
      "Epoch 10/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5862\n",
      "Epoch 10: val_loss improved from 1.55001 to 1.52984, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.5862 - val_loss: 1.5298\n",
      "Epoch 11/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5601\n",
      "Epoch 11: val_loss improved from 1.52984 to 1.51901, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 231us/sample - loss: 1.5601 - val_loss: 1.5190\n",
      "Epoch 12/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.8504\n",
      "Epoch 12: val_loss did not improve from 1.51901\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.8504 - val_loss: 1.5730\n",
      "Epoch 13/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.8003\n",
      "Epoch 13: val_loss did not improve from 1.51901\n",
      "32135/32135 [==============================] - 7s 228us/sample - loss: 1.8003 - val_loss: 1.5479\n",
      "Epoch 14/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6031\n",
      "Epoch 14: val_loss did not improve from 1.51901\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.6031 - val_loss: 1.5256\n",
      "Epoch 15/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5435\n",
      "Epoch 15: val_loss did not improve from 1.51901\n",
      "32135/32135 [==============================] - 7s 212us/sample - loss: 1.5435 - val_loss: 1.5300\n",
      "Epoch 16/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5449\n",
      "Epoch 16: val_loss improved from 1.51901 to 1.50788, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 209us/sample - loss: 1.5449 - val_loss: 1.5079\n",
      "Epoch 17/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5311\n",
      "Epoch 17: val_loss did not improve from 1.50788\n",
      "32135/32135 [==============================] - 6s 202us/sample - loss: 1.5311 - val_loss: 1.5122\n",
      "Epoch 18/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5241\n",
      "Epoch 18: val_loss improved from 1.50788 to 1.48732, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 214us/sample - loss: 1.5241 - val_loss: 1.4873\n",
      "Epoch 19/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5511\n",
      "Epoch 19: val_loss did not improve from 1.48732\n",
      "32135/32135 [==============================] - 7s 204us/sample - loss: 1.5511 - val_loss: 1.5078\n",
      "Epoch 20/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5213\n",
      "Epoch 20: val_loss did not improve from 1.48732\n",
      "32135/32135 [==============================] - 7s 224us/sample - loss: 1.5213 - val_loss: 1.4962\n",
      "Epoch 21/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5167\n",
      "Epoch 21: val_loss did not improve from 1.48732\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.5167 - val_loss: 1.4873\n",
      "Epoch 22/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6005\n",
      "Epoch 22: val_loss did not improve from 1.48732\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.6005 - val_loss: 1.5485\n",
      "Epoch 23/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5391\n",
      "Epoch 23: val_loss did not improve from 1.48732\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.5391 - val_loss: 1.5352\n",
      "Epoch 24/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5027\n",
      "Epoch 24: val_loss improved from 1.48732 to 1.48039, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.5027 - val_loss: 1.4804\n",
      "Epoch 25/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5034\n",
      "Epoch 25: val_loss did not improve from 1.48039\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.5034 - val_loss: 1.4824\n",
      "Epoch 26/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4963\n",
      "Epoch 26: val_loss improved from 1.48039 to 1.47336, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.4963 - val_loss: 1.4734\n",
      "Epoch 27/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4898\n",
      "Epoch 27: val_loss improved from 1.47336 to 1.47157, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 208us/sample - loss: 1.4898 - val_loss: 1.4716\n",
      "Epoch 28/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4890\n",
      "Epoch 28: val_loss improved from 1.47157 to 1.46830, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 220us/sample - loss: 1.4890 - val_loss: 1.4683\n",
      "Epoch 29/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4864\n",
      "Epoch 29: val_loss improved from 1.46830 to 1.46655, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.4864 - val_loss: 1.4665\n",
      "Epoch 30/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4824\n",
      "Epoch 30: val_loss improved from 1.46655 to 1.46505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 206us/sample - loss: 1.4824 - val_loss: 1.4651\n",
      "Epoch 31/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4814\n",
      "Epoch 31: val_loss improved from 1.46505 to 1.46210, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4814 - val_loss: 1.4621\n",
      "Epoch 32/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4791\n",
      "Epoch 32: val_loss improved from 1.46210 to 1.46133, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 208us/sample - loss: 1.4791 - val_loss: 1.4613\n",
      "Epoch 33/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4754\n",
      "Epoch 33: val_loss improved from 1.46133 to 1.46002, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 228us/sample - loss: 1.4754 - val_loss: 1.4600\n",
      "Epoch 34/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 34: val_loss improved from 1.46002 to 1.45938, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 215us/sample - loss: 1.4752 - val_loss: 1.4594\n",
      "Epoch 35/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4686\n",
      "Epoch 35: val_loss improved from 1.45938 to 1.45540, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 206us/sample - loss: 1.4686 - val_loss: 1.4554\n",
      "Epoch 36/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4709\n",
      "Epoch 36: val_loss did not improve from 1.45540\n",
      "32135/32135 [==============================] - 6s 200us/sample - loss: 1.4709 - val_loss: 1.4568\n",
      "Epoch 37/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 37: val_loss improved from 1.45540 to 1.45280, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 206us/sample - loss: 1.4689 - val_loss: 1.4528\n",
      "Epoch 38/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4679\n",
      "Epoch 38: val_loss did not improve from 1.45280\n",
      "32135/32135 [==============================] - 6s 201us/sample - loss: 1.4679 - val_loss: 1.4551\n",
      "Epoch 39/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4644\n",
      "Epoch 39: val_loss improved from 1.45280 to 1.44985, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 209us/sample - loss: 1.4644 - val_loss: 1.4498\n",
      "Epoch 40/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4637\n",
      "Epoch 40: val_loss did not improve from 1.44985\n",
      "32135/32135 [==============================] - 6s 202us/sample - loss: 1.4637 - val_loss: 1.4547\n",
      "Epoch 41/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4635\n",
      "Epoch 41: val_loss improved from 1.44985 to 1.44720, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4635 - val_loss: 1.4472\n",
      "Epoch 42/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4617\n",
      "Epoch 42: val_loss improved from 1.44720 to 1.44696, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4617 - val_loss: 1.4470\n",
      "Epoch 43/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4601\n",
      "Epoch 43: val_loss did not improve from 1.44696\n",
      "32135/32135 [==============================] - 6s 201us/sample - loss: 1.4601 - val_loss: 1.4489\n",
      "Epoch 44/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4583\n",
      "Epoch 44: val_loss did not improve from 1.44696\n",
      "32135/32135 [==============================] - 7s 211us/sample - loss: 1.4583 - val_loss: 1.4482\n",
      "Epoch 45/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4572\n",
      "Epoch 45: val_loss improved from 1.44696 to 1.44456, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 206us/sample - loss: 1.4572 - val_loss: 1.4446\n",
      "Epoch 46/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4553\n",
      "Epoch 46: val_loss did not improve from 1.44456\n",
      "32135/32135 [==============================] - 7s 220us/sample - loss: 1.4553 - val_loss: 1.4453\n",
      "Epoch 47/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4570\n",
      "Epoch 47: val_loss improved from 1.44456 to 1.44306, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 9s 278us/sample - loss: 1.4570 - val_loss: 1.4431\n",
      "Epoch 48/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4544\n",
      "Epoch 48: val_loss did not improve from 1.44306\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4544 - val_loss: 1.4434\n",
      "Epoch 49/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4522\n",
      "Epoch 49: val_loss improved from 1.44306 to 1.44219, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_34.h5\n",
      "32135/32135 [==============================] - 7s 208us/sample - loss: 1.4522 - val_loss: 1.4422\n",
      "Epoch 50/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4489\n",
      "Epoch 50: val_loss did not improve from 1.44219\n",
      "32135/32135 [==============================] - 7s 205us/sample - loss: 1.4489 - val_loss: 1.4435\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:02:54.401503: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_162_1/lstm_cell_495/bias/Assign' id:249077 op device:{requested: '', assigned: ''} def:{{{node lstm_162_1/lstm_cell_495/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_162_1/lstm_cell_495/bias, lstm_162_1/lstm_cell_495/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:03:07.163007: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_166_1/lstm_cell_499/kernel/v/Assign' id:254333 op device:{requested: '', assigned: ''} def:{{{node lstm_166_1/lstm_cell_499/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_166_1/lstm_cell_499/kernel/v, lstm_166_1/lstm_cell_499/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:03:19.795374: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_24_1/cond/Merge' id:252759 op device:{requested: '', assigned: ''} def:{{{node dropout_24_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_24_1/cond/Identity, dropout_24_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1281)\n",
      "(1656, 1281)\n",
      "(1704, 1281)\n",
      "(1872, 1281)\n",
      "(1712, 1281)\n",
      "(1369, 1281)\n",
      "(1802, 1281)\n",
      "(1595, 1281)\n",
      "(1752, 1281)\n",
      "(1514, 1281)\n",
      "(1908, 1281)\n",
      "(1727, 1281)\n",
      "(1776, 1281)\n",
      "(1872, 1281)\n",
      "(1704, 1281)\n",
      "(1824, 1281)\n",
      "(958, 1281)\n",
      "(1668, 1281)\n",
      "(1884, 1281)\n",
      "{2: 5.306370226944397, 4: 7.9196844671706375, 5: 6.303201988030108, 6: 4.848134286892826, 8: 9.107679541957205, 9: 5.93096773320836, 10: 7.652466981601338, 11: 6.586797811632675, 12: 8.351297132112805, 13: 8.488541995389504, 17: 8.497165742061895, 19: 7.45658649696335, 21: 10.0, 22: 1.0, 25: 6.9144863156838525, 26: 6.221561489913021, 27: 5.653907526052827, 28: 6.28794553841312, 29: 1.6792248422258802}\n",
      "Train on 32135 samples, validate on 3585 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:08:32.169989: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 10.6259\n",
      "Epoch 1: val_loss improved from inf to 1.46114, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 45s 1ms/sample - loss: 10.6259 - val_loss: 1.4611\n",
      "Epoch 2/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.4597\n",
      "Epoch 2: val_loss improved from 1.46114 to 1.45166, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 20s 636us/sample - loss: 10.4597 - val_loss: 1.4517\n",
      "Epoch 3/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.3815\n",
      "Epoch 3: val_loss improved from 1.45166 to 1.44532, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 20s 631us/sample - loss: 10.3815 - val_loss: 1.4453\n",
      "Epoch 4/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.3265\n",
      "Epoch 4: val_loss improved from 1.44532 to 1.44409, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 20s 635us/sample - loss: 10.3265 - val_loss: 1.4441\n",
      "Epoch 5/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2829\n",
      "Epoch 5: val_loss did not improve from 1.44409\n",
      "32135/32135 [==============================] - 21s 650us/sample - loss: 10.2829 - val_loss: 1.4626\n",
      "Epoch 6/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2789\n",
      "Epoch 6: val_loss did not improve from 1.44409\n",
      "32135/32135 [==============================] - 20s 625us/sample - loss: 10.2789 - val_loss: 1.4610\n",
      "Epoch 7/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2589\n",
      "Epoch 7: val_loss improved from 1.44409 to 1.44196, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 20s 633us/sample - loss: 10.2589 - val_loss: 1.4420\n",
      "Epoch 8/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1925\n",
      "Epoch 8: val_loss improved from 1.44196 to 1.43914, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 20s 630us/sample - loss: 10.1925 - val_loss: 1.4391\n",
      "Epoch 9/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1570\n",
      "Epoch 9: val_loss did not improve from 1.43914\n",
      "32135/32135 [==============================] - 20s 637us/sample - loss: 10.1570 - val_loss: 1.4409\n",
      "Epoch 10/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1376\n",
      "Epoch 10: val_loss did not improve from 1.43914\n",
      "32135/32135 [==============================] - 22s 676us/sample - loss: 10.1376 - val_loss: 1.4461\n",
      "Epoch 11/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0868\n",
      "Epoch 11: val_loss improved from 1.43914 to 1.43401, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 23s 722us/sample - loss: 10.0868 - val_loss: 1.4340\n",
      "Epoch 12/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.1030\n",
      "Epoch 12: val_loss did not improve from 1.43401\n",
      "32135/32135 [==============================] - 23s 710us/sample - loss: 10.1030 - val_loss: 1.4565\n",
      "Epoch 13/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0664\n",
      "Epoch 13: val_loss improved from 1.43401 to 1.43275, saving model to ./checkpoints/unknown_person_few_shot_p1_34.h5\n",
      "32135/32135 [==============================] - 23s 709us/sample - loss: 10.0664 - val_loss: 1.4327\n",
      "Epoch 14/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0208\n",
      "Epoch 14: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 23s 723us/sample - loss: 10.0208 - val_loss: 1.4365\n",
      "Epoch 15/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0216\n",
      "Epoch 15: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 21s 664us/sample - loss: 10.0216 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 10.0136\n",
      "Epoch 16: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 20s 628us/sample - loss: 10.0136 - val_loss: 1.4346\n",
      "Epoch 17/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9825\n",
      "Epoch 17: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 20s 621us/sample - loss: 9.9825 - val_loss: 1.4548\n",
      "Epoch 18/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9936\n",
      "Epoch 18: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 21s 652us/sample - loss: 9.9936 - val_loss: 1.4376\n",
      "Epoch 19/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9875\n",
      "Epoch 19: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 23s 722us/sample - loss: 9.9875 - val_loss: 1.4330\n",
      "Epoch 20/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9612\n",
      "Epoch 20: val_loss did not improve from 1.43275\n",
      "32135/32135 [==============================] - 23s 716us/sample - loss: 9.9612 - val_loss: 1.4386\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:16:08.925694: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_166_2/lstm_cell_536/bias/Assign' id:269115 op device:{requested: '', assigned: ''} def:{{{node lstm_166_2/lstm_cell_536/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_166_2/lstm_cell_536/bias, lstm_166_2/lstm_cell_536/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:16:22.677197: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_178_2/lstm_cell_548/recurrent_kernel/v/Assign' id:273916 op device:{requested: '', assigned: ''} def:{{{node lstm_178_2/lstm_cell_548/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_178_2/lstm_cell_548/recurrent_kernel/v, lstm_178_2/lstm_cell_548/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32135 samples, validate on 3585 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:16:38.803782: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:17:51.022964: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4498"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:18:15.810531: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.43849, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 51s 2ms/sample - loss: 1.4498 - val_loss: 1.4385\n",
      "Epoch 2/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4459\n",
      "Epoch 2: val_loss did not improve from 1.43849\n",
      "32135/32135 [==============================] - 23s 716us/sample - loss: 1.4459 - val_loss: 1.4398\n",
      "Epoch 3/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 3: val_loss improved from 1.43849 to 1.43481, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 23s 720us/sample - loss: 1.4411 - val_loss: 1.4348\n",
      "Epoch 4/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 4: val_loss improved from 1.43481 to 1.43342, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 22s 700us/sample - loss: 1.4404 - val_loss: 1.4334\n",
      "Epoch 5/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 5: val_loss improved from 1.43342 to 1.42637, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 22s 682us/sample - loss: 1.4375 - val_loss: 1.4264\n",
      "Epoch 6/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 6: val_loss did not improve from 1.42637\n",
      "32135/32135 [==============================] - 20s 626us/sample - loss: 1.4330 - val_loss: 1.4315\n",
      "Epoch 7/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4285\n",
      "Epoch 7: val_loss did not improve from 1.42637\n",
      "32135/32135 [==============================] - 20s 629us/sample - loss: 1.4285 - val_loss: 1.4306\n",
      "Epoch 8/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4286\n",
      "Epoch 8: val_loss improved from 1.42637 to 1.42147, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 21s 656us/sample - loss: 1.4286 - val_loss: 1.4215\n",
      "Epoch 9/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4281\n",
      "Epoch 9: val_loss did not improve from 1.42147\n",
      "32135/32135 [==============================] - 23s 717us/sample - loss: 1.4281 - val_loss: 1.4231\n",
      "Epoch 10/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 10: val_loss did not improve from 1.42147\n",
      "32135/32135 [==============================] - 23s 717us/sample - loss: 1.4237 - val_loss: 1.4220\n",
      "Epoch 11/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 11: val_loss did not improve from 1.42147\n",
      "32135/32135 [==============================] - 23s 723us/sample - loss: 1.4225 - val_loss: 1.4236\n",
      "Epoch 12/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 12: val_loss improved from 1.42147 to 1.41804, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 23s 718us/sample - loss: 1.4207 - val_loss: 1.4180\n",
      "Epoch 13/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 13: val_loss did not improve from 1.41804\n",
      "32135/32135 [==============================] - 21s 650us/sample - loss: 1.4173 - val_loss: 1.4233\n",
      "Epoch 14/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4167\n",
      "Epoch 14: val_loss improved from 1.41804 to 1.41678, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 22s 699us/sample - loss: 1.4167 - val_loss: 1.4168\n",
      "Epoch 15/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4142\n",
      "Epoch 15: val_loss did not improve from 1.41678\n",
      "32135/32135 [==============================] - 20s 626us/sample - loss: 1.4142 - val_loss: 1.4171\n",
      "Epoch 16/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4143\n",
      "Epoch 16: val_loss did not improve from 1.41678\n",
      "32135/32135 [==============================] - 23s 715us/sample - loss: 1.4143 - val_loss: 1.4176\n",
      "Epoch 17/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4109\n",
      "Epoch 17: val_loss did not improve from 1.41678\n",
      "32135/32135 [==============================] - 21s 647us/sample - loss: 1.4109 - val_loss: 1.4235\n",
      "Epoch 18/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 18: val_loss did not improve from 1.41678\n",
      "32135/32135 [==============================] - 20s 624us/sample - loss: 1.4141 - val_loss: 1.4171\n",
      "Epoch 19/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4118\n",
      "Epoch 19: val_loss improved from 1.41678 to 1.41527, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_34.h5\n",
      "32135/32135 [==============================] - 21s 639us/sample - loss: 1.4118 - val_loss: 1.4153\n",
      "Epoch 20/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4106\n",
      "Epoch 20: val_loss did not improve from 1.41527\n",
      "32135/32135 [==============================] - 20s 630us/sample - loss: 1.4106 - val_loss: 1.4165\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:25:39.624450: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_194/lstm_cell_564/kernel/Assign' id:286713 op device:{requested: '', assigned: ''} def:{{{node lstm_194/lstm_cell_564/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_194/lstm_cell_564/kernel, lstm_194/lstm_cell_564/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:25:47.308832: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_1' id:288846 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:25:53.475692: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_2' id:288847 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32135, 95)\n",
      "Train on 32135 samples, validate on 3585 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:26:11.312249: W tensorflow/c/c_api.cc:304] Operation '{name:'training_30/Adam/lstm_220/lstm_cell_590/recurrent_kernel/m/Assign' id:302134 op device:{requested: '', assigned: ''} def:{{{node training_30/Adam/lstm_220/lstm_cell_590/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_30/Adam/lstm_220/lstm_cell_590/recurrent_kernel/m, training_30/Adam/lstm_220/lstm_cell_590/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:27:32.186136: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 4.0674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:27:41.387744: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_31/mul' id:291687 op device:{requested: '', assigned: ''} def:{{{node loss_31/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_31/mul/x, loss_31/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.33723, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 79s 2ms/sample - loss: 4.0674 - val_loss: 3.3372\n",
      "Epoch 2/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 2.6834\n",
      "Epoch 2: val_loss improved from 3.33723 to 2.08953, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 213us/sample - loss: 2.6834 - val_loss: 2.0895\n",
      "Epoch 3/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 2.1957\n",
      "Epoch 3: val_loss improved from 2.08953 to 2.00556, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 2.1957 - val_loss: 2.0056\n",
      "Epoch 4/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.9638\n",
      "Epoch 4: val_loss improved from 2.00556 to 1.82658, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 1.9638 - val_loss: 1.8266\n",
      "Epoch 5/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.8024\n",
      "Epoch 5: val_loss improved from 1.82658 to 1.66584, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 1.8024 - val_loss: 1.6658\n",
      "Epoch 6/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6804\n",
      "Epoch 6: val_loss improved from 1.66584 to 1.58208, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 231us/sample - loss: 1.6804 - val_loss: 1.5821\n",
      "Epoch 7/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6248\n",
      "Epoch 7: val_loss improved from 1.58208 to 1.55738, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 1.6248 - val_loss: 1.5574\n",
      "Epoch 8/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6014\n",
      "Epoch 8: val_loss improved from 1.55738 to 1.52424, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 232us/sample - loss: 1.6014 - val_loss: 1.5242\n",
      "Epoch 9/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5950\n",
      "Epoch 9: val_loss did not improve from 1.52424\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.5950 - val_loss: 1.5321\n",
      "Epoch 10/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5756\n",
      "Epoch 10: val_loss improved from 1.52424 to 1.52376, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 231us/sample - loss: 1.5756 - val_loss: 1.5238\n",
      "Epoch 11/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5485\n",
      "Epoch 11: val_loss improved from 1.52376 to 1.50544, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 232us/sample - loss: 1.5485 - val_loss: 1.5054\n",
      "Epoch 12/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5445\n",
      "Epoch 12: val_loss did not improve from 1.50544\n",
      "32135/32135 [==============================] - 7s 224us/sample - loss: 1.5445 - val_loss: 1.5106\n",
      "Epoch 13/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5312\n",
      "Epoch 13: val_loss improved from 1.50544 to 1.49991, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 231us/sample - loss: 1.5312 - val_loss: 1.4999\n",
      "Epoch 14/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5412\n",
      "Epoch 14: val_loss improved from 1.49991 to 1.49925, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 213us/sample - loss: 1.5412 - val_loss: 1.4993\n",
      "Epoch 15/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5404\n",
      "Epoch 15: val_loss did not improve from 1.49925\n",
      "32135/32135 [==============================] - 7s 223us/sample - loss: 1.5404 - val_loss: 1.5054\n",
      "Epoch 16/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5211\n",
      "Epoch 16: val_loss improved from 1.49925 to 1.49005, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 216us/sample - loss: 1.5211 - val_loss: 1.4901\n",
      "Epoch 17/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5202\n",
      "Epoch 17: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.5202 - val_loss: 1.4917\n",
      "Epoch 18/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5308\n",
      "Epoch 18: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.5308 - val_loss: 1.4912\n",
      "Epoch 19/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5462\n",
      "Epoch 19: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.5462 - val_loss: 1.5009\n",
      "Epoch 20/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6286\n",
      "Epoch 20: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 224us/sample - loss: 1.6286 - val_loss: 1.6053\n",
      "Epoch 21/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5489\n",
      "Epoch 21: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 227us/sample - loss: 1.5489 - val_loss: 1.5144\n",
      "Epoch 22/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5901\n",
      "Epoch 22: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 224us/sample - loss: 1.5901 - val_loss: 1.5508\n",
      "Epoch 23/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.6283\n",
      "Epoch 23: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.6283 - val_loss: 1.5504\n",
      "Epoch 24/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5680\n",
      "Epoch 24: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 218us/sample - loss: 1.5680 - val_loss: 1.5515\n",
      "Epoch 25/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5161\n",
      "Epoch 25: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 216us/sample - loss: 1.5161 - val_loss: 1.4938\n",
      "Epoch 26/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5119\n",
      "Epoch 26: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 225us/sample - loss: 1.5119 - val_loss: 1.4905\n",
      "Epoch 27/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5113\n",
      "Epoch 27: val_loss did not improve from 1.49005\n",
      "32135/32135 [==============================] - 7s 226us/sample - loss: 1.5113 - val_loss: 1.4914\n",
      "Epoch 28/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5068\n",
      "Epoch 28: val_loss improved from 1.49005 to 1.48479, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.5068 - val_loss: 1.4848\n",
      "Epoch 29/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.5032\n",
      "Epoch 29: val_loss improved from 1.48479 to 1.48432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.5032 - val_loss: 1.4843\n",
      "Epoch 30/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4991\n",
      "Epoch 30: val_loss improved from 1.48432 to 1.48300, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 1.4991 - val_loss: 1.4830\n",
      "Epoch 31/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4978\n",
      "Epoch 31: val_loss improved from 1.48300 to 1.48271, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.4978 - val_loss: 1.4827\n",
      "Epoch 32/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4945\n",
      "Epoch 32: val_loss improved from 1.48271 to 1.47813, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 228us/sample - loss: 1.4945 - val_loss: 1.4781\n",
      "Epoch 33/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4937\n",
      "Epoch 33: val_loss improved from 1.47813 to 1.47755, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 229us/sample - loss: 1.4937 - val_loss: 1.4775\n",
      "Epoch 34/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4871\n",
      "Epoch 34: val_loss improved from 1.47755 to 1.47498, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 230us/sample - loss: 1.4871 - val_loss: 1.4750\n",
      "Epoch 35/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4892\n",
      "Epoch 35: val_loss improved from 1.47498 to 1.47254, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 232us/sample - loss: 1.4892 - val_loss: 1.4725\n",
      "Epoch 36/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4858\n",
      "Epoch 36: val_loss improved from 1.47254 to 1.47170, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 218us/sample - loss: 1.4858 - val_loss: 1.4717\n",
      "Epoch 37/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4832\n",
      "Epoch 37: val_loss improved from 1.47170 to 1.46942, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 206us/sample - loss: 1.4832 - val_loss: 1.4694\n",
      "Epoch 38/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4823\n",
      "Epoch 38: val_loss improved from 1.46942 to 1.46901, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 208us/sample - loss: 1.4823 - val_loss: 1.4690\n",
      "Epoch 39/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4802\n",
      "Epoch 39: val_loss improved from 1.46901 to 1.46768, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4802 - val_loss: 1.4677\n",
      "Epoch 40/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4815\n",
      "Epoch 40: val_loss improved from 1.46768 to 1.46574, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4815 - val_loss: 1.4657\n",
      "Epoch 41/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 41: val_loss improved from 1.46574 to 1.46525, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 212us/sample - loss: 1.4781 - val_loss: 1.4652\n",
      "Epoch 42/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4764\n",
      "Epoch 42: val_loss improved from 1.46525 to 1.46341, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 211us/sample - loss: 1.4764 - val_loss: 1.4634\n",
      "Epoch 43/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4757\n",
      "Epoch 43: val_loss improved from 1.46341 to 1.46172, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 208us/sample - loss: 1.4757 - val_loss: 1.4617\n",
      "Epoch 44/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4744\n",
      "Epoch 44: val_loss did not improve from 1.46172\n",
      "32135/32135 [==============================] - 6s 201us/sample - loss: 1.4744 - val_loss: 1.4619\n",
      "Epoch 45/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4762\n",
      "Epoch 45: val_loss improved from 1.46172 to 1.46065, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4762 - val_loss: 1.4607\n",
      "Epoch 46/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4730\n",
      "Epoch 46: val_loss did not improve from 1.46065\n",
      "32135/32135 [==============================] - 6s 202us/sample - loss: 1.4730 - val_loss: 1.4610\n",
      "Epoch 47/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4703\n",
      "Epoch 47: val_loss improved from 1.46065 to 1.45840, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4703 - val_loss: 1.4584\n",
      "Epoch 48/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4706\n",
      "Epoch 48: val_loss improved from 1.45840 to 1.45824, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 209us/sample - loss: 1.4706 - val_loss: 1.4582\n",
      "Epoch 49/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4706\n",
      "Epoch 49: val_loss improved from 1.45824 to 1.45756, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 207us/sample - loss: 1.4706 - val_loss: 1.4576\n",
      "Epoch 50/50\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 50: val_loss improved from 1.45756 to 1.45497, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_35.h5\n",
      "32135/32135 [==============================] - 7s 208us/sample - loss: 1.4689 - val_loss: 1.4550\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:34:44.995512: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_203_1/lstm_cell_610/bias/Assign' id:306759 op device:{requested: '', assigned: ''} def:{{{node lstm_203_1/lstm_cell_610/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_203_1/lstm_cell_610/bias, lstm_203_1/lstm_cell_610/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:35:01.387768: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_204_1/lstm_cell_611/kernel/m/Assign' id:310747 op device:{requested: '', assigned: ''} def:{{{node lstm_204_1/lstm_cell_611/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_204_1/lstm_cell_611/kernel/m, lstm_204_1/lstm_cell_611/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:35:17.871468: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_29_1/cond/Merge' id:309801 op device:{requested: '', assigned: ''} def:{{{node dropout_29_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_29_1/cond/Identity, dropout_29_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 1281)\n",
      "(1656, 1281)\n",
      "(1704, 1281)\n",
      "(1872, 1281)\n",
      "(1712, 1281)\n",
      "(1369, 1281)\n",
      "(1802, 1281)\n",
      "(1595, 1281)\n",
      "(1752, 1281)\n",
      "(1514, 1281)\n",
      "(1908, 1281)\n",
      "(1727, 1281)\n",
      "(1776, 1281)\n",
      "(1872, 1281)\n",
      "(1704, 1281)\n",
      "(1824, 1281)\n",
      "(958, 1281)\n",
      "(1668, 1281)\n",
      "(1884, 1281)\n",
      "{2: 2.680385519380276, 4: 7.0117141148491715, 5: 6.326003643797894, 6: 5.302419648693379, 8: 8.61005076283326, 9: 4.150649625189491, 10: 8.120956844637915, 11: 6.001589919753001, 12: 8.40557528893092, 13: 8.235594620530437, 17: 8.042501147379108, 19: 7.06281462525903, 21: 10.0, 22: 1.0, 25: 6.886336870506098, 26: 6.2649463861035, 27: 4.436205999749663, 28: 6.944935816308082, 29: 1.3768410219323255}\n",
      "Train on 32135 samples, validate on 3585 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:40:16.400838: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 10.2055\n",
      "Epoch 1: val_loss improved from inf to 1.46953, saving model to ./checkpoints/unknown_person_few_shot_p1_35.h5\n",
      "32135/32135 [==============================] - 51s 2ms/sample - loss: 10.2055 - val_loss: 1.4695\n",
      "Epoch 2/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9906\n",
      "Epoch 2: val_loss improved from 1.46953 to 1.44834, saving model to ./checkpoints/unknown_person_few_shot_p1_35.h5\n",
      "32135/32135 [==============================] - 20s 629us/sample - loss: 9.9906 - val_loss: 1.4483\n",
      "Epoch 3/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9391\n",
      "Epoch 3: val_loss did not improve from 1.44834\n",
      "32135/32135 [==============================] - 20s 625us/sample - loss: 9.9391 - val_loss: 1.4605\n",
      "Epoch 4/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.9268\n",
      "Epoch 4: val_loss did not improve from 1.44834\n",
      "32135/32135 [==============================] - 20s 628us/sample - loss: 9.9268 - val_loss: 1.4573\n",
      "Epoch 5/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.8351\n",
      "Epoch 5: val_loss did not improve from 1.44834\n",
      "32135/32135 [==============================] - 22s 687us/sample - loss: 9.8351 - val_loss: 1.4583\n",
      "Epoch 6/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.8037\n",
      "Epoch 6: val_loss improved from 1.44834 to 1.44509, saving model to ./checkpoints/unknown_person_few_shot_p1_35.h5\n",
      "32135/32135 [==============================] - 22s 683us/sample - loss: 9.8037 - val_loss: 1.4451\n",
      "Epoch 7/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.7636\n",
      "Epoch 7: val_loss did not improve from 1.44509\n",
      "32135/32135 [==============================] - 20s 622us/sample - loss: 9.7636 - val_loss: 1.4506\n",
      "Epoch 8/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.7436\n",
      "Epoch 8: val_loss did not improve from 1.44509\n",
      "32135/32135 [==============================] - 20s 629us/sample - loss: 9.7436 - val_loss: 1.4587\n",
      "Epoch 9/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.7302\n",
      "Epoch 9: val_loss did not improve from 1.44509\n",
      "32135/32135 [==============================] - 23s 716us/sample - loss: 9.7302 - val_loss: 1.4459\n",
      "Epoch 10/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.6991\n",
      "Epoch 10: val_loss improved from 1.44509 to 1.43804, saving model to ./checkpoints/unknown_person_few_shot_p1_35.h5\n",
      "32135/32135 [==============================] - 22s 693us/sample - loss: 9.6991 - val_loss: 1.4380\n",
      "Epoch 11/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.6633\n",
      "Epoch 11: val_loss did not improve from 1.43804\n",
      "32135/32135 [==============================] - 23s 717us/sample - loss: 9.6633 - val_loss: 1.4537\n",
      "Epoch 12/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.6754\n",
      "Epoch 12: val_loss did not improve from 1.43804\n",
      "32135/32135 [==============================] - 22s 688us/sample - loss: 9.6754 - val_loss: 1.4537\n",
      "Epoch 13/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.6125\n",
      "Epoch 13: val_loss improved from 1.43804 to 1.43615, saving model to ./checkpoints/unknown_person_few_shot_p1_35.h5\n",
      "32135/32135 [==============================] - 20s 631us/sample - loss: 9.6125 - val_loss: 1.4361\n",
      "Epoch 14/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.6174\n",
      "Epoch 14: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 20s 623us/sample - loss: 9.6174 - val_loss: 1.4422\n",
      "Epoch 15/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.5911\n",
      "Epoch 15: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 20s 625us/sample - loss: 9.5911 - val_loss: 1.4480\n",
      "Epoch 16/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.5902\n",
      "Epoch 16: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 20s 624us/sample - loss: 9.5902 - val_loss: 1.4521\n",
      "Epoch 17/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.5712\n",
      "Epoch 17: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 20s 623us/sample - loss: 9.5712 - val_loss: 1.4511\n",
      "Epoch 18/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.5678\n",
      "Epoch 18: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 21s 648us/sample - loss: 9.5678 - val_loss: 1.4536\n",
      "Epoch 19/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.5527\n",
      "Epoch 19: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 23s 713us/sample - loss: 9.5527 - val_loss: 1.4442\n",
      "Epoch 20/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 9.5087\n",
      "Epoch 20: val_loss did not improve from 1.43615\n",
      "32135/32135 [==============================] - 23s 714us/sample - loss: 9.5087 - val_loss: 1.4541\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:47:56.024062: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_203_2/lstm_cell_647/bias/Assign' id:326157 op device:{requested: '', assigned: ''} def:{{{node lstm_203_2/lstm_cell_647/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_203_2/lstm_cell_647/bias, lstm_203_2/lstm_cell_647/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:48:12.560381: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_217_2/lstm_cell_661/bias/m/Assign' id:330350 op device:{requested: '', assigned: ''} def:{{{node lstm_217_2/lstm_cell_661/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_217_2/lstm_cell_661/bias/m, lstm_217_2/lstm_cell_661/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32135 samples, validate on 3585 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:48:31.690435: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:49:58.466633: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:50:23.176002: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.44880, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 55s 2ms/sample - loss: 1.4663 - val_loss: 1.4488\n",
      "Epoch 2/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4565\n",
      "Epoch 2: val_loss improved from 1.44880 to 1.44685, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 20s 636us/sample - loss: 1.4565 - val_loss: 1.4468\n",
      "Epoch 3/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4527\n",
      "Epoch 3: val_loss improved from 1.44685 to 1.44074, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 23s 725us/sample - loss: 1.4527 - val_loss: 1.4407\n",
      "Epoch 4/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4475\n",
      "Epoch 4: val_loss did not improve from 1.44074\n",
      "32135/32135 [==============================] - 23s 714us/sample - loss: 1.4475 - val_loss: 1.4409\n",
      "Epoch 5/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4446\n",
      "Epoch 5: val_loss improved from 1.44074 to 1.43873, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 23s 723us/sample - loss: 1.4446 - val_loss: 1.4387\n",
      "Epoch 6/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 6: val_loss did not improve from 1.43873\n",
      "32135/32135 [==============================] - 23s 716us/sample - loss: 1.4420 - val_loss: 1.4461\n",
      "Epoch 7/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4398\n",
      "Epoch 7: val_loss improved from 1.43873 to 1.43704, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 23s 718us/sample - loss: 1.4398 - val_loss: 1.4370\n",
      "Epoch 8/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4410\n",
      "Epoch 8: val_loss did not improve from 1.43704\n",
      "32135/32135 [==============================] - 23s 717us/sample - loss: 1.4410 - val_loss: 1.4461\n",
      "Epoch 9/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 9: val_loss improved from 1.43704 to 1.43255, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 23s 725us/sample - loss: 1.4349 - val_loss: 1.4325\n",
      "Epoch 10/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4327\n",
      "Epoch 10: val_loss did not improve from 1.43255\n",
      "32135/32135 [==============================] - 23s 720us/sample - loss: 1.4327 - val_loss: 1.4329\n",
      "Epoch 11/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4290\n",
      "Epoch 11: val_loss improved from 1.43255 to 1.43134, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 21s 667us/sample - loss: 1.4290 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4291\n",
      "Epoch 12: val_loss did not improve from 1.43134\n",
      "32135/32135 [==============================] - 20s 637us/sample - loss: 1.4291 - val_loss: 1.4325\n",
      "Epoch 13/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 13: val_loss improved from 1.43134 to 1.43060, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 20s 634us/sample - loss: 1.4252 - val_loss: 1.4306\n",
      "Epoch 14/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4240\n",
      "Epoch 14: val_loss improved from 1.43060 to 1.42985, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 22s 684us/sample - loss: 1.4240 - val_loss: 1.4299\n",
      "Epoch 15/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 15: val_loss did not improve from 1.42985\n",
      "32135/32135 [==============================] - 20s 623us/sample - loss: 1.4237 - val_loss: 1.4349\n",
      "Epoch 16/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 16: val_loss did not improve from 1.42985\n",
      "32135/32135 [==============================] - 23s 709us/sample - loss: 1.4249 - val_loss: 1.4314\n",
      "Epoch 17/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 17: val_loss did not improve from 1.42985\n",
      "32135/32135 [==============================] - 23s 717us/sample - loss: 1.4212 - val_loss: 1.4338\n",
      "Epoch 18/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 18: val_loss improved from 1.42985 to 1.42392, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_35.h5\n",
      "32135/32135 [==============================] - 23s 723us/sample - loss: 1.4164 - val_loss: 1.4239\n",
      "Epoch 19/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 19: val_loss did not improve from 1.42392\n",
      "32135/32135 [==============================] - 23s 720us/sample - loss: 1.4211 - val_loss: 1.4256\n",
      "Epoch 20/20\n",
      "32135/32135 [==============================] - ETA: 0s - loss: 1.4140\n",
      "Epoch 20: val_loss did not improve from 1.42392\n",
      "32135/32135 [==============================] - 23s 719us/sample - loss: 1.4140 - val_loss: 1.4294\n",
      "35876\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:58:13.660132: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_226/lstm_cell_670/bias/Assign' id:342959 op device:{requested: '', assigned: ''} def:{{{node lstm_226/lstm_cell_670/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_226/lstm_cell_670/bias, lstm_226/lstm_cell_670/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:58:23.201984: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_1' id:345888 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 15:58:30.855483: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_2' id:345889 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32278, 95)\n",
      "Train on 32278 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:58:50.594269: W tensorflow/c/c_api.cc:304] Operation '{name:'training_36/Adam/lstm_232/lstm_cell_676/recurrent_kernel/v/Assign' id:359444 op device:{requested: '', assigned: ''} def:{{{node training_36/Adam/lstm_232/lstm_cell_676/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_36/Adam/lstm_232/lstm_cell_676/recurrent_kernel/v, training_36/Adam/lstm_232/lstm_cell_676/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:00:26.539570: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 4.6652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-17 16:00:38.975247: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_37/mul' id:348729 op device:{requested: '', assigned: ''} def:{{{node loss_37/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_37/mul/x, loss_37/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.23511, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 97s 3ms/sample - loss: 4.6652 - val_loss: 4.2351\n",
      "Epoch 2/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 3.5246\n",
      "Epoch 2: val_loss improved from 4.23511 to 2.85600, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 232us/sample - loss: 3.5246 - val_loss: 2.8560\n",
      "Epoch 3/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 2.4270\n",
      "Epoch 3: val_loss improved from 2.85600 to 1.87768, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 219us/sample - loss: 2.4270 - val_loss: 1.8777\n",
      "Epoch 4/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 2.1166\n",
      "Epoch 4: val_loss did not improve from 1.87768\n",
      "32278/32278 [==============================] - 7s 204us/sample - loss: 2.1166 - val_loss: 1.9255\n",
      "Epoch 5/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.9081\n",
      "Epoch 5: val_loss did not improve from 1.87768\n",
      "32278/32278 [==============================] - 7s 204us/sample - loss: 1.9081 - val_loss: 1.9275\n",
      "Epoch 6/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.7788\n",
      "Epoch 6: val_loss improved from 1.87768 to 1.66314, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 209us/sample - loss: 1.7788 - val_loss: 1.6631\n",
      "Epoch 7/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6914\n",
      "Epoch 7: val_loss improved from 1.66314 to 1.65662, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.6914 - val_loss: 1.6566\n",
      "Epoch 8/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6273\n",
      "Epoch 8: val_loss improved from 1.65662 to 1.57083, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.6273 - val_loss: 1.5708\n",
      "Epoch 9/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5911\n",
      "Epoch 9: val_loss improved from 1.57083 to 1.55247, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5911 - val_loss: 1.5525\n",
      "Epoch 10/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5697\n",
      "Epoch 10: val_loss improved from 1.55247 to 1.52617, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 211us/sample - loss: 1.5697 - val_loss: 1.5262\n",
      "Epoch 11/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6159\n",
      "Epoch 11: val_loss did not improve from 1.52617\n",
      "32278/32278 [==============================] - 7s 203us/sample - loss: 1.6159 - val_loss: 1.5743\n",
      "Epoch 12/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5660\n",
      "Epoch 12: val_loss improved from 1.52617 to 1.51728, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5660 - val_loss: 1.5173\n",
      "Epoch 13/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5622\n",
      "Epoch 13: val_loss improved from 1.51728 to 1.49954, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 212us/sample - loss: 1.5622 - val_loss: 1.4995\n",
      "Epoch 14/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5365\n",
      "Epoch 14: val_loss did not improve from 1.49954\n",
      "32278/32278 [==============================] - 7s 206us/sample - loss: 1.5365 - val_loss: 1.5162\n",
      "Epoch 15/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5496\n",
      "Epoch 15: val_loss improved from 1.49954 to 1.49388, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 212us/sample - loss: 1.5496 - val_loss: 1.4939\n",
      "Epoch 16/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5287\n",
      "Epoch 16: val_loss did not improve from 1.49388\n",
      "32278/32278 [==============================] - 7s 207us/sample - loss: 1.5287 - val_loss: 1.4958\n",
      "Epoch 17/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5440\n",
      "Epoch 17: val_loss did not improve from 1.49388\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.5440 - val_loss: 1.5259\n",
      "Epoch 18/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5108\n",
      "Epoch 18: val_loss did not improve from 1.49388\n",
      "32278/32278 [==============================] - 7s 206us/sample - loss: 1.5108 - val_loss: 1.4998\n",
      "Epoch 19/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6029\n",
      "Epoch 19: val_loss did not improve from 1.49388\n",
      "32278/32278 [==============================] - 6s 201us/sample - loss: 1.6029 - val_loss: 1.5364\n",
      "Epoch 20/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5115\n",
      "Epoch 20: val_loss improved from 1.49388 to 1.48493, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.5115 - val_loss: 1.4849\n",
      "Epoch 21/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5029\n",
      "Epoch 21: val_loss did not improve from 1.48493\n",
      "32278/32278 [==============================] - 7s 203us/sample - loss: 1.5029 - val_loss: 1.4917\n",
      "Epoch 22/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5125\n",
      "Epoch 22: val_loss did not improve from 1.48493\n",
      "32278/32278 [==============================] - 7s 203us/sample - loss: 1.5125 - val_loss: 1.4864\n",
      "Epoch 23/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4990\n",
      "Epoch 23: val_loss improved from 1.48493 to 1.48457, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.4990 - val_loss: 1.4846\n",
      "Epoch 24/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4942\n",
      "Epoch 24: val_loss improved from 1.48457 to 1.48165, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.4942 - val_loss: 1.4816\n",
      "Epoch 25/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4907\n",
      "Epoch 25: val_loss improved from 1.48165 to 1.47670, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 211us/sample - loss: 1.4907 - val_loss: 1.4767\n",
      "Epoch 26/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 26: val_loss improved from 1.47670 to 1.47656, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.4865 - val_loss: 1.4766\n",
      "Epoch 27/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4814\n",
      "Epoch 27: val_loss improved from 1.47656 to 1.47635, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.4814 - val_loss: 1.4764\n",
      "Epoch 28/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4808\n",
      "Epoch 28: val_loss improved from 1.47635 to 1.47468, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.4808 - val_loss: 1.4747\n",
      "Epoch 29/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4786\n",
      "Epoch 29: val_loss improved from 1.47468 to 1.47344, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 209us/sample - loss: 1.4786 - val_loss: 1.4734\n",
      "Epoch 30/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4795\n",
      "Epoch 30: val_loss improved from 1.47344 to 1.46794, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 215us/sample - loss: 1.4795 - val_loss: 1.4679\n",
      "Epoch 31/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 31: val_loss did not improve from 1.46794\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.4751 - val_loss: 1.4715\n",
      "Epoch 32/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4729\n",
      "Epoch 32: val_loss did not improve from 1.46794\n",
      "32278/32278 [==============================] - 7s 216us/sample - loss: 1.4729 - val_loss: 1.4698\n",
      "Epoch 33/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4706\n",
      "Epoch 33: val_loss improved from 1.46794 to 1.46750, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.4706 - val_loss: 1.4675\n",
      "Epoch 34/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4670\n",
      "Epoch 34: val_loss improved from 1.46750 to 1.46553, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.4670 - val_loss: 1.4655\n",
      "Epoch 35/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4676\n",
      "Epoch 35: val_loss did not improve from 1.46553\n",
      "32278/32278 [==============================] - 7s 224us/sample - loss: 1.4676 - val_loss: 1.4682\n",
      "Epoch 36/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 36: val_loss improved from 1.46553 to 1.46263, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 229us/sample - loss: 1.4658 - val_loss: 1.4626\n",
      "Epoch 37/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4652\n",
      "Epoch 37: val_loss did not improve from 1.46263\n",
      "32278/32278 [==============================] - 7s 222us/sample - loss: 1.4652 - val_loss: 1.4646\n",
      "Epoch 38/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4614\n",
      "Epoch 38: val_loss improved from 1.46263 to 1.45904, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 229us/sample - loss: 1.4614 - val_loss: 1.4590\n",
      "Epoch 39/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4626\n",
      "Epoch 39: val_loss did not improve from 1.45904\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4626 - val_loss: 1.4608\n",
      "Epoch 40/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 40: val_loss did not improve from 1.45904\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4597 - val_loss: 1.4627\n",
      "Epoch 41/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4599\n",
      "Epoch 41: val_loss improved from 1.45904 to 1.45655, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 229us/sample - loss: 1.4599 - val_loss: 1.4566\n",
      "Epoch 42/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4589\n",
      "Epoch 42: val_loss did not improve from 1.45655\n",
      "32278/32278 [==============================] - 7s 211us/sample - loss: 1.4589 - val_loss: 1.4581\n",
      "Epoch 43/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4562\n",
      "Epoch 43: val_loss did not improve from 1.45655\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4562 - val_loss: 1.4603\n",
      "Epoch 44/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4556\n",
      "Epoch 44: val_loss improved from 1.45655 to 1.45400, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 229us/sample - loss: 1.4556 - val_loss: 1.4540\n",
      "Epoch 45/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4552\n",
      "Epoch 45: val_loss did not improve from 1.45400\n",
      "32278/32278 [==============================] - 7s 222us/sample - loss: 1.4552 - val_loss: 1.4552\n",
      "Epoch 46/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4492\n",
      "Epoch 46: val_loss improved from 1.45400 to 1.45195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 228us/sample - loss: 1.4492 - val_loss: 1.4519\n",
      "Epoch 47/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4510\n",
      "Epoch 47: val_loss did not improve from 1.45195\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4510 - val_loss: 1.4523\n",
      "Epoch 48/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4502\n",
      "Epoch 48: val_loss did not improve from 1.45195\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4502 - val_loss: 1.4530\n",
      "Epoch 49/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4477\n",
      "Epoch 49: val_loss improved from 1.45195 to 1.45039, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_36.h5\n",
      "32278/32278 [==============================] - 7s 230us/sample - loss: 1.4477 - val_loss: 1.4504\n",
      "Epoch 50/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4459\n",
      "Epoch 50: val_loss did not improve from 1.45039\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4459 - val_loss: 1.4508\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:07:51.602092: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_242_1/lstm_cell_723/kernel/Assign' id:364092 op device:{requested: '', assigned: ''} def:{{{node lstm_242_1/lstm_cell_723/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_242_1/lstm_cell_723/kernel, lstm_242_1/lstm_cell_723/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:08:10.238226: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_222_1/lstm_cell_703/recurrent_kernel/m/Assign' id:367509 op device:{requested: '', assigned: ''} def:{{{node lstm_222_1/lstm_cell_703/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_222_1/lstm_cell_703/recurrent_kernel/m, lstm_222_1/lstm_cell_703/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-17 16:08:28.698146: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_34_1/cond/Merge' id:366843 op device:{requested: '', assigned: ''} def:{{{node dropout_34_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_34_1/cond/Identity, dropout_34_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1562, 1125)\n",
      "(1644, 1125)\n",
      "(1716, 1125)\n",
      "(1848, 1125)\n",
      "(1711, 1125)\n",
      "(1393, 1125)\n",
      "(1791, 1125)\n",
      "(1606, 1125)\n",
      "(1728, 1125)\n",
      "(1538, 1125)\n",
      "(1908, 1125)\n",
      "(1715, 1125)\n",
      "(1752, 1125)\n",
      "(1884, 1125)\n",
      "(1728, 1125)\n",
      "(1800, 1125)\n",
      "(982, 1125)\n",
      "(1656, 1125)\n",
      "(1884, 1125)\n",
      "{2: 5.914444849980243, 4: 8.793496982109838, 5: 5.8692126941418845, 6: 5.887511575365812, 8: 9.749204429255286, 9: 6.865675986281495, 10: 8.255513192146548, 11: 7.380337110849021, 12: 9.009263309031349, 13: 8.032608597291892, 17: 8.877225712846469, 19: 8.25245759721045, 21: 10.0, 22: 1.0, 25: 7.545906317208761, 26: 6.312752056418408, 27: 6.091565291095942, 28: 6.424582909783032, 29: 2.2853783900362874}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2905707/2131643591.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32278 samples, validate on 3598 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:14:01.555603: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 11.4450\n",
      "Epoch 1: val_loss improved from inf to 1.48045, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 57s 2ms/sample - loss: 11.4450 - val_loss: 1.4805\n",
      "Epoch 2/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 11.2323\n",
      "Epoch 2: val_loss improved from 1.48045 to 1.47371, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 20s 623us/sample - loss: 11.2323 - val_loss: 1.4737\n",
      "Epoch 3/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 11.1537\n",
      "Epoch 3: val_loss improved from 1.47371 to 1.47307, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 20s 620us/sample - loss: 11.1537 - val_loss: 1.4731\n",
      "Epoch 4/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 11.1214\n",
      "Epoch 4: val_loss improved from 1.47307 to 1.45687, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 22s 676us/sample - loss: 11.1214 - val_loss: 1.4569\n",
      "Epoch 5/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 11.0388\n",
      "Epoch 5: val_loss did not improve from 1.45687\n",
      "32278/32278 [==============================] - 20s 627us/sample - loss: 11.0388 - val_loss: 1.4595\n",
      "Epoch 6/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 11.0046\n",
      "Epoch 6: val_loss did not improve from 1.45687\n",
      "32278/32278 [==============================] - 20s 608us/sample - loss: 11.0046 - val_loss: 1.4690\n",
      "Epoch 7/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.9143\n",
      "Epoch 7: val_loss improved from 1.45687 to 1.45404, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 20s 615us/sample - loss: 10.9143 - val_loss: 1.4540\n",
      "Epoch 8/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.8872\n",
      "Epoch 8: val_loss did not improve from 1.45404\n",
      "32278/32278 [==============================] - 20s 628us/sample - loss: 10.8872 - val_loss: 1.4654\n",
      "Epoch 9/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.8768\n",
      "Epoch 9: val_loss improved from 1.45404 to 1.44919, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 20s 618us/sample - loss: 10.8768 - val_loss: 1.4492\n",
      "Epoch 10/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.8564\n",
      "Epoch 10: val_loss did not improve from 1.44919\n",
      "32278/32278 [==============================] - 20s 609us/sample - loss: 10.8564 - val_loss: 1.4691\n",
      "Epoch 11/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.8337\n",
      "Epoch 11: val_loss improved from 1.44919 to 1.44357, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 21s 661us/sample - loss: 10.8337 - val_loss: 1.4436\n",
      "Epoch 12/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.7804\n",
      "Epoch 12: val_loss did not improve from 1.44357\n",
      "32278/32278 [==============================] - 21s 661us/sample - loss: 10.7804 - val_loss: 1.4454\n",
      "Epoch 13/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.7701\n",
      "Epoch 13: val_loss did not improve from 1.44357\n",
      "32278/32278 [==============================] - 23s 712us/sample - loss: 10.7701 - val_loss: 1.4525\n",
      "Epoch 14/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.7624\n",
      "Epoch 14: val_loss improved from 1.44357 to 1.44071, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 21s 642us/sample - loss: 10.7624 - val_loss: 1.4407\n",
      "Epoch 15/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.7349\n",
      "Epoch 15: val_loss improved from 1.44071 to 1.43175, saving model to ./checkpoints/unknown_person_few_shot_p1_36.h5\n",
      "32278/32278 [==============================] - 23s 712us/sample - loss: 10.7349 - val_loss: 1.4318\n",
      "Epoch 16/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.7429\n",
      "Epoch 16: val_loss did not improve from 1.43175\n",
      "32278/32278 [==============================] - 23s 723us/sample - loss: 10.7429 - val_loss: 1.4473\n",
      "Epoch 17/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.7253\n",
      "Epoch 17: val_loss did not improve from 1.43175\n",
      "32278/32278 [==============================] - 23s 717us/sample - loss: 10.7253 - val_loss: 1.4427\n",
      "Epoch 18/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.6789\n",
      "Epoch 18: val_loss did not improve from 1.43175\n",
      "32278/32278 [==============================] - 23s 704us/sample - loss: 10.6789 - val_loss: 1.4413\n",
      "Epoch 19/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.6323\n",
      "Epoch 19: val_loss did not improve from 1.43175\n",
      "32278/32278 [==============================] - 23s 716us/sample - loss: 10.6323 - val_loss: 1.4376\n",
      "Epoch 20/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.6758\n",
      "Epoch 20: val_loss did not improve from 1.43175\n",
      "32278/32278 [==============================] - 23s 719us/sample - loss: 10.6758 - val_loss: 1.4357\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:21:53.293306: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_257_2/lstm_cell_775/recurrent_kernel/Assign' id:385912 op device:{requested: '', assigned: ''} def:{{{node lstm_257_2/lstm_cell_775/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_257_2/lstm_cell_775/recurrent_kernel, lstm_257_2/lstm_cell_775/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:22:13.248213: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_247_2/lstm_cell_765/kernel/m/Assign' id:387277 op device:{requested: '', assigned: ''} def:{{{node lstm_247_2/lstm_cell_765/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_247_2/lstm_cell_765/kernel/m, lstm_247_2/lstm_cell_765/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32278 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:22:35.704303: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:24:18.827722: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:24:43.664549: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.45808, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 61s 2ms/sample - loss: 1.4512 - val_loss: 1.4581\n",
      "Epoch 2/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4445\n",
      "Epoch 2: val_loss improved from 1.45808 to 1.45203, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 23s 721us/sample - loss: 1.4445 - val_loss: 1.4520\n",
      "Epoch 3/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4433\n",
      "Epoch 3: val_loss improved from 1.45203 to 1.44915, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 23s 717us/sample - loss: 1.4433 - val_loss: 1.4492\n",
      "Epoch 4/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 4: val_loss improved from 1.44915 to 1.44634, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 23s 725us/sample - loss: 1.4346 - val_loss: 1.4463\n",
      "Epoch 5/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4342\n",
      "Epoch 5: val_loss improved from 1.44634 to 1.43719, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 24s 729us/sample - loss: 1.4342 - val_loss: 1.4372\n",
      "Epoch 6/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4287\n",
      "Epoch 6: val_loss improved from 1.43719 to 1.42916, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 23s 722us/sample - loss: 1.4287 - val_loss: 1.4292\n",
      "Epoch 7/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 7: val_loss improved from 1.42916 to 1.42803, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 21s 650us/sample - loss: 1.4280 - val_loss: 1.4280\n",
      "Epoch 8/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 8: val_loss did not improve from 1.42803\n",
      "32278/32278 [==============================] - 23s 702us/sample - loss: 1.4252 - val_loss: 1.4329\n",
      "Epoch 9/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4218\n",
      "Epoch 9: val_loss did not improve from 1.42803\n",
      "32278/32278 [==============================] - 23s 713us/sample - loss: 1.4218 - val_loss: 1.4319\n",
      "Epoch 10/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 10: val_loss improved from 1.42803 to 1.42774, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 23s 713us/sample - loss: 1.4210 - val_loss: 1.4277\n",
      "Epoch 11/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 11: val_loss did not improve from 1.42774\n",
      "32278/32278 [==============================] - 21s 661us/sample - loss: 1.4172 - val_loss: 1.4433\n",
      "Epoch 12/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 12: val_loss did not improve from 1.42774\n",
      "32278/32278 [==============================] - 23s 702us/sample - loss: 1.4141 - val_loss: 1.4380\n",
      "Epoch 13/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4157\n",
      "Epoch 13: val_loss did not improve from 1.42774\n",
      "32278/32278 [==============================] - 23s 714us/sample - loss: 1.4157 - val_loss: 1.4307\n",
      "Epoch 14/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4107\n",
      "Epoch 14: val_loss did not improve from 1.42774\n",
      "32278/32278 [==============================] - 21s 664us/sample - loss: 1.4107 - val_loss: 1.4298\n",
      "Epoch 15/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 15: val_loss did not improve from 1.42774\n",
      "32278/32278 [==============================] - 20s 621us/sample - loss: 1.4097 - val_loss: 1.4285\n",
      "Epoch 16/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4086\n",
      "Epoch 16: val_loss improved from 1.42774 to 1.41968, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_36.h5\n",
      "32278/32278 [==============================] - 21s 649us/sample - loss: 1.4086 - val_loss: 1.4197\n",
      "Epoch 17/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 17: val_loss did not improve from 1.41968\n",
      "32278/32278 [==============================] - 20s 624us/sample - loss: 1.4088 - val_loss: 1.4228\n",
      "Epoch 18/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4040\n",
      "Epoch 18: val_loss did not improve from 1.41968\n",
      "32278/32278 [==============================] - 20s 631us/sample - loss: 1.4040 - val_loss: 1.4265\n",
      "Epoch 19/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 19: val_loss did not improve from 1.41968\n",
      "32278/32278 [==============================] - 22s 671us/sample - loss: 1.4062 - val_loss: 1.4290\n",
      "Epoch 20/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4038\n",
      "Epoch 20: val_loss did not improve from 1.41968\n",
      "32278/32278 [==============================] - 23s 712us/sample - loss: 1.4038 - val_loss: 1.4209\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:32:28.157845: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_264/lstm_cell_782/recurrent_kernel/Assign' id:400157 op device:{requested: '', assigned: ''} def:{{{node lstm_264/lstm_cell_782/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_264/lstm_cell_782/recurrent_kernel, lstm_264/lstm_cell_782/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:32:39.344153: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_1' id:402930 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:32:48.374944: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_2' id:402931 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32278, 95)\n",
      "Train on 32278 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:33:10.840738: W tensorflow/c/c_api.cc:304] Operation '{name:'training_42/Adam/lstm_272/lstm_cell_790/bias/v/Assign' id:416536 op device:{requested: '', assigned: ''} def:{{{node training_42/Adam/lstm_272/lstm_cell_790/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_42/Adam/lstm_272/lstm_cell_790/bias/v, training_42/Adam/lstm_272/lstm_cell_790/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:35:03.231717: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 4.5518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:35:13.251214: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_43/mul' id:405771 op device:{requested: '', assigned: ''} def:{{{node loss_43/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_43/mul/x, loss_43/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.89630, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 109s 3ms/sample - loss: 4.5518 - val_loss: 3.8963\n",
      "Epoch 2/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 3.3000\n",
      "Epoch 2: val_loss improved from 3.89630 to 2.71256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 238us/sample - loss: 3.3000 - val_loss: 2.7126\n",
      "Epoch 3/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 2.3461\n",
      "Epoch 3: val_loss improved from 2.71256 to 1.93737, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 233us/sample - loss: 2.3461 - val_loss: 1.9374\n",
      "Epoch 4/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.9595\n",
      "Epoch 4: val_loss improved from 1.93737 to 1.79213, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 233us/sample - loss: 1.9595 - val_loss: 1.7921\n",
      "Epoch 5/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.8076\n",
      "Epoch 5: val_loss improved from 1.79213 to 1.76238, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 238us/sample - loss: 1.8076 - val_loss: 1.7624\n",
      "Epoch 6/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.7133\n",
      "Epoch 6: val_loss improved from 1.76238 to 1.61755, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 226us/sample - loss: 1.7133 - val_loss: 1.6176\n",
      "Epoch 7/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6556\n",
      "Epoch 7: val_loss improved from 1.61755 to 1.60069, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 232us/sample - loss: 1.6556 - val_loss: 1.6007\n",
      "Epoch 8/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6332\n",
      "Epoch 8: val_loss improved from 1.60069 to 1.57721, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 235us/sample - loss: 1.6332 - val_loss: 1.5772\n",
      "Epoch 9/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6116\n",
      "Epoch 9: val_loss improved from 1.57721 to 1.54569, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 235us/sample - loss: 1.6116 - val_loss: 1.5457\n",
      "Epoch 10/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5925\n",
      "Epoch 10: val_loss did not improve from 1.54569\n",
      "32278/32278 [==============================] - 7s 227us/sample - loss: 1.5925 - val_loss: 1.5545\n",
      "Epoch 11/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5746\n",
      "Epoch 11: val_loss improved from 1.54569 to 1.53430, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 224us/sample - loss: 1.5746 - val_loss: 1.5343\n",
      "Epoch 12/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5574\n",
      "Epoch 12: val_loss improved from 1.53430 to 1.52249, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 216us/sample - loss: 1.5574 - val_loss: 1.5225\n",
      "Epoch 13/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.7580\n",
      "Epoch 13: val_loss did not improve from 1.52249\n",
      "32278/32278 [==============================] - 7s 206us/sample - loss: 1.7580 - val_loss: 1.5647\n",
      "Epoch 14/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5898\n",
      "Epoch 14: val_loss did not improve from 1.52249\n",
      "32278/32278 [==============================] - 7s 209us/sample - loss: 1.5898 - val_loss: 1.5573\n",
      "Epoch 15/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5525\n",
      "Epoch 15: val_loss improved from 1.52249 to 1.52216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 215us/sample - loss: 1.5525 - val_loss: 1.5222\n",
      "Epoch 16/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5483\n",
      "Epoch 16: val_loss improved from 1.52216 to 1.50882, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 215us/sample - loss: 1.5483 - val_loss: 1.5088\n",
      "Epoch 17/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6507\n",
      "Epoch 17: val_loss did not improve from 1.50882\n",
      "32278/32278 [==============================] - 7s 205us/sample - loss: 1.6507 - val_loss: 1.5186\n",
      "Epoch 18/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5677\n",
      "Epoch 18: val_loss did not improve from 1.50882\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.5677 - val_loss: 1.5195\n",
      "Epoch 19/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5585\n",
      "Epoch 19: val_loss did not improve from 1.50882\n",
      "32278/32278 [==============================] - 7s 204us/sample - loss: 1.5585 - val_loss: 1.5166\n",
      "Epoch 20/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5329\n",
      "Epoch 20: val_loss improved from 1.50882 to 1.50198, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 215us/sample - loss: 1.5329 - val_loss: 1.5020\n",
      "Epoch 21/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5423\n",
      "Epoch 21: val_loss improved from 1.50198 to 1.50096, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 213us/sample - loss: 1.5423 - val_loss: 1.5010\n",
      "Epoch 22/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5465\n",
      "Epoch 22: val_loss did not improve from 1.50096\n",
      "32278/32278 [==============================] - 7s 207us/sample - loss: 1.5465 - val_loss: 1.5030\n",
      "Epoch 23/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5835\n",
      "Epoch 23: val_loss did not improve from 1.50096\n",
      "32278/32278 [==============================] - 7s 209us/sample - loss: 1.5835 - val_loss: 1.5384\n",
      "Epoch 24/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5092\n",
      "Epoch 24: val_loss improved from 1.50096 to 1.49513, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 216us/sample - loss: 1.5092 - val_loss: 1.4951\n",
      "Epoch 25/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5043\n",
      "Epoch 25: val_loss improved from 1.49513 to 1.48509, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 211us/sample - loss: 1.5043 - val_loss: 1.4851\n",
      "Epoch 26/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4988\n",
      "Epoch 26: val_loss improved from 1.48509 to 1.48254, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.4988 - val_loss: 1.4825\n",
      "Epoch 27/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4924\n",
      "Epoch 27: val_loss improved from 1.48254 to 1.48097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 216us/sample - loss: 1.4924 - val_loss: 1.4810\n",
      "Epoch 28/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4888\n",
      "Epoch 28: val_loss improved from 1.48097 to 1.47837, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 214us/sample - loss: 1.4888 - val_loss: 1.4784\n",
      "Epoch 29/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4864\n",
      "Epoch 29: val_loss improved from 1.47837 to 1.47478, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 215us/sample - loss: 1.4864 - val_loss: 1.4748\n",
      "Epoch 30/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4849\n",
      "Epoch 30: val_loss improved from 1.47478 to 1.47168, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 214us/sample - loss: 1.4849 - val_loss: 1.4717\n",
      "Epoch 31/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4797\n",
      "Epoch 31: val_loss did not improve from 1.47168\n",
      "32278/32278 [==============================] - 7s 207us/sample - loss: 1.4797 - val_loss: 1.4724\n",
      "Epoch 32/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4788\n",
      "Epoch 32: val_loss did not improve from 1.47168\n",
      "32278/32278 [==============================] - 7s 206us/sample - loss: 1.4788 - val_loss: 1.4737\n",
      "Epoch 33/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 33: val_loss improved from 1.47168 to 1.46921, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 214us/sample - loss: 1.4787 - val_loss: 1.4692\n",
      "Epoch 34/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4733\n",
      "Epoch 34: val_loss improved from 1.46921 to 1.46783, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 213us/sample - loss: 1.4733 - val_loss: 1.4678\n",
      "Epoch 35/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4720\n",
      "Epoch 35: val_loss did not improve from 1.46783\n",
      "32278/32278 [==============================] - 7s 208us/sample - loss: 1.4720 - val_loss: 1.4681\n",
      "Epoch 36/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4705\n",
      "Epoch 36: val_loss improved from 1.46783 to 1.46460, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 216us/sample - loss: 1.4705 - val_loss: 1.4646\n",
      "Epoch 37/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4682\n",
      "Epoch 37: val_loss did not improve from 1.46460\n",
      "32278/32278 [==============================] - 7s 207us/sample - loss: 1.4682 - val_loss: 1.4666\n",
      "Epoch 38/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4673\n",
      "Epoch 38: val_loss improved from 1.46460 to 1.46119, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 217us/sample - loss: 1.4673 - val_loss: 1.4612\n",
      "Epoch 39/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4674\n",
      "Epoch 39: val_loss improved from 1.46119 to 1.46067, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 222us/sample - loss: 1.4674 - val_loss: 1.4607\n",
      "Epoch 40/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4639\n",
      "Epoch 40: val_loss did not improve from 1.46067\n",
      "32278/32278 [==============================] - 7s 207us/sample - loss: 1.4639 - val_loss: 1.4631\n",
      "Epoch 41/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4621\n",
      "Epoch 41: val_loss improved from 1.46067 to 1.45930, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 7s 213us/sample - loss: 1.4621 - val_loss: 1.4593\n",
      "Epoch 42/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4634\n",
      "Epoch 42: val_loss did not improve from 1.45930\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.4634 - val_loss: 1.4600\n",
      "Epoch 43/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4595\n",
      "Epoch 43: val_loss improved from 1.45930 to 1.45467, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.4595 - val_loss: 1.4547\n",
      "Epoch 44/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4558\n",
      "Epoch 44: val_loss did not improve from 1.45467\n",
      "32278/32278 [==============================] - 7s 226us/sample - loss: 1.4558 - val_loss: 1.4605\n",
      "Epoch 45/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4566\n",
      "Epoch 45: val_loss did not improve from 1.45467\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.4566 - val_loss: 1.4554\n",
      "Epoch 46/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4530\n",
      "Epoch 46: val_loss did not improve from 1.45467\n",
      "32278/32278 [==============================] - 7s 227us/sample - loss: 1.4530 - val_loss: 1.4551\n",
      "Epoch 47/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4541\n",
      "Epoch 47: val_loss improved from 1.45467 to 1.45349, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 235us/sample - loss: 1.4541 - val_loss: 1.4535\n",
      "Epoch 48/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4530\n",
      "Epoch 48: val_loss improved from 1.45349 to 1.45320, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 236us/sample - loss: 1.4530 - val_loss: 1.4532\n",
      "Epoch 49/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4526\n",
      "Epoch 49: val_loss did not improve from 1.45320\n",
      "32278/32278 [==============================] - 7s 227us/sample - loss: 1.4526 - val_loss: 1.4535\n",
      "Epoch 50/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4503\n",
      "Epoch 50: val_loss improved from 1.45320 to 1.44890, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_37.h5\n",
      "32278/32278 [==============================] - 8s 233us/sample - loss: 1.4503 - val_loss: 1.4489\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:42:48.007830: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_273_1/lstm_cell_828/bias/Assign' id:420203 op device:{requested: '', assigned: ''} def:{{{node lstm_273_1/lstm_cell_828/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_273_1/lstm_cell_828/bias, lstm_273_1/lstm_cell_828/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:43:10.652681: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_30_1/kernel/m/Assign' id:424526 op device:{requested: '', assigned: ''} def:{{{node conv2d_30_1/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_30_1/kernel/m, conv2d_30_1/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:43:32.824101: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_39_1/cond/Merge' id:423885 op device:{requested: '', assigned: ''} def:{{{node dropout_39_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_39_1/cond/Identity, dropout_39_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1562, 1125)\n",
      "(1644, 1125)\n",
      "(1716, 1125)\n",
      "(1848, 1125)\n",
      "(1711, 1125)\n",
      "(1393, 1125)\n",
      "(1791, 1125)\n",
      "(1606, 1125)\n",
      "(1728, 1125)\n",
      "(1538, 1125)\n",
      "(1908, 1125)\n",
      "(1715, 1125)\n",
      "(1752, 1125)\n",
      "(1884, 1125)\n",
      "(1728, 1125)\n",
      "(1800, 1125)\n",
      "(982, 1125)\n",
      "(1656, 1125)\n",
      "(1884, 1125)\n",
      "{2: 5.510744745805349, 4: 6.88735228239167, 5: 6.162425854860864, 6: 4.455452525870104, 8: 8.850079798953285, 9: 5.675979182302291, 10: 7.917522825582645, 11: 6.240615293244494, 12: 8.33268833344301, 13: 8.251711970759263, 17: 8.128778059785908, 19: 6.6525740576768175, 21: 10.0, 22: 1.0, 25: 6.729101087281562, 26: 6.206628685807864, 27: 4.82677129936519, 28: 6.6278028549366645, 29: 1.5580914306086462}\n",
      "Train on 32278 samples, validate on 3598 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:49:17.428355: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 10.5459\n",
      "Epoch 1: val_loss improved from inf to 1.49961, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 66s 2ms/sample - loss: 10.5459 - val_loss: 1.4996\n",
      "Epoch 2/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.3078\n",
      "Epoch 2: val_loss improved from 1.49961 to 1.49425, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 24s 733us/sample - loss: 10.3078 - val_loss: 1.4942\n",
      "Epoch 3/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.2906\n",
      "Epoch 3: val_loss did not improve from 1.49425\n",
      "32278/32278 [==============================] - 23s 716us/sample - loss: 10.2906 - val_loss: 1.4971\n",
      "Epoch 4/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.1917\n",
      "Epoch 4: val_loss improved from 1.49425 to 1.46681, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 22s 693us/sample - loss: 10.1917 - val_loss: 1.4668\n",
      "Epoch 5/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.2093\n",
      "Epoch 5: val_loss did not improve from 1.46681\n",
      "32278/32278 [==============================] - 23s 727us/sample - loss: 10.2093 - val_loss: 1.4890\n",
      "Epoch 6/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.1384\n",
      "Epoch 6: val_loss did not improve from 1.46681\n",
      "32278/32278 [==============================] - 23s 700us/sample - loss: 10.1384 - val_loss: 1.4671\n",
      "Epoch 7/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0691\n",
      "Epoch 7: val_loss improved from 1.46681 to 1.46380, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 24s 735us/sample - loss: 10.0691 - val_loss: 1.4638\n",
      "Epoch 8/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0416\n",
      "Epoch 8: val_loss improved from 1.46380 to 1.46102, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 24s 732us/sample - loss: 10.0416 - val_loss: 1.4610\n",
      "Epoch 9/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0199\n",
      "Epoch 9: val_loss did not improve from 1.46102\n",
      "32278/32278 [==============================] - 23s 723us/sample - loss: 10.0199 - val_loss: 1.4628\n",
      "Epoch 10/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0209\n",
      "Epoch 10: val_loss improved from 1.46102 to 1.46049, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 24s 730us/sample - loss: 10.0209 - val_loss: 1.4605\n",
      "Epoch 11/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9654\n",
      "Epoch 11: val_loss did not improve from 1.46049\n",
      "32278/32278 [==============================] - 23s 698us/sample - loss: 9.9654 - val_loss: 1.4684\n",
      "Epoch 12/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9649\n",
      "Epoch 12: val_loss did not improve from 1.46049\n",
      "32278/32278 [==============================] - 21s 641us/sample - loss: 9.9649 - val_loss: 1.4629\n",
      "Epoch 13/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9543\n",
      "Epoch 13: val_loss improved from 1.46049 to 1.45753, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 21s 653us/sample - loss: 9.9543 - val_loss: 1.4575\n",
      "Epoch 14/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9246\n",
      "Epoch 14: val_loss did not improve from 1.45753\n",
      "32278/32278 [==============================] - 23s 698us/sample - loss: 9.9246 - val_loss: 1.4581\n",
      "Epoch 15/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8841\n",
      "Epoch 15: val_loss improved from 1.45753 to 1.44870, saving model to ./checkpoints/unknown_person_few_shot_p1_37.h5\n",
      "32278/32278 [==============================] - 21s 653us/sample - loss: 9.8841 - val_loss: 1.4487\n",
      "Epoch 16/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8961\n",
      "Epoch 16: val_loss did not improve from 1.44870\n",
      "32278/32278 [==============================] - 21s 637us/sample - loss: 9.8961 - val_loss: 1.4796\n",
      "Epoch 17/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8783\n",
      "Epoch 17: val_loss did not improve from 1.44870\n",
      "32278/32278 [==============================] - 21s 637us/sample - loss: 9.8783 - val_loss: 1.4635\n",
      "Epoch 18/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8658\n",
      "Epoch 18: val_loss did not improve from 1.44870\n",
      "32278/32278 [==============================] - 21s 642us/sample - loss: 9.8658 - val_loss: 1.4613\n",
      "Epoch 19/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8451\n",
      "Epoch 19: val_loss did not improve from 1.44870\n",
      "32278/32278 [==============================] - 21s 652us/sample - loss: 9.8451 - val_loss: 1.4601\n",
      "Epoch 20/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8415\n",
      "Epoch 20: val_loss did not improve from 1.44870\n",
      "32278/32278 [==============================] - 21s 649us/sample - loss: 9.8415 - val_loss: 1.4495\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:57:33.550579: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_274_2/lstm_cell_866/kernel/Assign' id:439732 op device:{requested: '', assigned: ''} def:{{{node lstm_274_2/lstm_cell_866/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_274_2/lstm_cell_866/kernel, lstm_274_2/lstm_cell_866/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 16:57:56.939866: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_275_2/lstm_cell_867/bias/v/Assign' id:444837 op device:{requested: '', assigned: ''} def:{{{node lstm_275_2/lstm_cell_867/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_275_2/lstm_cell_867/bias/v, lstm_275_2/lstm_cell_867/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32278 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 16:58:22.787443: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:00:23.351836: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:00:45.201769: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.44802, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 63s 2ms/sample - loss: 1.4477 - val_loss: 1.4480\n",
      "Epoch 2/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4429\n",
      "Epoch 2: val_loss improved from 1.44802 to 1.44470, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 20s 620us/sample - loss: 1.4429 - val_loss: 1.4447\n",
      "Epoch 3/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4400\n",
      "Epoch 3: val_loss did not improve from 1.44470\n",
      "32278/32278 [==============================] - 22s 687us/sample - loss: 1.4400 - val_loss: 1.4515\n",
      "Epoch 4/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 4: val_loss did not improve from 1.44470\n",
      "32278/32278 [==============================] - 23s 719us/sample - loss: 1.4375 - val_loss: 1.4481\n",
      "Epoch 5/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4342\n",
      "Epoch 5: val_loss improved from 1.44470 to 1.44322, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 23s 708us/sample - loss: 1.4342 - val_loss: 1.4432\n",
      "Epoch 6/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4315\n",
      "Epoch 6: val_loss improved from 1.44322 to 1.44007, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 20s 629us/sample - loss: 1.4315 - val_loss: 1.4401\n",
      "Epoch 7/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4285\n",
      "Epoch 7: val_loss did not improve from 1.44007\n",
      "32278/32278 [==============================] - 21s 648us/sample - loss: 1.4285 - val_loss: 1.4467\n",
      "Epoch 8/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4268\n",
      "Epoch 8: val_loss did not improve from 1.44007\n",
      "32278/32278 [==============================] - 20s 628us/sample - loss: 1.4268 - val_loss: 1.4405\n",
      "Epoch 9/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 9: val_loss improved from 1.44007 to 1.43865, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 23s 724us/sample - loss: 1.4249 - val_loss: 1.4387\n",
      "Epoch 10/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 10: val_loss improved from 1.43865 to 1.43331, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 23s 718us/sample - loss: 1.4232 - val_loss: 1.4333\n",
      "Epoch 11/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4216\n",
      "Epoch 11: val_loss did not improve from 1.43331\n",
      "32278/32278 [==============================] - 21s 641us/sample - loss: 1.4216 - val_loss: 1.4485\n",
      "Epoch 12/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 12: val_loss did not improve from 1.43331\n",
      "32278/32278 [==============================] - 21s 636us/sample - loss: 1.4174 - val_loss: 1.4390\n",
      "Epoch 13/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4181\n",
      "Epoch 13: val_loss did not improve from 1.43331\n",
      "32278/32278 [==============================] - 20s 625us/sample - loss: 1.4181 - val_loss: 1.4411\n",
      "Epoch 14/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 14: val_loss improved from 1.43331 to 1.43053, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 21s 651us/sample - loss: 1.4163 - val_loss: 1.4305\n",
      "Epoch 15/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4153\n",
      "Epoch 15: val_loss improved from 1.43053 to 1.42959, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_37.h5\n",
      "32278/32278 [==============================] - 21s 641us/sample - loss: 1.4153 - val_loss: 1.4296\n",
      "Epoch 16/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 16: val_loss did not improve from 1.42959\n",
      "32278/32278 [==============================] - 21s 666us/sample - loss: 1.4100 - val_loss: 1.4439\n",
      "Epoch 17/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4161\n",
      "Epoch 17: val_loss did not improve from 1.42959\n",
      "32278/32278 [==============================] - 23s 713us/sample - loss: 1.4161 - val_loss: 1.4390\n",
      "Epoch 18/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4101\n",
      "Epoch 18: val_loss did not improve from 1.42959\n",
      "32278/32278 [==============================] - 21s 640us/sample - loss: 1.4101 - val_loss: 1.4317\n",
      "Epoch 19/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 19: val_loss did not improve from 1.42959\n",
      "32278/32278 [==============================] - 21s 648us/sample - loss: 1.4097 - val_loss: 1.4343\n",
      "Epoch 20/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4084\n",
      "Epoch 20: val_loss did not improve from 1.42959\n",
      "32278/32278 [==============================] - 23s 708us/sample - loss: 1.4084 - val_loss: 1.4313\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:08:23.617716: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_303/lstm_cell_895/bias/Assign' id:457538 op device:{requested: '', assigned: ''} def:{{{node lstm_303/lstm_cell_895/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_303/lstm_cell_895/bias, lstm_303/lstm_cell_895/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:08:36.990692: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_1' id:459972 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:08:47.755939: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_2' id:459973 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32278, 95)\n",
      "Train on 32278 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:09:13.633533: W tensorflow/c/c_api.cc:304] Operation '{name:'training_48/Adam/lstm_318/lstm_cell_910/kernel/m/Assign' id:473060 op device:{requested: '', assigned: ''} def:{{{node training_48/Adam/lstm_318/lstm_cell_910/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_48/Adam/lstm_318/lstm_cell_910/kernel/m, training_48/Adam/lstm_318/lstm_cell_910/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:11:20.355154: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 4.5545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:11:30.132672: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_49/mul' id:462813 op device:{requested: '', assigned: ''} def:{{{node loss_49/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_49/mul/x, loss_49/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.12342, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 123s 4ms/sample - loss: 4.5545 - val_loss: 4.1234\n",
      "Epoch 2/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 3.6721\n",
      "Epoch 2: val_loss improved from 4.12342 to 3.19661, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 3.6721 - val_loss: 3.1966\n",
      "Epoch 3/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 2.8247\n",
      "Epoch 3: val_loss improved from 3.19661 to 2.34083, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 2.8247 - val_loss: 2.3408\n",
      "Epoch 4/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 2.1539\n",
      "Epoch 4: val_loss improved from 2.34083 to 1.90364, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 2.1539 - val_loss: 1.9036\n",
      "Epoch 5/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.9650\n",
      "Epoch 5: val_loss improved from 1.90364 to 1.78197, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.9650 - val_loss: 1.7820\n",
      "Epoch 6/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.7675\n",
      "Epoch 6: val_loss improved from 1.78197 to 1.67792, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 213us/sample - loss: 1.7675 - val_loss: 1.6779\n",
      "Epoch 7/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6821\n",
      "Epoch 7: val_loss improved from 1.67792 to 1.58928, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.6821 - val_loss: 1.5893\n",
      "Epoch 8/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6370\n",
      "Epoch 8: val_loss improved from 1.58928 to 1.55918, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 209us/sample - loss: 1.6370 - val_loss: 1.5592\n",
      "Epoch 9/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5918\n",
      "Epoch 9: val_loss improved from 1.55918 to 1.53608, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5918 - val_loss: 1.5361\n",
      "Epoch 10/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6625\n",
      "Epoch 10: val_loss improved from 1.53608 to 1.52878, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 212us/sample - loss: 1.6625 - val_loss: 1.5288\n",
      "Epoch 11/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5909\n",
      "Epoch 11: val_loss improved from 1.52878 to 1.52526, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5909 - val_loss: 1.5253\n",
      "Epoch 12/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5810\n",
      "Epoch 12: val_loss improved from 1.52526 to 1.52214, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 218us/sample - loss: 1.5810 - val_loss: 1.5221\n",
      "Epoch 13/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6399\n",
      "Epoch 13: val_loss did not improve from 1.52214\n",
      "32278/32278 [==============================] - 7s 203us/sample - loss: 1.6399 - val_loss: 1.5504\n",
      "Epoch 14/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.8040\n",
      "Epoch 14: val_loss did not improve from 1.52214\n",
      "32278/32278 [==============================] - 7s 207us/sample - loss: 1.8040 - val_loss: 1.5547\n",
      "Epoch 15/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5887\n",
      "Epoch 15: val_loss did not improve from 1.52214\n",
      "32278/32278 [==============================] - 7s 226us/sample - loss: 1.5887 - val_loss: 1.5316\n",
      "Epoch 16/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6912\n",
      "Epoch 16: val_loss improved from 1.52214 to 1.51787, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 233us/sample - loss: 1.6912 - val_loss: 1.5179\n",
      "Epoch 17/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6354\n",
      "Epoch 17: val_loss did not improve from 1.51787\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.6354 - val_loss: 1.5812\n",
      "Epoch 18/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5608\n",
      "Epoch 18: val_loss improved from 1.51787 to 1.51502, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 232us/sample - loss: 1.5608 - val_loss: 1.5150\n",
      "Epoch 19/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.7062\n",
      "Epoch 19: val_loss improved from 1.51502 to 1.51500, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.7062 - val_loss: 1.5150\n",
      "Epoch 20/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.8696\n",
      "Epoch 20: val_loss did not improve from 1.51500\n",
      "32278/32278 [==============================] - 7s 226us/sample - loss: 1.8696 - val_loss: 1.6305\n",
      "Epoch 21/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6199\n",
      "Epoch 21: val_loss did not improve from 1.51500\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.6199 - val_loss: 1.5823\n",
      "Epoch 22/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.9004\n",
      "Epoch 22: val_loss did not improve from 1.51500\n",
      "32278/32278 [==============================] - 7s 225us/sample - loss: 1.9004 - val_loss: 1.5449\n",
      "Epoch 23/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.6534\n",
      "Epoch 23: val_loss did not improve from 1.51500\n",
      "32278/32278 [==============================] - 7s 215us/sample - loss: 1.6534 - val_loss: 1.6599\n",
      "Epoch 24/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5519\n",
      "Epoch 24: val_loss improved from 1.51500 to 1.51382, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5519 - val_loss: 1.5138\n",
      "Epoch 25/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5406\n",
      "Epoch 25: val_loss improved from 1.51382 to 1.50986, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 209us/sample - loss: 1.5406 - val_loss: 1.5099\n",
      "Epoch 26/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5346\n",
      "Epoch 26: val_loss improved from 1.50986 to 1.50982, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5346 - val_loss: 1.5098\n",
      "Epoch 27/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5275\n",
      "Epoch 27: val_loss improved from 1.50982 to 1.50455, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 210us/sample - loss: 1.5275 - val_loss: 1.5046\n",
      "Epoch 28/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5252\n",
      "Epoch 28: val_loss improved from 1.50455 to 1.50248, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 211us/sample - loss: 1.5252 - val_loss: 1.5025\n",
      "Epoch 29/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5202\n",
      "Epoch 29: val_loss improved from 1.50248 to 1.50073, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 230us/sample - loss: 1.5202 - val_loss: 1.5007\n",
      "Epoch 30/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5160\n",
      "Epoch 30: val_loss improved from 1.50073 to 1.49800, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 235us/sample - loss: 1.5160 - val_loss: 1.4980\n",
      "Epoch 31/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5160\n",
      "Epoch 31: val_loss improved from 1.49800 to 1.49645, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 233us/sample - loss: 1.5160 - val_loss: 1.4964\n",
      "Epoch 32/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5091\n",
      "Epoch 32: val_loss improved from 1.49645 to 1.49411, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.5091 - val_loss: 1.4941\n",
      "Epoch 33/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5068\n",
      "Epoch 33: val_loss improved from 1.49411 to 1.49097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.5068 - val_loss: 1.4910\n",
      "Epoch 34/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5066\n",
      "Epoch 34: val_loss improved from 1.49097 to 1.48800, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.5066 - val_loss: 1.4880\n",
      "Epoch 35/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5033\n",
      "Epoch 35: val_loss did not improve from 1.48800\n",
      "32278/32278 [==============================] - 7s 227us/sample - loss: 1.5033 - val_loss: 1.4886\n",
      "Epoch 36/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.5006\n",
      "Epoch 36: val_loss improved from 1.48800 to 1.48680, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.5006 - val_loss: 1.4868\n",
      "Epoch 37/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4969\n",
      "Epoch 37: val_loss improved from 1.48680 to 1.48409, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 232us/sample - loss: 1.4969 - val_loss: 1.4841\n",
      "Epoch 38/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4961\n",
      "Epoch 38: val_loss did not improve from 1.48409\n",
      "32278/32278 [==============================] - 7s 218us/sample - loss: 1.4961 - val_loss: 1.4849\n",
      "Epoch 39/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4930\n",
      "Epoch 39: val_loss improved from 1.48409 to 1.48181, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 212us/sample - loss: 1.4930 - val_loss: 1.4818\n",
      "Epoch 40/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4900\n",
      "Epoch 40: val_loss improved from 1.48181 to 1.47881, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 217us/sample - loss: 1.4900 - val_loss: 1.4788\n",
      "Epoch 41/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4891\n",
      "Epoch 41: val_loss improved from 1.47881 to 1.47800, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 232us/sample - loss: 1.4891 - val_loss: 1.4780\n",
      "Epoch 42/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4881\n",
      "Epoch 42: val_loss improved from 1.47800 to 1.47634, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.4881 - val_loss: 1.4763\n",
      "Epoch 43/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4849\n",
      "Epoch 43: val_loss did not improve from 1.47634\n",
      "32278/32278 [==============================] - 7s 227us/sample - loss: 1.4849 - val_loss: 1.4773\n",
      "Epoch 44/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4826\n",
      "Epoch 44: val_loss improved from 1.47634 to 1.47386, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 8s 234us/sample - loss: 1.4826 - val_loss: 1.4739\n",
      "Epoch 45/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4807\n",
      "Epoch 45: val_loss did not improve from 1.47386\n",
      "32278/32278 [==============================] - 7s 226us/sample - loss: 1.4807 - val_loss: 1.4740\n",
      "Epoch 46/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4797\n",
      "Epoch 46: val_loss did not improve from 1.47386\n",
      "32278/32278 [==============================] - 7s 228us/sample - loss: 1.4797 - val_loss: 1.4740\n",
      "Epoch 47/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4780\n",
      "Epoch 47: val_loss improved from 1.47386 to 1.47256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 224us/sample - loss: 1.4780 - val_loss: 1.4726\n",
      "Epoch 48/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4768\n",
      "Epoch 48: val_loss improved from 1.47256 to 1.47110, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 212us/sample - loss: 1.4768 - val_loss: 1.4711\n",
      "Epoch 49/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4767\n",
      "Epoch 49: val_loss improved from 1.47110 to 1.46946, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 221us/sample - loss: 1.4767 - val_loss: 1.4695\n",
      "Epoch 50/50\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 50: val_loss improved from 1.46946 to 1.46853, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_38.h5\n",
      "32278/32278 [==============================] - 7s 223us/sample - loss: 1.4751 - val_loss: 1.4685\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:19:23.249247: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_300_1/lstm_cell_929/kernel/Assign' id:475616 op device:{requested: '', assigned: ''} def:{{{node lstm_300_1/lstm_cell_929/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_300_1/lstm_cell_929/kernel, lstm_300_1/lstm_cell_929/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:19:48.721079: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_312_1/lstm_cell_941/bias/v/Assign' id:482481 op device:{requested: '', assigned: ''} def:{{{node lstm_312_1/lstm_cell_941/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_312_1/lstm_cell_941/bias/v, lstm_312_1/lstm_cell_941/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:20:14.427940: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_44_1/cond/Merge' id:480927 op device:{requested: '', assigned: ''} def:{{{node dropout_44_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_44_1/cond/Identity, dropout_44_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1562, 1125)\n",
      "(1644, 1125)\n",
      "(1716, 1125)\n",
      "(1848, 1125)\n",
      "(1711, 1125)\n",
      "(1393, 1125)\n",
      "(1791, 1125)\n",
      "(1606, 1125)\n",
      "(1728, 1125)\n",
      "(1538, 1125)\n",
      "(1908, 1125)\n",
      "(1715, 1125)\n",
      "(1752, 1125)\n",
      "(1884, 1125)\n",
      "(1728, 1125)\n",
      "(1800, 1125)\n",
      "(982, 1125)\n",
      "(1656, 1125)\n",
      "(1884, 1125)\n",
      "{2: 2.654281967778277, 4: 7.474586455056422, 5: 5.686517234373942, 6: 4.6813860142701476, 8: 8.78089597813306, 9: 4.204971158048966, 10: 8.00053066727408, 11: 6.2766789586116465, 12: 8.09059881677204, 13: 8.49322383447121, 17: 7.958868976895658, 19: 7.322241853764845, 21: 10.0, 22: 1.1075524664947025, 25: 6.755503980004556, 26: 6.106957158775402, 27: 4.646227152680732, 28: 6.9924924740053065, 29: 1.0}\n",
      "Train on 32278 samples, validate on 3598 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:26:00.694201: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 10.4925\n",
      "Epoch 1: val_loss improved from inf to 1.52542, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 68s 2ms/sample - loss: 10.4925 - val_loss: 1.5254\n",
      "Epoch 2/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.2461\n",
      "Epoch 2: val_loss improved from 1.52542 to 1.49184, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 628us/sample - loss: 10.2461 - val_loss: 1.4918\n",
      "Epoch 3/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.1795\n",
      "Epoch 3: val_loss did not improve from 1.49184\n",
      "32278/32278 [==============================] - 23s 704us/sample - loss: 10.1795 - val_loss: 1.5096\n",
      "Epoch 4/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.1127\n",
      "Epoch 4: val_loss improved from 1.49184 to 1.48903, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 24s 736us/sample - loss: 10.1127 - val_loss: 1.4890\n",
      "Epoch 5/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0686\n",
      "Epoch 5: val_loss did not improve from 1.48903\n",
      "32278/32278 [==============================] - 23s 717us/sample - loss: 10.0686 - val_loss: 1.4914\n",
      "Epoch 6/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0199\n",
      "Epoch 6: val_loss improved from 1.48903 to 1.48452, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 22s 684us/sample - loss: 10.0199 - val_loss: 1.4845\n",
      "Epoch 7/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 10.0079\n",
      "Epoch 7: val_loss did not improve from 1.48452\n",
      "32278/32278 [==============================] - 20s 625us/sample - loss: 10.0079 - val_loss: 1.4922\n",
      "Epoch 8/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9952 \n",
      "Epoch 8: val_loss did not improve from 1.48452\n",
      "32278/32278 [==============================] - 21s 666us/sample - loss: 9.9952 - val_loss: 1.4925\n",
      "Epoch 9/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9318\n",
      "Epoch 9: val_loss did not improve from 1.48452\n",
      "32278/32278 [==============================] - 20s 621us/sample - loss: 9.9318 - val_loss: 1.4963\n",
      "Epoch 10/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.9175\n",
      "Epoch 10: val_loss did not improve from 1.48452\n",
      "32278/32278 [==============================] - 22s 688us/sample - loss: 9.9175 - val_loss: 1.4949\n",
      "Epoch 11/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8930\n",
      "Epoch 11: val_loss improved from 1.48452 to 1.48316, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 24s 732us/sample - loss: 9.8930 - val_loss: 1.4832\n",
      "Epoch 12/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8843\n",
      "Epoch 12: val_loss did not improve from 1.48316\n",
      "32278/32278 [==============================] - 22s 692us/sample - loss: 9.8843 - val_loss: 1.4840\n",
      "Epoch 13/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8647\n",
      "Epoch 13: val_loss did not improve from 1.48316\n",
      "32278/32278 [==============================] - 23s 714us/sample - loss: 9.8647 - val_loss: 1.4885\n",
      "Epoch 14/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8386\n",
      "Epoch 14: val_loss did not improve from 1.48316\n",
      "32278/32278 [==============================] - 20s 631us/sample - loss: 9.8386 - val_loss: 1.4890\n",
      "Epoch 15/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8298\n",
      "Epoch 15: val_loss improved from 1.48316 to 1.47635, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 616us/sample - loss: 9.8298 - val_loss: 1.4764\n",
      "Epoch 16/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8034\n",
      "Epoch 16: val_loss improved from 1.47635 to 1.46961, saving model to ./checkpoints/unknown_person_few_shot_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 617us/sample - loss: 9.8034 - val_loss: 1.4696\n",
      "Epoch 17/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8118\n",
      "Epoch 17: val_loss did not improve from 1.46961\n",
      "32278/32278 [==============================] - 20s 619us/sample - loss: 9.8118 - val_loss: 1.4802\n",
      "Epoch 18/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.8186\n",
      "Epoch 18: val_loss did not improve from 1.46961\n",
      "32278/32278 [==============================] - 20s 622us/sample - loss: 9.8186 - val_loss: 1.4757\n",
      "Epoch 19/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.7654\n",
      "Epoch 19: val_loss did not improve from 1.46961\n",
      "32278/32278 [==============================] - 20s 621us/sample - loss: 9.7654 - val_loss: 1.4856\n",
      "Epoch 20/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 9.7303\n",
      "Epoch 20: val_loss did not improve from 1.46961\n",
      "32278/32278 [==============================] - 20s 619us/sample - loss: 9.7303 - val_loss: 1.4774\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:34:04.076174: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_331_2/lstm_cell_997/bias/Assign' id:500005 op device:{requested: '', assigned: ''} def:{{{node lstm_331_2/lstm_cell_997/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_331_2/lstm_cell_997/bias, lstm_331_2/lstm_cell_997/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:34:30.555502: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_321_2/lstm_cell_987/recurrent_kernel/v/Assign' id:502009 op device:{requested: '', assigned: ''} def:{{{node lstm_321_2/lstm_cell_987/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_321_2/lstm_cell_987/recurrent_kernel/v, lstm_321_2/lstm_cell_987/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32278 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:34:59.474457: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:37:14.185693: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:37:35.590028: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.46452, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 68s 2ms/sample - loss: 1.4742 - val_loss: 1.4645\n",
      "Epoch 2/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4627\n",
      "Epoch 2: val_loss improved from 1.46452 to 1.46267, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 607us/sample - loss: 1.4627 - val_loss: 1.4627\n",
      "Epoch 3/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4598\n",
      "Epoch 3: val_loss improved from 1.46267 to 1.45692, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 606us/sample - loss: 1.4598 - val_loss: 1.4569\n",
      "Epoch 4/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 4: val_loss improved from 1.45692 to 1.45329, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 605us/sample - loss: 1.4535 - val_loss: 1.4533\n",
      "Epoch 5/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4515\n",
      "Epoch 5: val_loss did not improve from 1.45329\n",
      "32278/32278 [==============================] - 19s 598us/sample - loss: 1.4515 - val_loss: 1.4537\n",
      "Epoch 6/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4460\n",
      "Epoch 6: val_loss did not improve from 1.45329\n",
      "32278/32278 [==============================] - 22s 697us/sample - loss: 1.4460 - val_loss: 1.4556\n",
      "Epoch 7/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4457\n",
      "Epoch 7: val_loss improved from 1.45329 to 1.44639, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 21s 636us/sample - loss: 1.4457 - val_loss: 1.4464\n",
      "Epoch 8/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4399\n",
      "Epoch 8: val_loss improved from 1.44639 to 1.44599, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 20s 618us/sample - loss: 1.4399 - val_loss: 1.4460\n",
      "Epoch 9/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4403\n",
      "Epoch 9: val_loss did not improve from 1.44599\n",
      "32278/32278 [==============================] - 21s 637us/sample - loss: 1.4403 - val_loss: 1.4491\n",
      "Epoch 10/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 10: val_loss did not improve from 1.44599\n",
      "32278/32278 [==============================] - 21s 646us/sample - loss: 1.4361 - val_loss: 1.4496\n",
      "Epoch 11/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4376\n",
      "Epoch 11: val_loss did not improve from 1.44599\n",
      "32278/32278 [==============================] - 23s 713us/sample - loss: 1.4376 - val_loss: 1.4514\n",
      "Epoch 12/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4329\n",
      "Epoch 12: val_loss improved from 1.44599 to 1.44229, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 23s 723us/sample - loss: 1.4329 - val_loss: 1.4423\n",
      "Epoch 13/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 13: val_loss did not improve from 1.44229\n",
      "32278/32278 [==============================] - 22s 671us/sample - loss: 1.4349 - val_loss: 1.4446\n",
      "Epoch 14/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4286\n",
      "Epoch 14: val_loss did not improve from 1.44229\n",
      "32278/32278 [==============================] - 21s 636us/sample - loss: 1.4286 - val_loss: 1.4515\n",
      "Epoch 15/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 15: val_loss improved from 1.44229 to 1.44197, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 22s 681us/sample - loss: 1.4280 - val_loss: 1.4420\n",
      "Epoch 16/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4282\n",
      "Epoch 16: val_loss did not improve from 1.44197\n",
      "32278/32278 [==============================] - 20s 635us/sample - loss: 1.4282 - val_loss: 1.4432\n",
      "Epoch 17/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4258\n",
      "Epoch 17: val_loss improved from 1.44197 to 1.44132, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 23s 722us/sample - loss: 1.4258 - val_loss: 1.4413\n",
      "Epoch 18/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4229\n",
      "Epoch 18: val_loss improved from 1.44132 to 1.43626, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_38.h5\n",
      "32278/32278 [==============================] - 23s 720us/sample - loss: 1.4229 - val_loss: 1.4363\n",
      "Epoch 19/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 19: val_loss did not improve from 1.43626\n",
      "32278/32278 [==============================] - 23s 714us/sample - loss: 1.4211 - val_loss: 1.4398\n",
      "Epoch 20/20\n",
      "32278/32278 [==============================] - ETA: 0s - loss: 1.4187\n",
      "Epoch 20: val_loss did not improve from 1.43626\n",
      "32278/32278 [==============================] - 21s 661us/sample - loss: 1.4187 - val_loss: 1.4446\n",
      "36041\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:45:27.444085: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_348/lstm_cell_1014/bias/Assign' id:515900 op device:{requested: '', assigned: ''} def:{{{node lstm_348/lstm_cell_1014/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_348/lstm_cell_1014/bias, lstm_348/lstm_cell_1014/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:45:42.061739: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_1' id:517014 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:45:53.912260: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_2' id:517015 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32446, 95)\n",
      "Train on 32446 samples, validate on 3595 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:46:23.399586: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_39/kernel/Assign' id:517210 op device:{requested: '', assigned: ''} def:{{{node conv2d_39/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_39/kernel, conv2d_39/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:48:45.390524: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 4.4233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-17 17:48:57.326586: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_55/mul' id:519855 op device:{requested: '', assigned: ''} def:{{{node loss_55/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_55/mul/x, loss_55/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.54226, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 139s 4ms/sample - loss: 4.4233 - val_loss: 3.5423\n",
      "Epoch 2/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 3.0957\n",
      "Epoch 2: val_loss improved from 3.54226 to 2.31031, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 207us/sample - loss: 3.0957 - val_loss: 2.3103\n",
      "Epoch 3/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.2777\n",
      "Epoch 3: val_loss improved from 2.31031 to 2.01067, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 204us/sample - loss: 2.2777 - val_loss: 2.0107\n",
      "Epoch 4/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.0667\n",
      "Epoch 4: val_loss improved from 2.01067 to 1.75576, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 204us/sample - loss: 2.0667 - val_loss: 1.7558\n",
      "Epoch 5/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.8318\n",
      "Epoch 5: val_loss improved from 1.75576 to 1.63591, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 228us/sample - loss: 1.8318 - val_loss: 1.6359\n",
      "Epoch 6/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7192\n",
      "Epoch 6: val_loss improved from 1.63591 to 1.55528, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 229us/sample - loss: 1.7192 - val_loss: 1.5553\n",
      "Epoch 7/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6604\n",
      "Epoch 7: val_loss improved from 1.55528 to 1.51681, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 224us/sample - loss: 1.6604 - val_loss: 1.5168\n",
      "Epoch 8/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6250\n",
      "Epoch 8: val_loss improved from 1.51681 to 1.48433, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 8s 231us/sample - loss: 1.6250 - val_loss: 1.4843\n",
      "Epoch 9/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5952\n",
      "Epoch 9: val_loss improved from 1.48433 to 1.46654, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5952 - val_loss: 1.4665\n",
      "Epoch 10/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5797\n",
      "Epoch 10: val_loss improved from 1.46654 to 1.45632, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 229us/sample - loss: 1.5797 - val_loss: 1.4563\n",
      "Epoch 11/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5649\n",
      "Epoch 11: val_loss improved from 1.45632 to 1.44230, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5649 - val_loss: 1.4423\n",
      "Epoch 12/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5513\n",
      "Epoch 12: val_loss improved from 1.44230 to 1.43195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 211us/sample - loss: 1.5513 - val_loss: 1.4319\n",
      "Epoch 13/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5519\n",
      "Epoch 13: val_loss improved from 1.43195 to 1.42653, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 209us/sample - loss: 1.5519 - val_loss: 1.4265\n",
      "Epoch 14/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5587\n",
      "Epoch 14: val_loss improved from 1.42653 to 1.42587, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 211us/sample - loss: 1.5587 - val_loss: 1.4259\n",
      "Epoch 15/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5442\n",
      "Epoch 15: val_loss did not improve from 1.42587\n",
      "32446/32446 [==============================] - 7s 203us/sample - loss: 1.5442 - val_loss: 1.4283\n",
      "Epoch 16/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5510\n",
      "Epoch 16: val_loss did not improve from 1.42587\n",
      "32446/32446 [==============================] - 7s 203us/sample - loss: 1.5510 - val_loss: 1.4418\n",
      "Epoch 17/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5295\n",
      "Epoch 17: val_loss improved from 1.42587 to 1.41506, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 210us/sample - loss: 1.5295 - val_loss: 1.4151\n",
      "Epoch 18/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5294\n",
      "Epoch 18: val_loss did not improve from 1.41506\n",
      "32446/32446 [==============================] - 7s 202us/sample - loss: 1.5294 - val_loss: 1.4172\n",
      "Epoch 19/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5278\n",
      "Epoch 19: val_loss did not improve from 1.41506\n",
      "32446/32446 [==============================] - 7s 219us/sample - loss: 1.5278 - val_loss: 1.4249\n",
      "Epoch 20/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5509\n",
      "Epoch 20: val_loss did not improve from 1.41506\n",
      "32446/32446 [==============================] - 7s 218us/sample - loss: 1.5509 - val_loss: 1.4383\n",
      "Epoch 21/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5389\n",
      "Epoch 21: val_loss did not improve from 1.41506\n",
      "32446/32446 [==============================] - 7s 204us/sample - loss: 1.5389 - val_loss: 1.4462\n",
      "Epoch 22/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5228\n",
      "Epoch 22: val_loss did not improve from 1.41506\n",
      "32446/32446 [==============================] - 7s 205us/sample - loss: 1.5228 - val_loss: 1.4216\n",
      "Epoch 23/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5145\n",
      "Epoch 23: val_loss improved from 1.41506 to 1.41344, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 214us/sample - loss: 1.5145 - val_loss: 1.4134\n",
      "Epoch 24/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5070\n",
      "Epoch 24: val_loss improved from 1.41344 to 1.40231, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 214us/sample - loss: 1.5070 - val_loss: 1.4023\n",
      "Epoch 25/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5057\n",
      "Epoch 25: val_loss did not improve from 1.40231\n",
      "32446/32446 [==============================] - 7s 205us/sample - loss: 1.5057 - val_loss: 1.4028\n",
      "Epoch 26/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5025\n",
      "Epoch 26: val_loss improved from 1.40231 to 1.39663, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 216us/sample - loss: 1.5025 - val_loss: 1.3966\n",
      "Epoch 27/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4991\n",
      "Epoch 27: val_loss improved from 1.39663 to 1.39476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.4991 - val_loss: 1.3948\n",
      "Epoch 28/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4964\n",
      "Epoch 28: val_loss improved from 1.39476 to 1.39217, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4964 - val_loss: 1.3922\n",
      "Epoch 29/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4924\n",
      "Epoch 29: val_loss improved from 1.39217 to 1.38928, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4924 - val_loss: 1.3893\n",
      "Epoch 30/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4877\n",
      "Epoch 30: val_loss improved from 1.38928 to 1.38632, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4877 - val_loss: 1.3863\n",
      "Epoch 31/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4860\n",
      "Epoch 31: val_loss improved from 1.38632 to 1.38589, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.4860 - val_loss: 1.3859\n",
      "Epoch 32/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4864\n",
      "Epoch 32: val_loss improved from 1.38589 to 1.38375, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4864 - val_loss: 1.3837\n",
      "Epoch 33/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4799\n",
      "Epoch 33: val_loss improved from 1.38375 to 1.38110, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 228us/sample - loss: 1.4799 - val_loss: 1.3811\n",
      "Epoch 34/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 34: val_loss improved from 1.38110 to 1.38029, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4794 - val_loss: 1.3803\n",
      "Epoch 35/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4755\n",
      "Epoch 35: val_loss improved from 1.38029 to 1.37680, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 228us/sample - loss: 1.4755 - val_loss: 1.3768\n",
      "Epoch 36/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 36: val_loss improved from 1.37680 to 1.37587, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 224us/sample - loss: 1.4752 - val_loss: 1.3759\n",
      "Epoch 37/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4730\n",
      "Epoch 37: val_loss did not improve from 1.37587\n",
      "32446/32446 [==============================] - 7s 223us/sample - loss: 1.4730 - val_loss: 1.3761\n",
      "Epoch 38/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4699\n",
      "Epoch 38: val_loss improved from 1.37587 to 1.37325, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 221us/sample - loss: 1.4699 - val_loss: 1.3733\n",
      "Epoch 39/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4674\n",
      "Epoch 39: val_loss improved from 1.37325 to 1.37255, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 212us/sample - loss: 1.4674 - val_loss: 1.3726\n",
      "Epoch 40/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4648\n",
      "Epoch 40: val_loss improved from 1.37255 to 1.36911, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 216us/sample - loss: 1.4648 - val_loss: 1.3691\n",
      "Epoch 41/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4626\n",
      "Epoch 41: val_loss improved from 1.36911 to 1.36810, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 213us/sample - loss: 1.4626 - val_loss: 1.3681\n",
      "Epoch 42/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4617\n",
      "Epoch 42: val_loss improved from 1.36810 to 1.36643, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 215us/sample - loss: 1.4617 - val_loss: 1.3664\n",
      "Epoch 43/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 43: val_loss improved from 1.36643 to 1.36600, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 213us/sample - loss: 1.4597 - val_loss: 1.3660\n",
      "Epoch 44/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4560\n",
      "Epoch 44: val_loss improved from 1.36600 to 1.36406, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 210us/sample - loss: 1.4560 - val_loss: 1.3641\n",
      "Epoch 45/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4540\n",
      "Epoch 45: val_loss improved from 1.36406 to 1.36175, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 216us/sample - loss: 1.4540 - val_loss: 1.3617\n",
      "Epoch 46/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4562\n",
      "Epoch 46: val_loss improved from 1.36175 to 1.36040, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 216us/sample - loss: 1.4562 - val_loss: 1.3604\n",
      "Epoch 47/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4537\n",
      "Epoch 47: val_loss did not improve from 1.36040\n",
      "32446/32446 [==============================] - 7s 212us/sample - loss: 1.4537 - val_loss: 1.3624\n",
      "Epoch 48/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4520\n",
      "Epoch 48: val_loss improved from 1.36040 to 1.35788, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 218us/sample - loss: 1.4520 - val_loss: 1.3579\n",
      "Epoch 49/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4513\n",
      "Epoch 49: val_loss improved from 1.35788 to 1.35760, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 215us/sample - loss: 1.4513 - val_loss: 1.3576\n",
      "Epoch 50/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4481\n",
      "Epoch 50: val_loss improved from 1.35760 to 1.35630, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_39.h5\n",
      "32446/32446 [==============================] - 7s 214us/sample - loss: 1.4481 - val_loss: 1.3563\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:57:02.901255: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_39_1/bias/Assign' id:538026 op device:{requested: '', assigned: ''} def:{{{node dense_39_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_39_1/bias, dense_39_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 17:57:33.293945: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_348_1/lstm_cell_1051/recurrent_kernel/v/Assign' id:539503 op device:{requested: '', assigned: ''} def:{{{node lstm_348_1/lstm_cell_1051/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_348_1/lstm_cell_1051/recurrent_kernel/v, lstm_348_1/lstm_cell_1051/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-17 17:58:03.625772: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_49_1/cond/Merge' id:537969 op device:{requested: '', assigned: ''} def:{{{node dropout_49_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_49_1/cond/Identity, dropout_49_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1541, 960)\n",
      "(1644, 960)\n",
      "(1716, 960)\n",
      "(1848, 960)\n",
      "(1736, 960)\n",
      "(1394, 960)\n",
      "(1790, 960)\n",
      "(1583, 960)\n",
      "(1752, 960)\n",
      "(1524, 960)\n",
      "(1896, 960)\n",
      "(1727, 960)\n",
      "(1776, 960)\n",
      "(1860, 960)\n",
      "(1752, 960)\n",
      "(1788, 960)\n",
      "(982, 960)\n",
      "(1656, 960)\n",
      "(1884, 960)\n",
      "{2: 5.224629358082426, 4: 8.050461523495905, 5: 5.321941641236638, 6: 5.624350318310701, 8: 9.18854279630637, 9: 5.885327263752932, 10: 7.8831749285737445, 11: 6.886707330693654, 12: 8.637855014609507, 13: 7.940603799552528, 17: 8.490526338544237, 19: 7.825780104410233, 21: 10.0, 22: 1.0, 25: 7.074642508439647, 26: 6.5364661207166765, 27: 5.741949639536099, 28: 6.227792829632619, 29: 1.0783854964169781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2905707/2131643591.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32446 samples, validate on 3595 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:04:32.278824: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 10.9526\n",
      "Epoch 1: val_loss improved from inf to 1.41902, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 74s 2ms/sample - loss: 10.9526 - val_loss: 1.4190\n",
      "Epoch 2/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.7633\n",
      "Epoch 2: val_loss improved from 1.41902 to 1.41552, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 20s 631us/sample - loss: 10.7633 - val_loss: 1.4155\n",
      "Epoch 3/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.6681\n",
      "Epoch 3: val_loss improved from 1.41552 to 1.37412, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 21s 641us/sample - loss: 10.6681 - val_loss: 1.3741\n",
      "Epoch 4/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.6137\n",
      "Epoch 4: val_loss did not improve from 1.37412\n",
      "32446/32446 [==============================] - 22s 681us/sample - loss: 10.6137 - val_loss: 1.4016\n",
      "Epoch 5/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5129\n",
      "Epoch 5: val_loss did not improve from 1.37412\n",
      "32446/32446 [==============================] - 22s 670us/sample - loss: 10.5129 - val_loss: 1.3887\n",
      "Epoch 6/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4828\n",
      "Epoch 6: val_loss did not improve from 1.37412\n",
      "32446/32446 [==============================] - 21s 662us/sample - loss: 10.4828 - val_loss: 1.3792\n",
      "Epoch 7/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4622\n",
      "Epoch 7: val_loss improved from 1.37412 to 1.37349, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 22s 682us/sample - loss: 10.4622 - val_loss: 1.3735\n",
      "Epoch 8/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4055\n",
      "Epoch 8: val_loss did not improve from 1.37349\n",
      "32446/32446 [==============================] - 21s 656us/sample - loss: 10.4055 - val_loss: 1.3740\n",
      "Epoch 9/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3757\n",
      "Epoch 9: val_loss improved from 1.37349 to 1.36725, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 21s 637us/sample - loss: 10.3757 - val_loss: 1.3672\n",
      "Epoch 10/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3959\n",
      "Epoch 10: val_loss did not improve from 1.36725\n",
      "32446/32446 [==============================] - 20s 626us/sample - loss: 10.3959 - val_loss: 1.3701\n",
      "Epoch 11/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3221\n",
      "Epoch 11: val_loss did not improve from 1.36725\n",
      "32446/32446 [==============================] - 20s 630us/sample - loss: 10.3221 - val_loss: 1.3741\n",
      "Epoch 12/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2931\n",
      "Epoch 12: val_loss did not improve from 1.36725\n",
      "32446/32446 [==============================] - 20s 629us/sample - loss: 10.2931 - val_loss: 1.3688\n",
      "Epoch 13/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2768\n",
      "Epoch 13: val_loss did not improve from 1.36725\n",
      "32446/32446 [==============================] - 21s 655us/sample - loss: 10.2768 - val_loss: 1.3833\n",
      "Epoch 14/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2759\n",
      "Epoch 14: val_loss did not improve from 1.36725\n",
      "32446/32446 [==============================] - 21s 641us/sample - loss: 10.2759 - val_loss: 1.3686\n",
      "Epoch 15/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2451\n",
      "Epoch 15: val_loss did not improve from 1.36725\n",
      "32446/32446 [==============================] - 20s 622us/sample - loss: 10.2451 - val_loss: 1.3728\n",
      "Epoch 16/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2294\n",
      "Epoch 16: val_loss improved from 1.36725 to 1.36104, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 21s 640us/sample - loss: 10.2294 - val_loss: 1.3610\n",
      "Epoch 17/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2274\n",
      "Epoch 17: val_loss did not improve from 1.36104\n",
      "32446/32446 [==============================] - 21s 646us/sample - loss: 10.2274 - val_loss: 1.3658\n",
      "Epoch 18/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.1667\n",
      "Epoch 18: val_loss did not improve from 1.36104\n",
      "32446/32446 [==============================] - 22s 685us/sample - loss: 10.1667 - val_loss: 1.3712\n",
      "Epoch 19/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.1885\n",
      "Epoch 19: val_loss did not improve from 1.36104\n",
      "32446/32446 [==============================] - 21s 655us/sample - loss: 10.1885 - val_loss: 1.3616\n",
      "Epoch 20/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.1530\n",
      "Epoch 20: val_loss improved from 1.36104 to 1.35956, saving model to ./checkpoints/unknown_person_few_shot_p1_39.h5\n",
      "32446/32446 [==============================] - 22s 669us/sample - loss: 10.1530 - val_loss: 1.3596\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:12:38.835880: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_353_2/lstm_cell_1093/recurrent_kernel/Assign' id:554636 op device:{requested: '', assigned: ''} def:{{{node lstm_353_2/lstm_cell_1093/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_353_2/lstm_cell_1093/recurrent_kernel, lstm_353_2/lstm_cell_1093/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 18:13:08.823195: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_368_2/lstm_cell_1108/bias/m/Assign' id:558563 op device:{requested: '', assigned: ''} def:{{{node lstm_368_2/lstm_cell_1108/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_368_2/lstm_cell_1108/bias/m, lstm_368_2/lstm_cell_1108/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32446 samples, validate on 3595 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:13:41.253234: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:16:13.972217: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:16:36.882221: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.35310, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 75s 2ms/sample - loss: 1.4488 - val_loss: 1.3531\n",
      "Epoch 2/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4448\n",
      "Epoch 2: val_loss did not improve from 1.35310\n",
      "32446/32446 [==============================] - 21s 634us/sample - loss: 1.4448 - val_loss: 1.3552\n",
      "Epoch 3/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4392\n",
      "Epoch 3: val_loss improved from 1.35310 to 1.34659, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 22s 672us/sample - loss: 1.4392 - val_loss: 1.3466\n",
      "Epoch 4/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4350\n",
      "Epoch 4: val_loss did not improve from 1.34659\n",
      "32446/32446 [==============================] - 22s 683us/sample - loss: 1.4350 - val_loss: 1.3471\n",
      "Epoch 5/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 5: val_loss did not improve from 1.34659\n",
      "32446/32446 [==============================] - 21s 640us/sample - loss: 1.4312 - val_loss: 1.3530\n",
      "Epoch 6/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4289\n",
      "Epoch 6: val_loss improved from 1.34659 to 1.34339, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 21s 640us/sample - loss: 1.4289 - val_loss: 1.3434\n",
      "Epoch 7/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4244\n",
      "Epoch 7: val_loss did not improve from 1.34339\n",
      "32446/32446 [==============================] - 20s 628us/sample - loss: 1.4244 - val_loss: 1.3496\n",
      "Epoch 8/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4219\n",
      "Epoch 8: val_loss improved from 1.34339 to 1.33950, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 23s 698us/sample - loss: 1.4219 - val_loss: 1.3395\n",
      "Epoch 9/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4197\n",
      "Epoch 9: val_loss improved from 1.33950 to 1.33549, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 24s 725us/sample - loss: 1.4197 - val_loss: 1.3355\n",
      "Epoch 10/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4195\n",
      "Epoch 10: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 23s 699us/sample - loss: 1.4195 - val_loss: 1.3414\n",
      "Epoch 11/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4162\n",
      "Epoch 11: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 20s 628us/sample - loss: 1.4162 - val_loss: 1.3359\n",
      "Epoch 12/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4153\n",
      "Epoch 12: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 21s 638us/sample - loss: 1.4153 - val_loss: 1.3364\n",
      "Epoch 13/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4144\n",
      "Epoch 13: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 21s 642us/sample - loss: 1.4144 - val_loss: 1.3393\n",
      "Epoch 14/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4111\n",
      "Epoch 14: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 23s 702us/sample - loss: 1.4111 - val_loss: 1.3433\n",
      "Epoch 15/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 15: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 23s 712us/sample - loss: 1.4053 - val_loss: 1.3357\n",
      "Epoch 16/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4095\n",
      "Epoch 16: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 24s 725us/sample - loss: 1.4095 - val_loss: 1.3359\n",
      "Epoch 17/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4052\n",
      "Epoch 17: val_loss did not improve from 1.33549\n",
      "32446/32446 [==============================] - 23s 720us/sample - loss: 1.4052 - val_loss: 1.3430\n",
      "Epoch 18/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 18: val_loss improved from 1.33549 to 1.33107, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 24s 728us/sample - loss: 1.4049 - val_loss: 1.3311\n",
      "Epoch 19/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4016\n",
      "Epoch 19: val_loss improved from 1.33107 to 1.32873, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_39.h5\n",
      "32446/32446 [==============================] - 24s 728us/sample - loss: 1.4016 - val_loss: 1.3287\n",
      "Epoch 20/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 20: val_loss did not improve from 1.32873\n",
      "32446/32446 [==============================] - 23s 718us/sample - loss: 1.4001 - val_loss: 1.3358\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:24:40.331252: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_370/lstm_cell_1110/kernel/Assign' id:570438 op device:{requested: '', assigned: ''} def:{{{node lstm_370/lstm_cell_1110/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_370/lstm_cell_1110/kernel, lstm_370/lstm_cell_1110/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 18:24:56.665184: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_1' id:574056 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 18:25:09.940136: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_2' id:574057 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32446, 95)\n",
      "Train on 32446 samples, validate on 3595 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:25:40.752568: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_396/lstm_cell_1136/bias/Assign' id:574986 op device:{requested: '', assigned: ''} def:{{{node lstm_396/lstm_cell_1136/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_396/lstm_cell_1136/bias, lstm_396/lstm_cell_1136/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:28:18.965874: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 4.1942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:28:28.985759: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_61/mul' id:576897 op device:{requested: '', assigned: ''} def:{{{node loss_61/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_61/mul/x, loss_61/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.46155, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 151s 5ms/sample - loss: 4.1942 - val_loss: 3.4616\n",
      "Epoch 2/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.9937\n",
      "Epoch 2: val_loss improved from 3.46155 to 2.24341, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 217us/sample - loss: 2.9937 - val_loss: 2.2434\n",
      "Epoch 3/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.2655\n",
      "Epoch 3: val_loss improved from 2.24341 to 1.95448, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 234us/sample - loss: 2.2655 - val_loss: 1.9545\n",
      "Epoch 4/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.0030\n",
      "Epoch 4: val_loss improved from 1.95448 to 1.75447, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 2.0030 - val_loss: 1.7545\n",
      "Epoch 5/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.8231\n",
      "Epoch 5: val_loss improved from 1.75447 to 1.63992, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 225us/sample - loss: 1.8231 - val_loss: 1.6399\n",
      "Epoch 6/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7099\n",
      "Epoch 6: val_loss improved from 1.63992 to 1.54915, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 209us/sample - loss: 1.7099 - val_loss: 1.5492\n",
      "Epoch 7/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6548\n",
      "Epoch 7: val_loss improved from 1.54915 to 1.51046, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 211us/sample - loss: 1.6548 - val_loss: 1.5105\n",
      "Epoch 8/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6329\n",
      "Epoch 8: val_loss improved from 1.51046 to 1.50155, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 224us/sample - loss: 1.6329 - val_loss: 1.5016\n",
      "Epoch 9/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5943\n",
      "Epoch 9: val_loss improved from 1.50155 to 1.47400, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.5943 - val_loss: 1.4740\n",
      "Epoch 10/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5886\n",
      "Epoch 10: val_loss improved from 1.47400 to 1.47130, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 234us/sample - loss: 1.5886 - val_loss: 1.4713\n",
      "Epoch 11/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5684\n",
      "Epoch 11: val_loss improved from 1.47130 to 1.45871, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 234us/sample - loss: 1.5684 - val_loss: 1.4587\n",
      "Epoch 12/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6292\n",
      "Epoch 12: val_loss did not improve from 1.45871\n",
      "32446/32446 [==============================] - 7s 227us/sample - loss: 1.6292 - val_loss: 1.4989\n",
      "Epoch 13/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5936\n",
      "Epoch 13: val_loss did not improve from 1.45871\n",
      "32446/32446 [==============================] - 7s 227us/sample - loss: 1.5936 - val_loss: 1.4938\n",
      "Epoch 14/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6627\n",
      "Epoch 14: val_loss did not improve from 1.45871\n",
      "32446/32446 [==============================] - 7s 211us/sample - loss: 1.6627 - val_loss: 1.5234\n",
      "Epoch 15/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5631\n",
      "Epoch 15: val_loss did not improve from 1.45871\n",
      "32446/32446 [==============================] - 7s 205us/sample - loss: 1.5631 - val_loss: 1.4647\n",
      "Epoch 16/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6415\n",
      "Epoch 16: val_loss did not improve from 1.45871\n",
      "32446/32446 [==============================] - 7s 205us/sample - loss: 1.6415 - val_loss: 1.4817\n",
      "Epoch 17/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5730\n",
      "Epoch 17: val_loss did not improve from 1.45871\n",
      "32446/32446 [==============================] - 7s 205us/sample - loss: 1.5730 - val_loss: 1.4970\n",
      "Epoch 18/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5401\n",
      "Epoch 18: val_loss improved from 1.45871 to 1.43463, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 225us/sample - loss: 1.5401 - val_loss: 1.4346\n",
      "Epoch 19/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5476\n",
      "Epoch 19: val_loss did not improve from 1.43463\n",
      "32446/32446 [==============================] - 7s 227us/sample - loss: 1.5476 - val_loss: 1.4646\n",
      "Epoch 20/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6459\n",
      "Epoch 20: val_loss did not improve from 1.43463\n",
      "32446/32446 [==============================] - 7s 212us/sample - loss: 1.6459 - val_loss: 1.5441\n",
      "Epoch 21/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.0669\n",
      "Epoch 21: val_loss did not improve from 1.43463\n",
      "32446/32446 [==============================] - 7s 213us/sample - loss: 2.0669 - val_loss: 1.5243\n",
      "Epoch 22/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7300\n",
      "Epoch 22: val_loss did not improve from 1.43463\n",
      "32446/32446 [==============================] - 7s 227us/sample - loss: 1.7300 - val_loss: 1.6231\n",
      "Epoch 23/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5750\n",
      "Epoch 23: val_loss did not improve from 1.43463\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5750 - val_loss: 1.5559\n",
      "Epoch 24/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5299\n",
      "Epoch 24: val_loss improved from 1.43463 to 1.42909, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 243us/sample - loss: 1.5299 - val_loss: 1.4291\n",
      "Epoch 25/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5222\n",
      "Epoch 25: val_loss improved from 1.42909 to 1.42223, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 238us/sample - loss: 1.5222 - val_loss: 1.4222\n",
      "Epoch 26/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5184\n",
      "Epoch 26: val_loss improved from 1.42223 to 1.41879, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 219us/sample - loss: 1.5184 - val_loss: 1.4188\n",
      "Epoch 27/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5150\n",
      "Epoch 27: val_loss improved from 1.41879 to 1.41449, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 228us/sample - loss: 1.5150 - val_loss: 1.4145\n",
      "Epoch 28/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5172\n",
      "Epoch 28: val_loss did not improve from 1.41449\n",
      "32446/32446 [==============================] - 7s 225us/sample - loss: 1.5172 - val_loss: 1.4200\n",
      "Epoch 29/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5101\n",
      "Epoch 29: val_loss improved from 1.41449 to 1.41334, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.5101 - val_loss: 1.4133\n",
      "Epoch 30/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5047\n",
      "Epoch 30: val_loss improved from 1.41334 to 1.40469, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.5047 - val_loss: 1.4047\n",
      "Epoch 31/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5046\n",
      "Epoch 31: val_loss improved from 1.40469 to 1.40235, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 233us/sample - loss: 1.5046 - val_loss: 1.4024\n",
      "Epoch 32/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5000\n",
      "Epoch 32: val_loss did not improve from 1.40235\n",
      "32446/32446 [==============================] - 7s 225us/sample - loss: 1.5000 - val_loss: 1.4025\n",
      "Epoch 33/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4976\n",
      "Epoch 33: val_loss improved from 1.40235 to 1.39898, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 231us/sample - loss: 1.4976 - val_loss: 1.3990\n",
      "Epoch 34/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4971\n",
      "Epoch 34: val_loss improved from 1.39898 to 1.39776, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4971 - val_loss: 1.3978\n",
      "Epoch 35/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4961\n",
      "Epoch 35: val_loss improved from 1.39776 to 1.39743, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 224us/sample - loss: 1.4961 - val_loss: 1.3974\n",
      "Epoch 36/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 36: val_loss did not improve from 1.39743\n",
      "32446/32446 [==============================] - 8s 246us/sample - loss: 1.5028 - val_loss: 1.4047\n",
      "Epoch 37/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4942\n",
      "Epoch 37: val_loss improved from 1.39743 to 1.39686, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 211us/sample - loss: 1.4942 - val_loss: 1.3969\n",
      "Epoch 38/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4913\n",
      "Epoch 38: val_loss improved from 1.39686 to 1.39371, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 207us/sample - loss: 1.4913 - val_loss: 1.3937\n",
      "Epoch 39/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4894\n",
      "Epoch 39: val_loss improved from 1.39371 to 1.39116, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 210us/sample - loss: 1.4894 - val_loss: 1.3912\n",
      "Epoch 40/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4868\n",
      "Epoch 40: val_loss did not improve from 1.39116\n",
      "32446/32446 [==============================] - 6s 200us/sample - loss: 1.4868 - val_loss: 1.3923\n",
      "Epoch 41/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 41: val_loss improved from 1.39116 to 1.38843, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 208us/sample - loss: 1.4865 - val_loss: 1.3884\n",
      "Epoch 42/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4850\n",
      "Epoch 42: val_loss did not improve from 1.38843\n",
      "32446/32446 [==============================] - 7s 201us/sample - loss: 1.4850 - val_loss: 1.3892\n",
      "Epoch 43/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4845\n",
      "Epoch 43: val_loss improved from 1.38843 to 1.38694, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 228us/sample - loss: 1.4845 - val_loss: 1.3869\n",
      "Epoch 44/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4833\n",
      "Epoch 44: val_loss improved from 1.38694 to 1.38535, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4833 - val_loss: 1.3854\n",
      "Epoch 45/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4818\n",
      "Epoch 45: val_loss improved from 1.38535 to 1.38432, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.4818 - val_loss: 1.3843\n",
      "Epoch 46/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4804\n",
      "Epoch 46: val_loss improved from 1.38432 to 1.38375, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 231us/sample - loss: 1.4804 - val_loss: 1.3837\n",
      "Epoch 47/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4797\n",
      "Epoch 47: val_loss improved from 1.38375 to 1.38229, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4797 - val_loss: 1.3823\n",
      "Epoch 48/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4780\n",
      "Epoch 48: val_loss improved from 1.38229 to 1.37908, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4780 - val_loss: 1.3791\n",
      "Epoch 49/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4769\n",
      "Epoch 49: val_loss did not improve from 1.37908\n",
      "32446/32446 [==============================] - 7s 225us/sample - loss: 1.4769 - val_loss: 1.3795\n",
      "Epoch 50/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 50: val_loss improved from 1.37908 to 1.37881, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_40.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.4781 - val_loss: 1.3788\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:36:58.032747: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_404_1/lstm_cell_1181/recurrent_kernel/Assign' id:594522 op device:{requested: '', assigned: ''} def:{{{node lstm_404_1/lstm_cell_1181/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_404_1/lstm_cell_1181/recurrent_kernel, lstm_404_1/lstm_cell_1181/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 18:37:30.233689: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_378_1/lstm_cell_1155/recurrent_kernel/m/Assign' id:595797 op device:{requested: '', assigned: ''} def:{{{node lstm_378_1/lstm_cell_1155/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_378_1/lstm_cell_1155/recurrent_kernel/m, lstm_378_1/lstm_cell_1155/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 18:38:02.495788: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_54_1/cond/Merge' id:595011 op device:{requested: '', assigned: ''} def:{{{node dropout_54_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_54_1/cond/Identity, dropout_54_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1541, 960)\n",
      "(1644, 960)\n",
      "(1716, 960)\n",
      "(1848, 960)\n",
      "(1736, 960)\n",
      "(1394, 960)\n",
      "(1790, 960)\n",
      "(1583, 960)\n",
      "(1752, 960)\n",
      "(1524, 960)\n",
      "(1896, 960)\n",
      "(1727, 960)\n",
      "(1776, 960)\n",
      "(1860, 960)\n",
      "(1752, 960)\n",
      "(1788, 960)\n",
      "(982, 960)\n",
      "(1656, 960)\n",
      "(1884, 960)\n",
      "{2: 4.515762300916046, 4: 8.19650041362174, 5: 5.592652789317922, 6: 4.906726930027115, 8: 9.130663138066998, 9: 6.257255095509849, 10: 7.815816457708165, 11: 7.097598927318668, 12: 8.390518488982952, 13: 8.319261279473967, 17: 8.567341326981206, 19: 7.750622256071061, 21: 10.0, 22: 1.0, 25: 7.112254083488986, 26: 6.0503123284806986, 27: 6.009776790137264, 28: 6.331519192231084, 29: 1.1685625596043818}\n",
      "Train on 32446 samples, validate on 3595 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:45:20.008534: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 11.1869\n",
      "Epoch 1: val_loss improved from inf to 1.42200, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 80s 2ms/sample - loss: 11.1869 - val_loss: 1.4220\n",
      "Epoch 2/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.9321\n",
      "Epoch 2: val_loss did not improve from 1.42200\n",
      "32446/32446 [==============================] - 23s 717us/sample - loss: 10.9321 - val_loss: 1.4297\n",
      "Epoch 3/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.8689\n",
      "Epoch 3: val_loss improved from 1.42200 to 1.41284, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 24s 729us/sample - loss: 10.8689 - val_loss: 1.4128\n",
      "Epoch 4/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.7910\n",
      "Epoch 4: val_loss improved from 1.41284 to 1.41190, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 24s 727us/sample - loss: 10.7910 - val_loss: 1.4119\n",
      "Epoch 5/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.7301\n",
      "Epoch 5: val_loss improved from 1.41190 to 1.39821, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 23s 706us/sample - loss: 10.7301 - val_loss: 1.3982\n",
      "Epoch 6/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.6898\n",
      "Epoch 6: val_loss improved from 1.39821 to 1.39274, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 24s 729us/sample - loss: 10.6898 - val_loss: 1.3927\n",
      "Epoch 7/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.6474\n",
      "Epoch 7: val_loss did not improve from 1.39274\n",
      "32446/32446 [==============================] - 23s 717us/sample - loss: 10.6474 - val_loss: 1.3969\n",
      "Epoch 8/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5935\n",
      "Epoch 8: val_loss did not improve from 1.39274\n",
      "32446/32446 [==============================] - 22s 673us/sample - loss: 10.5935 - val_loss: 1.4209\n",
      "Epoch 9/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5484\n",
      "Epoch 9: val_loss improved from 1.39274 to 1.37502, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 22s 684us/sample - loss: 10.5484 - val_loss: 1.3750\n",
      "Epoch 10/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5438\n",
      "Epoch 10: val_loss did not improve from 1.37502\n",
      "32446/32446 [==============================] - 21s 660us/sample - loss: 10.5438 - val_loss: 1.3912\n",
      "Epoch 11/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5298\n",
      "Epoch 11: val_loss did not improve from 1.37502\n",
      "32446/32446 [==============================] - 21s 662us/sample - loss: 10.5298 - val_loss: 1.3772\n",
      "Epoch 12/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4810\n",
      "Epoch 12: val_loss did not improve from 1.37502\n",
      "32446/32446 [==============================] - 23s 694us/sample - loss: 10.4810 - val_loss: 1.3838\n",
      "Epoch 13/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4579\n",
      "Epoch 13: val_loss did not improve from 1.37502\n",
      "32446/32446 [==============================] - 23s 713us/sample - loss: 10.4579 - val_loss: 1.3898\n",
      "Epoch 14/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4035\n",
      "Epoch 14: val_loss did not improve from 1.37502\n",
      "32446/32446 [==============================] - 23s 720us/sample - loss: 10.4035 - val_loss: 1.3874\n",
      "Epoch 15/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4316\n",
      "Epoch 15: val_loss improved from 1.37502 to 1.37371, saving model to ./checkpoints/unknown_person_few_shot_p1_40.h5\n",
      "32446/32446 [==============================] - 24s 732us/sample - loss: 10.4316 - val_loss: 1.3737\n",
      "Epoch 16/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3947\n",
      "Epoch 16: val_loss did not improve from 1.37371\n",
      "32446/32446 [==============================] - 24s 729us/sample - loss: 10.3947 - val_loss: 1.3984\n",
      "Epoch 17/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4000\n",
      "Epoch 17: val_loss did not improve from 1.37371\n",
      "32446/32446 [==============================] - 24s 725us/sample - loss: 10.4000 - val_loss: 1.3978\n",
      "Epoch 18/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3609\n",
      "Epoch 18: val_loss did not improve from 1.37371\n",
      "32446/32446 [==============================] - 23s 723us/sample - loss: 10.3609 - val_loss: 1.3811\n",
      "Epoch 19/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3482\n",
      "Epoch 19: val_loss did not improve from 1.37371\n",
      "32446/32446 [==============================] - 23s 722us/sample - loss: 10.3482 - val_loss: 1.3760\n",
      "Epoch 20/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3199\n",
      "Epoch 20: val_loss did not improve from 1.37371\n",
      "32446/32446 [==============================] - 22s 669us/sample - loss: 10.3199 - val_loss: 1.3891\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:54:08.813770: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_377_2/lstm_cell_1191/kernel/Assign' id:609578 op device:{requested: '', assigned: ''} def:{{{node lstm_377_2/lstm_cell_1191/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_377_2/lstm_cell_1191/kernel, lstm_377_2/lstm_cell_1191/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 18:54:41.972956: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_378_2/lstm_cell_1192/bias/m/Assign' id:615200 op device:{requested: '', assigned: ''} def:{{{node lstm_378_2/lstm_cell_1192/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_378_2/lstm_cell_1192/bias/m, lstm_378_2/lstm_cell_1192/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32446 samples, validate on 3595 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:55:19.392850: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:58:07.719467: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:58:30.463155: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37151, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 81s 2ms/sample - loss: 1.4743 - val_loss: 1.3715\n",
      "Epoch 2/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4684\n",
      "Epoch 2: val_loss did not improve from 1.37151\n",
      "32446/32446 [==============================] - 21s 655us/sample - loss: 1.4684 - val_loss: 1.3747\n",
      "Epoch 3/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4640\n",
      "Epoch 3: val_loss did not improve from 1.37151\n",
      "32446/32446 [==============================] - 20s 622us/sample - loss: 1.4640 - val_loss: 1.3732\n",
      "Epoch 4/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4609\n",
      "Epoch 4: val_loss improved from 1.37151 to 1.36228, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 20s 622us/sample - loss: 1.4609 - val_loss: 1.3623\n",
      "Epoch 5/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4562\n",
      "Epoch 5: val_loss improved from 1.36228 to 1.35942, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 20s 615us/sample - loss: 1.4562 - val_loss: 1.3594\n",
      "Epoch 6/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4556\n",
      "Epoch 6: val_loss did not improve from 1.35942\n",
      "32446/32446 [==============================] - 20s 607us/sample - loss: 1.4556 - val_loss: 1.3597\n",
      "Epoch 7/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4495\n",
      "Epoch 7: val_loss improved from 1.35942 to 1.35479, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 20s 618us/sample - loss: 1.4495 - val_loss: 1.3548\n",
      "Epoch 8/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4511\n",
      "Epoch 8: val_loss did not improve from 1.35479\n",
      "32446/32446 [==============================] - 21s 659us/sample - loss: 1.4511 - val_loss: 1.3613\n",
      "Epoch 9/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4476\n",
      "Epoch 9: val_loss did not improve from 1.35479\n",
      "32446/32446 [==============================] - 23s 703us/sample - loss: 1.4476 - val_loss: 1.3598\n",
      "Epoch 10/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4437\n",
      "Epoch 10: val_loss improved from 1.35479 to 1.34908, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 22s 670us/sample - loss: 1.4437 - val_loss: 1.3491\n",
      "Epoch 11/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4409\n",
      "Epoch 11: val_loss did not improve from 1.34908\n",
      "32446/32446 [==============================] - 20s 612us/sample - loss: 1.4409 - val_loss: 1.3520\n",
      "Epoch 12/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 12: val_loss improved from 1.34908 to 1.34488, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 23s 709us/sample - loss: 1.4361 - val_loss: 1.3449\n",
      "Epoch 13/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4335\n",
      "Epoch 13: val_loss did not improve from 1.34488\n",
      "32446/32446 [==============================] - 22s 665us/sample - loss: 1.4335 - val_loss: 1.3476\n",
      "Epoch 14/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4356\n",
      "Epoch 14: val_loss did not improve from 1.34488\n",
      "32446/32446 [==============================] - 22s 687us/sample - loss: 1.4356 - val_loss: 1.3459\n",
      "Epoch 15/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4320\n",
      "Epoch 15: val_loss did not improve from 1.34488\n",
      "32446/32446 [==============================] - 21s 661us/sample - loss: 1.4320 - val_loss: 1.3508\n",
      "Epoch 16/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 16: val_loss did not improve from 1.34488\n",
      "32446/32446 [==============================] - 23s 715us/sample - loss: 1.4321 - val_loss: 1.3454\n",
      "Epoch 17/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4279\n",
      "Epoch 17: val_loss did not improve from 1.34488\n",
      "32446/32446 [==============================] - 21s 662us/sample - loss: 1.4279 - val_loss: 1.3476\n",
      "Epoch 18/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 18: val_loss improved from 1.34488 to 1.34140, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 21s 633us/sample - loss: 1.4246 - val_loss: 1.3414\n",
      "Epoch 19/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4256\n",
      "Epoch 19: val_loss improved from 1.34140 to 1.33614, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_40.h5\n",
      "32446/32446 [==============================] - 20s 627us/sample - loss: 1.4256 - val_loss: 1.3361\n",
      "Epoch 20/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4256\n",
      "Epoch 20: val_loss did not improve from 1.33614\n",
      "32446/32446 [==============================] - 20s 619us/sample - loss: 1.4256 - val_loss: 1.3374\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:06:22.678825: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_420/lstm_cell_1234/recurrent_kernel/Assign' id:629645 op device:{requested: '', assigned: ''} def:{{{node lstm_420/lstm_cell_1234/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_420/lstm_cell_1234/recurrent_kernel, lstm_420/lstm_cell_1234/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:06:41.118597: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_1' id:631098 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:06:55.979553: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_2' id:631099 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32446, 95)\n",
      "Train on 32446 samples, validate on 3595 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:07:30.041087: W tensorflow/c/c_api.cc:304] Operation '{name:'training_66/Adam/lstm_436/lstm_cell_1250/bias/m/Assign' id:644301 op device:{requested: '', assigned: ''} def:{{{node training_66/Adam/lstm_436/lstm_cell_1250/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_66/Adam/lstm_436/lstm_cell_1250/bias/m, training_66/Adam/lstm_436/lstm_cell_1250/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:10:26.587440: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 4.6477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:10:36.611060: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_67/mul' id:633939 op device:{requested: '', assigned: ''} def:{{{node loss_67/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_67/mul/x, loss_67/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.90592, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 168s 5ms/sample - loss: 4.6477 - val_loss: 3.9059\n",
      "Epoch 2/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 3.5627\n",
      "Epoch 2: val_loss improved from 3.90592 to 2.78395, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 262us/sample - loss: 3.5627 - val_loss: 2.7840\n",
      "Epoch 3/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.5643\n",
      "Epoch 3: val_loss improved from 2.78395 to 2.05677, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 239us/sample - loss: 2.5643 - val_loss: 2.0568\n",
      "Epoch 4/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 2.0724\n",
      "Epoch 4: val_loss improved from 2.05677 to 1.74684, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 239us/sample - loss: 2.0724 - val_loss: 1.7468\n",
      "Epoch 5/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.8501\n",
      "Epoch 5: val_loss improved from 1.74684 to 1.68892, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 229us/sample - loss: 1.8501 - val_loss: 1.6889\n",
      "Epoch 6/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7438\n",
      "Epoch 6: val_loss improved from 1.68892 to 1.56496, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 228us/sample - loss: 1.7438 - val_loss: 1.5650\n",
      "Epoch 7/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6736\n",
      "Epoch 7: val_loss improved from 1.56496 to 1.52361, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 233us/sample - loss: 1.6736 - val_loss: 1.5236\n",
      "Epoch 8/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6561\n",
      "Epoch 8: val_loss improved from 1.52361 to 1.50215, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.6561 - val_loss: 1.5021\n",
      "Epoch 9/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7331\n",
      "Epoch 9: val_loss did not improve from 1.50215\n",
      "32446/32446 [==============================] - 7s 223us/sample - loss: 1.7331 - val_loss: 1.5345\n",
      "Epoch 10/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6066\n",
      "Epoch 10: val_loss improved from 1.50215 to 1.49760, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.6066 - val_loss: 1.4976\n",
      "Epoch 11/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6019\n",
      "Epoch 11: val_loss improved from 1.49760 to 1.48015, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 229us/sample - loss: 1.6019 - val_loss: 1.4801\n",
      "Epoch 12/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5888\n",
      "Epoch 12: val_loss did not improve from 1.48015\n",
      "32446/32446 [==============================] - 6s 199us/sample - loss: 1.5888 - val_loss: 1.4989\n",
      "Epoch 13/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5661\n",
      "Epoch 13: val_loss improved from 1.48015 to 1.45517, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 207us/sample - loss: 1.5661 - val_loss: 1.4552\n",
      "Epoch 14/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6460\n",
      "Epoch 14: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 6s 200us/sample - loss: 1.6460 - val_loss: 1.4884\n",
      "Epoch 15/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5617\n",
      "Epoch 15: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 6s 198us/sample - loss: 1.5617 - val_loss: 1.4590\n",
      "Epoch 16/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5581\n",
      "Epoch 16: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 6s 199us/sample - loss: 1.5581 - val_loss: 1.4596\n",
      "Epoch 17/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5803\n",
      "Epoch 17: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 6s 199us/sample - loss: 1.5803 - val_loss: 1.5001\n",
      "Epoch 18/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5673\n",
      "Epoch 18: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 7s 217us/sample - loss: 1.5673 - val_loss: 1.4923\n",
      "Epoch 19/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5686\n",
      "Epoch 19: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 7s 223us/sample - loss: 1.5686 - val_loss: 1.4915\n",
      "Epoch 20/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7378\n",
      "Epoch 20: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 7s 222us/sample - loss: 1.7378 - val_loss: 1.5387\n",
      "Epoch 21/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7176\n",
      "Epoch 21: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 7s 223us/sample - loss: 1.7176 - val_loss: 1.6880\n",
      "Epoch 22/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.7904\n",
      "Epoch 22: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 7s 224us/sample - loss: 1.7904 - val_loss: 1.5444\n",
      "Epoch 23/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.6383\n",
      "Epoch 23: val_loss did not improve from 1.45517\n",
      "32446/32446 [==============================] - 7s 223us/sample - loss: 1.6383 - val_loss: 1.6306\n",
      "Epoch 24/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5437\n",
      "Epoch 24: val_loss improved from 1.45517 to 1.44815, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 233us/sample - loss: 1.5437 - val_loss: 1.4481\n",
      "Epoch 25/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5351\n",
      "Epoch 25: val_loss improved from 1.44815 to 1.43709, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5351 - val_loss: 1.4371\n",
      "Epoch 26/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5290\n",
      "Epoch 26: val_loss improved from 1.43709 to 1.42443, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 210us/sample - loss: 1.5290 - val_loss: 1.4244\n",
      "Epoch 27/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5258\n",
      "Epoch 27: val_loss improved from 1.42443 to 1.42134, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 210us/sample - loss: 1.5258 - val_loss: 1.4213\n",
      "Epoch 28/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5228\n",
      "Epoch 28: val_loss did not improve from 1.42134\n",
      "32446/32446 [==============================] - 6s 200us/sample - loss: 1.5228 - val_loss: 1.4217\n",
      "Epoch 29/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5190\n",
      "Epoch 29: val_loss improved from 1.42134 to 1.41420, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 210us/sample - loss: 1.5190 - val_loss: 1.4142\n",
      "Epoch 30/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5224\n",
      "Epoch 30: val_loss did not improve from 1.41420\n",
      "32446/32446 [==============================] - 7s 200us/sample - loss: 1.5224 - val_loss: 1.4235\n",
      "Epoch 31/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5135\n",
      "Epoch 31: val_loss improved from 1.41420 to 1.40762, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 208us/sample - loss: 1.5135 - val_loss: 1.4076\n",
      "Epoch 32/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5132\n",
      "Epoch 32: val_loss improved from 1.40762 to 1.40651, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5132 - val_loss: 1.4065\n",
      "Epoch 33/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5119\n",
      "Epoch 33: val_loss improved from 1.40651 to 1.40559, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 236us/sample - loss: 1.5119 - val_loss: 1.4056\n",
      "Epoch 34/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5074\n",
      "Epoch 34: val_loss improved from 1.40559 to 1.40201, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.5074 - val_loss: 1.4020\n",
      "Epoch 35/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5069\n",
      "Epoch 35: val_loss improved from 1.40201 to 1.39957, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5069 - val_loss: 1.3996\n",
      "Epoch 36/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5033\n",
      "Epoch 36: val_loss improved from 1.39957 to 1.39864, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 222us/sample - loss: 1.5033 - val_loss: 1.3986\n",
      "Epoch 37/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 37: val_loss improved from 1.39864 to 1.39738, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.5028 - val_loss: 1.3974\n",
      "Epoch 38/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.5002\n",
      "Epoch 38: val_loss improved from 1.39738 to 1.39442, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.5002 - val_loss: 1.3944\n",
      "Epoch 39/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4992\n",
      "Epoch 39: val_loss improved from 1.39442 to 1.39173, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.4992 - val_loss: 1.3917\n",
      "Epoch 40/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4954\n",
      "Epoch 40: val_loss improved from 1.39173 to 1.39012, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4954 - val_loss: 1.3901\n",
      "Epoch 41/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4951\n",
      "Epoch 41: val_loss improved from 1.39012 to 1.38998, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4951 - val_loss: 1.3900\n",
      "Epoch 42/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4964\n",
      "Epoch 42: val_loss improved from 1.38998 to 1.38743, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 231us/sample - loss: 1.4964 - val_loss: 1.3874\n",
      "Epoch 43/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4906\n",
      "Epoch 43: val_loss did not improve from 1.38743\n",
      "32446/32446 [==============================] - 7s 221us/sample - loss: 1.4906 - val_loss: 1.3875\n",
      "Epoch 44/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4905\n",
      "Epoch 44: val_loss improved from 1.38743 to 1.38412, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 229us/sample - loss: 1.4905 - val_loss: 1.3841\n",
      "Epoch 45/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4908\n",
      "Epoch 45: val_loss did not improve from 1.38412\n",
      "32446/32446 [==============================] - 7s 222us/sample - loss: 1.4908 - val_loss: 1.3845\n",
      "Epoch 46/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4862\n",
      "Epoch 46: val_loss improved from 1.38412 to 1.38271, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 7s 230us/sample - loss: 1.4862 - val_loss: 1.3827\n",
      "Epoch 47/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4852\n",
      "Epoch 47: val_loss improved from 1.38271 to 1.37888, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 231us/sample - loss: 1.4852 - val_loss: 1.3789\n",
      "Epoch 48/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4823\n",
      "Epoch 48: val_loss did not improve from 1.37888\n",
      "32446/32446 [==============================] - 7s 222us/sample - loss: 1.4823 - val_loss: 1.3813\n",
      "Epoch 49/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4822\n",
      "Epoch 49: val_loss improved from 1.37888 to 1.37775, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4822 - val_loss: 1.3777\n",
      "Epoch 50/50\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4806\n",
      "Epoch 50: val_loss improved from 1.37775 to 1.37555, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_41.h5\n",
      "32446/32446 [==============================] - 8s 232us/sample - loss: 1.4806 - val_loss: 1.3756\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:19:23.360405: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_418_1/lstm_cell_1269/kernel/Assign' id:647862 op device:{requested: '', assigned: ''} def:{{{node lstm_418_1/lstm_cell_1269/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_418_1/lstm_cell_1269/kernel, lstm_418_1/lstm_cell_1269/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:19:58.845408: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_411_1/lstm_cell_1262/kernel/m/Assign' id:652774 op device:{requested: '', assigned: ''} def:{{{node lstm_411_1/lstm_cell_1262/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_411_1/lstm_cell_1262/kernel/m, lstm_411_1/lstm_cell_1262/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:20:33.821941: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_59_1/cond/Merge' id:652053 op device:{requested: '', assigned: ''} def:{{{node dropout_59_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_59_1/cond/Identity, dropout_59_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1541, 960)\n",
      "(1644, 960)\n",
      "(1716, 960)\n",
      "(1848, 960)\n",
      "(1736, 960)\n",
      "(1394, 960)\n",
      "(1790, 960)\n",
      "(1583, 960)\n",
      "(1752, 960)\n",
      "(1524, 960)\n",
      "(1896, 960)\n",
      "(1727, 960)\n",
      "(1776, 960)\n",
      "(1860, 960)\n",
      "(1752, 960)\n",
      "(1788, 960)\n",
      "(982, 960)\n",
      "(1656, 960)\n",
      "(1884, 960)\n",
      "{2: 4.168571018843835, 4: 7.786446756394807, 5: 5.770608058879177, 6: 4.1954455143254314, 8: 9.07492546427258, 9: 5.66705833100108, 10: 7.991297997192044, 11: 6.630888553764025, 12: 8.598232768889517, 13: 8.297560039135593, 17: 8.54744149899501, 19: 7.170718619244442, 21: 10.0, 22: 1.0, 25: 6.926627700691349, 26: 6.51534140716977, 27: 5.50129758085594, 28: 6.529677247000645, 29: 1.1341452272848178}\n",
      "Train on 32446 samples, validate on 3595 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:27:42.221198: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 11.0411\n",
      "Epoch 1: val_loss improved from inf to 1.40815, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 85s 3ms/sample - loss: 11.0411 - val_loss: 1.4081\n",
      "Epoch 2/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.7513\n",
      "Epoch 2: val_loss improved from 1.40815 to 1.40701, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 647us/sample - loss: 10.7513 - val_loss: 1.4070\n",
      "Epoch 3/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.6756\n",
      "Epoch 3: val_loss improved from 1.40701 to 1.38194, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 644us/sample - loss: 10.6756 - val_loss: 1.3819\n",
      "Epoch 4/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5811\n",
      "Epoch 4: val_loss did not improve from 1.38194\n",
      "32446/32446 [==============================] - 21s 636us/sample - loss: 10.5811 - val_loss: 1.3914\n",
      "Epoch 5/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.5336\n",
      "Epoch 5: val_loss did not improve from 1.38194\n",
      "32446/32446 [==============================] - 21s 644us/sample - loss: 10.5336 - val_loss: 1.4019\n",
      "Epoch 6/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4872\n",
      "Epoch 6: val_loss did not improve from 1.38194\n",
      "32446/32446 [==============================] - 21s 660us/sample - loss: 10.4872 - val_loss: 1.3977\n",
      "Epoch 7/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4809\n",
      "Epoch 7: val_loss did not improve from 1.38194\n",
      "32446/32446 [==============================] - 22s 679us/sample - loss: 10.4809 - val_loss: 1.3827\n",
      "Epoch 8/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.4167\n",
      "Epoch 8: val_loss improved from 1.38194 to 1.37802, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 24s 725us/sample - loss: 10.4167 - val_loss: 1.3780\n",
      "Epoch 9/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3615\n",
      "Epoch 9: val_loss did not improve from 1.37802\n",
      "32446/32446 [==============================] - 24s 730us/sample - loss: 10.3615 - val_loss: 1.3850\n",
      "Epoch 10/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3218\n",
      "Epoch 10: val_loss did not improve from 1.37802\n",
      "32446/32446 [==============================] - 22s 684us/sample - loss: 10.3218 - val_loss: 1.3866\n",
      "Epoch 11/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.3251\n",
      "Epoch 11: val_loss did not improve from 1.37802\n",
      "32446/32446 [==============================] - 20s 628us/sample - loss: 10.3251 - val_loss: 1.3799\n",
      "Epoch 12/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2927\n",
      "Epoch 12: val_loss improved from 1.37802 to 1.36721, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 639us/sample - loss: 10.2927 - val_loss: 1.3672\n",
      "Epoch 13/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2885\n",
      "Epoch 13: val_loss improved from 1.36721 to 1.36426, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 638us/sample - loss: 10.2885 - val_loss: 1.3643\n",
      "Epoch 14/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2551\n",
      "Epoch 14: val_loss improved from 1.36426 to 1.36160, saving model to ./checkpoints/unknown_person_few_shot_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 638us/sample - loss: 10.2551 - val_loss: 1.3616\n",
      "Epoch 15/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2464\n",
      "Epoch 15: val_loss did not improve from 1.36160\n",
      "32446/32446 [==============================] - 20s 631us/sample - loss: 10.2464 - val_loss: 1.3658\n",
      "Epoch 16/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2361\n",
      "Epoch 16: val_loss did not improve from 1.36160\n",
      "32446/32446 [==============================] - 20s 629us/sample - loss: 10.2361 - val_loss: 1.3651\n",
      "Epoch 17/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.2103\n",
      "Epoch 17: val_loss did not improve from 1.36160\n",
      "32446/32446 [==============================] - 20s 627us/sample - loss: 10.2103 - val_loss: 1.3617\n",
      "Epoch 18/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.1890\n",
      "Epoch 18: val_loss did not improve from 1.36160\n",
      "32446/32446 [==============================] - 20s 628us/sample - loss: 10.1890 - val_loss: 1.3695\n",
      "Epoch 19/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.1725\n",
      "Epoch 19: val_loss did not improve from 1.36160\n",
      "32446/32446 [==============================] - 21s 634us/sample - loss: 10.1725 - val_loss: 1.3652\n",
      "Epoch 20/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 10.1676\n",
      "Epoch 20: val_loss did not improve from 1.36160\n",
      "32446/32446 [==============================] - 21s 643us/sample - loss: 10.1676 - val_loss: 1.3725\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:36:03.715917: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_443_2/lstm_cell_1331/bias/Assign' id:671291 op device:{requested: '', assigned: ''} def:{{{node lstm_443_2/lstm_cell_1331/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_443_2/lstm_cell_1331/bias, lstm_443_2/lstm_cell_1331/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:36:41.351896: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_440_2/lstm_cell_1328/kernel/v/Assign' id:673250 op device:{requested: '', assigned: ''} def:{{{node lstm_440_2/lstm_cell_1328/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_440_2/lstm_cell_1328/kernel/v, lstm_440_2/lstm_cell_1328/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32446 samples, validate on 3595 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:37:21.628664: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:40:29.024543: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:40:52.515063: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37544, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 88s 3ms/sample - loss: 1.4774 - val_loss: 1.3754\n",
      "Epoch 2/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4693\n",
      "Epoch 2: val_loss improved from 1.37544 to 1.35791, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 646us/sample - loss: 1.4693 - val_loss: 1.3579\n",
      "Epoch 3/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4611\n",
      "Epoch 3: val_loss did not improve from 1.35791\n",
      "32446/32446 [==============================] - 23s 697us/sample - loss: 1.4611 - val_loss: 1.3601\n",
      "Epoch 4/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4586\n",
      "Epoch 4: val_loss improved from 1.35791 to 1.35129, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 22s 674us/sample - loss: 1.4586 - val_loss: 1.3513\n",
      "Epoch 5/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4562\n",
      "Epoch 5: val_loss improved from 1.35129 to 1.35087, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 23s 701us/sample - loss: 1.4562 - val_loss: 1.3509\n",
      "Epoch 6/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4503\n",
      "Epoch 6: val_loss did not improve from 1.35087\n",
      "32446/32446 [==============================] - 23s 721us/sample - loss: 1.4503 - val_loss: 1.3531\n",
      "Epoch 7/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4473\n",
      "Epoch 7: val_loss did not improve from 1.35087\n",
      "32446/32446 [==============================] - 24s 727us/sample - loss: 1.4473 - val_loss: 1.3585\n",
      "Epoch 8/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4450\n",
      "Epoch 8: val_loss improved from 1.35087 to 1.34561, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 24s 733us/sample - loss: 1.4450 - val_loss: 1.3456\n",
      "Epoch 9/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 9: val_loss improved from 1.34561 to 1.33713, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 24s 732us/sample - loss: 1.4411 - val_loss: 1.3371\n",
      "Epoch 10/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4381\n",
      "Epoch 10: val_loss did not improve from 1.33713\n",
      "32446/32446 [==============================] - 23s 724us/sample - loss: 1.4381 - val_loss: 1.3386\n",
      "Epoch 11/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 11: val_loss did not improve from 1.33713\n",
      "32446/32446 [==============================] - 23s 719us/sample - loss: 1.4361 - val_loss: 1.3425\n",
      "Epoch 12/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4356\n",
      "Epoch 12: val_loss did not improve from 1.33713\n",
      "32446/32446 [==============================] - 23s 720us/sample - loss: 1.4356 - val_loss: 1.3407\n",
      "Epoch 13/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4307\n",
      "Epoch 13: val_loss did not improve from 1.33713\n",
      "32446/32446 [==============================] - 24s 725us/sample - loss: 1.4307 - val_loss: 1.3396\n",
      "Epoch 14/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 14: val_loss improved from 1.33713 to 1.33621, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 24s 732us/sample - loss: 1.4324 - val_loss: 1.3362\n",
      "Epoch 15/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4322\n",
      "Epoch 15: val_loss did not improve from 1.33621\n",
      "32446/32446 [==============================] - 21s 652us/sample - loss: 1.4322 - val_loss: 1.3364\n",
      "Epoch 16/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4298\n",
      "Epoch 16: val_loss did not improve from 1.33621\n",
      "32446/32446 [==============================] - 20s 617us/sample - loss: 1.4298 - val_loss: 1.3375\n",
      "Epoch 17/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4245\n",
      "Epoch 17: val_loss did not improve from 1.33621\n",
      "32446/32446 [==============================] - 21s 638us/sample - loss: 1.4245 - val_loss: 1.3394\n",
      "Epoch 18/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4240\n",
      "Epoch 18: val_loss did not improve from 1.33621\n",
      "32446/32446 [==============================] - 20s 625us/sample - loss: 1.4240 - val_loss: 1.3403\n",
      "Epoch 19/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4238\n",
      "Epoch 19: val_loss improved from 1.33621 to 1.33337, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 21s 648us/sample - loss: 1.4238 - val_loss: 1.3334\n",
      "Epoch 20/20\n",
      "32446/32446 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 20: val_loss improved from 1.33337 to 1.33034, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_41.h5\n",
      "32446/32446 [==============================] - 20s 631us/sample - loss: 1.4246 - val_loss: 1.3303\n",
      "36197\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:50:16.758502: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_464/lstm_cell_1352/recurrent_kernel/Assign' id:687842 op device:{requested: '', assigned: ''} def:{{{node lstm_464/lstm_cell_1352/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_464/lstm_cell_1352/recurrent_kernel, lstm_464/lstm_cell_1352/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:50:36.748266: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_1' id:688140 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 19:50:52.959043: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_2' id:688141 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32582, 95)\n",
      "Train on 32582 samples, validate on 3615 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:51:29.915350: W tensorflow/c/c_api.cc:304] Operation '{name:'training_72/Adam/lstm_477/lstm_cell_1365/bias/m/Assign' id:701403 op device:{requested: '', assigned: ''} def:{{{node training_72/Adam/lstm_477/lstm_cell_1365/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_72/Adam/lstm_477/lstm_cell_1365/bias/m, training_72/Adam/lstm_477/lstm_cell_1365/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:54:44.442172: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 4.8861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-17 19:54:57.204446: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_73/mul' id:690981 op device:{requested: '', assigned: ''} def:{{{node loss_73/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_73/mul/x, loss_73/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.47390, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 190s 6ms/sample - loss: 4.8861 - val_loss: 4.4739\n",
      "Epoch 2/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 4.2532\n",
      "Epoch 2: val_loss improved from 4.47390 to 3.84809, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 215us/sample - loss: 4.2532 - val_loss: 3.8481\n",
      "Epoch 3/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 3.6259\n",
      "Epoch 3: val_loss improved from 3.84809 to 3.21057, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 218us/sample - loss: 3.6259 - val_loss: 3.2106\n",
      "Epoch 4/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 2.9039\n",
      "Epoch 4: val_loss improved from 3.21057 to 2.39352, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 213us/sample - loss: 2.9039 - val_loss: 2.3935\n",
      "Epoch 5/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 2.1362\n",
      "Epoch 5: val_loss improved from 2.39352 to 1.89695, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 215us/sample - loss: 2.1362 - val_loss: 1.8969\n",
      "Epoch 6/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.9554\n",
      "Epoch 6: val_loss improved from 1.89695 to 1.74080, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 216us/sample - loss: 1.9554 - val_loss: 1.7408\n",
      "Epoch 7/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.7517\n",
      "Epoch 7: val_loss improved from 1.74080 to 1.61122, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 215us/sample - loss: 1.7517 - val_loss: 1.6112\n",
      "Epoch 8/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6668\n",
      "Epoch 8: val_loss improved from 1.61122 to 1.53571, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 218us/sample - loss: 1.6668 - val_loss: 1.5357\n",
      "Epoch 9/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6174\n",
      "Epoch 9: val_loss improved from 1.53571 to 1.50520, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 218us/sample - loss: 1.6174 - val_loss: 1.5052\n",
      "Epoch 10/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6055\n",
      "Epoch 10: val_loss improved from 1.50520 to 1.49354, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 221us/sample - loss: 1.6055 - val_loss: 1.4935\n",
      "Epoch 11/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5750\n",
      "Epoch 11: val_loss improved from 1.49354 to 1.48318, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 233us/sample - loss: 1.5750 - val_loss: 1.4832\n",
      "Epoch 12/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5677\n",
      "Epoch 12: val_loss improved from 1.48318 to 1.47187, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 234us/sample - loss: 1.5677 - val_loss: 1.4719\n",
      "Epoch 13/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5748\n",
      "Epoch 13: val_loss did not improve from 1.47187\n",
      "32582/32582 [==============================] - 7s 226us/sample - loss: 1.5748 - val_loss: 1.4781\n",
      "Epoch 14/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5405\n",
      "Epoch 14: val_loss improved from 1.47187 to 1.45783, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 236us/sample - loss: 1.5405 - val_loss: 1.4578\n",
      "Epoch 15/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5348\n",
      "Epoch 15: val_loss improved from 1.45783 to 1.45319, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 236us/sample - loss: 1.5348 - val_loss: 1.4532\n",
      "Epoch 16/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5415\n",
      "Epoch 16: val_loss improved from 1.45319 to 1.44617, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 233us/sample - loss: 1.5415 - val_loss: 1.4462\n",
      "Epoch 17/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5558\n",
      "Epoch 17: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 225us/sample - loss: 1.5558 - val_loss: 1.4641\n",
      "Epoch 18/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5246\n",
      "Epoch 18: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 204us/sample - loss: 1.5246 - val_loss: 1.4490\n",
      "Epoch 19/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5309\n",
      "Epoch 19: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 204us/sample - loss: 1.5309 - val_loss: 1.4477\n",
      "Epoch 20/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5499\n",
      "Epoch 20: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 204us/sample - loss: 1.5499 - val_loss: 1.4662\n",
      "Epoch 21/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6918\n",
      "Epoch 21: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 224us/sample - loss: 1.6918 - val_loss: 1.5196\n",
      "Epoch 22/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5794\n",
      "Epoch 22: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 225us/sample - loss: 1.5794 - val_loss: 1.4816\n",
      "Epoch 23/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5275\n",
      "Epoch 23: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 227us/sample - loss: 1.5275 - val_loss: 1.4526\n",
      "Epoch 24/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5384\n",
      "Epoch 24: val_loss did not improve from 1.44617\n",
      "32582/32582 [==============================] - 7s 222us/sample - loss: 1.5384 - val_loss: 1.4537\n",
      "Epoch 25/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5122\n",
      "Epoch 25: val_loss improved from 1.44617 to 1.43703, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.5122 - val_loss: 1.4370\n",
      "Epoch 26/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5042\n",
      "Epoch 26: val_loss improved from 1.43703 to 1.43670, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 9s 289us/sample - loss: 1.5042 - val_loss: 1.4367\n",
      "Epoch 27/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5018\n",
      "Epoch 27: val_loss improved from 1.43670 to 1.43035, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.5018 - val_loss: 1.4304\n",
      "Epoch 28/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4999\n",
      "Epoch 28: val_loss improved from 1.43035 to 1.42815, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4999 - val_loss: 1.4281\n",
      "Epoch 29/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4986\n",
      "Epoch 29: val_loss improved from 1.42815 to 1.42512, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4986 - val_loss: 1.4251\n",
      "Epoch 30/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4951\n",
      "Epoch 30: val_loss improved from 1.42512 to 1.42306, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4951 - val_loss: 1.4231\n",
      "Epoch 31/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4927\n",
      "Epoch 31: val_loss improved from 1.42306 to 1.42166, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4927 - val_loss: 1.4217\n",
      "Epoch 32/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4874\n",
      "Epoch 32: val_loss improved from 1.42166 to 1.41958, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4874 - val_loss: 1.4196\n",
      "Epoch 33/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4898\n",
      "Epoch 33: val_loss improved from 1.41958 to 1.41807, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4898 - val_loss: 1.4181\n",
      "Epoch 34/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4861\n",
      "Epoch 34: val_loss improved from 1.41807 to 1.41638, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4861 - val_loss: 1.4164\n",
      "Epoch 35/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 35: val_loss improved from 1.41638 to 1.41488, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4836 - val_loss: 1.4149\n",
      "Epoch 36/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4842\n",
      "Epoch 36: val_loss improved from 1.41488 to 1.41332, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4842 - val_loss: 1.4133\n",
      "Epoch 37/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4817\n",
      "Epoch 37: val_loss improved from 1.41332 to 1.41100, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4817 - val_loss: 1.4110\n",
      "Epoch 38/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4807\n",
      "Epoch 38: val_loss improved from 1.41100 to 1.40979, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4807 - val_loss: 1.4098\n",
      "Epoch 39/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4788\n",
      "Epoch 39: val_loss improved from 1.40979 to 1.40771, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4788 - val_loss: 1.4077\n",
      "Epoch 40/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 40: val_loss improved from 1.40771 to 1.40674, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4772 - val_loss: 1.4067\n",
      "Epoch 41/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4768\n",
      "Epoch 41: val_loss improved from 1.40674 to 1.40571, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4768 - val_loss: 1.4057\n",
      "Epoch 42/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4742\n",
      "Epoch 42: val_loss improved from 1.40571 to 1.40441, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4742 - val_loss: 1.4044\n",
      "Epoch 43/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4732\n",
      "Epoch 43: val_loss improved from 1.40441 to 1.40189, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 238us/sample - loss: 1.4732 - val_loss: 1.4019\n",
      "Epoch 44/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4717\n",
      "Epoch 44: val_loss improved from 1.40189 to 1.40168, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 237us/sample - loss: 1.4717 - val_loss: 1.4017\n",
      "Epoch 45/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4724\n",
      "Epoch 45: val_loss improved from 1.40168 to 1.40073, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 16s 501us/sample - loss: 1.4724 - val_loss: 1.4007\n",
      "Epoch 46/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4682\n",
      "Epoch 46: val_loss improved from 1.40073 to 1.39903, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 11s 331us/sample - loss: 1.4682 - val_loss: 1.3990\n",
      "Epoch 47/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4674\n",
      "Epoch 47: val_loss did not improve from 1.39903\n",
      "32582/32582 [==============================] - 9s 268us/sample - loss: 1.4674 - val_loss: 1.3993\n",
      "Epoch 48/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4692\n",
      "Epoch 48: val_loss improved from 1.39903 to 1.39618, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 12s 370us/sample - loss: 1.4692 - val_loss: 1.3962\n",
      "Epoch 49/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4642\n",
      "Epoch 49: val_loss did not improve from 1.39618\n",
      "32582/32582 [==============================] - 8s 232us/sample - loss: 1.4642 - val_loss: 1.3966\n",
      "Epoch 50/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4659\n",
      "Epoch 50: val_loss improved from 1.39618 to 1.39481, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_42.h5\n",
      "32582/32582 [==============================] - 8s 233us/sample - loss: 1.4659 - val_loss: 1.3948\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:04:18.440257: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_474_1/lstm_cell_1399/recurrent_kernel/Assign' id:707966 op device:{requested: '', assigned: ''} def:{{{node lstm_474_1/lstm_cell_1399/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_474_1/lstm_cell_1399/recurrent_kernel, lstm_474_1/lstm_cell_1399/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 20:04:56.856718: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_465_1/lstm_cell_1390/kernel/m/Assign' id:710071 op device:{requested: '', assigned: ''} def:{{{node lstm_465_1/lstm_cell_1390/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_465_1/lstm_cell_1390/kernel/m, lstm_465_1/lstm_cell_1390/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-17 20:05:35.191765: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_64_1/cond/Merge' id:709095 op device:{requested: '', assigned: ''} def:{{{node dropout_64_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_64_1/cond/Identity, dropout_64_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499, 804)\n",
      "(1704, 804)\n",
      "(1704, 804)\n",
      "(1848, 804)\n",
      "(1736, 804)\n",
      "(1378, 804)\n",
      "(1802, 804)\n",
      "(1582, 804)\n",
      "(1716, 804)\n",
      "(1538, 804)\n",
      "(1908, 804)\n",
      "(1727, 804)\n",
      "(1776, 804)\n",
      "(1848, 804)\n",
      "(1752, 804)\n",
      "(1812, 804)\n",
      "(959, 804)\n",
      "(1656, 804)\n",
      "(1896, 804)\n",
      "{2: 4.806699428342192, 4: 8.14033477572766, 5: 6.301553921005061, 6: 4.828459116804587, 8: 8.94999244149497, 9: 5.4917183735271315, 10: 7.970945595886608, 11: 6.70528728434411, 12: 8.718194960507422, 13: 8.617293761664925, 17: 8.36434773036929, 19: 7.988846484072102, 21: 10.0, 22: 1.0, 25: 7.497133883383764, 26: 6.430414250105795, 27: 5.160981676129067, 28: 7.005782329731832, 29: 1.1887404203898624}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2905707/2131643591.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32582 samples, validate on 3615 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:13:10.649379: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 11.4858\n",
      "Epoch 1: val_loss improved from inf to 1.43466, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 91s 3ms/sample - loss: 11.4858 - val_loss: 1.4347\n",
      "Epoch 2/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.1941\n",
      "Epoch 2: val_loss did not improve from 1.43466\n",
      "32582/32582 [==============================] - 21s 637us/sample - loss: 11.1941 - val_loss: 1.4421\n",
      "Epoch 3/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.1474\n",
      "Epoch 3: val_loss did not improve from 1.43466\n",
      "32582/32582 [==============================] - 21s 631us/sample - loss: 11.1474 - val_loss: 1.4357\n",
      "Epoch 4/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0702\n",
      "Epoch 4: val_loss improved from 1.43466 to 1.42784, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 22s 668us/sample - loss: 11.0702 - val_loss: 1.4278\n",
      "Epoch 5/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0141\n",
      "Epoch 5: val_loss improved from 1.42784 to 1.42425, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 645us/sample - loss: 11.0141 - val_loss: 1.4242\n",
      "Epoch 6/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.9478\n",
      "Epoch 6: val_loss improved from 1.42425 to 1.41664, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 638us/sample - loss: 10.9478 - val_loss: 1.4166\n",
      "Epoch 7/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8970\n",
      "Epoch 7: val_loss improved from 1.41664 to 1.41548, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 22s 686us/sample - loss: 10.8970 - val_loss: 1.4155\n",
      "Epoch 8/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8861\n",
      "Epoch 8: val_loss did not improve from 1.41548\n",
      "32582/32582 [==============================] - 24s 731us/sample - loss: 10.8861 - val_loss: 1.4197\n",
      "Epoch 9/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8502\n",
      "Epoch 9: val_loss improved from 1.41548 to 1.40491, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 24s 737us/sample - loss: 10.8502 - val_loss: 1.4049\n",
      "Epoch 10/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8037\n",
      "Epoch 10: val_loss did not improve from 1.40491\n",
      "32582/32582 [==============================] - 23s 715us/sample - loss: 10.8037 - val_loss: 1.4117\n",
      "Epoch 11/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7674\n",
      "Epoch 11: val_loss improved from 1.40491 to 1.39891, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 647us/sample - loss: 10.7674 - val_loss: 1.3989\n",
      "Epoch 12/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7440\n",
      "Epoch 12: val_loss did not improve from 1.39891\n",
      "32582/32582 [==============================] - 23s 715us/sample - loss: 10.7440 - val_loss: 1.4108\n",
      "Epoch 13/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7462\n",
      "Epoch 13: val_loss improved from 1.39891 to 1.39645, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 659us/sample - loss: 10.7462 - val_loss: 1.3964\n",
      "Epoch 14/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7006\n",
      "Epoch 14: val_loss did not improve from 1.39645\n",
      "32582/32582 [==============================] - 23s 714us/sample - loss: 10.7006 - val_loss: 1.3989\n",
      "Epoch 15/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7104\n",
      "Epoch 15: val_loss improved from 1.39645 to 1.39418, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 24s 733us/sample - loss: 10.7104 - val_loss: 1.3942\n",
      "Epoch 16/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6559\n",
      "Epoch 16: val_loss improved from 1.39418 to 1.39388, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 649us/sample - loss: 10.6559 - val_loss: 1.3939\n",
      "Epoch 17/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6702\n",
      "Epoch 17: val_loss improved from 1.39388 to 1.38703, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 637us/sample - loss: 10.6702 - val_loss: 1.3870\n",
      "Epoch 18/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6381\n",
      "Epoch 18: val_loss improved from 1.38703 to 1.38683, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 641us/sample - loss: 10.6381 - val_loss: 1.3868\n",
      "Epoch 19/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6162\n",
      "Epoch 19: val_loss did not improve from 1.38683\n",
      "32582/32582 [==============================] - 20s 626us/sample - loss: 10.6162 - val_loss: 1.3872\n",
      "Epoch 20/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.5983\n",
      "Epoch 20: val_loss improved from 1.38683 to 1.38156, saving model to ./checkpoints/unknown_person_few_shot_p1_42.h5\n",
      "32582/32582 [==============================] - 23s 698us/sample - loss: 10.5983 - val_loss: 1.3816\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:21:54.310071: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_480_2/lstm_cell_1442/recurrent_kernel/Assign' id:728324 op device:{requested: '', assigned: ''} def:{{{node lstm_480_2/lstm_cell_1442/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_480_2/lstm_cell_1442/recurrent_kernel, lstm_480_2/lstm_cell_1442/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 20:22:34.082975: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_464_2/lstm_cell_1426/recurrent_kernel/v/Assign' id:730102 op device:{requested: '', assigned: ''} def:{{{node lstm_464_2/lstm_cell_1426/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_464_2/lstm_cell_1426/recurrent_kernel/v, lstm_464_2/lstm_cell_1426/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32582 samples, validate on 3615 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:23:16.083075: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:26:38.396023: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4620"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:27:12.064706: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39318, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 104s 3ms/sample - loss: 1.4620 - val_loss: 1.3932\n",
      "Epoch 2/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4565\n",
      "Epoch 2: val_loss improved from 1.39318 to 1.38860, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 26s 794us/sample - loss: 1.4565 - val_loss: 1.3886\n",
      "Epoch 3/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4534\n",
      "Epoch 3: val_loss improved from 1.38860 to 1.38187, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 24s 744us/sample - loss: 1.4534 - val_loss: 1.3819\n",
      "Epoch 4/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4504\n",
      "Epoch 4: val_loss did not improve from 1.38187\n",
      "32582/32582 [==============================] - 24s 745us/sample - loss: 1.4504 - val_loss: 1.3822\n",
      "Epoch 5/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4462\n",
      "Epoch 5: val_loss did not improve from 1.38187\n",
      "32582/32582 [==============================] - 23s 691us/sample - loss: 1.4462 - val_loss: 1.3825\n",
      "Epoch 6/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4458\n",
      "Epoch 6: val_loss improved from 1.38187 to 1.37739, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 24s 749us/sample - loss: 1.4458 - val_loss: 1.3774\n",
      "Epoch 7/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4418\n",
      "Epoch 7: val_loss did not improve from 1.37739\n",
      "32582/32582 [==============================] - 24s 724us/sample - loss: 1.4418 - val_loss: 1.3781\n",
      "Epoch 8/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 8: val_loss did not improve from 1.37739\n",
      "32582/32582 [==============================] - 22s 663us/sample - loss: 1.4383 - val_loss: 1.3780\n",
      "Epoch 9/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4369\n",
      "Epoch 9: val_loss improved from 1.37739 to 1.37457, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 22s 671us/sample - loss: 1.4369 - val_loss: 1.3746\n",
      "Epoch 10/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4360\n",
      "Epoch 10: val_loss improved from 1.37457 to 1.37340, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 22s 661us/sample - loss: 1.4360 - val_loss: 1.3734\n",
      "Epoch 11/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4317\n",
      "Epoch 11: val_loss improved from 1.37340 to 1.36821, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 648us/sample - loss: 1.4317 - val_loss: 1.3682\n",
      "Epoch 12/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4319\n",
      "Epoch 12: val_loss did not improve from 1.36821\n",
      "32582/32582 [==============================] - 22s 662us/sample - loss: 1.4319 - val_loss: 1.3693\n",
      "Epoch 13/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 13: val_loss improved from 1.36821 to 1.36811, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 657us/sample - loss: 1.4269 - val_loss: 1.3681\n",
      "Epoch 14/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4264\n",
      "Epoch 14: val_loss did not improve from 1.36811\n",
      "32582/32582 [==============================] - 23s 714us/sample - loss: 1.4264 - val_loss: 1.3762\n",
      "Epoch 15/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4265\n",
      "Epoch 15: val_loss improved from 1.36811 to 1.36525, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 24s 724us/sample - loss: 1.4265 - val_loss: 1.3652\n",
      "Epoch 16/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 16: val_loss did not improve from 1.36525\n",
      "32582/32582 [==============================] - 24s 739us/sample - loss: 1.4220 - val_loss: 1.3654\n",
      "Epoch 17/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4229\n",
      "Epoch 17: val_loss improved from 1.36525 to 1.36076, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 24s 732us/sample - loss: 1.4229 - val_loss: 1.3608\n",
      "Epoch 18/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4193\n",
      "Epoch 18: val_loss did not improve from 1.36076\n",
      "32582/32582 [==============================] - 23s 711us/sample - loss: 1.4193 - val_loss: 1.3672\n",
      "Epoch 19/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 19: val_loss did not improve from 1.36076\n",
      "32582/32582 [==============================] - 21s 639us/sample - loss: 1.4204 - val_loss: 1.3610\n",
      "Epoch 20/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 20: val_loss improved from 1.36076 to 1.35824, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_42.h5\n",
      "32582/32582 [==============================] - 21s 645us/sample - loss: 1.4172 - val_loss: 1.3582\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:35:53.462975: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_498/lstm_cell_1460/bias/Assign' id:744398 op device:{requested: '', assigned: ''} def:{{{node lstm_498/lstm_cell_1460/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_498/lstm_cell_1460/bias, lstm_498/lstm_cell_1460/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 20:36:15.440712: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_1' id:745182 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 20:36:33.575670: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_2' id:745183 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32582, 95)\n",
      "Train on 32582 samples, validate on 3615 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:37:14.146593: W tensorflow/c/c_api.cc:304] Operation '{name:'training_78/Adam/lstm_514/lstm_cell_1476/bias/v/Assign' id:759088 op device:{requested: '', assigned: ''} def:{{{node training_78/Adam/lstm_514/lstm_cell_1476/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_78/Adam/lstm_514/lstm_cell_1476/bias/v, training_78/Adam/lstm_514/lstm_cell_1476/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:40:49.411450: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 4.3475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:41:10.479522: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_79/mul' id:748023 op device:{requested: '', assigned: ''} def:{{{node loss_79/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_79/mul/x, loss_79/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.62578, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 215s 7ms/sample - loss: 4.3475 - val_loss: 3.6258\n",
      "Epoch 2/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 3.0967\n",
      "Epoch 2: val_loss improved from 3.62578 to 2.36478, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 11s 330us/sample - loss: 3.0967 - val_loss: 2.3648\n",
      "Epoch 3/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 2.2247\n",
      "Epoch 3: val_loss improved from 2.36478 to 1.83939, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 9s 270us/sample - loss: 2.2247 - val_loss: 1.8394\n",
      "Epoch 4/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.9608\n",
      "Epoch 4: val_loss improved from 1.83939 to 1.76671, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 232us/sample - loss: 1.9608 - val_loss: 1.7667\n",
      "Epoch 5/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.8298\n",
      "Epoch 5: val_loss improved from 1.76671 to 1.64609, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 213us/sample - loss: 1.8298 - val_loss: 1.6461\n",
      "Epoch 6/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.7114\n",
      "Epoch 6: val_loss improved from 1.64609 to 1.57280, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 216us/sample - loss: 1.7114 - val_loss: 1.5728\n",
      "Epoch 7/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6580\n",
      "Epoch 7: val_loss improved from 1.57280 to 1.54101, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 214us/sample - loss: 1.6580 - val_loss: 1.5410\n",
      "Epoch 8/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6272\n",
      "Epoch 8: val_loss improved from 1.54101 to 1.50428, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 213us/sample - loss: 1.6272 - val_loss: 1.5043\n",
      "Epoch 9/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.7161\n",
      "Epoch 9: val_loss did not improve from 1.50428\n",
      "32582/32582 [==============================] - 7s 202us/sample - loss: 1.7161 - val_loss: 1.5331\n",
      "Epoch 10/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6239\n",
      "Epoch 10: val_loss did not improve from 1.50428\n",
      "32582/32582 [==============================] - 7s 206us/sample - loss: 1.6239 - val_loss: 1.5273\n",
      "Epoch 11/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5961\n",
      "Epoch 11: val_loss improved from 1.50428 to 1.48276, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 212us/sample - loss: 1.5961 - val_loss: 1.4828\n",
      "Epoch 12/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5647\n",
      "Epoch 12: val_loss improved from 1.48276 to 1.47842, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 216us/sample - loss: 1.5647 - val_loss: 1.4784\n",
      "Epoch 13/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5901\n",
      "Epoch 13: val_loss improved from 1.47842 to 1.47338, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 212us/sample - loss: 1.5901 - val_loss: 1.4734\n",
      "Epoch 14/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5526\n",
      "Epoch 14: val_loss improved from 1.47338 to 1.45963, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 213us/sample - loss: 1.5526 - val_loss: 1.4596\n",
      "Epoch 15/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5604\n",
      "Epoch 15: val_loss did not improve from 1.45963\n",
      "32582/32582 [==============================] - 7s 202us/sample - loss: 1.5604 - val_loss: 1.4625\n",
      "Epoch 16/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5432\n",
      "Epoch 16: val_loss improved from 1.45963 to 1.45726, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 212us/sample - loss: 1.5432 - val_loss: 1.4573\n",
      "Epoch 17/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5288\n",
      "Epoch 17: val_loss improved from 1.45726 to 1.44186, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 229us/sample - loss: 1.5288 - val_loss: 1.4419\n",
      "Epoch 18/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5324\n",
      "Epoch 18: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 7s 205us/sample - loss: 1.5324 - val_loss: 1.4473\n",
      "Epoch 19/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6172\n",
      "Epoch 19: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 7s 210us/sample - loss: 1.6172 - val_loss: 1.4650\n",
      "Epoch 20/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.7065\n",
      "Epoch 20: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 7s 206us/sample - loss: 1.7065 - val_loss: 1.5520\n",
      "Epoch 21/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6226\n",
      "Epoch 21: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 7s 221us/sample - loss: 1.6226 - val_loss: 1.5314\n",
      "Epoch 22/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6042\n",
      "Epoch 22: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 6s 199us/sample - loss: 1.6042 - val_loss: 1.5085\n",
      "Epoch 23/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5512\n",
      "Epoch 23: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 7s 223us/sample - loss: 1.5512 - val_loss: 1.4870\n",
      "Epoch 24/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5358\n",
      "Epoch 24: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 6s 199us/sample - loss: 1.5358 - val_loss: 1.4587\n",
      "Epoch 25/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5252\n",
      "Epoch 25: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 6s 198us/sample - loss: 1.5252 - val_loss: 1.4522\n",
      "Epoch 26/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5174\n",
      "Epoch 26: val_loss did not improve from 1.44186\n",
      "32582/32582 [==============================] - 7s 219us/sample - loss: 1.5174 - val_loss: 1.4422\n",
      "Epoch 27/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5111\n",
      "Epoch 27: val_loss improved from 1.44186 to 1.43815, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.5111 - val_loss: 1.4382\n",
      "Epoch 28/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5084\n",
      "Epoch 28: val_loss improved from 1.43815 to 1.43512, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 224us/sample - loss: 1.5084 - val_loss: 1.4351\n",
      "Epoch 29/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5054\n",
      "Epoch 29: val_loss improved from 1.43512 to 1.43208, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 207us/sample - loss: 1.5054 - val_loss: 1.4321\n",
      "Epoch 30/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5009\n",
      "Epoch 30: val_loss improved from 1.43208 to 1.42934, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 237us/sample - loss: 1.5009 - val_loss: 1.4293\n",
      "Epoch 31/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4998\n",
      "Epoch 31: val_loss improved from 1.42934 to 1.42658, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 212us/sample - loss: 1.4998 - val_loss: 1.4266\n",
      "Epoch 32/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4976\n",
      "Epoch 32: val_loss improved from 1.42658 to 1.42418, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 240us/sample - loss: 1.4976 - val_loss: 1.4242\n",
      "Epoch 33/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4946\n",
      "Epoch 33: val_loss improved from 1.42418 to 1.42360, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4946 - val_loss: 1.4236\n",
      "Epoch 34/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4932\n",
      "Epoch 34: val_loss improved from 1.42360 to 1.42046, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4932 - val_loss: 1.4205\n",
      "Epoch 35/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 35: val_loss improved from 1.42046 to 1.41986, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4903 - val_loss: 1.4199\n",
      "Epoch 36/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4901\n",
      "Epoch 36: val_loss improved from 1.41986 to 1.41814, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 208us/sample - loss: 1.4901 - val_loss: 1.4181\n",
      "Epoch 37/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4875\n",
      "Epoch 37: val_loss improved from 1.41814 to 1.41650, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4875 - val_loss: 1.4165\n",
      "Epoch 38/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4841\n",
      "Epoch 38: val_loss improved from 1.41650 to 1.41487, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 209us/sample - loss: 1.4841 - val_loss: 1.4149\n",
      "Epoch 39/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4826\n",
      "Epoch 39: val_loss did not improve from 1.41487\n",
      "32582/32582 [==============================] - 7s 219us/sample - loss: 1.4826 - val_loss: 1.4152\n",
      "Epoch 40/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4838\n",
      "Epoch 40: val_loss improved from 1.41487 to 1.41153, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 234us/sample - loss: 1.4838 - val_loss: 1.4115\n",
      "Epoch 41/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 41: val_loss improved from 1.41153 to 1.40918, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 235us/sample - loss: 1.4794 - val_loss: 1.4092\n",
      "Epoch 42/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4793\n",
      "Epoch 42: val_loss did not improve from 1.40918\n",
      "32582/32582 [==============================] - 7s 223us/sample - loss: 1.4793 - val_loss: 1.4101\n",
      "Epoch 43/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4758\n",
      "Epoch 43: val_loss improved from 1.40918 to 1.40705, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 214us/sample - loss: 1.4758 - val_loss: 1.4070\n",
      "Epoch 44/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4759\n",
      "Epoch 44: val_loss did not improve from 1.40705\n",
      "32582/32582 [==============================] - 7s 202us/sample - loss: 1.4759 - val_loss: 1.4072\n",
      "Epoch 45/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4748\n",
      "Epoch 45: val_loss improved from 1.40705 to 1.40332, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 7s 211us/sample - loss: 1.4748 - val_loss: 1.4033\n",
      "Epoch 46/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 46: val_loss did not improve from 1.40332\n",
      "32582/32582 [==============================] - 7s 206us/sample - loss: 1.4731 - val_loss: 1.4039\n",
      "Epoch 47/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4707\n",
      "Epoch 47: val_loss improved from 1.40332 to 1.40176, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 231us/sample - loss: 1.4707 - val_loss: 1.4018\n",
      "Epoch 48/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4717\n",
      "Epoch 48: val_loss did not improve from 1.40176\n",
      "32582/32582 [==============================] - 7s 223us/sample - loss: 1.4717 - val_loss: 1.4018\n",
      "Epoch 49/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4695\n",
      "Epoch 49: val_loss improved from 1.40176 to 1.39927, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_43.h5\n",
      "32582/32582 [==============================] - 8s 234us/sample - loss: 1.4695 - val_loss: 1.3993\n",
      "Epoch 50/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4703\n",
      "Epoch 50: val_loss did not improve from 1.39927\n",
      "32582/32582 [==============================] - 7s 225us/sample - loss: 1.4703 - val_loss: 1.4014\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:50:26.578627: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_483_1/lstm_cell_1482/kernel/Assign' id:760506 op device:{requested: '', assigned: ''} def:{{{node lstm_483_1/lstm_cell_1482/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_483_1/lstm_cell_1482/kernel, lstm_483_1/lstm_cell_1482/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 20:51:08.701074: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_504_1/lstm_cell_1503/kernel/v/Assign' id:767786 op device:{requested: '', assigned: ''} def:{{{node lstm_504_1/lstm_cell_1503/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_504_1/lstm_cell_1503/kernel/v, lstm_504_1/lstm_cell_1503/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 20:51:50.746708: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_69_1/cond/Merge' id:766137 op device:{requested: '', assigned: ''} def:{{{node dropout_69_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_69_1/cond/Identity, dropout_69_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499, 804)\n",
      "(1704, 804)\n",
      "(1704, 804)\n",
      "(1848, 804)\n",
      "(1736, 804)\n",
      "(1378, 804)\n",
      "(1802, 804)\n",
      "(1582, 804)\n",
      "(1716, 804)\n",
      "(1538, 804)\n",
      "(1908, 804)\n",
      "(1727, 804)\n",
      "(1776, 804)\n",
      "(1848, 804)\n",
      "(1752, 804)\n",
      "(1812, 804)\n",
      "(959, 804)\n",
      "(1656, 804)\n",
      "(1896, 804)\n",
      "{2: 6.028525235303775, 4: 8.370021932876858, 5: 5.898224891298802, 6: 5.246049982246136, 8: 9.138022840875053, 9: 6.603291215776954, 10: 7.768720434089778, 11: 6.960128258215804, 12: 8.403175321053375, 13: 8.14461294320881, 17: 8.569367105127517, 19: 7.697368644836993, 21: 10.0, 22: 1.0, 25: 7.2760319715327295, 26: 6.579626512853069, 27: 6.153077700834727, 28: 6.4678334003803455, 29: 1.758972990177584}\n",
      "Train on 32582 samples, validate on 3615 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:59:30.537425: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 11.6645\n",
      "Epoch 1: val_loss improved from inf to 1.46775, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 101s 3ms/sample - loss: 11.6645 - val_loss: 1.4677\n",
      "Epoch 2/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.3809\n",
      "Epoch 2: val_loss improved from 1.46775 to 1.45079, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 24s 736us/sample - loss: 11.3809 - val_loss: 1.4508\n",
      "Epoch 3/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.2416\n",
      "Epoch 3: val_loss improved from 1.45079 to 1.41919, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 23s 715us/sample - loss: 11.2416 - val_loss: 1.4192\n",
      "Epoch 4/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.2237\n",
      "Epoch 4: val_loss improved from 1.41919 to 1.41537, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 21s 650us/sample - loss: 11.2237 - val_loss: 1.4154\n",
      "Epoch 5/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.1689\n",
      "Epoch 5: val_loss improved from 1.41537 to 1.41491, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 23s 704us/sample - loss: 11.1689 - val_loss: 1.4149\n",
      "Epoch 6/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.1125\n",
      "Epoch 6: val_loss improved from 1.41491 to 1.41375, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 23s 709us/sample - loss: 11.1125 - val_loss: 1.4137\n",
      "Epoch 7/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0600\n",
      "Epoch 7: val_loss improved from 1.41375 to 1.40796, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 23s 707us/sample - loss: 11.0600 - val_loss: 1.4080\n",
      "Epoch 8/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0457\n",
      "Epoch 8: val_loss did not improve from 1.40796\n",
      "32582/32582 [==============================] - 24s 750us/sample - loss: 11.0457 - val_loss: 1.4085\n",
      "Epoch 9/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0247\n",
      "Epoch 9: val_loss improved from 1.40796 to 1.40751, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 24s 733us/sample - loss: 11.0247 - val_loss: 1.4075\n",
      "Epoch 10/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.9503\n",
      "Epoch 10: val_loss improved from 1.40751 to 1.40020, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 24s 749us/sample - loss: 10.9503 - val_loss: 1.4002\n",
      "Epoch 11/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.9866\n",
      "Epoch 11: val_loss did not improve from 1.40020\n",
      "32582/32582 [==============================] - 24s 725us/sample - loss: 10.9866 - val_loss: 1.4068\n",
      "Epoch 12/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.9346\n",
      "Epoch 12: val_loss did not improve from 1.40020\n",
      "32582/32582 [==============================] - 24s 726us/sample - loss: 10.9346 - val_loss: 1.4072\n",
      "Epoch 13/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8933\n",
      "Epoch 13: val_loss improved from 1.40020 to 1.38801, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 25s 752us/sample - loss: 10.8933 - val_loss: 1.3880\n",
      "Epoch 14/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8713\n",
      "Epoch 14: val_loss did not improve from 1.38801\n",
      "32582/32582 [==============================] - 24s 733us/sample - loss: 10.8713 - val_loss: 1.4018\n",
      "Epoch 15/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8448\n",
      "Epoch 15: val_loss did not improve from 1.38801\n",
      "32582/32582 [==============================] - 24s 725us/sample - loss: 10.8448 - val_loss: 1.3903\n",
      "Epoch 16/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8653\n",
      "Epoch 16: val_loss did not improve from 1.38801\n",
      "32582/32582 [==============================] - 24s 729us/sample - loss: 10.8653 - val_loss: 1.3921\n",
      "Epoch 17/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8687\n",
      "Epoch 17: val_loss did not improve from 1.38801\n",
      "32582/32582 [==============================] - 22s 672us/sample - loss: 10.8687 - val_loss: 1.3915\n",
      "Epoch 18/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8259\n",
      "Epoch 18: val_loss improved from 1.38801 to 1.38393, saving model to ./checkpoints/unknown_person_few_shot_p1_43.h5\n",
      "32582/32582 [==============================] - 23s 693us/sample - loss: 10.8259 - val_loss: 1.3839\n",
      "Epoch 19/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8058\n",
      "Epoch 19: val_loss did not improve from 1.38393\n",
      "32582/32582 [==============================] - 24s 733us/sample - loss: 10.8058 - val_loss: 1.3898\n",
      "Epoch 20/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7870\n",
      "Epoch 20: val_loss did not improve from 1.38393\n",
      "32582/32582 [==============================] - 22s 681us/sample - loss: 10.7870 - val_loss: 1.3929\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:08:52.519765: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_55_2/bias/Assign' id:785592 op device:{requested: '', assigned: ''} def:{{{node dense_55_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_55_2/bias, dense_55_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 21:09:36.944908: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_482_2/lstm_cell_1518/recurrent_kernel/m/Assign' id:786216 op device:{requested: '', assigned: ''} def:{{{node lstm_482_2/lstm_cell_1518/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_482_2/lstm_cell_1518/recurrent_kernel/m, lstm_482_2/lstm_cell_1518/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32582 samples, validate on 3615 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:10:23.756337: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:14:08.928104: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:14:34.767332: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39353, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 102s 3ms/sample - loss: 1.4667 - val_loss: 1.3935\n",
      "Epoch 2/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4637\n",
      "Epoch 2: val_loss improved from 1.39353 to 1.39018, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 22s 679us/sample - loss: 1.4637 - val_loss: 1.3902\n",
      "Epoch 3/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4596\n",
      "Epoch 3: val_loss improved from 1.39018 to 1.38969, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 22s 661us/sample - loss: 1.4596 - val_loss: 1.3897\n",
      "Epoch 4/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4553\n",
      "Epoch 4: val_loss did not improve from 1.38969\n",
      "32582/32582 [==============================] - 21s 631us/sample - loss: 1.4553 - val_loss: 1.3923\n",
      "Epoch 5/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4470\n",
      "Epoch 5: val_loss improved from 1.38969 to 1.38196, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 21s 635us/sample - loss: 1.4470 - val_loss: 1.3820\n",
      "Epoch 6/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4454\n",
      "Epoch 6: val_loss improved from 1.38196 to 1.37728, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 21s 632us/sample - loss: 1.4454 - val_loss: 1.3773\n",
      "Epoch 7/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4437\n",
      "Epoch 7: val_loss improved from 1.37728 to 1.37673, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 21s 640us/sample - loss: 1.4437 - val_loss: 1.3767\n",
      "Epoch 8/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4414\n",
      "Epoch 8: val_loss improved from 1.37673 to 1.37439, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 21s 637us/sample - loss: 1.4414 - val_loss: 1.3744\n",
      "Epoch 9/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4389\n",
      "Epoch 9: val_loss did not improve from 1.37439\n",
      "32582/32582 [==============================] - 20s 629us/sample - loss: 1.4389 - val_loss: 1.3767\n",
      "Epoch 10/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4360\n",
      "Epoch 10: val_loss did not improve from 1.37439\n",
      "32582/32582 [==============================] - 20s 629us/sample - loss: 1.4360 - val_loss: 1.3747\n",
      "Epoch 11/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4345\n",
      "Epoch 11: val_loss improved from 1.37439 to 1.37316, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 22s 662us/sample - loss: 1.4345 - val_loss: 1.3732\n",
      "Epoch 12/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 12: val_loss improved from 1.37316 to 1.37147, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 24s 752us/sample - loss: 1.4321 - val_loss: 1.3715\n",
      "Epoch 13/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4295\n",
      "Epoch 13: val_loss improved from 1.37147 to 1.36909, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 27s 830us/sample - loss: 1.4295 - val_loss: 1.3691\n",
      "Epoch 14/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 14: val_loss did not improve from 1.36909\n",
      "32582/32582 [==============================] - 23s 711us/sample - loss: 1.4294 - val_loss: 1.3696\n",
      "Epoch 15/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4265\n",
      "Epoch 15: val_loss improved from 1.36909 to 1.36742, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 30s 909us/sample - loss: 1.4265 - val_loss: 1.3674\n",
      "Epoch 16/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4257\n",
      "Epoch 16: val_loss improved from 1.36742 to 1.36656, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 29s 884us/sample - loss: 1.4257 - val_loss: 1.3666\n",
      "Epoch 17/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4241\n",
      "Epoch 17: val_loss did not improve from 1.36656\n",
      "32582/32582 [==============================] - 25s 771us/sample - loss: 1.4241 - val_loss: 1.3685\n",
      "Epoch 18/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4222\n",
      "Epoch 18: val_loss improved from 1.36656 to 1.36212, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_43.h5\n",
      "32582/32582 [==============================] - 21s 635us/sample - loss: 1.4222 - val_loss: 1.3621\n",
      "Epoch 19/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4223\n",
      "Epoch 19: val_loss did not improve from 1.36212\n",
      "32582/32582 [==============================] - 25s 773us/sample - loss: 1.4223 - val_loss: 1.3701\n",
      "Epoch 20/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 20: val_loss did not improve from 1.36212\n",
      "32582/32582 [==============================] - 29s 901us/sample - loss: 1.4186 - val_loss: 1.3624\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:23:30.418668: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_525/lstm_cell_1561/recurrent_kernel/Assign' id:799781 op device:{requested: '', assigned: ''} def:{{{node lstm_525/lstm_cell_1561/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_525/lstm_cell_1561/recurrent_kernel, lstm_525/lstm_cell_1561/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 21:23:54.898813: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_1' id:802224 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 21:24:15.261568: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_2' id:802225 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32582, 95)\n",
      "Train on 32582 samples, validate on 3615 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:25:00.743481: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_549/lstm_cell_1585/recurrent_kernel/Assign' id:803970 op device:{requested: '', assigned: ''} def:{{{node lstm_549/lstm_cell_1585/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_549/lstm_cell_1585/recurrent_kernel, lstm_549/lstm_cell_1585/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:29:39.661186: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 4.4706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 21:30:46.195728: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_85/mul' id:805065 op device:{requested: '', assigned: ''} def:{{{node loss_85/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_85/mul/x, loss_85/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.66115, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 327s 10ms/sample - loss: 4.4706 - val_loss: 3.6612\n",
      "Epoch 2/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 2.9277\n",
      "Epoch 2: val_loss improved from 3.66115 to 2.10449, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 70s 2ms/sample - loss: 2.9277 - val_loss: 2.1045\n",
      "Epoch 3/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 2.1757\n",
      "Epoch 3: val_loss improved from 2.10449 to 1.99599, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 74s 2ms/sample - loss: 2.1757 - val_loss: 1.9960\n",
      "Epoch 4/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 2.0111\n",
      "Epoch 4: val_loss improved from 1.99599 to 1.81515, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 70s 2ms/sample - loss: 2.0111 - val_loss: 1.8152\n",
      "Epoch 5/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.8477\n",
      "Epoch 5: val_loss improved from 1.81515 to 1.68871, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 79s 2ms/sample - loss: 1.8477 - val_loss: 1.6887\n",
      "Epoch 6/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.7308\n",
      "Epoch 6: val_loss improved from 1.68871 to 1.59086, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 65s 2ms/sample - loss: 1.7308 - val_loss: 1.5909\n",
      "Epoch 7/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6801\n",
      "Epoch 7: val_loss improved from 1.59086 to 1.55476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 76s 2ms/sample - loss: 1.6801 - val_loss: 1.5548\n",
      "Epoch 8/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6511\n",
      "Epoch 8: val_loss improved from 1.55476 to 1.51411, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 72s 2ms/sample - loss: 1.6511 - val_loss: 1.5141\n",
      "Epoch 9/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6135\n",
      "Epoch 9: val_loss improved from 1.51411 to 1.49914, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 56s 2ms/sample - loss: 1.6135 - val_loss: 1.4991\n",
      "Epoch 10/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6260\n",
      "Epoch 10: val_loss did not improve from 1.49914\n",
      "32582/32582 [==============================] - 58s 2ms/sample - loss: 1.6260 - val_loss: 1.4995\n",
      "Epoch 11/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5776\n",
      "Epoch 11: val_loss improved from 1.49914 to 1.47851, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 61s 2ms/sample - loss: 1.5776 - val_loss: 1.4785\n",
      "Epoch 12/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5819\n",
      "Epoch 12: val_loss improved from 1.47851 to 1.47154, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 71s 2ms/sample - loss: 1.5819 - val_loss: 1.4715\n",
      "Epoch 13/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.8902\n",
      "Epoch 13: val_loss did not improve from 1.47154\n",
      "32582/32582 [==============================] - 68s 2ms/sample - loss: 1.8902 - val_loss: 1.5318\n",
      "Epoch 14/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6183\n",
      "Epoch 14: val_loss did not improve from 1.47154\n",
      "32582/32582 [==============================] - 60s 2ms/sample - loss: 1.6183 - val_loss: 1.5159\n",
      "Epoch 15/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5745\n",
      "Epoch 15: val_loss did not improve from 1.47154\n",
      "32582/32582 [==============================] - 63s 2ms/sample - loss: 1.5745 - val_loss: 1.4763\n",
      "Epoch 16/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5652\n",
      "Epoch 16: val_loss did not improve from 1.47154\n",
      "32582/32582 [==============================] - 59s 2ms/sample - loss: 1.5652 - val_loss: 1.4941\n",
      "Epoch 17/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5568\n",
      "Epoch 17: val_loss improved from 1.47154 to 1.46468, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 60s 2ms/sample - loss: 1.5568 - val_loss: 1.4647\n",
      "Epoch 18/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5754\n",
      "Epoch 18: val_loss did not improve from 1.46468\n",
      "32582/32582 [==============================] - 60s 2ms/sample - loss: 1.5754 - val_loss: 1.4774\n",
      "Epoch 19/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5477\n",
      "Epoch 19: val_loss improved from 1.46468 to 1.46120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 56s 2ms/sample - loss: 1.5477 - val_loss: 1.4612\n",
      "Epoch 20/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5537\n",
      "Epoch 20: val_loss did not improve from 1.46120\n",
      "32582/32582 [==============================] - 65s 2ms/sample - loss: 1.5537 - val_loss: 1.4771\n",
      "Epoch 21/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5385\n",
      "Epoch 21: val_loss did not improve from 1.46120\n",
      "32582/32582 [==============================] - 68s 2ms/sample - loss: 1.5385 - val_loss: 1.4616\n",
      "Epoch 22/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.7505\n",
      "Epoch 22: val_loss did not improve from 1.46120\n",
      "32582/32582 [==============================] - 77s 2ms/sample - loss: 1.7505 - val_loss: 1.5512\n",
      "Epoch 23/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.6138\n",
      "Epoch 23: val_loss did not improve from 1.46120\n",
      "32582/32582 [==============================] - 57s 2ms/sample - loss: 1.6138 - val_loss: 1.5652\n",
      "Epoch 24/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5396\n",
      "Epoch 24: val_loss improved from 1.46120 to 1.45514, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 60s 2ms/sample - loss: 1.5396 - val_loss: 1.4551\n",
      "Epoch 25/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5342\n",
      "Epoch 25: val_loss improved from 1.45514 to 1.45195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 62s 2ms/sample - loss: 1.5342 - val_loss: 1.4519\n",
      "Epoch 26/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5274\n",
      "Epoch 26: val_loss improved from 1.45195 to 1.44446, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 66s 2ms/sample - loss: 1.5274 - val_loss: 1.4445\n",
      "Epoch 27/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5251\n",
      "Epoch 27: val_loss improved from 1.44446 to 1.44265, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 80s 2ms/sample - loss: 1.5251 - val_loss: 1.4427\n",
      "Epoch 28/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5201\n",
      "Epoch 28: val_loss improved from 1.44265 to 1.44064, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 83s 3ms/sample - loss: 1.5201 - val_loss: 1.4406\n",
      "Epoch 29/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5168\n",
      "Epoch 29: val_loss improved from 1.44064 to 1.43539, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 79s 2ms/sample - loss: 1.5168 - val_loss: 1.4354\n",
      "Epoch 30/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5161 \n",
      "Epoch 30: val_loss improved from 1.43539 to 1.43343, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 92s 3ms/sample - loss: 1.5161 - val_loss: 1.4334\n",
      "Epoch 31/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5137\n",
      "Epoch 31: val_loss improved from 1.43343 to 1.43181, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 74s 2ms/sample - loss: 1.5137 - val_loss: 1.4318\n",
      "Epoch 32/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5111\n",
      "Epoch 32: val_loss improved from 1.43181 to 1.42998, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 74s 2ms/sample - loss: 1.5111 - val_loss: 1.4300\n",
      "Epoch 33/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5105\n",
      "Epoch 33: val_loss improved from 1.42998 to 1.42766, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 67s 2ms/sample - loss: 1.5105 - val_loss: 1.4277\n",
      "Epoch 34/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5085\n",
      "Epoch 34: val_loss improved from 1.42766 to 1.42689, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 76s 2ms/sample - loss: 1.5085 - val_loss: 1.4269\n",
      "Epoch 35/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5066 \n",
      "Epoch 35: val_loss did not improve from 1.42689\n",
      "32582/32582 [==============================] - 148s 5ms/sample - loss: 1.5066 - val_loss: 1.4274\n",
      "Epoch 36/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5039 \n",
      "Epoch 36: val_loss improved from 1.42689 to 1.42479, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 185s 6ms/sample - loss: 1.5039 - val_loss: 1.4248\n",
      "Epoch 37/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.5016 \n",
      "Epoch 37: val_loss improved from 1.42479 to 1.42229, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 184s 6ms/sample - loss: 1.5016 - val_loss: 1.4223\n",
      "Epoch 38/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4986 \n",
      "Epoch 38: val_loss improved from 1.42229 to 1.42041, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 151s 5ms/sample - loss: 1.4986 - val_loss: 1.4204\n",
      "Epoch 39/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4962 \n",
      "Epoch 39: val_loss improved from 1.42041 to 1.41798, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 150s 5ms/sample - loss: 1.4962 - val_loss: 1.4180\n",
      "Epoch 40/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4960\n",
      "Epoch 40: val_loss improved from 1.41798 to 1.41700, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 73s 2ms/sample - loss: 1.4960 - val_loss: 1.4170\n",
      "Epoch 41/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4920 \n",
      "Epoch 41: val_loss improved from 1.41700 to 1.41429, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 98s 3ms/sample - loss: 1.4920 - val_loss: 1.4143\n",
      "Epoch 42/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4898\n",
      "Epoch 42: val_loss improved from 1.41429 to 1.41195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 63s 2ms/sample - loss: 1.4898 - val_loss: 1.4120\n",
      "Epoch 43/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4887\n",
      "Epoch 43: val_loss did not improve from 1.41195\n",
      "32582/32582 [==============================] - 71s 2ms/sample - loss: 1.4887 - val_loss: 1.4122\n",
      "Epoch 44/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4888\n",
      "Epoch 44: val_loss improved from 1.41195 to 1.40928, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 66s 2ms/sample - loss: 1.4888 - val_loss: 1.4093\n",
      "Epoch 45/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4858\n",
      "Epoch 45: val_loss did not improve from 1.40928\n",
      "32582/32582 [==============================] - 67s 2ms/sample - loss: 1.4858 - val_loss: 1.4094\n",
      "Epoch 46/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4861\n",
      "Epoch 46: val_loss improved from 1.40928 to 1.40546, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 71s 2ms/sample - loss: 1.4861 - val_loss: 1.4055\n",
      "Epoch 47/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4813\n",
      "Epoch 47: val_loss did not improve from 1.40546\n",
      "32582/32582 [==============================] - 69s 2ms/sample - loss: 1.4813 - val_loss: 1.4056\n",
      "Epoch 48/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4793\n",
      "Epoch 48: val_loss improved from 1.40546 to 1.40422, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 72s 2ms/sample - loss: 1.4793 - val_loss: 1.4042\n",
      "Epoch 49/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4816\n",
      "Epoch 49: val_loss improved from 1.40422 to 1.40212, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 86s 3ms/sample - loss: 1.4816 - val_loss: 1.4021\n",
      "Epoch 50/50\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4783 \n",
      "Epoch 50: val_loss improved from 1.40212 to 1.40177, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_44.h5\n",
      "32582/32582 [==============================] - 93s 3ms/sample - loss: 1.4783 - val_loss: 1.4018\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 22:40:27.072983: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_553_1/lstm_cell_1626/bias/Assign' id:822859 op device:{requested: '', assigned: ''} def:{{{node lstm_553_1/lstm_cell_1626/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_553_1/lstm_cell_1626/bias, lstm_553_1/lstm_cell_1626/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 22:41:25.975968: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_534_1/lstm_cell_1607/recurrent_kernel/v/Assign' id:824728 op device:{requested: '', assigned: ''} def:{{{node lstm_534_1/lstm_cell_1607/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_534_1/lstm_cell_1607/recurrent_kernel/v, lstm_534_1/lstm_cell_1607/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 22:42:21.122460: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_74_1/cond/Merge' id:823179 op device:{requested: '', assigned: ''} def:{{{node dropout_74_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_74_1/cond/Identity, dropout_74_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499, 804)\n",
      "(1704, 804)\n",
      "(1704, 804)\n",
      "(1848, 804)\n",
      "(1736, 804)\n",
      "(1378, 804)\n",
      "(1802, 804)\n",
      "(1582, 804)\n",
      "(1716, 804)\n",
      "(1538, 804)\n",
      "(1908, 804)\n",
      "(1727, 804)\n",
      "(1776, 804)\n",
      "(1848, 804)\n",
      "(1752, 804)\n",
      "(1812, 804)\n",
      "(959, 804)\n",
      "(1656, 804)\n",
      "(1896, 804)\n",
      "{2: 4.177583913800552, 4: 8.005550061876946, 5: 5.868600358880975, 6: 5.4199013688381426, 8: 9.002697717965463, 9: 5.74511002087716, 10: 7.861940815989279, 11: 6.8762259154148255, 12: 8.58791282072264, 13: 8.333498940732564, 17: 8.434382008978933, 19: 7.444135133512331, 21: 10.0, 22: 1.0, 25: 7.063903555918534, 26: 6.728639435142386, 27: 5.501878625540062, 28: 6.992754897683852, 29: 1.7843393141515684}\n",
      "Train on 32582 samples, validate on 3615 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 22:52:37.114217: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 11.5248\n",
      "Epoch 1: val_loss improved from inf to 1.43550, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 189s 6ms/sample - loss: 11.5248 - val_loss: 1.4355\n",
      "Epoch 2/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.1972\n",
      "Epoch 2: val_loss did not improve from 1.43550\n",
      "32582/32582 [==============================] - 136s 4ms/sample - loss: 11.1972 - val_loss: 1.4412\n",
      "Epoch 3/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0925\n",
      "Epoch 3: val_loss did not improve from 1.43550\n",
      "32582/32582 [==============================] - 177s 5ms/sample - loss: 11.0925 - val_loss: 1.4387\n",
      "Epoch 4/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 11.0398\n",
      "Epoch 4: val_loss improved from 1.43550 to 1.43485, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 157s 5ms/sample - loss: 11.0398 - val_loss: 1.4348\n",
      "Epoch 5/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.9349\n",
      "Epoch 5: val_loss improved from 1.43485 to 1.41373, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 98s 3ms/sample - loss: 10.9349 - val_loss: 1.4137\n",
      "Epoch 6/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.9022\n",
      "Epoch 6: val_loss improved from 1.41373 to 1.41345, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 117s 4ms/sample - loss: 10.9022 - val_loss: 1.4135\n",
      "Epoch 7/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8631\n",
      "Epoch 7: val_loss did not improve from 1.41345\n",
      "32582/32582 [==============================] - 83s 3ms/sample - loss: 10.8631 - val_loss: 1.4176\n",
      "Epoch 8/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.8079\n",
      "Epoch 8: val_loss improved from 1.41345 to 1.41163, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 81s 2ms/sample - loss: 10.8079 - val_loss: 1.4116\n",
      "Epoch 9/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7935\n",
      "Epoch 9: val_loss did not improve from 1.41163\n",
      "32582/32582 [==============================] - 78s 2ms/sample - loss: 10.7935 - val_loss: 1.4120\n",
      "Epoch 10/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7742\n",
      "Epoch 10: val_loss improved from 1.41163 to 1.40038, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 68s 2ms/sample - loss: 10.7742 - val_loss: 1.4004\n",
      "Epoch 11/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7440\n",
      "Epoch 11: val_loss did not improve from 1.40038\n",
      "32582/32582 [==============================] - 65s 2ms/sample - loss: 10.7440 - val_loss: 1.4115\n",
      "Epoch 12/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.7295\n",
      "Epoch 12: val_loss did not improve from 1.40038\n",
      "32582/32582 [==============================] - 71s 2ms/sample - loss: 10.7295 - val_loss: 1.4053\n",
      "Epoch 13/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6974\n",
      "Epoch 13: val_loss did not improve from 1.40038\n",
      "32582/32582 [==============================] - 82s 3ms/sample - loss: 10.6974 - val_loss: 1.4015\n",
      "Epoch 14/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6646\n",
      "Epoch 14: val_loss improved from 1.40038 to 1.39433, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 79s 2ms/sample - loss: 10.6646 - val_loss: 1.3943\n",
      "Epoch 15/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6113\n",
      "Epoch 15: val_loss did not improve from 1.39433\n",
      "32582/32582 [==============================] - 63s 2ms/sample - loss: 10.6113 - val_loss: 1.3943\n",
      "Epoch 16/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6296\n",
      "Epoch 16: val_loss improved from 1.39433 to 1.39270, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 71s 2ms/sample - loss: 10.6296 - val_loss: 1.3927\n",
      "Epoch 17/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.5983\n",
      "Epoch 17: val_loss did not improve from 1.39270\n",
      "32582/32582 [==============================] - 61s 2ms/sample - loss: 10.5983 - val_loss: 1.3931\n",
      "Epoch 18/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.6020\n",
      "Epoch 18: val_loss improved from 1.39270 to 1.38991, saving model to ./checkpoints/unknown_person_few_shot_p1_44.h5\n",
      "32582/32582 [==============================] - 79s 2ms/sample - loss: 10.6020 - val_loss: 1.3899\n",
      "Epoch 19/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.5695\n",
      "Epoch 19: val_loss did not improve from 1.38991\n",
      "32582/32582 [==============================] - 83s 3ms/sample - loss: 10.5695 - val_loss: 1.3934\n",
      "Epoch 20/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 10.5597\n",
      "Epoch 20: val_loss did not improve from 1.38991\n",
      "32582/32582 [==============================] - 82s 3ms/sample - loss: 10.5597 - val_loss: 1.3989\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:24:56.767551: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_536_2/lstm_cell_1646/kernel/Assign' id:839506 op device:{requested: '', assigned: ''} def:{{{node lstm_536_2/lstm_cell_1646/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_536_2/lstm_cell_1646/kernel, lstm_536_2/lstm_cell_1646/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 23:25:56.485762: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_537_2/lstm_cell_1647/kernel/m/Assign' id:843523 op device:{requested: '', assigned: ''} def:{{{node lstm_537_2/lstm_cell_1647/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_537_2/lstm_cell_1647/kernel/m, lstm_537_2/lstm_cell_1647/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32582 samples, validate on 3615 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:26:59.744687: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:32:07.022406: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:32:55.196171: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39459, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 136s 4ms/sample - loss: 1.4767 - val_loss: 1.3946\n",
      "Epoch 2/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 2: val_loss improved from 1.39459 to 1.38615, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 62s 2ms/sample - loss: 1.4658 - val_loss: 1.3862\n",
      "Epoch 3/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4656\n",
      "Epoch 3: val_loss did not improve from 1.38615\n",
      "32582/32582 [==============================] - 63s 2ms/sample - loss: 1.4656 - val_loss: 1.3903\n",
      "Epoch 4/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4587\n",
      "Epoch 4: val_loss improved from 1.38615 to 1.38498, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 61s 2ms/sample - loss: 1.4587 - val_loss: 1.3850\n",
      "Epoch 5/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4558\n",
      "Epoch 5: val_loss did not improve from 1.38498\n",
      "32582/32582 [==============================] - 63s 2ms/sample - loss: 1.4558 - val_loss: 1.3852\n",
      "Epoch 6/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4499\n",
      "Epoch 6: val_loss improved from 1.38498 to 1.38115, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 48s 1ms/sample - loss: 1.4499 - val_loss: 1.3812\n",
      "Epoch 7/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4494\n",
      "Epoch 7: val_loss did not improve from 1.38115\n",
      "32582/32582 [==============================] - 59s 2ms/sample - loss: 1.4494 - val_loss: 1.3866\n",
      "Epoch 8/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4462\n",
      "Epoch 8: val_loss improved from 1.38115 to 1.37575, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 58s 2ms/sample - loss: 1.4462 - val_loss: 1.3757\n",
      "Epoch 9/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4422\n",
      "Epoch 9: val_loss improved from 1.37575 to 1.37565, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 59s 2ms/sample - loss: 1.4422 - val_loss: 1.3757\n",
      "Epoch 10/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4417\n",
      "Epoch 10: val_loss did not improve from 1.37565\n",
      "32582/32582 [==============================] - 47s 1ms/sample - loss: 1.4417 - val_loss: 1.3768\n",
      "Epoch 11/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4409\n",
      "Epoch 11: val_loss did not improve from 1.37565\n",
      "32582/32582 [==============================] - 48s 1ms/sample - loss: 1.4409 - val_loss: 1.3766\n",
      "Epoch 12/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4351\n",
      "Epoch 12: val_loss improved from 1.37565 to 1.37531, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 49s 1ms/sample - loss: 1.4351 - val_loss: 1.3753\n",
      "Epoch 13/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4331\n",
      "Epoch 13: val_loss improved from 1.37531 to 1.36727, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 49s 2ms/sample - loss: 1.4331 - val_loss: 1.3673\n",
      "Epoch 14/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4310\n",
      "Epoch 14: val_loss did not improve from 1.36727\n",
      "32582/32582 [==============================] - 44s 1ms/sample - loss: 1.4310 - val_loss: 1.3686\n",
      "Epoch 15/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4284\n",
      "Epoch 15: val_loss did not improve from 1.36727\n",
      "32582/32582 [==============================] - 46s 1ms/sample - loss: 1.4284 - val_loss: 1.3703\n",
      "Epoch 16/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 16: val_loss did not improve from 1.36727\n",
      "32582/32582 [==============================] - 48s 1ms/sample - loss: 1.4280 - val_loss: 1.3704\n",
      "Epoch 17/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 17: val_loss improved from 1.36727 to 1.36413, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 44s 1ms/sample - loss: 1.4243 - val_loss: 1.3641\n",
      "Epoch 18/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 18: val_loss improved from 1.36413 to 1.36387, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_44.h5\n",
      "32582/32582 [==============================] - 43s 1ms/sample - loss: 1.4275 - val_loss: 1.3639\n",
      "Epoch 19/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4257\n",
      "Epoch 19: val_loss did not improve from 1.36387\n",
      "32582/32582 [==============================] - 46s 1ms/sample - loss: 1.4257 - val_loss: 1.3695\n",
      "Epoch 20/20\n",
      "32582/32582 [==============================] - ETA: 0s - loss: 1.4230\n",
      "Epoch 20: val_loss did not improve from 1.36387\n",
      "32582/32582 [==============================] - 41s 1ms/sample - loss: 1.4230 - val_loss: 1.3663\n",
      "36353\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:52:24.472039: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_568/lstm_cell_1678/recurrent_kernel/Assign' id:857813 op device:{requested: '', assigned: ''} def:{{{node lstm_568/lstm_cell_1678/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_568/lstm_cell_1678/recurrent_kernel, lstm_568/lstm_cell_1678/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 23:52:52.522372: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_1' id:859266 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-17 23:53:15.554275: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_2' id:859267 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32719, 95)\n",
      "Train on 32719 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:54:06.324257: W tensorflow/c/c_api.cc:304] Operation '{name:'training_90/Adam/lstm_583/lstm_cell_1693/recurrent_kernel/m/Assign' id:872449 op device:{requested: '', assigned: ''} def:{{{node training_90/Adam/lstm_583/lstm_cell_1693/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_90/Adam/lstm_583/lstm_cell_1693/recurrent_kernel/m, training_90/Adam/lstm_583/lstm_cell_1693/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 23:58:38.970848: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 4.5292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-17 23:59:24.964609: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_91/mul' id:862107 op device:{requested: '', assigned: ''} def:{{{node loss_91/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_91/mul/x, loss_91/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.90668, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 301s 9ms/sample - loss: 4.5292 - val_loss: 3.9067\n",
      "Epoch 2/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 3.2821\n",
      "Epoch 2: val_loss improved from 3.90668 to 2.51924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 3.2821 - val_loss: 2.5192\n",
      "Epoch 3/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 2.2394\n",
      "Epoch 3: val_loss improved from 2.51924 to 2.11802, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 2.2394 - val_loss: 2.1180\n",
      "Epoch 4/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 2.1279\n",
      "Epoch 4: val_loss improved from 2.11802 to 1.88623, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 2.1279 - val_loss: 1.8862\n",
      "Epoch 5/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.8997\n",
      "Epoch 5: val_loss improved from 1.88623 to 1.79801, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.8997 - val_loss: 1.7980\n",
      "Epoch 6/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7668\n",
      "Epoch 6: val_loss improved from 1.79801 to 1.64827, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.7668 - val_loss: 1.6483\n",
      "Epoch 7/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6985\n",
      "Epoch 7: val_loss improved from 1.64827 to 1.59898, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.6985 - val_loss: 1.5990\n",
      "Epoch 8/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6547\n",
      "Epoch 8: val_loss improved from 1.59898 to 1.55720, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.6547 - val_loss: 1.5572\n",
      "Epoch 9/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6184\n",
      "Epoch 9: val_loss improved from 1.55720 to 1.54284, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.6184 - val_loss: 1.5428\n",
      "Epoch 10/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5848\n",
      "Epoch 10: val_loss improved from 1.54284 to 1.53467, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.5848 - val_loss: 1.5347\n",
      "Epoch 11/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6220\n",
      "Epoch 11: val_loss improved from 1.53467 to 1.53278, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.6220 - val_loss: 1.5328\n",
      "Epoch 12/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5650\n",
      "Epoch 12: val_loss improved from 1.53278 to 1.51916, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.5650 - val_loss: 1.5192\n",
      "Epoch 13/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7117\n",
      "Epoch 13: val_loss improved from 1.51916 to 1.51537, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 1.7117 - val_loss: 1.5154\n",
      "Epoch 14/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6049\n",
      "Epoch 14: val_loss did not improve from 1.51537\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.6049 - val_loss: 1.5383\n",
      "Epoch 15/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5489\n",
      "Epoch 15: val_loss improved from 1.51537 to 1.49989, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.5489 - val_loss: 1.4999\n",
      "Epoch 16/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7335\n",
      "Epoch 16: val_loss did not improve from 1.49989\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.7335 - val_loss: 1.5655\n",
      "Epoch 17/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6997\n",
      "Epoch 17: val_loss did not improve from 1.49989\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.6997 - val_loss: 1.6296\n",
      "Epoch 18/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5692\n",
      "Epoch 18: val_loss improved from 1.49989 to 1.48712, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.5692 - val_loss: 1.4871\n",
      "Epoch 19/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6043\n",
      "Epoch 19: val_loss did not improve from 1.48712\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.6043 - val_loss: 1.5054\n",
      "Epoch 20/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7340\n",
      "Epoch 20: val_loss did not improve from 1.48712\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.7340 - val_loss: 1.6423\n",
      "Epoch 21/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5681\n",
      "Epoch 21: val_loss did not improve from 1.48712\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.5681 - val_loss: 1.4970\n",
      "Epoch 22/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5459\n",
      "Epoch 22: val_loss improved from 1.48712 to 1.48495, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.5459 - val_loss: 1.4850\n",
      "Epoch 23/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5287\n",
      "Epoch 23: val_loss improved from 1.48495 to 1.47759, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.5287 - val_loss: 1.4776\n",
      "Epoch 24/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5199\n",
      "Epoch 24: val_loss improved from 1.47759 to 1.47470, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 1.5199 - val_loss: 1.4747\n",
      "Epoch 25/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5118\n",
      "Epoch 25: val_loss improved from 1.47470 to 1.46539, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 34s 1ms/sample - loss: 1.5118 - val_loss: 1.4654\n",
      "Epoch 26/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5086\n",
      "Epoch 26: val_loss improved from 1.46539 to 1.46148, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.5086 - val_loss: 1.4615\n",
      "Epoch 27/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5066\n",
      "Epoch 27: val_loss improved from 1.46148 to 1.45777, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.5066 - val_loss: 1.4578\n",
      "Epoch 28/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5014\n",
      "Epoch 28: val_loss improved from 1.45777 to 1.45405, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.5014 - val_loss: 1.4541\n",
      "Epoch 29/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5012\n",
      "Epoch 29: val_loss improved from 1.45405 to 1.45010, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.5012 - val_loss: 1.4501\n",
      "Epoch 30/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4966\n",
      "Epoch 30: val_loss improved from 1.45010 to 1.44842, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.4966 - val_loss: 1.4484\n",
      "Epoch 31/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4934\n",
      "Epoch 31: val_loss improved from 1.44842 to 1.44497, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 1.4934 - val_loss: 1.4450\n",
      "Epoch 32/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4908\n",
      "Epoch 32: val_loss improved from 1.44497 to 1.44278, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.4908 - val_loss: 1.4428\n",
      "Epoch 33/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4923\n",
      "Epoch 33: val_loss improved from 1.44278 to 1.44065, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4923 - val_loss: 1.4406\n",
      "Epoch 34/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 34: val_loss improved from 1.44065 to 1.43672, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.4836 - val_loss: 1.4367\n",
      "Epoch 35/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4847\n",
      "Epoch 35: val_loss improved from 1.43672 to 1.43640, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.4847 - val_loss: 1.4364\n",
      "Epoch 36/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4825\n",
      "Epoch 36: val_loss improved from 1.43640 to 1.43185, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4825 - val_loss: 1.4318\n",
      "Epoch 37/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4793\n",
      "Epoch 37: val_loss improved from 1.43185 to 1.43091, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 52s 2ms/sample - loss: 1.4793 - val_loss: 1.4309\n",
      "Epoch 38/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4798\n",
      "Epoch 38: val_loss improved from 1.43091 to 1.43070, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 48s 1ms/sample - loss: 1.4798 - val_loss: 1.4307\n",
      "Epoch 39/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4769\n",
      "Epoch 39: val_loss improved from 1.43070 to 1.42776, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.4769 - val_loss: 1.4278\n",
      "Epoch 40/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4739\n",
      "Epoch 40: val_loss improved from 1.42776 to 1.42479, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4739 - val_loss: 1.4248\n",
      "Epoch 41/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4746\n",
      "Epoch 41: val_loss did not improve from 1.42479\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.4746 - val_loss: 1.4254\n",
      "Epoch 42/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4735\n",
      "Epoch 42: val_loss improved from 1.42479 to 1.42209, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4735 - val_loss: 1.4221\n",
      "Epoch 43/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4698\n",
      "Epoch 43: val_loss improved from 1.42209 to 1.41943, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.4698 - val_loss: 1.4194\n",
      "Epoch 44/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4676\n",
      "Epoch 44: val_loss improved from 1.41943 to 1.41939, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.4676 - val_loss: 1.4194\n",
      "Epoch 45/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4683\n",
      "Epoch 45: val_loss improved from 1.41939 to 1.41861, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 33s 996us/sample - loss: 1.4683 - val_loss: 1.4186\n",
      "Epoch 46/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4674\n",
      "Epoch 46: val_loss did not improve from 1.41861\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 1.4674 - val_loss: 1.4199\n",
      "Epoch 47/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 47: val_loss improved from 1.41861 to 1.41363, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4658 - val_loss: 1.4136\n",
      "Epoch 48/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 48: val_loss did not improve from 1.41363\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4623 - val_loss: 1.4147\n",
      "Epoch 49/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4605\n",
      "Epoch 49: val_loss improved from 1.41363 to 1.41168, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4605 - val_loss: 1.4117\n",
      "Epoch 50/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4619\n",
      "Epoch 50: val_loss improved from 1.41168 to 1.41149, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_45.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.4619 - val_loss: 1.4115\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 00:36:09.003156: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_564_1/lstm_cell_1711/recurrent_kernel/Assign' id:875730 op device:{requested: '', assigned: ''} def:{{{node lstm_564_1/lstm_cell_1711/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_564_1/lstm_cell_1711/recurrent_kernel, lstm_564_1/lstm_cell_1711/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 00:37:03.111988: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_591_1/lstm_cell_1738/kernel/v/Assign' id:882065 op device:{requested: '', assigned: ''} def:{{{node lstm_591_1/lstm_cell_1738/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_591_1/lstm_cell_1738/kernel/v, lstm_591_1/lstm_cell_1738/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 00:37:56.320051: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_79_1/cond/Merge' id:880221 op device:{requested: '', assigned: ''} def:{{{node dropout_79_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_79_1/cond/Identity, dropout_79_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1491, 648)\n",
      "(1704, 648)\n",
      "(1704, 648)\n",
      "(1848, 648)\n",
      "(1723, 648)\n",
      "(1358, 648)\n",
      "(1824, 648)\n",
      "(1559, 648)\n",
      "(1740, 648)\n",
      "(1526, 648)\n",
      "(1920, 648)\n",
      "(1739, 648)\n",
      "(1764, 648)\n",
      "(1848, 648)\n",
      "(1752, 648)\n",
      "(1800, 648)\n",
      "(946, 648)\n",
      "(1680, 648)\n",
      "(1896, 648)\n",
      "{2: 6.559524878233354, 4: 9.004412162939166, 5: 5.120766545611022, 6: 4.685872843348555, 8: 9.439801463796448, 9: 7.606048083450494, 10: 7.680856762361215, 11: 7.7758247302214984, 12: 8.962572661208652, 13: 7.991775140685454, 17: 9.178104632140458, 19: 8.13176097012683, 21: 10.0, 22: 1.0, 25: 7.6131259436219505, 26: 6.817618975194104, 27: 7.274608362113416, 28: 6.093101312075023, 29: 1.1744032228746943}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2905707/2131643591.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32719 samples, validate on 3634 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 00:47:04.558122: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 12.1951\n",
      "Epoch 1: val_loss improved from inf to 1.45451, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 136s 4ms/sample - loss: 12.1951 - val_loss: 1.4545\n",
      "Epoch 2/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.8591\n",
      "Epoch 2: val_loss improved from 1.45451 to 1.44087, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 11.8591 - val_loss: 1.4409\n",
      "Epoch 3/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.6861\n",
      "Epoch 3: val_loss improved from 1.44087 to 1.44073, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 11.6861 - val_loss: 1.4407\n",
      "Epoch 4/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.5960\n",
      "Epoch 4: val_loss improved from 1.44073 to 1.43176, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 11.5960 - val_loss: 1.4318\n",
      "Epoch 5/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.5344\n",
      "Epoch 5: val_loss did not improve from 1.43176\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 11.5344 - val_loss: 1.4352\n",
      "Epoch 6/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.4972\n",
      "Epoch 6: val_loss did not improve from 1.43176\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 11.4972 - val_loss: 1.4459\n",
      "Epoch 7/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.4761\n",
      "Epoch 7: val_loss improved from 1.43176 to 1.42430, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 11.4761 - val_loss: 1.4243\n",
      "Epoch 8/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.4298\n",
      "Epoch 8: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 11.4298 - val_loss: 1.4284\n",
      "Epoch 9/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.3790\n",
      "Epoch 9: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 11.3790 - val_loss: 1.4307\n",
      "Epoch 10/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.3086\n",
      "Epoch 10: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 11.3086 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.2750\n",
      "Epoch 11: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 11.2750 - val_loss: 1.4373\n",
      "Epoch 12/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.2677\n",
      "Epoch 12: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 11.2677 - val_loss: 1.4309\n",
      "Epoch 13/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.2651\n",
      "Epoch 13: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 11.2651 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.2445\n",
      "Epoch 14: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 11.2445 - val_loss: 1.4388\n",
      "Epoch 15/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.2152\n",
      "Epoch 15: val_loss did not improve from 1.42430\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 11.2152 - val_loss: 1.4335\n",
      "Epoch 16/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1812\n",
      "Epoch 16: val_loss improved from 1.42430 to 1.41865, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 11.1812 - val_loss: 1.4186\n",
      "Epoch 17/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1955\n",
      "Epoch 17: val_loss did not improve from 1.41865\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 11.1955 - val_loss: 1.4198\n",
      "Epoch 18/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1690\n",
      "Epoch 18: val_loss improved from 1.41865 to 1.41382, saving model to ./checkpoints/unknown_person_few_shot_p1_45.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 11.1690 - val_loss: 1.4138\n",
      "Epoch 19/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1664\n",
      "Epoch 19: val_loss did not improve from 1.41382\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 11.1664 - val_loss: 1.4288\n",
      "Epoch 20/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1180\n",
      "Epoch 20: val_loss did not improve from 1.41382\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 11.1180 - val_loss: 1.4191\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:02:04.958494: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_587_2/lstm_cell_1771/kernel/Assign' id:898790 op device:{requested: '', assigned: ''} def:{{{node lstm_587_2/lstm_cell_1771/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_587_2/lstm_cell_1771/kernel, lstm_587_2/lstm_cell_1771/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 01:02:55.067340: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_577_2/lstm_cell_1761/recurrent_kernel/v/Assign' id:901258 op device:{requested: '', assigned: ''} def:{{{node lstm_577_2/lstm_cell_1761/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_577_2/lstm_cell_1761/recurrent_kernel/v, lstm_577_2/lstm_cell_1761/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32719 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:03:47.886401: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:08:15.609516: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:09:02.153003: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41077, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 136s 4ms/sample - loss: 1.4608 - val_loss: 1.4108\n",
      "Epoch 2/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 2: val_loss improved from 1.41077 to 1.40675, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 55s 2ms/sample - loss: 1.4535 - val_loss: 1.4067\n",
      "Epoch 3/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4475\n",
      "Epoch 3: val_loss improved from 1.40675 to 1.39634, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 47s 1ms/sample - loss: 1.4475 - val_loss: 1.3963\n",
      "Epoch 4/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4467\n",
      "Epoch 4: val_loss improved from 1.39634 to 1.39317, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 46s 1ms/sample - loss: 1.4467 - val_loss: 1.3932\n",
      "Epoch 5/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4444\n",
      "Epoch 5: val_loss did not improve from 1.39317\n",
      "32719/32719 [==============================] - 47s 1ms/sample - loss: 1.4444 - val_loss: 1.3941\n",
      "Epoch 6/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4376\n",
      "Epoch 6: val_loss did not improve from 1.39317\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 1.4376 - val_loss: 1.3960\n",
      "Epoch 7/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4343\n",
      "Epoch 7: val_loss improved from 1.39317 to 1.38943, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 46s 1ms/sample - loss: 1.4343 - val_loss: 1.3894\n",
      "Epoch 8/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4301\n",
      "Epoch 8: val_loss did not improve from 1.38943\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4301 - val_loss: 1.3897\n",
      "Epoch 9/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4284\n",
      "Epoch 9: val_loss improved from 1.38943 to 1.38546, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.4284 - val_loss: 1.3855\n",
      "Epoch 10/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 10: val_loss did not improve from 1.38546\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.4252 - val_loss: 1.3867\n",
      "Epoch 11/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4244\n",
      "Epoch 11: val_loss improved from 1.38546 to 1.38241, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.4244 - val_loss: 1.3824\n",
      "Epoch 12/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 12: val_loss did not improve from 1.38241\n",
      "32719/32719 [==============================] - 48s 1ms/sample - loss: 1.4204 - val_loss: 1.3824\n",
      "Epoch 13/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 13: val_loss improved from 1.38241 to 1.38146, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 1.4225 - val_loss: 1.3815\n",
      "Epoch 14/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 14: val_loss did not improve from 1.38146\n",
      "32719/32719 [==============================] - 46s 1ms/sample - loss: 1.4191 - val_loss: 1.3830\n",
      "Epoch 15/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 15: val_loss improved from 1.38146 to 1.37725, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 52s 2ms/sample - loss: 1.4176 - val_loss: 1.3773\n",
      "Epoch 16/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4139\n",
      "Epoch 16: val_loss did not improve from 1.37725\n",
      "32719/32719 [==============================] - 47s 1ms/sample - loss: 1.4139 - val_loss: 1.3782\n",
      "Epoch 17/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4137\n",
      "Epoch 17: val_loss did not improve from 1.37725\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4137 - val_loss: 1.3881\n",
      "Epoch 18/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 18: val_loss did not improve from 1.37725\n",
      "32719/32719 [==============================] - 48s 1ms/sample - loss: 1.4141 - val_loss: 1.3781\n",
      "Epoch 19/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4091\n",
      "Epoch 19: val_loss improved from 1.37725 to 1.37470, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_45.h5\n",
      "32719/32719 [==============================] - 47s 1ms/sample - loss: 1.4091 - val_loss: 1.3747\n",
      "Epoch 20/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 20: val_loss did not improve from 1.37470\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.4066 - val_loss: 1.3749\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:25:33.228136: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_605/lstm_cell_1789/recurrent_kernel/Assign' id:914855 op device:{requested: '', assigned: ''} def:{{{node lstm_605/lstm_cell_1789/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_605/lstm_cell_1789/recurrent_kernel, lstm_605/lstm_cell_1789/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 01:26:05.441549: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_1' id:916308 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 01:26:31.574028: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_2' id:916309 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32719, 95)\n",
      "Train on 32719 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:27:29.791248: W tensorflow/c/c_api.cc:304] Operation '{name:'training_96/Adam/lstm_598/lstm_cell_1782/recurrent_kernel/m/Assign' id:929161 op device:{requested: '', assigned: ''} def:{{{node training_96/Adam/lstm_598/lstm_cell_1782/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_96/Adam/lstm_598/lstm_cell_1782/recurrent_kernel/m, training_96/Adam/lstm_598/lstm_cell_1782/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:33:02.064142: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 4.9797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 01:33:39.398230: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_97/mul' id:919149 op device:{requested: '', assigned: ''} def:{{{node loss_97/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_97/mul/x, loss_97/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.59306, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 341s 10ms/sample - loss: 4.9797 - val_loss: 4.5931\n",
      "Epoch 2/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 4.2300\n",
      "Epoch 2: val_loss improved from 4.59306 to 3.67484, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 4.2300 - val_loss: 3.6748\n",
      "Epoch 3/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 3.0629\n",
      "Epoch 3: val_loss improved from 3.67484 to 2.36614, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 3.0629 - val_loss: 2.3661\n",
      "Epoch 4/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 2.2901\n",
      "Epoch 4: val_loss improved from 2.36614 to 2.02398, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 2.2901 - val_loss: 2.0240\n",
      "Epoch 5/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 2.0491\n",
      "Epoch 5: val_loss improved from 2.02398 to 1.86577, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 2.0491 - val_loss: 1.8658\n",
      "Epoch 6/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.8795\n",
      "Epoch 6: val_loss improved from 1.86577 to 1.70636, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.8795 - val_loss: 1.7064\n",
      "Epoch 7/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7371\n",
      "Epoch 7: val_loss improved from 1.70636 to 1.61918, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.7371 - val_loss: 1.6192\n",
      "Epoch 8/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6595\n",
      "Epoch 8: val_loss improved from 1.61918 to 1.57125, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.6595 - val_loss: 1.5712\n",
      "Epoch 9/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6232\n",
      "Epoch 9: val_loss improved from 1.57125 to 1.54422, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.6232 - val_loss: 1.5442\n",
      "Epoch 10/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5950\n",
      "Epoch 10: val_loss improved from 1.54422 to 1.52288, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.5950 - val_loss: 1.5229\n",
      "Epoch 11/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6062\n",
      "Epoch 11: val_loss did not improve from 1.52288\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.6062 - val_loss: 1.5316\n",
      "Epoch 12/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5635\n",
      "Epoch 12: val_loss improved from 1.52288 to 1.50002, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.5635 - val_loss: 1.5000\n",
      "Epoch 13/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5584\n",
      "Epoch 13: val_loss improved from 1.50002 to 1.49792, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 1.5584 - val_loss: 1.4979\n",
      "Epoch 14/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5589\n",
      "Epoch 14: val_loss improved from 1.49792 to 1.49678, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.5589 - val_loss: 1.4968\n",
      "Epoch 15/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5546\n",
      "Epoch 15: val_loss improved from 1.49678 to 1.49317, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.5546 - val_loss: 1.4932\n",
      "Epoch 16/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5587\n",
      "Epoch 16: val_loss did not improve from 1.49317\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.5587 - val_loss: 1.4956\n",
      "Epoch 17/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6574\n",
      "Epoch 17: val_loss did not improve from 1.49317\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.6574 - val_loss: 1.6053\n",
      "Epoch 18/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5549\n",
      "Epoch 18: val_loss did not improve from 1.49317\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.5549 - val_loss: 1.4941\n",
      "Epoch 19/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5746\n",
      "Epoch 19: val_loss did not improve from 1.49317\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.5746 - val_loss: 1.5171\n",
      "Epoch 20/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5498\n",
      "Epoch 20: val_loss improved from 1.49317 to 1.48867, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.5498 - val_loss: 1.4887\n",
      "Epoch 21/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5467\n",
      "Epoch 21: val_loss did not improve from 1.48867\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 1.5467 - val_loss: 1.4898\n",
      "Epoch 22/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5635\n",
      "Epoch 22: val_loss did not improve from 1.48867\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.5635 - val_loss: 1.5142\n",
      "Epoch 23/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5393\n",
      "Epoch 23: val_loss did not improve from 1.48867\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.5393 - val_loss: 1.4901\n",
      "Epoch 24/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5280\n",
      "Epoch 24: val_loss improved from 1.48867 to 1.48425, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.5280 - val_loss: 1.4843\n",
      "Epoch 25/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5274\n",
      "Epoch 25: val_loss did not improve from 1.48425\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.5274 - val_loss: 1.4855\n",
      "Epoch 26/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5195\n",
      "Epoch 26: val_loss improved from 1.48425 to 1.47673, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.5195 - val_loss: 1.4767\n",
      "Epoch 27/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5154\n",
      "Epoch 27: val_loss improved from 1.47673 to 1.47302, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.5154 - val_loss: 1.4730\n",
      "Epoch 28/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5135\n",
      "Epoch 28: val_loss improved from 1.47302 to 1.47027, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.5135 - val_loss: 1.4703\n",
      "Epoch 29/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5088\n",
      "Epoch 29: val_loss improved from 1.47027 to 1.46652, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.5088 - val_loss: 1.4665\n",
      "Epoch 30/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5072\n",
      "Epoch 30: val_loss improved from 1.46652 to 1.46285, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.5072 - val_loss: 1.4628\n",
      "Epoch 31/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 31: val_loss improved from 1.46285 to 1.46017, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.5028 - val_loss: 1.4602\n",
      "Epoch 32/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5012\n",
      "Epoch 32: val_loss improved from 1.46017 to 1.45923, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.5012 - val_loss: 1.4592\n",
      "Epoch 33/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5001\n",
      "Epoch 33: val_loss improved from 1.45923 to 1.45550, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.5001 - val_loss: 1.4555\n",
      "Epoch 34/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4959\n",
      "Epoch 34: val_loss improved from 1.45550 to 1.45474, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.4959 - val_loss: 1.4547\n",
      "Epoch 35/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4933\n",
      "Epoch 35: val_loss improved from 1.45474 to 1.45007, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 1.4933 - val_loss: 1.4501\n",
      "Epoch 36/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4904\n",
      "Epoch 36: val_loss improved from 1.45007 to 1.44958, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 46s 1ms/sample - loss: 1.4904 - val_loss: 1.4496\n",
      "Epoch 37/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4882\n",
      "Epoch 37: val_loss improved from 1.44958 to 1.44556, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.4882 - val_loss: 1.4456\n",
      "Epoch 38/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4853\n",
      "Epoch 38: val_loss improved from 1.44556 to 1.44300, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.4853 - val_loss: 1.4430\n",
      "Epoch 39/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4826\n",
      "Epoch 39: val_loss improved from 1.44300 to 1.43965, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 1.4826 - val_loss: 1.4396\n",
      "Epoch 40/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4834\n",
      "Epoch 40: val_loss improved from 1.43965 to 1.43851, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4834 - val_loss: 1.4385\n",
      "Epoch 41/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 41: val_loss improved from 1.43851 to 1.43568, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.4781 - val_loss: 1.4357\n",
      "Epoch 42/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4768\n",
      "Epoch 42: val_loss improved from 1.43568 to 1.43305, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.4768 - val_loss: 1.4331\n",
      "Epoch 43/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4757\n",
      "Epoch 43: val_loss improved from 1.43305 to 1.43202, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.4757 - val_loss: 1.4320\n",
      "Epoch 44/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4727\n",
      "Epoch 44: val_loss improved from 1.43202 to 1.43110, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4727 - val_loss: 1.4311\n",
      "Epoch 45/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4719\n",
      "Epoch 45: val_loss improved from 1.43110 to 1.42735, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 1.4719 - val_loss: 1.4273\n",
      "Epoch 46/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4698\n",
      "Epoch 46: val_loss did not improve from 1.42735\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 1.4698 - val_loss: 1.4289\n",
      "Epoch 47/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4674\n",
      "Epoch 47: val_loss improved from 1.42735 to 1.42450, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4674 - val_loss: 1.4245\n",
      "Epoch 48/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4671\n",
      "Epoch 48: val_loss improved from 1.42450 to 1.42386, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.4671 - val_loss: 1.4239\n",
      "Epoch 49/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4655\n",
      "Epoch 49: val_loss improved from 1.42386 to 1.42356, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.4655 - val_loss: 1.4236\n",
      "Epoch 50/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4637\n",
      "Epoch 50: val_loss improved from 1.42356 to 1.42045, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_46.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.4637 - val_loss: 1.4204\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:11:30.312138: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_624_1/lstm_cell_1845/kernel/Assign' id:936434 op device:{requested: '', assigned: ''} def:{{{node lstm_624_1/lstm_cell_1845/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_624_1/lstm_cell_1845/kernel, lstm_624_1/lstm_cell_1845/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 02:12:35.047346: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_592_1/lstm_cell_1813/kernel/v/Assign' id:938567 op device:{requested: '', assigned: ''} def:{{{node lstm_592_1/lstm_cell_1813/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_592_1/lstm_cell_1813/kernel/v, lstm_592_1/lstm_cell_1813/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 02:13:37.994077: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_84_1/cond/Merge' id:937263 op device:{requested: '', assigned: ''} def:{{{node dropout_84_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_84_1/cond/Identity, dropout_84_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1491, 648)\n",
      "(1704, 648)\n",
      "(1704, 648)\n",
      "(1848, 648)\n",
      "(1723, 648)\n",
      "(1358, 648)\n",
      "(1824, 648)\n",
      "(1559, 648)\n",
      "(1740, 648)\n",
      "(1526, 648)\n",
      "(1920, 648)\n",
      "(1739, 648)\n",
      "(1764, 648)\n",
      "(1848, 648)\n",
      "(1752, 648)\n",
      "(1800, 648)\n",
      "(946, 648)\n",
      "(1680, 648)\n",
      "(1896, 648)\n",
      "{2: 5.523333168627249, 4: 8.00210870184, 5: 5.231675346213349, 6: 4.762641597936673, 8: 9.113581083761396, 9: 6.30374910484563, 10: 7.728189028765338, 11: 6.91215482186341, 12: 8.440820291975172, 13: 8.687173734065556, 17: 8.506327845373, 19: 7.656557192795895, 21: 10.0, 22: 1.7163274069300432, 25: 7.314319755752476, 26: 6.702250604250948, 27: 6.160148597365306, 28: 6.840460351185849, 29: 1.0}\n",
      "Train on 32719 samples, validate on 3634 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:22:38.933838: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 11.7532\n",
      "Epoch 1: val_loss improved from inf to 1.46819, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 154s 5ms/sample - loss: 11.7532 - val_loss: 1.4682\n",
      "Epoch 2/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.4331\n",
      "Epoch 2: val_loss improved from 1.46819 to 1.44830, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 11.4331 - val_loss: 1.4483\n",
      "Epoch 3/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.2793\n",
      "Epoch 3: val_loss improved from 1.44830 to 1.43289, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 11.2793 - val_loss: 1.4329\n",
      "Epoch 4/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1988\n",
      "Epoch 4: val_loss improved from 1.43289 to 1.42946, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 11.1988 - val_loss: 1.4295\n",
      "Epoch 5/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1416\n",
      "Epoch 5: val_loss did not improve from 1.42946\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 11.1416 - val_loss: 1.4352\n",
      "Epoch 6/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1276\n",
      "Epoch 6: val_loss did not improve from 1.42946\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 11.1276 - val_loss: 1.4509\n",
      "Epoch 7/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.0582\n",
      "Epoch 7: val_loss did not improve from 1.42946\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 11.0582 - val_loss: 1.4325\n",
      "Epoch 8/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.0319\n",
      "Epoch 8: val_loss improved from 1.42946 to 1.42069, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 48s 1ms/sample - loss: 11.0319 - val_loss: 1.4207\n",
      "Epoch 9/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.0002\n",
      "Epoch 9: val_loss improved from 1.42069 to 1.41675, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 11.0002 - val_loss: 1.4168\n",
      "Epoch 10/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.9596\n",
      "Epoch 10: val_loss did not improve from 1.41675\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 10.9596 - val_loss: 1.4336\n",
      "Epoch 11/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.9508\n",
      "Epoch 11: val_loss did not improve from 1.41675\n",
      "32719/32719 [==============================] - 48s 1ms/sample - loss: 10.9508 - val_loss: 1.4227\n",
      "Epoch 12/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8833\n",
      "Epoch 12: val_loss did not improve from 1.41675\n",
      "32719/32719 [==============================] - 47s 1ms/sample - loss: 10.8833 - val_loss: 1.4182\n",
      "Epoch 13/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.9043\n",
      "Epoch 13: val_loss did not improve from 1.41675\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 10.9043 - val_loss: 1.4318\n",
      "Epoch 14/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8664\n",
      "Epoch 14: val_loss improved from 1.41675 to 1.40845, saving model to ./checkpoints/unknown_person_few_shot_p1_46.h5\n",
      "32719/32719 [==============================] - 46s 1ms/sample - loss: 10.8664 - val_loss: 1.4084\n",
      "Epoch 15/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8368\n",
      "Epoch 15: val_loss did not improve from 1.40845\n",
      "32719/32719 [==============================] - 45s 1ms/sample - loss: 10.8368 - val_loss: 1.4155\n",
      "Epoch 16/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8115\n",
      "Epoch 16: val_loss did not improve from 1.40845\n",
      "32719/32719 [==============================] - 50s 2ms/sample - loss: 10.8115 - val_loss: 1.4318\n",
      "Epoch 17/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7729\n",
      "Epoch 17: val_loss did not improve from 1.40845\n",
      "32719/32719 [==============================] - 50s 2ms/sample - loss: 10.7729 - val_loss: 1.4217\n",
      "Epoch 18/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7965\n",
      "Epoch 18: val_loss did not improve from 1.40845\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 10.7965 - val_loss: 1.4172\n",
      "Epoch 19/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7922\n",
      "Epoch 19: val_loss did not improve from 1.40845\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 10.7922 - val_loss: 1.4123\n",
      "Epoch 20/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7608\n",
      "Epoch 20: val_loss did not improve from 1.40845\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 10.7608 - val_loss: 1.4146\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:39:53.513723: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_66_2/bias/Assign' id:950491 op device:{requested: '', assigned: ''} def:{{{node conv2d_66_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_66_2/bias, conv2d_66_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 02:40:50.759845: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_601_2/lstm_cell_1859/kernel/m/Assign' id:957457 op device:{requested: '', assigned: ''} def:{{{node lstm_601_2/lstm_cell_1859/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_601_2/lstm_cell_1859/kernel/m, lstm_601_2/lstm_cell_1859/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32719 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:41:50.401054: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:47:09.305902: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:47:53.043912: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41563, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 159s 5ms/sample - loss: 1.4631 - val_loss: 1.4156\n",
      "Epoch 2/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4554\n",
      "Epoch 2: val_loss improved from 1.41563 to 1.41196, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4554 - val_loss: 1.4120\n",
      "Epoch 3/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4502\n",
      "Epoch 3: val_loss improved from 1.41196 to 1.40569, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.4502 - val_loss: 1.4057\n",
      "Epoch 4/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4452\n",
      "Epoch 4: val_loss improved from 1.40569 to 1.40002, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4452 - val_loss: 1.4000\n",
      "Epoch 5/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4437\n",
      "Epoch 5: val_loss did not improve from 1.40002\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4437 - val_loss: 1.4003\n",
      "Epoch 6/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4386\n",
      "Epoch 6: val_loss improved from 1.40002 to 1.39598, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4386 - val_loss: 1.3960\n",
      "Epoch 7/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4355\n",
      "Epoch 7: val_loss did not improve from 1.39598\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4355 - val_loss: 1.3973\n",
      "Epoch 8/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 8: val_loss improved from 1.39598 to 1.39379, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 44s 1ms/sample - loss: 1.4354 - val_loss: 1.3938\n",
      "Epoch 9/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4332\n",
      "Epoch 9: val_loss did not improve from 1.39379\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.4332 - val_loss: 1.3950\n",
      "Epoch 10/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 10: val_loss improved from 1.39379 to 1.38507, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4280 - val_loss: 1.3851\n",
      "Epoch 11/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4239\n",
      "Epoch 11: val_loss did not improve from 1.38507\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4239 - val_loss: 1.3877\n",
      "Epoch 12/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4235\n",
      "Epoch 12: val_loss did not improve from 1.38507\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4235 - val_loss: 1.3856\n",
      "Epoch 13/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4221\n",
      "Epoch 13: val_loss did not improve from 1.38507\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4221 - val_loss: 1.3861\n",
      "Epoch 14/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4187\n",
      "Epoch 14: val_loss did not improve from 1.38507\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4187 - val_loss: 1.3856\n",
      "Epoch 15/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4189\n",
      "Epoch 15: val_loss improved from 1.38507 to 1.37977, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 1.4189 - val_loss: 1.3798\n",
      "Epoch 16/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4185\n",
      "Epoch 16: val_loss did not improve from 1.37977\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 1.4185 - val_loss: 1.3831\n",
      "Epoch 17/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 17: val_loss improved from 1.37977 to 1.37829, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 1.4158 - val_loss: 1.3783\n",
      "Epoch 18/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4138\n",
      "Epoch 18: val_loss improved from 1.37829 to 1.37769, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_46.h5\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 1.4138 - val_loss: 1.3777\n",
      "Epoch 19/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 19: val_loss did not improve from 1.37769\n",
      "32719/32719 [==============================] - 38s 1ms/sample - loss: 1.4097 - val_loss: 1.3796\n",
      "Epoch 20/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 20: val_loss did not improve from 1.37769\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 1.4063 - val_loss: 1.3778\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 03:03:19.804696: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_636/lstm_cell_1894/bias/Assign' id:970916 op device:{requested: '', assigned: ''} def:{{{node lstm_636/lstm_cell_1894/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_636/lstm_cell_1894/bias, lstm_636/lstm_cell_1894/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 03:03:56.524747: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_1' id:973350 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 03:04:24.862227: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_2' id:973351 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32719, 95)\n",
      "Train on 32719 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 03:05:25.528148: W tensorflow/c/c_api.cc:304] Operation '{name:'training_102/Adam/lstm_665/lstm_cell_1923/bias/m/Assign' id:986658 op device:{requested: '', assigned: ''} def:{{{node training_102/Adam/lstm_665/lstm_cell_1923/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_102/Adam/lstm_665/lstm_cell_1923/bias/m, training_102/Adam/lstm_665/lstm_cell_1923/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 03:10:44.074312: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 4.5936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 03:11:14.340311: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_103/mul' id:976191 op device:{requested: '', assigned: ''} def:{{{node loss_103/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_103/mul/x, loss_103/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.00160, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 325s 10ms/sample - loss: 4.5936 - val_loss: 4.0016\n",
      "Epoch 2/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 3.3746\n",
      "Epoch 2: val_loss improved from 4.00160 to 2.53991, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 29s 874us/sample - loss: 3.3746 - val_loss: 2.5399\n",
      "Epoch 3/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 2.1870\n",
      "Epoch 3: val_loss improved from 2.53991 to 2.01726, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 829us/sample - loss: 2.1870 - val_loss: 2.0173\n",
      "Epoch 4/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 2.0856\n",
      "Epoch 4: val_loss improved from 2.01726 to 1.82822, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 30s 915us/sample - loss: 2.0856 - val_loss: 1.8282\n",
      "Epoch 5/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.8511\n",
      "Epoch 5: val_loss improved from 1.82822 to 1.79078, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 29s 886us/sample - loss: 1.8511 - val_loss: 1.7908\n",
      "Epoch 6/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7693\n",
      "Epoch 6: val_loss improved from 1.79078 to 1.66465, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 30s 924us/sample - loss: 1.7693 - val_loss: 1.6646\n",
      "Epoch 7/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.7047\n",
      "Epoch 7: val_loss improved from 1.66465 to 1.62539, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 30s 919us/sample - loss: 1.7047 - val_loss: 1.6254\n",
      "Epoch 8/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6679\n",
      "Epoch 8: val_loss improved from 1.62539 to 1.60352, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 802us/sample - loss: 1.6679 - val_loss: 1.6035\n",
      "Epoch 9/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6594\n",
      "Epoch 9: val_loss improved from 1.60352 to 1.58748, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 32s 970us/sample - loss: 1.6594 - val_loss: 1.5875\n",
      "Epoch 10/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6117\n",
      "Epoch 10: val_loss improved from 1.58748 to 1.55159, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.6117 - val_loss: 1.5516\n",
      "Epoch 11/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6344\n",
      "Epoch 11: val_loss improved from 1.55159 to 1.55110, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.6344 - val_loss: 1.5511\n",
      "Epoch 12/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5870\n",
      "Epoch 12: val_loss improved from 1.55110 to 1.54068, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 788us/sample - loss: 1.5870 - val_loss: 1.5407\n",
      "Epoch 13/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5917\n",
      "Epoch 13: val_loss improved from 1.54068 to 1.53216, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 25s 759us/sample - loss: 1.5917 - val_loss: 1.5322\n",
      "Epoch 14/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6536\n",
      "Epoch 14: val_loss did not improve from 1.53216\n",
      "32719/32719 [==============================] - 31s 940us/sample - loss: 1.6536 - val_loss: 1.5980\n",
      "Epoch 15/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5550\n",
      "Epoch 15: val_loss improved from 1.53216 to 1.52470, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.5550 - val_loss: 1.5247\n",
      "Epoch 16/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.6354\n",
      "Epoch 16: val_loss did not improve from 1.52470\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.6354 - val_loss: 1.5376\n",
      "Epoch 17/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5940\n",
      "Epoch 17: val_loss did not improve from 1.52470\n",
      "32719/32719 [==============================] - 26s 780us/sample - loss: 1.5940 - val_loss: 1.5461\n",
      "Epoch 18/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5527\n",
      "Epoch 18: val_loss improved from 1.52470 to 1.49949, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 809us/sample - loss: 1.5527 - val_loss: 1.4995\n",
      "Epoch 19/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5690\n",
      "Epoch 19: val_loss did not improve from 1.49949\n",
      "32719/32719 [==============================] - 27s 814us/sample - loss: 1.5690 - val_loss: 1.5216\n",
      "Epoch 20/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5468\n",
      "Epoch 20: val_loss did not improve from 1.49949\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.5468 - val_loss: 1.5000\n",
      "Epoch 21/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5691\n",
      "Epoch 21: val_loss did not improve from 1.49949\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.5691 - val_loss: 1.5240\n",
      "Epoch 22/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5777\n",
      "Epoch 22: val_loss did not improve from 1.49949\n",
      "32719/32719 [==============================] - 31s 943us/sample - loss: 1.5777 - val_loss: 1.5392\n",
      "Epoch 23/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5413\n",
      "Epoch 23: val_loss improved from 1.49949 to 1.49098, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 1.5413 - val_loss: 1.4910\n",
      "Epoch 24/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5347\n",
      "Epoch 24: val_loss improved from 1.49098 to 1.49023, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 34s 1ms/sample - loss: 1.5347 - val_loss: 1.4902\n",
      "Epoch 25/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5268\n",
      "Epoch 25: val_loss improved from 1.49023 to 1.47772, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 25s 774us/sample - loss: 1.5268 - val_loss: 1.4777\n",
      "Epoch 26/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5240\n",
      "Epoch 26: val_loss improved from 1.47772 to 1.47342, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 30s 910us/sample - loss: 1.5240 - val_loss: 1.4734\n",
      "Epoch 27/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5176\n",
      "Epoch 27: val_loss improved from 1.47342 to 1.46964, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 31s 936us/sample - loss: 1.5176 - val_loss: 1.4696\n",
      "Epoch 28/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5179\n",
      "Epoch 28: val_loss improved from 1.46964 to 1.46951, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 31s 938us/sample - loss: 1.5179 - val_loss: 1.4695\n",
      "Epoch 29/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5138\n",
      "Epoch 29: val_loss improved from 1.46951 to 1.46497, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 29s 900us/sample - loss: 1.5138 - val_loss: 1.4650\n",
      "Epoch 30/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5116\n",
      "Epoch 30: val_loss improved from 1.46497 to 1.46357, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 814us/sample - loss: 1.5116 - val_loss: 1.4636\n",
      "Epoch 31/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5082\n",
      "Epoch 31: val_loss improved from 1.46357 to 1.46078, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 28s 842us/sample - loss: 1.5082 - val_loss: 1.4608\n",
      "Epoch 32/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5056\n",
      "Epoch 32: val_loss did not improve from 1.46078\n",
      "32719/32719 [==============================] - 24s 740us/sample - loss: 1.5056 - val_loss: 1.4610\n",
      "Epoch 33/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5032\n",
      "Epoch 33: val_loss improved from 1.46078 to 1.45777, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 808us/sample - loss: 1.5032 - val_loss: 1.4578\n",
      "Epoch 34/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.5029\n",
      "Epoch 34: val_loss improved from 1.45777 to 1.45726, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 823us/sample - loss: 1.5029 - val_loss: 1.4573\n",
      "Epoch 35/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4991\n",
      "Epoch 35: val_loss improved from 1.45726 to 1.45385, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 25s 774us/sample - loss: 1.4991 - val_loss: 1.4539\n",
      "Epoch 36/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4976\n",
      "Epoch 36: val_loss improved from 1.45385 to 1.45225, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 829us/sample - loss: 1.4976 - val_loss: 1.4523\n",
      "Epoch 37/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4967\n",
      "Epoch 37: val_loss improved from 1.45225 to 1.45196, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 795us/sample - loss: 1.4967 - val_loss: 1.4520\n",
      "Epoch 38/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4932\n",
      "Epoch 38: val_loss improved from 1.45196 to 1.45025, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 810us/sample - loss: 1.4932 - val_loss: 1.4502\n",
      "Epoch 39/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4925\n",
      "Epoch 39: val_loss improved from 1.45025 to 1.44872, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 28s 852us/sample - loss: 1.4925 - val_loss: 1.4487\n",
      "Epoch 40/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4894\n",
      "Epoch 40: val_loss improved from 1.44872 to 1.44548, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 809us/sample - loss: 1.4894 - val_loss: 1.4455\n",
      "Epoch 41/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4882\n",
      "Epoch 41: val_loss improved from 1.44548 to 1.44418, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 820us/sample - loss: 1.4882 - val_loss: 1.4442\n",
      "Epoch 42/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4879\n",
      "Epoch 42: val_loss improved from 1.44418 to 1.44409, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 821us/sample - loss: 1.4879 - val_loss: 1.4441\n",
      "Epoch 43/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4861\n",
      "Epoch 43: val_loss improved from 1.44409 to 1.44134, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 821us/sample - loss: 1.4861 - val_loss: 1.4413\n",
      "Epoch 44/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4830\n",
      "Epoch 44: val_loss improved from 1.44134 to 1.43991, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 29s 892us/sample - loss: 1.4830 - val_loss: 1.4399\n",
      "Epoch 45/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4818\n",
      "Epoch 45: val_loss did not improve from 1.43991\n",
      "32719/32719 [==============================] - 26s 791us/sample - loss: 1.4818 - val_loss: 1.4405\n",
      "Epoch 46/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 46: val_loss improved from 1.43991 to 1.43741, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 24s 735us/sample - loss: 1.4772 - val_loss: 1.4374\n",
      "Epoch 47/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 47: val_loss improved from 1.43741 to 1.43586, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 27s 840us/sample - loss: 1.4781 - val_loss: 1.4359\n",
      "Epoch 48/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4778\n",
      "Epoch 48: val_loss improved from 1.43586 to 1.43222, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 25s 768us/sample - loss: 1.4778 - val_loss: 1.4322\n",
      "Epoch 49/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4754\n",
      "Epoch 49: val_loss improved from 1.43222 to 1.43161, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 26s 804us/sample - loss: 1.4754 - val_loss: 1.4316\n",
      "Epoch 50/50\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 50: val_loss improved from 1.43161 to 1.42941, saving model to ./checkpoints/unknown_person_few_shot_baseline_p1_47.h5\n",
      "32719/32719 [==============================] - 25s 774us/sample - loss: 1.4752 - val_loss: 1.4294\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 03:39:41.394273: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_659_1/lstm_cell_1954/kernel/Assign' id:993156 op device:{requested: '', assigned: ''} def:{{{node lstm_659_1/lstm_cell_1954/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_659_1/lstm_cell_1954/kernel, lstm_659_1/lstm_cell_1954/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 03:40:43.023323: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_638_1/lstm_cell_1933/bias/v/Assign' id:995754 op device:{requested: '', assigned: ''} def:{{{node lstm_638_1/lstm_cell_1933/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_638_1/lstm_cell_1933/bias/v, lstm_638_1/lstm_cell_1933/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 03:41:44.749692: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_89_1/cond/Merge' id:994305 op device:{requested: '', assigned: ''} def:{{{node dropout_89_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_89_1/cond/Identity, dropout_89_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1491, 648)\n",
      "(1704, 648)\n",
      "(1704, 648)\n",
      "(1848, 648)\n",
      "(1723, 648)\n",
      "(1358, 648)\n",
      "(1824, 648)\n",
      "(1559, 648)\n",
      "(1740, 648)\n",
      "(1526, 648)\n",
      "(1920, 648)\n",
      "(1739, 648)\n",
      "(1764, 648)\n",
      "(1848, 648)\n",
      "(1752, 648)\n",
      "(1800, 648)\n",
      "(946, 648)\n",
      "(1680, 648)\n",
      "(1896, 648)\n",
      "{2: 4.088478187500917, 4: 7.601945186282998, 5: 5.612934158975187, 6: 5.671131271185197, 8: 9.285030961569502, 9: 5.680852800481298, 10: 8.155433498657354, 11: 6.428956587770914, 12: 8.38540569193972, 13: 7.476509559934849, 17: 8.341349286123055, 19: 7.317311882786248, 21: 10.0, 22: 1.0, 25: 6.8377676121439785, 26: 6.365475282102452, 27: 5.451580544101894, 28: 6.474297311772733, 29: 1.437089135570588}\n",
      "Train on 32719 samples, validate on 3634 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 03:51:32.049767: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 11.6254\n",
      "Epoch 1: val_loss improved from inf to 1.47119, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 149s 5ms/sample - loss: 11.6254 - val_loss: 1.4712\n",
      "Epoch 2/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1973\n",
      "Epoch 2: val_loss improved from 1.47119 to 1.45746, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 43s 1ms/sample - loss: 11.1973 - val_loss: 1.4575\n",
      "Epoch 3/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.1597\n",
      "Epoch 3: val_loss improved from 1.45746 to 1.45372, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 11.1597 - val_loss: 1.4537\n",
      "Epoch 4/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 11.0263\n",
      "Epoch 4: val_loss improved from 1.45372 to 1.45014, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 40s 1ms/sample - loss: 11.0263 - val_loss: 1.4501\n",
      "Epoch 5/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.9834\n",
      "Epoch 5: val_loss improved from 1.45014 to 1.44489, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 41s 1ms/sample - loss: 10.9834 - val_loss: 1.4449\n",
      "Epoch 6/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.9296\n",
      "Epoch 6: val_loss improved from 1.44489 to 1.44262, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 37s 1ms/sample - loss: 10.9296 - val_loss: 1.4426\n",
      "Epoch 7/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8876\n",
      "Epoch 7: val_loss improved from 1.44262 to 1.42182, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 10.8876 - val_loss: 1.4218\n",
      "Epoch 8/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8624\n",
      "Epoch 8: val_loss did not improve from 1.42182\n",
      "32719/32719 [==============================] - 42s 1ms/sample - loss: 10.8624 - val_loss: 1.4518\n",
      "Epoch 9/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.8012\n",
      "Epoch 9: val_loss did not improve from 1.42182\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 10.8012 - val_loss: 1.4342\n",
      "Epoch 10/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7725\n",
      "Epoch 10: val_loss did not improve from 1.42182\n",
      "32719/32719 [==============================] - 36s 1ms/sample - loss: 10.7725 - val_loss: 1.4384\n",
      "Epoch 11/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7068\n",
      "Epoch 11: val_loss improved from 1.42182 to 1.42160, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 39s 1ms/sample - loss: 10.7068 - val_loss: 1.4216\n",
      "Epoch 12/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.7019\n",
      "Epoch 12: val_loss did not improve from 1.42160\n",
      "32719/32719 [==============================] - 34s 1ms/sample - loss: 10.7019 - val_loss: 1.4301\n",
      "Epoch 13/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.6778\n",
      "Epoch 13: val_loss did not improve from 1.42160\n",
      "32719/32719 [==============================] - 33s 1ms/sample - loss: 10.6778 - val_loss: 1.4293\n",
      "Epoch 14/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.6458\n",
      "Epoch 14: val_loss did not improve from 1.42160\n",
      "32719/32719 [==============================] - 34s 1ms/sample - loss: 10.6458 - val_loss: 1.4287\n",
      "Epoch 15/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.6500\n",
      "Epoch 15: val_loss did not improve from 1.42160\n",
      "32719/32719 [==============================] - 34s 1ms/sample - loss: 10.6500 - val_loss: 1.4332\n",
      "Epoch 16/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.6014\n",
      "Epoch 16: val_loss improved from 1.42160 to 1.42116, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 31s 949us/sample - loss: 10.6014 - val_loss: 1.4212\n",
      "Epoch 17/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.5916\n",
      "Epoch 17: val_loss improved from 1.42116 to 1.41738, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 35s 1ms/sample - loss: 10.5916 - val_loss: 1.4174\n",
      "Epoch 18/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.6095\n",
      "Epoch 18: val_loss improved from 1.41738 to 1.41554, saving model to ./checkpoints/unknown_person_few_shot_p1_47.h5\n",
      "32719/32719 [==============================] - 30s 905us/sample - loss: 10.6095 - val_loss: 1.4155\n",
      "Epoch 19/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.5384\n",
      "Epoch 19: val_loss did not improve from 1.41554\n",
      "32719/32719 [==============================] - 31s 946us/sample - loss: 10.5384 - val_loss: 1.4166\n",
      "Epoch 20/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 10.5640\n",
      "Epoch 20: val_loss did not improve from 1.41554\n",
      "32719/32719 [==============================] - 29s 899us/sample - loss: 10.5640 - val_loss: 1.4215\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:05:52.912257: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_631_2/lstm_cell_1963/kernel/Assign' id:1008072 op device:{requested: '', assigned: ''} def:{{{node lstm_631_2/lstm_cell_1963/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_631_2/lstm_cell_1963/kernel, lstm_631_2/lstm_cell_1963/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 04:06:56.208234: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_655_2/lstm_cell_1987/kernel/m/Assign' id:1014754 op device:{requested: '', assigned: ''} def:{{{node lstm_655_2/lstm_cell_1987/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_655_2/lstm_cell_1987/kernel/m, lstm_655_2/lstm_cell_1987/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32719 samples, validate on 3634 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:07:59.926279: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:12:58.656541: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:13:22.406403: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41983, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 127s 4ms/sample - loss: 1.4701 - val_loss: 1.4198\n",
      "Epoch 2/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4600\n",
      "Epoch 2: val_loss improved from 1.41983 to 1.41263, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 22s 681us/sample - loss: 1.4600 - val_loss: 1.4126\n",
      "Epoch 3/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4564\n",
      "Epoch 3: val_loss improved from 1.41263 to 1.40356, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 21s 649us/sample - loss: 1.4564 - val_loss: 1.4036\n",
      "Epoch 4/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4507\n",
      "Epoch 4: val_loss improved from 1.40356 to 1.40150, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 21s 647us/sample - loss: 1.4507 - val_loss: 1.4015\n",
      "Epoch 5/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4473\n",
      "Epoch 5: val_loss improved from 1.40150 to 1.39657, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 23s 695us/sample - loss: 1.4473 - val_loss: 1.3966\n",
      "Epoch 6/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4437\n",
      "Epoch 6: val_loss did not improve from 1.39657\n",
      "32719/32719 [==============================] - 24s 726us/sample - loss: 1.4437 - val_loss: 1.3972\n",
      "Epoch 7/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4401\n",
      "Epoch 7: val_loss improved from 1.39657 to 1.39188, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 24s 735us/sample - loss: 1.4401 - val_loss: 1.3919\n",
      "Epoch 8/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4359\n",
      "Epoch 8: val_loss did not improve from 1.39188\n",
      "32719/32719 [==============================] - 23s 704us/sample - loss: 1.4359 - val_loss: 1.3985\n",
      "Epoch 9/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 9: val_loss improved from 1.39188 to 1.39184, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 22s 662us/sample - loss: 1.4361 - val_loss: 1.3918\n",
      "Epoch 10/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 10: val_loss did not improve from 1.39184\n",
      "32719/32719 [==============================] - 24s 734us/sample - loss: 1.4354 - val_loss: 1.3924\n",
      "Epoch 11/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4338\n",
      "Epoch 11: val_loss improved from 1.39184 to 1.38579, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 23s 698us/sample - loss: 1.4338 - val_loss: 1.3858\n",
      "Epoch 12/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4291\n",
      "Epoch 12: val_loss did not improve from 1.38579\n",
      "32719/32719 [==============================] - 24s 731us/sample - loss: 1.4291 - val_loss: 1.3896\n",
      "Epoch 13/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4279\n",
      "Epoch 13: val_loss did not improve from 1.38579\n",
      "32719/32719 [==============================] - 23s 697us/sample - loss: 1.4279 - val_loss: 1.3863\n",
      "Epoch 14/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 14: val_loss improved from 1.38579 to 1.38494, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 25s 749us/sample - loss: 1.4243 - val_loss: 1.3849\n",
      "Epoch 15/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4234\n",
      "Epoch 15: val_loss improved from 1.38494 to 1.38237, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 24s 748us/sample - loss: 1.4234 - val_loss: 1.3824\n",
      "Epoch 16/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4201\n",
      "Epoch 16: val_loss improved from 1.38237 to 1.38171, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 24s 748us/sample - loss: 1.4201 - val_loss: 1.3817\n",
      "Epoch 17/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 17: val_loss improved from 1.38171 to 1.37890, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 21s 656us/sample - loss: 1.4186 - val_loss: 1.3789\n",
      "Epoch 18/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4190\n",
      "Epoch 18: val_loss did not improve from 1.37890\n",
      "32719/32719 [==============================] - 21s 634us/sample - loss: 1.4190 - val_loss: 1.3817\n",
      "Epoch 19/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4151\n",
      "Epoch 19: val_loss did not improve from 1.37890\n",
      "32719/32719 [==============================] - 21s 635us/sample - loss: 1.4151 - val_loss: 1.3870\n",
      "Epoch 20/20\n",
      "32719/32719 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 20: val_loss improved from 1.37890 to 1.37851, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p1_47.h5\n",
      "32719/32719 [==============================] - 21s 644us/sample - loss: 1.4163 - val_loss: 1.3785\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "\n",
    "test_person_id = [1]\n",
    "ra_all = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "idx = 30\n",
    "for ra in ra_all:\n",
    "    flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "    ## Data Normalization before training ans testing\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalers = []\n",
    "    X_train_normalized = []\n",
    "    X_val_normalized = []\n",
    "    X_test_normalized = []\n",
    "    train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "    np.random.shuffle(train_idx)\n",
    "    val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "    test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "    \n",
    "    for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "        scaler = StandardScaler()\n",
    "        if len(feature.shape)==2:\n",
    "            X_train_i = feature[train_idx,:]\n",
    "            X_val_i = feature[val_idx,:]\n",
    "            X_test_i = feature[test_idx,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i)\n",
    "            scalers.append(scaler)\n",
    "        else:\n",
    "            X_train_i = feature[train_idx,:,:]\n",
    "            X_val_i = feature[val_idx,:,:]\n",
    "            X_test_i = feature[test_idx,:,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "            scalers.append(scaler)\n",
    "        X_train_normalized.append(X_train_normalized_i)\n",
    "        X_val_normalized.append(X_val_normalized_i)\n",
    "        X_test_normalized.append(X_test_normalized_i)\n",
    "    y_train = gts[train_idx,:]\n",
    "    y_val = gts[val_idx,:]\n",
    "    y_test = gts[test_idx,:]\n",
    "    X_train_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "    for feature in X_train_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_train_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_train_normalized_new.append(feature)\n",
    "    X_train_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_val_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "    for feature in X_val_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_val_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_val_normalized_new.append(feature)\n",
    "    X_val_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_test_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "    for feature in X_test_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_test_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_test_normalized_new.append(feature)\n",
    "    X_test_normalized_new.append(combined_feature)\n",
    "    \n",
    "    \n",
    "    num_epochs = 50\n",
    "    \n",
    "    \n",
    "    # Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    \n",
    "    \n",
    "    rates = [0.4, 0.5, 0.6]\n",
    "    \n",
    "    for r in rates:\n",
    "        model = individual_model(X_train_normalized)\n",
    "        model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=20, frequency=1)\n",
    "        model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=4096, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import tensorflow as tf\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        from tensorflow.keras.models import Model\n",
    "        layers = model.layers\n",
    "        second_last_layer_output = layers[-4].output\n",
    "        feature_extractor_model = Model(inputs=model.input, outputs=second_last_layer_output)\n",
    "        train_features = feature_extractor_model.predict(X_train_normalized_new)\n",
    "        test_features = feature_extractor_model.predict(X_test_normalized_new)\n",
    "        \n",
    "        p_train = people_nums[train_idx,:]\n",
    "        p_val = people_nums[val_idx,:]\n",
    "        p_test = people_nums[test_idx,:]\n",
    "        ## Calculate the distance between test person and training person\n",
    "        def euclidean_distance(a, b):\n",
    "            return np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "        \n",
    "        distance_dict = {}\n",
    "        for ii in range(len(person_nums)):\n",
    "            if person_nums[ii] == test_person_id[0]:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                ind = np.where(p_train ==person_nums[ii])[0]\n",
    "                tmp_train_features = train_features[ind, :]\n",
    "                distances = np.array([euclidean_distance(train_sample, test_features) for train_sample in tmp_train_features])\n",
    "                print(distances.shape)\n",
    "                average_distances = np.mean(distances, axis=1)\n",
    "        \n",
    "                # Step 4: Find the overall average distance\n",
    "                overall_average_distance = np.mean(average_distances)\n",
    "                distance_dict[person_nums[ii]] = overall_average_distance\n",
    "        \n",
    "        \n",
    "        def normalize_to_weights(distance_dict):\n",
    "            distances = np.array(list(distance_dict.values()))\n",
    "            # Handle the case where a distance is zero to avoid division by zero\n",
    "            distances = np.clip(distances, a_min=1e-10, a_max=None)\n",
    "            weights = 1 / distances\n",
    "            normalized_weights = weights\n",
    "            # normalized_weights = weights / sum(weights)\n",
    "            # print(sum(weights))\n",
    "            # print(sum(normalized_weights))\n",
    "            # Assign the normalized weights back to the dictionary\n",
    "            normalized_weight_dict = dict(zip(distance_dict.keys(), normalized_weights))\n",
    "            return normalized_weight_dict\n",
    "        def scale_dict_values(my_dict):\n",
    "            scaled_dict = my_dict.copy()\n",
    "            min_val = min(scaled_dict.values())\n",
    "            max_val = max(scaled_dict.values())\n",
    "            \n",
    "            for key in scaled_dict:\n",
    "                scaled_dict[key] = 1 + 9 * (scaled_dict[key] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            return scaled_dict\n",
    "        weights_dict = normalize_to_weights(distance_dict)\n",
    "        weights_dict = scale_dict_values(weights_dict)\n",
    "        print(weights_dict)\n",
    "        \n",
    "        w_train = np.zeros_like(p_train)\n",
    "        for i in range(len(w_train)):\n",
    "            if p_train[i] == test_person_id[0]:\n",
    "                w_train[i] = 50\n",
    "            else:\n",
    "                w_train[i] = weights_dict[int(p_train[i])]\n",
    "        \n",
    "        w_train = np.squeeze(w_train)\n",
    "        \n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,sample_weight= w_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_2_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        idx += 1\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0508e9a1-9544-41f8-af41-e3d3b02a8d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:26:15.572240: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35564\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "ra = 0.1\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71b59e4-6581-4ea8-994d-a02a6654ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:28:08.412890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.413109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.413290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.424592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.424840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.425075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.425250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.425413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.425581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.632900: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.633103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.633270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.633433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.633587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.633740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.633892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.634046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.634198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.641886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.642074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.642249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.642417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.642586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.642749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.642914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.643061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1325 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-12-04 23:28:08.643472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.643621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46608 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-12-04 23:28:08.643987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:08.644128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46608 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-12-04 23:28:08.644353: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-12-04 23:28:10.546766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.547068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.547283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.547468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.547668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.547844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.548039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.548223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.548473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.548724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.548910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.549090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.549274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.549424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1325 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-12-04 23:28:10.549477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.549625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46608 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-12-04 23:28:10.549685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:28:10.549828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46608 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-12-04 23:28:10.549884: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-12-04 23:28:10.598228: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-12-04 23:28:10.688071: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_35/lstm_cell_35/recurrent_kernel/Assign' id:5978 op device:{requested: '', assigned: ''} def:{{{node lstm_35/lstm_cell_35/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_35/lstm_cell_35/recurrent_kernel, lstm_35/lstm_cell_35/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 23:28:11.642493: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_23/lstm_cell_23/recurrent_kernel/v/Assign' id:7961 op device:{requested: '', assigned: ''} def:{{{node lstm_23/lstm_cell_23/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_23/lstm_cell_23/recurrent_kernel/v, lstm_23/lstm_cell_23/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 23:28:12.406077: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3/BiasAdd' id:6369 op device:{requested: '', assigned: ''} def:{{{node dense_3/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3/MatMul, dense_3/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 23:28:12.969795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-04 23:28:13.235615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.4309466201228738\n",
      "[1.64824845 1.07861418]\n",
      "1.363431316614151\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_30.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0f9579-80ce-49ce-b04d-1a1ef5f8f1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_trace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5d7092-a2a3-43ff-93c3-1bb6b89c24c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:16:01.744258: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_72_1/lstm_cell_183/recurrent_kernel/Assign' id:42902 op device:{requested: '', assigned: ''} def:{{{node lstm_72_1/lstm_cell_183/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_72_1/lstm_cell_183/recurrent_kernel, lstm_72_1/lstm_cell_183/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:16:04.221340: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_65_1/lstm_cell_176/kernel/m/Assign' id:44312 op device:{requested: '', assigned: ''} def:{{{node lstm_65_1/lstm_cell_176/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_65_1/lstm_cell_176/kernel/m, lstm_65_1/lstm_cell_176/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:16:06.320304: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_7_1/BiasAdd' id:43293 op device:{requested: '', assigned: ''} def:{{{node dense_7_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_7_1/MatMul, dense_7_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.5802543349538152\n",
      "[2.0283664 1.0291001]\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_31.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00fc98e6-4676-47c9-919c-9f2589c5e8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:16:17.933294: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_11_1/bias/Assign' id:52519 op device:{requested: '', assigned: ''} def:{{{node dense_11_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_11_1/bias, dense_11_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:16:20.548517: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_96_1/lstm_cell_207/kernel/v/Assign' id:54096 op device:{requested: '', assigned: ''} def:{{{node lstm_96_1/lstm_cell_207/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_96_1/lstm_cell_207/kernel/v, lstm_96_1/lstm_cell_207/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:16:23.022554: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_11_1/BiasAdd' id:52524 op device:{requested: '', assigned: ''} def:{{{node dense_11_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_11_1/MatMul, dense_11_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.556036700328025\n",
      "[1.97304775 1.03158723]\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_32.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316717ff-f897-48f8-989e-2cd5c0a94e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.97304775, 1.03158723])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(pred_trace-gt_trace), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3161b8ee-da5c-4679-8941-f8705f81f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35720\n"
     ]
    }
   ],
   "source": [
    "ra = 0.2\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4c0737-e1a0-4c0d-a227-1bb42bb16bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:28:42.266325: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_121/lstm_cell_47/bias/Assign' id:11216 op device:{requested: '', assigned: ''} def:{{{node lstm_121/lstm_cell_47/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_121/lstm_cell_47/bias, lstm_121/lstm_cell_47/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 23:28:43.588844: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_124/lstm_cell_50/kernel/v/Assign' id:17037 op device:{requested: '', assigned: ''} def:{{{node lstm_124/lstm_cell_50/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_124/lstm_cell_50/kernel/v, lstm_124/lstm_cell_50/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 23:28:44.605524: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_15/BiasAdd' id:15600 op device:{requested: '', assigned: ''} def:{{{node dense_15/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_15/MatMul, dense_15/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.218855242027518\n",
      "[1.22015819 1.01174974]\n",
      "1.1159539668359488\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_33.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d9d626-379e-40fc-a83d-cd517856f5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_trace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee41b927-222c-45ba-b37e-025e6db6dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:19:35.252231: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_157/lstm_cell_268/bias/Assign' id:66442 op device:{requested: '', assigned: ''} def:{{{node lstm_157/lstm_cell_268/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_157/lstm_cell_268/bias, lstm_157/lstm_cell_268/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:19:38.652597: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_18/bias/m/Assign' id:71570 op device:{requested: '', assigned: ''} def:{{{node conv2d_18/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_18/bias/m, conv2d_18/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:19:41.921055: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_19/BiasAdd' id:70986 op device:{requested: '', assigned: ''} def:{{{node dense_19/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_19/MatMul, dense_19/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.2314980047275832\n",
      "[1.27544104 0.99165454]\n",
      "1.1335477862402656\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_34.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9113251b-4116-46a8-9cde-8c380a871a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:19:54.022487: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_219/lstm_cell_330/bias/Assign' id:79675 op device:{requested: '', assigned: ''} def:{{{node lstm_219/lstm_cell_330/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_219/lstm_cell_330/bias, lstm_219/lstm_cell_330/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:19:57.808013: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_188/lstm_cell_299/bias/m/Assign' id:80871 op device:{requested: '', assigned: ''} def:{{{node lstm_188/lstm_cell_299/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_188/lstm_cell_299/bias/m, lstm_188/lstm_cell_299/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:20:01.458168: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_23/BiasAdd' id:80217 op device:{requested: '', assigned: ''} def:{{{node dense_23/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_23/MatMul, dense_23/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.1924612502582739\n",
      "[1.11713594 0.97117749]\n",
      "1.0441567151345938\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_35.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2fd51bb-02e6-4d39-9a65-165eba2aca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35876\n"
     ]
    }
   ],
   "source": [
    "ra = 0.3\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e41830-a7a6-422b-b435-1e1c53b2e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:21:14.787271: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_229/lstm_cell_340/bias/Assign' id:84584 op device:{requested: '', assigned: ''} def:{{{node lstm_229/lstm_cell_340/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_229/lstm_cell_340/bias, lstm_229/lstm_cell_340/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:21:19.004134: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_248/lstm_cell_359/bias/v/Assign' id:91090 op device:{requested: '', assigned: ''} def:{{{node lstm_248/lstm_cell_359/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_248/lstm_cell_359/bias/v, lstm_248/lstm_cell_359/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 17:21:23.090654: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_27/BiasAdd' id:89448 op device:{requested: '', assigned: ''} def:{{{node dense_27/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_27/MatMul, dense_27/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9912475832303365\n",
      "[0.74966378 0.96920572]\n",
      "0.8594347479495597\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_36.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "916491e4-001e-48b9-9b97-d8c45369c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:24:41.590485: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_28/kernel/Assign' id:98588 op device:{requested: '', assigned: ''} def:{{{node dense_28/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_28/kernel, dense_28/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:24:46.230001: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_30/bias/m/Assign' id:99263 op device:{requested: '', assigned: ''} def:{{{node conv2d_30/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_30/bias/m, conv2d_30/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 17:24:50.720819: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_31/BiasAdd' id:98679 op device:{requested: '', assigned: ''} def:{{{node dense_31/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_31/MatMul, dense_31/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9794415101475186\n",
      "[0.82866433 0.86041447]\n",
      "0.8445393975744856\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_37.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b83c34c-ec42-4594-a190-4d103071c42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:25:03.306146: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_331/lstm_cell_442/kernel/Assign' id:107499 op device:{requested: '', assigned: ''} def:{{{node lstm_331/lstm_cell_442/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_331/lstm_cell_442/kernel, lstm_331/lstm_cell_442/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:25:08.339969: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_332/lstm_cell_443/recurrent_kernel/v/Assign' id:109697 op device:{requested: '', assigned: ''} def:{{{node lstm_332/lstm_cell_443/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_332/lstm_cell_443/recurrent_kernel/v, lstm_332/lstm_cell_443/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:25:13.251837: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_35/BiasAdd' id:107910 op device:{requested: '', assigned: ''} def:{{{node dense_35/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_35/MatMul, dense_35/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9826867126888699\n",
      "[0.83903733 0.88581324]\n",
      "0.8624252879873235\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_38.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb785db-95ae-4536-bbce-0a267afca02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36044\n"
     ]
    }
   ],
   "source": [
    "ra = 0.4\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7fb17e1-2707-459d-954a-de3f27cfe220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:28:16.971948: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_345_1/lstm_cell_493/bias/Assign' id:122308 op device:{requested: '', assigned: ''} def:{{{node lstm_345_1/lstm_cell_493/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_345_1/lstm_cell_493/bias, lstm_345_1/lstm_cell_493/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:28:22.835928: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_352_1/lstm_cell_500/recurrent_kernel/v/Assign' id:127904 op device:{requested: '', assigned: ''} def:{{{node lstm_352_1/lstm_cell_500/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_352_1/lstm_cell_500/recurrent_kernel/v, lstm_352_1/lstm_cell_500/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 17:28:28.532585: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_39_1/BiasAdd' id:126372 op device:{requested: '', assigned: ''} def:{{{node dense_39_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_39_1/MatMul, dense_39_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9554087764417116\n",
      "[0.75469456 0.93544452]\n",
      "0.8450695410370826\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_39.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff965d15-02a6-4cd7-a1fc-d825358dee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:28:41.159090: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_388/lstm_cell_536/recurrent_kernel/Assign' id:132490 op device:{requested: '', assigned: ''} def:{{{node lstm_388/lstm_cell_536/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_388/lstm_cell_536/recurrent_kernel, lstm_388/lstm_cell_536/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:28:47.360363: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_377/lstm_cell_525/bias/m/Assign' id:136317 op device:{requested: '', assigned: ''} def:{{{node lstm_377/lstm_cell_525/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_377/lstm_cell_525/bias/m, lstm_377/lstm_cell_525/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:28:53.438103: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_43/BiasAdd' id:135603 op device:{requested: '', assigned: ''} def:{{{node dense_43/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_43/MatMul, dense_43/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.0706682844844606\n",
      "[1.05177512 0.94257371]\n",
      "0.9971744135022164\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_40.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9d455e6-0530-47dd-b568-a919ffaf85ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:29:06.354285: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_428/lstm_cell_576/bias/Assign' id:142210 op device:{requested: '', assigned: ''} def:{{{node lstm_428/lstm_cell_576/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_428/lstm_cell_576/bias, lstm_428/lstm_cell_576/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:29:12.954222: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_426/lstm_cell_574/bias/v/Assign' id:146371 op device:{requested: '', assigned: ''} def:{{{node lstm_426/lstm_cell_574/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_426/lstm_cell_574/bias/v, lstm_426/lstm_cell_574/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:29:19.448271: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_47/BiasAdd' id:144834 op device:{requested: '', assigned: ''} def:{{{node dense_47/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_47/MatMul, dense_47/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.1197021401165173\n",
      "[1.11369272 0.95160396]\n",
      "1.0326483428478241\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_41.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a3027b-95eb-42cb-ab2b-6d1947985cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36197\n"
     ]
    }
   ],
   "source": [
    "ra = 0.5\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d8c51d6-7fd9-444a-ac6d-f03240dcf99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:37:51.192838: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_476/lstm_cell_624/recurrent_kernel/Assign' id:153194 op device:{requested: '', assigned: ''} def:{{{node lstm_476/lstm_cell_624/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_476/lstm_cell_624/recurrent_kernel, lstm_476/lstm_cell_624/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:37:58.829891: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_449/lstm_cell_597/recurrent_kernel/m/Assign' id:154744 op device:{requested: '', assigned: ''} def:{{{node lstm_449/lstm_cell_597/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_449/lstm_cell_597/recurrent_kernel/m, lstm_449/lstm_cell_597/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 17:38:05.660579: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_51/BiasAdd' id:154065 op device:{requested: '', assigned: ''} def:{{{node dense_51/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_51/MatMul, dense_51/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9623850648527714\n",
      "[0.87322454 0.90860211]\n",
      "0.8909133263488314\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_42.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cf66719-d17c-460b-bce6-d0f87f735ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:38:18.730780: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_55/bias/Assign' id:157102 op device:{requested: '', assigned: ''} def:{{{node conv2d_55/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_55/bias, conv2d_55/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:38:26.161435: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_497/lstm_cell_645/recurrent_kernel/m/Assign' id:164140 op device:{requested: '', assigned: ''} def:{{{node lstm_497/lstm_cell_645/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_497/lstm_cell_645/recurrent_kernel/m, lstm_497/lstm_cell_645/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:38:33.437502: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_55/BiasAdd' id:163296 op device:{requested: '', assigned: ''} def:{{{node dense_55/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_55/MatMul, dense_55/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9647145876243933\n",
      "[0.85802788 0.90293106]\n",
      "0.8804794674489036\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_43.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71403567-47a6-4e0e-9114-1f6962dc250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:38:47.839609: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_524/lstm_cell_672/bias/Assign' id:167503 op device:{requested: '', assigned: ''} def:{{{node lstm_524/lstm_cell_672/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_524/lstm_cell_672/bias, lstm_524/lstm_cell_672/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:38:55.735921: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_530/lstm_cell_678/recurrent_kernel/v/Assign' id:173954 op device:{requested: '', assigned: ''} def:{{{node lstm_530/lstm_cell_678/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_530/lstm_cell_678/recurrent_kernel/v, lstm_530/lstm_cell_678/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:39:03.552488: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_59/BiasAdd' id:172527 op device:{requested: '', assigned: ''} def:{{{node dense_59/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_59/MatMul, dense_59/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9206954546977039\n",
      "[0.76041884 0.91256574]\n",
      "0.8364922911373537\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_44.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be785c61-e127-40f5-98bd-3e3fb348e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36356\n"
     ]
    }
   ],
   "source": [
    "ra = 0.6\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b25a6a8f-ed4d-4bc0-8b2d-9061beb24c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:39:25.515951: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_583/lstm_cell_731/recurrent_kernel/Assign' id:180247 op device:{requested: '', assigned: ''} def:{{{node lstm_583/lstm_cell_731/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_583/lstm_cell_731/recurrent_kernel, lstm_583/lstm_cell_731/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:39:33.801034: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_562/lstm_cell_710/bias/m/Assign' id:182472 op device:{requested: '', assigned: ''} def:{{{node lstm_562/lstm_cell_710/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_562/lstm_cell_710/bias/m, lstm_562/lstm_cell_710/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 17:39:41.986291: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_63/BiasAdd' id:181758 op device:{requested: '', assigned: ''} def:{{{node dense_63/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_63/MatMul, dense_63/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8449708328690639\n",
      "[0.60093208 0.90335741]\n",
      "0.7521447451026352\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_45.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb373d7a-f131-4af5-a695-a059ee930ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:39:55.333778: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_605/lstm_cell_753/kernel/Assign' id:187056 op device:{requested: '', assigned: ''} def:{{{node lstm_605/lstm_cell_753/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_605/lstm_cell_753/kernel, lstm_605/lstm_cell_753/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:40:04.014000: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_618/lstm_cell_766/bias/m/Assign' id:191988 op device:{requested: '', assigned: ''} def:{{{node lstm_618/lstm_cell_766/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_618/lstm_cell_766/bias/m, lstm_618/lstm_cell_766/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:40:12.555568: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_67/BiasAdd' id:190989 op device:{requested: '', assigned: ''} def:{{{node dense_67/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_67/MatMul, dense_67/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8847833188005196\n",
      "[0.70343339 0.88656535]\n",
      "0.7949993676609464\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_46.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe1b214a-1f5e-4c14-b21c-78c0a0818c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:40:27.579519: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_656/lstm_cell_804/bias/Assign' id:198558 op device:{requested: '', assigned: ''} def:{{{node lstm_656/lstm_cell_804/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_656/lstm_cell_804/bias, lstm_656/lstm_cell_804/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:40:36.738918: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_663/lstm_cell_811/bias/m/Assign' id:201339 op device:{requested: '', assigned: ''} def:{{{node lstm_663/lstm_cell_811/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_663/lstm_cell_811/bias/m, lstm_663/lstm_cell_811/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:40:45.707650: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_71/BiasAdd' id:200220 op device:{requested: '', assigned: ''} def:{{{node dense_71/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_71/MatMul, dense_71/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8737179145332454\n",
      "[0.65530011 0.9065386 ]\n",
      "0.7809193509596365\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p1_47.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9003b2f-ea70-47c0-8d29-6ce17b49aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35408\n"
     ]
    }
   ],
   "source": [
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "test_person_id = [1]\n",
    "flag_tr_val_te = split_data_unknown(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e48bcb81-e6d4-4906-adf5-fe1711efb077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:52:43.136462: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_34_7/lstm_cell_1033/kernel/Assign' id:255035 op device:{requested: '', assigned: ''} def:{{{node lstm_34_7/lstm_cell_1033/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_34_7/lstm_cell_1033/kernel, lstm_34_7/lstm_cell_1033/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:52:54.718867: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_17_7/lstm_cell_1016/recurrent_kernel/v/Assign' id:257108 op device:{requested: '', assigned: ''} def:{{{node lstm_17_7/lstm_cell_1016/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_17_7/lstm_cell_1016/recurrent_kernel/v, lstm_17_7/lstm_cell_1016/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:53:06.185560: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3_7/BiasAdd' id:255606 op device:{requested: '', assigned: ''} def:{{{node dense_3_7/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3_7/MatMul, dense_3_7/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "2.35031060793081\n",
      "[3.29274596 1.3040394 ]\n",
      "2.298392683491671\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_p1_20.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a2767b0-109c-4876-9ce3-bc964a95cdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:53:28.467748: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_31_8/lstm_cell_1067/bias/Assign' id:263815 op device:{requested: '', assigned: ''} def:{{{node lstm_31_8/lstm_cell_1067/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_31_8/lstm_cell_1067/bias, lstm_31_8/lstm_cell_1067/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:53:40.422007: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_35_8/lstm_cell_1071/kernel/v/Assign' id:266604 op device:{requested: '', assigned: ''} def:{{{node lstm_35_8/lstm_cell_1071/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_35_8/lstm_cell_1071/kernel/v, lstm_35_8/lstm_cell_1071/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:53:52.187939: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3_8/BiasAdd' id:264837 op device:{requested: '', assigned: ''} def:{{{node dense_3_8/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3_8/MatMul, dense_3_8/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "2.254110615955384\n",
      "[3.14297978 1.25324794]\n",
      "2.1981138586997986\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_p1_21.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53088e03-8502-4c4b-a018-0f6e85be7701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:54:14.208816: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_32_9/lstm_cell_1105/recurrent_kernel/Assign' id:273197 op device:{requested: '', assigned: ''} def:{{{node lstm_32_9/lstm_cell_1105/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_32_9/lstm_cell_1105/recurrent_kernel, lstm_32_9/lstm_cell_1105/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:54:26.513853: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_2_9/lstm_cell_1075/recurrent_kernel/v/Assign' id:275345 op device:{requested: '', assigned: ''} def:{{{node lstm_2_9/lstm_cell_1075/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_2_9/lstm_cell_1075/recurrent_kernel/v, lstm_2_9/lstm_cell_1075/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 17:54:38.680751: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3_9/BiasAdd' id:274068 op device:{requested: '', assigned: ''} def:{{{node dense_3_9/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3_9/MatMul, dense_3_9/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "2.292599542928206\n",
      "[3.22305439 1.24684484]\n",
      "2.234949617905724\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_p1_22.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8741d07-af3c-44d1-a358-5cdf222f5e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
