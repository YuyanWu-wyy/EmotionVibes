{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f8da1-2837-4bf7-b3f4-dfcaa7ab42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe25376-b856-4296-ba02-5e3771ff9451",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-18T09:22:17.146537Z",
     "iopub.status.busy": "2023-11-18T09:22:17.146368Z",
     "iopub.status.idle": "2023-11-19T02:40:07.423372Z",
     "shell.execute_reply": "2023-11-19T02:40:07.422906Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:22:17.326511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35499\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:23:40.532942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.544832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.545064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.548426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.548614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.548779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.622809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.622999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.623152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:40.623284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-18 04:23:40.623658: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:23:41.552689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:41.552912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:41.553078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:41.553279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:41.553507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 04:23:41.553637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-18 04:23:41.553668: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-18 04:23:41.578904: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-18 04:23:41.800421: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_18/lstm_cell_18/kernel/Assign' id:2986 op device:{requested: '', assigned: ''} def:{{{node lstm_18/lstm_cell_18/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_18/lstm_cell_18/kernel, lstm_18/lstm_cell_18/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 04:23:41.935691: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 04:23:41.969199: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31938, 95)\n",
      "Train on 31938 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:23:46.369736: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign' id:17397 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_24/lstm_cell_24/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_24/lstm_cell_24/kernel/v, training/Adam/lstm_24/lstm_cell_24/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:23:50.158511: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-18 04:23:52.272157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-18 04:23:52.294978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 3.2820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 04:24:12.070288: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.83195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 27s 837us/sample - loss: 3.2820 - val_loss: 1.8320\n",
      "Epoch 2/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.8627\n",
      "Epoch 2: val_loss improved from 1.83195 to 1.53482, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 19s 609us/sample - loss: 1.8627 - val_loss: 1.5348\n",
      "Epoch 3/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.6226\n",
      "Epoch 3: val_loss improved from 1.53482 to 1.45206, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 21s 656us/sample - loss: 1.6226 - val_loss: 1.4521\n",
      "Epoch 4/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5574\n",
      "Epoch 4: val_loss improved from 1.45206 to 1.40183, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 705us/sample - loss: 1.5574 - val_loss: 1.4018\n",
      "Epoch 5/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5320\n",
      "Epoch 5: val_loss improved from 1.40183 to 1.37830, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 20s 611us/sample - loss: 1.5320 - val_loss: 1.3783\n",
      "Epoch 6/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5149\n",
      "Epoch 6: val_loss improved from 1.37830 to 1.37287, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 21s 658us/sample - loss: 1.5149 - val_loss: 1.3729\n",
      "Epoch 7/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5020\n",
      "Epoch 7: val_loss improved from 1.37287 to 1.36458, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 713us/sample - loss: 1.5020 - val_loss: 1.3646\n",
      "Epoch 8/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5013\n",
      "Epoch 8: val_loss did not improve from 1.36458\n",
      "31938/31938 [==============================] - 22s 686us/sample - loss: 1.5013 - val_loss: 1.3685\n",
      "Epoch 9/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4967\n",
      "Epoch 9: val_loss improved from 1.36458 to 1.35636, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 20s 627us/sample - loss: 1.4967 - val_loss: 1.3564\n",
      "Epoch 10/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4922\n",
      "Epoch 10: val_loss did not improve from 1.35636\n",
      "31938/31938 [==============================] - 20s 618us/sample - loss: 1.4922 - val_loss: 1.3623\n",
      "Epoch 11/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5373\n",
      "Epoch 11: val_loss did not improve from 1.35636\n",
      "31938/31938 [==============================] - 22s 681us/sample - loss: 1.5373 - val_loss: 1.3746\n",
      "Epoch 12/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 12: val_loss improved from 1.35636 to 1.35556, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 715us/sample - loss: 1.4854 - val_loss: 1.3556\n",
      "Epoch 13/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5008\n",
      "Epoch 13: val_loss did not improve from 1.35556\n",
      "31938/31938 [==============================] - 23s 709us/sample - loss: 1.5008 - val_loss: 1.3636\n",
      "Epoch 14/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4931\n",
      "Epoch 14: val_loss did not improve from 1.35556\n",
      "31938/31938 [==============================] - 19s 605us/sample - loss: 1.4931 - val_loss: 1.3607\n",
      "Epoch 15/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4785\n",
      "Epoch 15: val_loss improved from 1.35556 to 1.34792, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 21s 656us/sample - loss: 1.4785 - val_loss: 1.3479\n",
      "Epoch 16/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4782\n",
      "Epoch 16: val_loss did not improve from 1.34792\n",
      "31938/31938 [==============================] - 22s 704us/sample - loss: 1.4782 - val_loss: 1.3608\n",
      "Epoch 17/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4671\n",
      "Epoch 17: val_loss improved from 1.34792 to 1.34462, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 712us/sample - loss: 1.4671 - val_loss: 1.3446\n",
      "Epoch 18/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4709\n",
      "Epoch 18: val_loss did not improve from 1.34462\n",
      "31938/31938 [==============================] - 22s 704us/sample - loss: 1.4709 - val_loss: 1.3451\n",
      "Epoch 19/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5708\n",
      "Epoch 19: val_loss did not improve from 1.34462\n",
      "31938/31938 [==============================] - 21s 668us/sample - loss: 1.5708 - val_loss: 1.3577\n",
      "Epoch 20/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5781\n",
      "Epoch 20: val_loss did not improve from 1.34462\n",
      "31938/31938 [==============================] - 21s 656us/sample - loss: 1.5781 - val_loss: 1.3670\n",
      "Epoch 21/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5265\n",
      "Epoch 21: val_loss did not improve from 1.34462\n",
      "31938/31938 [==============================] - 22s 681us/sample - loss: 1.5265 - val_loss: 1.3581\n",
      "Epoch 22/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4908\n",
      "Epoch 22: val_loss did not improve from 1.34462\n",
      "31938/31938 [==============================] - 21s 661us/sample - loss: 1.4908 - val_loss: 1.3558\n",
      "Epoch 23/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 23: val_loss did not improve from 1.34462\n",
      "31938/31938 [==============================] - 21s 649us/sample - loss: 1.4752 - val_loss: 1.3512\n",
      "Epoch 24/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4657\n",
      "Epoch 24: val_loss improved from 1.34462 to 1.34086, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 20s 637us/sample - loss: 1.4657 - val_loss: 1.3409\n",
      "Epoch 25/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4551\n",
      "Epoch 25: val_loss improved from 1.34086 to 1.33999, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 22s 704us/sample - loss: 1.4551 - val_loss: 1.3400\n",
      "Epoch 26/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 26: val_loss improved from 1.33999 to 1.33672, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 22s 704us/sample - loss: 1.4535 - val_loss: 1.3367\n",
      "Epoch 27/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4481\n",
      "Epoch 27: val_loss improved from 1.33672 to 1.33127, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 21s 665us/sample - loss: 1.4481 - val_loss: 1.3313\n",
      "Epoch 28/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4482\n",
      "Epoch 28: val_loss improved from 1.33127 to 1.32930, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 712us/sample - loss: 1.4482 - val_loss: 1.3293\n",
      "Epoch 29/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4449\n",
      "Epoch 29: val_loss improved from 1.32930 to 1.32745, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 710us/sample - loss: 1.4449 - val_loss: 1.3275\n",
      "Epoch 30/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4421\n",
      "Epoch 30: val_loss did not improve from 1.32745\n",
      "31938/31938 [==============================] - 23s 705us/sample - loss: 1.4421 - val_loss: 1.3351\n",
      "Epoch 31/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 31: val_loss improved from 1.32745 to 1.32612, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 713us/sample - loss: 1.4404 - val_loss: 1.3261\n",
      "Epoch 32/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4368\n",
      "Epoch 32: val_loss improved from 1.32612 to 1.32194, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 715us/sample - loss: 1.4368 - val_loss: 1.3219\n",
      "Epoch 33/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 33: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 23s 714us/sample - loss: 1.4346 - val_loss: 1.3272\n",
      "Epoch 34/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 34: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 23s 716us/sample - loss: 1.4324 - val_loss: 1.3231\n",
      "Epoch 35/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 35: val_loss improved from 1.32194 to 1.31859, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 716us/sample - loss: 1.4311 - val_loss: 1.3186\n",
      "Epoch 36/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4303\n",
      "Epoch 36: val_loss did not improve from 1.31859\n",
      "31938/31938 [==============================] - 23s 706us/sample - loss: 1.4303 - val_loss: 1.3227\n",
      "Epoch 37/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4267\n",
      "Epoch 37: val_loss improved from 1.31859 to 1.31686, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 710us/sample - loss: 1.4267 - val_loss: 1.3169\n",
      "Epoch 38/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4315\n",
      "Epoch 38: val_loss improved from 1.31686 to 1.31560, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 708us/sample - loss: 1.4315 - val_loss: 1.3156\n",
      "Epoch 39/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 39: val_loss did not improve from 1.31560\n",
      "31938/31938 [==============================] - 23s 706us/sample - loss: 1.4269 - val_loss: 1.3201\n",
      "Epoch 40/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 40: val_loss improved from 1.31560 to 1.31389, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 710us/sample - loss: 1.4232 - val_loss: 1.3139\n",
      "Epoch 41/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4209\n",
      "Epoch 41: val_loss improved from 1.31389 to 1.31259, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 709us/sample - loss: 1.4209 - val_loss: 1.3126\n",
      "Epoch 42/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 42: val_loss improved from 1.31259 to 1.31167, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4186 - val_loss: 1.3117\n",
      "Epoch 43/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 43: val_loss did not improve from 1.31167\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4159 - val_loss: 1.3126\n",
      "Epoch 44/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 44: val_loss did not improve from 1.31167\n",
      "31938/31938 [==============================] - 23s 726us/sample - loss: 1.4141 - val_loss: 1.3184\n",
      "Epoch 45/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4154\n",
      "Epoch 45: val_loss did not improve from 1.31167\n",
      "31938/31938 [==============================] - 20s 619us/sample - loss: 1.4154 - val_loss: 1.3129\n",
      "Epoch 46/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4112\n",
      "Epoch 46: val_loss did not improve from 1.31167\n",
      "31938/31938 [==============================] - 20s 614us/sample - loss: 1.4112 - val_loss: 1.3143\n",
      "Epoch 47/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4125\n",
      "Epoch 47: val_loss improved from 1.31167 to 1.30640, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 19s 604us/sample - loss: 1.4125 - val_loss: 1.3064\n",
      "Epoch 48/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4113\n",
      "Epoch 48: val_loss did not improve from 1.30640\n",
      "31938/31938 [==============================] - 19s 601us/sample - loss: 1.4113 - val_loss: 1.3092\n",
      "Epoch 49/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 49: val_loss did not improve from 1.30640\n",
      "31938/31938 [==============================] - 20s 630us/sample - loss: 1.4083 - val_loss: 1.3083\n",
      "Epoch 50/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 50: val_loss improved from 1.30640 to 1.30505, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_30.h5\n",
      "31938/31938 [==============================] - 22s 676us/sample - loss: 1.4083 - val_loss: 1.3051\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:42:19.326393: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_4_1/lstm_cell_41/bias/Assign' id:19309 op device:{requested: '', assigned: ''} def:{{{node lstm_4_1/lstm_cell_41/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_4_1/lstm_cell_41/bias, lstm_4_1/lstm_cell_41/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 04:42:20.991098: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_16_1/lstm_cell_53/bias/v/Assign' id:26145 op device:{requested: '', assigned: ''} def:{{{node lstm_16_1/lstm_cell_53/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_16_1/lstm_cell_53/bias/v, lstm_16_1/lstm_cell_53/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 04:42:22.305880: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_4_1/cond/Merge' id:24591 op device:{requested: '', assigned: ''} def:{{{node dropout_4_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_4_1/cond/Identity, dropout_4_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1502)\n",
      "(1632, 1502)\n",
      "(1752, 1502)\n",
      "(1872, 1502)\n",
      "(1687, 1502)\n",
      "(1345, 1502)\n",
      "(1826, 1502)\n",
      "(1595, 1502)\n",
      "(1764, 1502)\n",
      "(1502, 1502)\n",
      "(1932, 1502)\n",
      "(1728, 1502)\n",
      "(1788, 1502)\n",
      "(1836, 1502)\n",
      "(1728, 1502)\n",
      "(1812, 1502)\n",
      "(947, 1502)\n",
      "(1680, 1502)\n",
      "(1872, 1502)\n",
      "{1: 8.299379707668747, 4: 8.294086490878973, 5: 5.23998791503016, 6: 4.214386531509476, 8: 9.07758008897038, 9: 9.514766791336326, 10: 7.497948680550492, 11: 7.077311719295321, 12: 9.79260691551981, 13: 7.786872805692438, 17: 9.374432787773344, 19: 6.7664071176305125, 21: 10.0, 22: 1.8995818183712379, 25: 7.776288872451477, 26: 9.451708252159147, 27: 6.462325939971038, 28: 5.784876702053403, 29: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907579/3261308647.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31938 samples, validate on 3561 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:46:09.746982: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 10.5963\n",
      "Epoch 1: val_loss improved from inf to 1.32956, saving model to ./checkpoints/unknown_person_few_shot_p2_30.h5\n",
      "31938/31938 [==============================] - 28s 871us/sample - loss: 10.5963 - val_loss: 1.3296\n",
      "Epoch 2/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.5261\n",
      "Epoch 2: val_loss improved from 1.32956 to 1.32583, saving model to ./checkpoints/unknown_person_few_shot_p2_30.h5\n",
      "31938/31938 [==============================] - 21s 653us/sample - loss: 10.5261 - val_loss: 1.3258\n",
      "Epoch 3/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.4809\n",
      "Epoch 3: val_loss did not improve from 1.32583\n",
      "31938/31938 [==============================] - 20s 617us/sample - loss: 10.4809 - val_loss: 1.3307\n",
      "Epoch 4/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.4091\n",
      "Epoch 4: val_loss did not improve from 1.32583\n",
      "31938/31938 [==============================] - 20s 621us/sample - loss: 10.4091 - val_loss: 1.3271\n",
      "Epoch 5/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3909\n",
      "Epoch 5: val_loss improved from 1.32583 to 1.31789, saving model to ./checkpoints/unknown_person_few_shot_p2_30.h5\n",
      "31938/31938 [==============================] - 21s 666us/sample - loss: 10.3909 - val_loss: 1.3179\n",
      "Epoch 6/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3510\n",
      "Epoch 6: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 22s 702us/sample - loss: 10.3510 - val_loss: 1.3224\n",
      "Epoch 7/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3317\n",
      "Epoch 7: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 20s 636us/sample - loss: 10.3317 - val_loss: 1.3229\n",
      "Epoch 8/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3241\n",
      "Epoch 8: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 20s 619us/sample - loss: 10.3241 - val_loss: 1.3203\n",
      "Epoch 9/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2986\n",
      "Epoch 9: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 20s 619us/sample - loss: 10.2986 - val_loss: 1.3232\n",
      "Epoch 10/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2722\n",
      "Epoch 10: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 20s 622us/sample - loss: 10.2722 - val_loss: 1.3240\n",
      "Epoch 11/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2724\n",
      "Epoch 11: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 21s 659us/sample - loss: 10.2724 - val_loss: 1.3243\n",
      "Epoch 12/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2603\n",
      "Epoch 12: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 20s 624us/sample - loss: 10.2603 - val_loss: 1.3260\n",
      "Epoch 13/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2536\n",
      "Epoch 13: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 21s 648us/sample - loss: 10.2536 - val_loss: 1.3244\n",
      "Epoch 14/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2175\n",
      "Epoch 14: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 20s 628us/sample - loss: 10.2175 - val_loss: 1.3271\n",
      "Epoch 15/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1920\n",
      "Epoch 15: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 21s 647us/sample - loss: 10.1920 - val_loss: 1.3258\n",
      "Epoch 16/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2178\n",
      "Epoch 16: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 23s 709us/sample - loss: 10.2178 - val_loss: 1.3229\n",
      "Epoch 17/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1868\n",
      "Epoch 17: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 23s 709us/sample - loss: 10.1868 - val_loss: 1.3273\n",
      "Epoch 18/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1779\n",
      "Epoch 18: val_loss did not improve from 1.31789\n",
      "31938/31938 [==============================] - 23s 716us/sample - loss: 10.1779 - val_loss: 1.3209\n",
      "Epoch 19/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1704\n",
      "Epoch 19: val_loss improved from 1.31789 to 1.31713, saving model to ./checkpoints/unknown_person_few_shot_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 714us/sample - loss: 10.1704 - val_loss: 1.3171\n",
      "Epoch 20/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1596\n",
      "Epoch 20: val_loss did not improve from 1.31713\n",
      "31938/31938 [==============================] - 23s 711us/sample - loss: 10.1596 - val_loss: 1.3338\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:53:19.479249: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_32_2/lstm_cell_106/bias/Assign' id:43189 op device:{requested: '', assigned: ''} def:{{{node lstm_32_2/lstm_cell_106/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_32_2/lstm_cell_106/bias, lstm_32_2/lstm_cell_106/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 04:53:22.067887: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_21_2/lstm_cell_95/bias/v/Assign' id:45618 op device:{requested: '', assigned: ''} def:{{{node lstm_21_2/lstm_cell_95/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_21_2/lstm_cell_95/bias/v, lstm_21_2/lstm_cell_95/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31938 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:53:27.434569: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:53:41.069344: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_6/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 04:54:05.489337: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.30910, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_30.h5\n",
      "31938/31938 [==============================] - 31s 979us/sample - loss: 1.4066 - val_loss: 1.3091\n",
      "Epoch 2/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4073\n",
      "Epoch 2: val_loss did not improve from 1.30910\n",
      "31938/31938 [==============================] - 23s 710us/sample - loss: 1.4073 - val_loss: 1.3136\n",
      "Epoch 3/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4022\n",
      "Epoch 3: val_loss improved from 1.30910 to 1.30759, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_30.h5\n",
      "31938/31938 [==============================] - 22s 696us/sample - loss: 1.4022 - val_loss: 1.3076\n",
      "Epoch 4/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4034\n",
      "Epoch 4: val_loss improved from 1.30759 to 1.30487, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_30.h5\n",
      "31938/31938 [==============================] - 23s 707us/sample - loss: 1.4034 - val_loss: 1.3049\n",
      "Epoch 5/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4017\n",
      "Epoch 5: val_loss did not improve from 1.30487\n",
      "31938/31938 [==============================] - 22s 704us/sample - loss: 1.4017 - val_loss: 1.3062\n",
      "Epoch 6/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3967\n",
      "Epoch 6: val_loss did not improve from 1.30487\n",
      "31938/31938 [==============================] - 23s 708us/sample - loss: 1.3967 - val_loss: 1.3062\n",
      "Epoch 7/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3956\n",
      "Epoch 7: val_loss did not improve from 1.30487\n",
      "31938/31938 [==============================] - 23s 710us/sample - loss: 1.3956 - val_loss: 1.3066\n",
      "Epoch 8/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3971\n",
      "Epoch 8: val_loss did not improve from 1.30487\n",
      "31938/31938 [==============================] - 22s 686us/sample - loss: 1.3971 - val_loss: 1.3127\n",
      "Epoch 9/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 9: val_loss did not improve from 1.30487\n",
      "31938/31938 [==============================] - 20s 640us/sample - loss: 1.3957 - val_loss: 1.3082\n",
      "Epoch 10/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3958\n",
      "Epoch 10: val_loss improved from 1.30487 to 1.30359, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_30.h5\n",
      "31938/31938 [==============================] - 20s 615us/sample - loss: 1.3958 - val_loss: 1.3036\n",
      "Epoch 11/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3929\n",
      "Epoch 11: val_loss improved from 1.30359 to 1.30170, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_30.h5\n",
      "31938/31938 [==============================] - 20s 624us/sample - loss: 1.3929 - val_loss: 1.3017\n",
      "Epoch 12/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 12: val_loss did not improve from 1.30170\n",
      "31938/31938 [==============================] - 20s 641us/sample - loss: 1.3917 - val_loss: 1.3107\n",
      "Epoch 13/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3904\n",
      "Epoch 13: val_loss improved from 1.30170 to 1.30068, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_30.h5\n",
      "31938/31938 [==============================] - 20s 629us/sample - loss: 1.3904 - val_loss: 1.3007\n",
      "Epoch 14/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 14: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 20s 619us/sample - loss: 1.3905 - val_loss: 1.3072\n",
      "Epoch 15/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3889\n",
      "Epoch 15: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 20s 616us/sample - loss: 1.3889 - val_loss: 1.3008\n",
      "Epoch 16/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3889\n",
      "Epoch 16: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 19s 608us/sample - loss: 1.3889 - val_loss: 1.3023\n",
      "Epoch 17/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3866\n",
      "Epoch 17: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 20s 617us/sample - loss: 1.3866 - val_loss: 1.3021\n",
      "Epoch 18/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3884\n",
      "Epoch 18: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 22s 704us/sample - loss: 1.3884 - val_loss: 1.3028\n",
      "Epoch 19/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3866\n",
      "Epoch 19: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 23s 708us/sample - loss: 1.3866 - val_loss: 1.3044\n",
      "Epoch 20/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3843\n",
      "Epoch 20: val_loss did not improve from 1.30068\n",
      "31938/31938 [==============================] - 23s 710us/sample - loss: 1.3843 - val_loss: 1.3016\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:00:57.218403: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_51/lstm_cell_125/bias/Assign' id:59399 op device:{requested: '', assigned: ''} def:{{{node lstm_51/lstm_cell_125/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_51/lstm_cell_125/bias, lstm_51/lstm_cell_125/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:00:58.622585: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_1' id:60678 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:00:59.715991: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_2' id:60679 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31938, 95)\n",
      "Train on 31938 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:01:06.115352: W tensorflow/c/c_api.cc:304] Operation '{name:'training_6/Adam/lstm_68/lstm_cell_142/kernel/v/Assign' id:74544 op device:{requested: '', assigned: ''} def:{{{node training_6/Adam/lstm_68/lstm_cell_142/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_6/Adam/lstm_68/lstm_cell_142/kernel/v, training_6/Adam/lstm_68/lstm_cell_142/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:01:29.589669: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 2.9320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:02:04.249479: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_7/mul' id:63519 op device:{requested: '', assigned: ''} def:{{{node loss_7/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_7/mul/x, loss_7/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.82732, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 61s 2ms/sample - loss: 2.9320 - val_loss: 1.8273\n",
      "Epoch 2/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.7567\n",
      "Epoch 2: val_loss improved from 1.82732 to 1.48332, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.7567 - val_loss: 1.4833\n",
      "Epoch 3/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.6071\n",
      "Epoch 3: val_loss improved from 1.48332 to 1.43110, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.6071 - val_loss: 1.4311\n",
      "Epoch 4/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5575\n",
      "Epoch 4: val_loss improved from 1.43110 to 1.41330, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 981us/sample - loss: 1.5575 - val_loss: 1.4133\n",
      "Epoch 5/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5360\n",
      "Epoch 5: val_loss improved from 1.41330 to 1.40422, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.5360 - val_loss: 1.4042\n",
      "Epoch 6/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5229\n",
      "Epoch 6: val_loss improved from 1.40422 to 1.37920, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 991us/sample - loss: 1.5229 - val_loss: 1.3792\n",
      "Epoch 7/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5107\n",
      "Epoch 7: val_loss improved from 1.37920 to 1.37317, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 30s 929us/sample - loss: 1.5107 - val_loss: 1.3732\n",
      "Epoch 8/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5126\n",
      "Epoch 8: val_loss improved from 1.37317 to 1.36980, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.5126 - val_loss: 1.3698\n",
      "Epoch 9/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5096\n",
      "Epoch 9: val_loss improved from 1.36980 to 1.36270, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.5096 - val_loss: 1.3627\n",
      "Epoch 10/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4946\n",
      "Epoch 10: val_loss improved from 1.36270 to 1.35903, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.4946 - val_loss: 1.3590\n",
      "Epoch 11/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4994\n",
      "Epoch 11: val_loss improved from 1.35903 to 1.35809, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4994 - val_loss: 1.3581\n",
      "Epoch 12/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4923\n",
      "Epoch 12: val_loss improved from 1.35809 to 1.35751, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4923 - val_loss: 1.3575\n",
      "Epoch 13/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4920\n",
      "Epoch 13: val_loss improved from 1.35751 to 1.35128, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4920 - val_loss: 1.3513\n",
      "Epoch 14/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4864\n",
      "Epoch 14: val_loss did not improve from 1.35128\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4864 - val_loss: 1.3564\n",
      "Epoch 15/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 15: val_loss did not improve from 1.35128\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.4854 - val_loss: 1.3601\n",
      "Epoch 16/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5151\n",
      "Epoch 16: val_loss did not improve from 1.35128\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.5151 - val_loss: 1.3549\n",
      "Epoch 17/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4896\n",
      "Epoch 17: val_loss did not improve from 1.35128\n",
      "31938/31938 [==============================] - 32s 992us/sample - loss: 1.4896 - val_loss: 1.3561\n",
      "Epoch 18/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4848\n",
      "Epoch 18: val_loss improved from 1.35128 to 1.35050, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 985us/sample - loss: 1.4848 - val_loss: 1.3505\n",
      "Epoch 19/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4775\n",
      "Epoch 19: val_loss did not improve from 1.35050\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4775 - val_loss: 1.3522\n",
      "Epoch 20/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4828\n",
      "Epoch 20: val_loss improved from 1.35050 to 1.35035, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4828 - val_loss: 1.3504\n",
      "Epoch 21/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4911\n",
      "Epoch 21: val_loss improved from 1.35035 to 1.35012, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 966us/sample - loss: 1.4911 - val_loss: 1.3501\n",
      "Epoch 22/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5208\n",
      "Epoch 22: val_loss did not improve from 1.35012\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.5208 - val_loss: 1.3517\n",
      "Epoch 23/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5208\n",
      "Epoch 23: val_loss did not improve from 1.35012\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.5208 - val_loss: 1.3520\n",
      "Epoch 24/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5073\n",
      "Epoch 24: val_loss did not improve from 1.35012\n",
      "31938/31938 [==============================] - 32s 995us/sample - loss: 1.5073 - val_loss: 1.3632\n",
      "Epoch 25/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4718\n",
      "Epoch 25: val_loss improved from 1.35012 to 1.34938, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 29s 911us/sample - loss: 1.4718 - val_loss: 1.3494\n",
      "Epoch 26/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4636\n",
      "Epoch 26: val_loss improved from 1.34938 to 1.34848, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 30s 946us/sample - loss: 1.4636 - val_loss: 1.3485\n",
      "Epoch 27/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4593\n",
      "Epoch 27: val_loss improved from 1.34848 to 1.34591, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 970us/sample - loss: 1.4593 - val_loss: 1.3459\n",
      "Epoch 28/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 28: val_loss improved from 1.34591 to 1.34125, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4597 - val_loss: 1.3413\n",
      "Epoch 29/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4563\n",
      "Epoch 29: val_loss improved from 1.34125 to 1.34069, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4563 - val_loss: 1.3407\n",
      "Epoch 30/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4521\n",
      "Epoch 30: val_loss improved from 1.34069 to 1.33576, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.4521 - val_loss: 1.3358\n",
      "Epoch 31/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4479\n",
      "Epoch 31: val_loss improved from 1.33576 to 1.33271, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 979us/sample - loss: 1.4479 - val_loss: 1.3327\n",
      "Epoch 32/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4431\n",
      "Epoch 32: val_loss improved from 1.33271 to 1.33098, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4431 - val_loss: 1.3310\n",
      "Epoch 33/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4418\n",
      "Epoch 33: val_loss did not improve from 1.33098\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4418 - val_loss: 1.3381\n",
      "Epoch 34/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4407\n",
      "Epoch 34: val_loss improved from 1.33098 to 1.32954, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4407 - val_loss: 1.3295\n",
      "Epoch 35/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4384\n",
      "Epoch 35: val_loss did not improve from 1.32954\n",
      "31938/31938 [==============================] - 32s 996us/sample - loss: 1.4384 - val_loss: 1.3320\n",
      "Epoch 36/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 36: val_loss improved from 1.32954 to 1.32930, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 963us/sample - loss: 1.4375 - val_loss: 1.3293\n",
      "Epoch 37/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 37: val_loss did not improve from 1.32930\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4349 - val_loss: 1.3305\n",
      "Epoch 38/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4317\n",
      "Epoch 38: val_loss did not improve from 1.32930\n",
      "31938/31938 [==============================] - 32s 995us/sample - loss: 1.4317 - val_loss: 1.3340\n",
      "Epoch 39/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4321\n",
      "Epoch 39: val_loss did not improve from 1.32930\n",
      "31938/31938 [==============================] - 32s 990us/sample - loss: 1.4321 - val_loss: 1.3302\n",
      "Epoch 40/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4276\n",
      "Epoch 40: val_loss improved from 1.32930 to 1.32738, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 30s 930us/sample - loss: 1.4276 - val_loss: 1.3274\n",
      "Epoch 41/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 41: val_loss improved from 1.32738 to 1.32083, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4242 - val_loss: 1.3208\n",
      "Epoch 42/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4251\n",
      "Epoch 42: val_loss did not improve from 1.32083\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4251 - val_loss: 1.3218\n",
      "Epoch 43/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4254\n",
      "Epoch 43: val_loss improved from 1.32083 to 1.31744, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 994us/sample - loss: 1.4254 - val_loss: 1.3174\n",
      "Epoch 44/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4228\n",
      "Epoch 44: val_loss did not improve from 1.31744\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4228 - val_loss: 1.3216\n",
      "Epoch 45/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 45: val_loss did not improve from 1.31744\n",
      "31938/31938 [==============================] - 32s 989us/sample - loss: 1.4210 - val_loss: 1.3243\n",
      "Epoch 46/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4198\n",
      "Epoch 46: val_loss did not improve from 1.31744\n",
      "31938/31938 [==============================] - 31s 983us/sample - loss: 1.4198 - val_loss: 1.3213\n",
      "Epoch 47/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4161\n",
      "Epoch 47: val_loss improved from 1.31744 to 1.31664, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4161 - val_loss: 1.3166\n",
      "Epoch 48/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4139\n",
      "Epoch 48: val_loss did not improve from 1.31664\n",
      "31938/31938 [==============================] - 31s 983us/sample - loss: 1.4139 - val_loss: 1.3168\n",
      "Epoch 49/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4129\n",
      "Epoch 49: val_loss improved from 1.31664 to 1.31530, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 30s 941us/sample - loss: 1.4129 - val_loss: 1.3153\n",
      "Epoch 50/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4103\n",
      "Epoch 50: val_loss improved from 1.31530 to 1.31340, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 989us/sample - loss: 1.4103 - val_loss: 1.3134\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:28:48.301392: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_6_1/kernel/Assign' id:81664 op device:{requested: '', assigned: ''} def:{{{node dense_6_1/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_6_1/kernel, dense_6_1/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:28:54.923847: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_6_1/bias/v/Assign' id:83523 op device:{requested: '', assigned: ''} def:{{{node dense_6_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_6_1/bias/v, dense_6_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:29:01.220391: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_9_1/cond/Merge' id:81633 op device:{requested: '', assigned: ''} def:{{{node dropout_9_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_9_1/cond/Identity, dropout_9_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1502)\n",
      "(1632, 1502)\n",
      "(1752, 1502)\n",
      "(1872, 1502)\n",
      "(1687, 1502)\n",
      "(1345, 1502)\n",
      "(1826, 1502)\n",
      "(1595, 1502)\n",
      "(1764, 1502)\n",
      "(1502, 1502)\n",
      "(1932, 1502)\n",
      "(1728, 1502)\n",
      "(1788, 1502)\n",
      "(1836, 1502)\n",
      "(1728, 1502)\n",
      "(1812, 1502)\n",
      "(947, 1502)\n",
      "(1680, 1502)\n",
      "(1872, 1502)\n",
      "{1: 8.483841936941179, 4: 8.283420209766954, 5: 4.598268510759526, 6: 3.7721075988370916, 8: 9.159682977503513, 9: 9.672468891958934, 10: 7.213315517009146, 11: 7.275196649068874, 12: 10.0, 13: 7.643174468460457, 17: 9.517130729464045, 19: 7.1285648044952445, 21: 9.91082460893685, 22: 1.1213615899281346, 25: 8.173685320962033, 26: 8.812712845275714, 27: 6.339362831984991, 28: 6.089006128036751, 29: 1.0}\n",
      "Train on 31938 samples, validate on 3561 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:34:50.388732: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 10.5280\n",
      "Epoch 1: val_loss improved from inf to 1.35055, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 49s 2ms/sample - loss: 10.5280 - val_loss: 1.3506\n",
      "Epoch 2/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.4658\n",
      "Epoch 2: val_loss improved from 1.35055 to 1.34328, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 970us/sample - loss: 10.4658 - val_loss: 1.3433\n",
      "Epoch 3/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.4169\n",
      "Epoch 3: val_loss improved from 1.34328 to 1.34144, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 968us/sample - loss: 10.4169 - val_loss: 1.3414\n",
      "Epoch 4/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3478\n",
      "Epoch 4: val_loss improved from 1.34144 to 1.34009, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 981us/sample - loss: 10.3478 - val_loss: 1.3401\n",
      "Epoch 5/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3266\n",
      "Epoch 5: val_loss did not improve from 1.34009\n",
      "31938/31938 [==============================] - 30s 936us/sample - loss: 10.3266 - val_loss: 1.3483\n",
      "Epoch 6/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3009\n",
      "Epoch 6: val_loss did not improve from 1.34009\n",
      "31938/31938 [==============================] - 31s 957us/sample - loss: 10.3009 - val_loss: 1.3415\n",
      "Epoch 7/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2896\n",
      "Epoch 7: val_loss did not improve from 1.34009\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 10.2896 - val_loss: 1.3424\n",
      "Epoch 8/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2391\n",
      "Epoch 8: val_loss did not improve from 1.34009\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 10.2391 - val_loss: 1.3463\n",
      "Epoch 9/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2373\n",
      "Epoch 9: val_loss did not improve from 1.34009\n",
      "31938/31938 [==============================] - 32s 993us/sample - loss: 10.2373 - val_loss: 1.3542\n",
      "Epoch 10/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2408\n",
      "Epoch 10: val_loss improved from 1.34009 to 1.33462, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 967us/sample - loss: 10.2408 - val_loss: 1.3346\n",
      "Epoch 11/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2208\n",
      "Epoch 11: val_loss did not improve from 1.33462\n",
      "31938/31938 [==============================] - 31s 966us/sample - loss: 10.2208 - val_loss: 1.3516\n",
      "Epoch 12/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2007\n",
      "Epoch 12: val_loss improved from 1.33462 to 1.33113, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 10.2007 - val_loss: 1.3311\n",
      "Epoch 13/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1860\n",
      "Epoch 13: val_loss did not improve from 1.33113\n",
      "31938/31938 [==============================] - 30s 935us/sample - loss: 10.1860 - val_loss: 1.3352\n",
      "Epoch 14/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1845\n",
      "Epoch 14: val_loss did not improve from 1.33113\n",
      "31938/31938 [==============================] - 31s 958us/sample - loss: 10.1845 - val_loss: 1.3335\n",
      "Epoch 15/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1701\n",
      "Epoch 15: val_loss improved from 1.33113 to 1.33084, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 10.1701 - val_loss: 1.3308\n",
      "Epoch 16/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1806\n",
      "Epoch 16: val_loss improved from 1.33084 to 1.32698, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 31s 971us/sample - loss: 10.1806 - val_loss: 1.3270\n",
      "Epoch 17/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1588\n",
      "Epoch 17: val_loss did not improve from 1.32698\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 10.1588 - val_loss: 1.3322\n",
      "Epoch 18/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1248\n",
      "Epoch 18: val_loss improved from 1.32698 to 1.32669, saving model to ./checkpoints/unknown_person_few_shot_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 991us/sample - loss: 10.1248 - val_loss: 1.3267\n",
      "Epoch 19/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1251\n",
      "Epoch 19: val_loss did not improve from 1.32669\n",
      "31938/31938 [==============================] - 30s 930us/sample - loss: 10.1251 - val_loss: 1.3324\n",
      "Epoch 20/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0913\n",
      "Epoch 20: val_loss did not improve from 1.32669\n",
      "31938/31938 [==============================] - 31s 961us/sample - loss: 10.0913 - val_loss: 1.3288\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:45:37.165585: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_52_2/lstm_cell_200/kernel/Assign' id:97480 op device:{requested: '', assigned: ''} def:{{{node lstm_52_2/lstm_cell_200/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_52_2/lstm_cell_200/kernel, lstm_52_2/lstm_cell_200/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:45:45.199510: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_7_2/kernel/v/Assign' id:102325 op device:{requested: '', assigned: ''} def:{{{node conv2d_7_2/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_7_2/kernel/v, conv2d_7_2/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31938 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:45:56.540599: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:46:33.815294: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_3/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:47:06.356118: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.31964, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 47s 1ms/sample - loss: 1.4105 - val_loss: 1.3196\n",
      "Epoch 2/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 2: val_loss improved from 1.31964 to 1.31627, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 997us/sample - loss: 1.4093 - val_loss: 1.3163\n",
      "Epoch 3/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 3: val_loss did not improve from 1.31627\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4087 - val_loss: 1.3170\n",
      "Epoch 4/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 4: val_loss improved from 1.31627 to 1.31321, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4069 - val_loss: 1.3132\n",
      "Epoch 5/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4040\n",
      "Epoch 5: val_loss improved from 1.31321 to 1.31194, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 988us/sample - loss: 1.4040 - val_loss: 1.3119\n",
      "Epoch 6/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3999\n",
      "Epoch 6: val_loss improved from 1.31194 to 1.30932, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.3999 - val_loss: 1.3093\n",
      "Epoch 7/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 7: val_loss improved from 1.30932 to 1.30804, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4015 - val_loss: 1.3080\n",
      "Epoch 8/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3985\n",
      "Epoch 8: val_loss did not improve from 1.30804\n",
      "31938/31938 [==============================] - 31s 958us/sample - loss: 1.3985 - val_loss: 1.3107\n",
      "Epoch 9/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3989\n",
      "Epoch 9: val_loss did not improve from 1.30804\n",
      "31938/31938 [==============================] - 31s 977us/sample - loss: 1.3989 - val_loss: 1.3111\n",
      "Epoch 10/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 10: val_loss did not improve from 1.30804\n",
      "31938/31938 [==============================] - 31s 976us/sample - loss: 1.3980 - val_loss: 1.3144\n",
      "Epoch 11/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3973\n",
      "Epoch 11: val_loss did not improve from 1.30804\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.3973 - val_loss: 1.3109\n",
      "Epoch 12/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 12: val_loss improved from 1.30804 to 1.30323, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.3984 - val_loss: 1.3032\n",
      "Epoch 13/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3941\n",
      "Epoch 13: val_loss did not improve from 1.30323\n",
      "31938/31938 [==============================] - 31s 970us/sample - loss: 1.3941 - val_loss: 1.3103\n",
      "Epoch 14/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 14: val_loss did not improve from 1.30323\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.3947 - val_loss: 1.3107\n",
      "Epoch 15/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 15: val_loss improved from 1.30323 to 1.30269, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_31.h5\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.3918 - val_loss: 1.3027\n",
      "Epoch 16/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3938\n",
      "Epoch 16: val_loss did not improve from 1.30269\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 1.3938 - val_loss: 1.3106\n",
      "Epoch 17/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 17: val_loss did not improve from 1.30269\n",
      "31938/31938 [==============================] - 31s 983us/sample - loss: 1.3918 - val_loss: 1.3105\n",
      "Epoch 18/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3912\n",
      "Epoch 18: val_loss did not improve from 1.30269\n",
      "31938/31938 [==============================] - 31s 963us/sample - loss: 1.3912 - val_loss: 1.3033\n",
      "Epoch 19/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 19: val_loss did not improve from 1.30269\n",
      "31938/31938 [==============================] - 30s 928us/sample - loss: 1.3882 - val_loss: 1.3057\n",
      "Epoch 20/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.3889\n",
      "Epoch 20: val_loss did not improve from 1.30269\n",
      "31938/31938 [==============================] - 31s 969us/sample - loss: 1.3889 - val_loss: 1.3072\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:57:31.610583: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_95/lstm_cell_243/recurrent_kernel/Assign' id:117587 op device:{requested: '', assigned: ''} def:{{{node lstm_95/lstm_cell_243/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_95/lstm_cell_243/recurrent_kernel, lstm_95/lstm_cell_243/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:57:35.502724: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_1' id:117720 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 05:57:38.085774: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_2' id:117721 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31938, 95)\n",
      "Train on 31938 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:57:48.507255: W tensorflow/c/c_api.cc:304] Operation '{name:'training_12/Adam/lstm_78/lstm_cell_226/kernel/v/Assign' id:131181 op device:{requested: '', assigned: ''} def:{{{node training_12/Adam/lstm_78/lstm_cell_226/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_12/Adam/lstm_78/lstm_cell_226/kernel/v, training_12/Adam/lstm_78/lstm_cell_226/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:58:34.739708: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 3.3650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 05:59:10.200615: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_13/mul' id:120561 op device:{requested: '', assigned: ''} def:{{{node loss_13/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_13/mul/x, loss_13/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.82519, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 82s 3ms/sample - loss: 3.3650 - val_loss: 1.8252\n",
      "Epoch 2/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.7607\n",
      "Epoch 2: val_loss improved from 1.82519 to 1.49769, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 35s 1ms/sample - loss: 1.7607 - val_loss: 1.4977\n",
      "Epoch 3/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5949\n",
      "Epoch 3: val_loss improved from 1.49769 to 1.43581, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 30s 933us/sample - loss: 1.5949 - val_loss: 1.4358\n",
      "Epoch 4/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5527\n",
      "Epoch 4: val_loss improved from 1.43581 to 1.40515, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 969us/sample - loss: 1.5527 - val_loss: 1.4051\n",
      "Epoch 5/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5314\n",
      "Epoch 5: val_loss improved from 1.40515 to 1.39202, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 30s 949us/sample - loss: 1.5314 - val_loss: 1.3920\n",
      "Epoch 6/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5176\n",
      "Epoch 6: val_loss improved from 1.39202 to 1.37764, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 966us/sample - loss: 1.5176 - val_loss: 1.3776\n",
      "Epoch 7/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5087\n",
      "Epoch 7: val_loss did not improve from 1.37764\n",
      "31938/31938 [==============================] - 30s 952us/sample - loss: 1.5087 - val_loss: 1.3785\n",
      "Epoch 8/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5101\n",
      "Epoch 8: val_loss improved from 1.37764 to 1.36833, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.5101 - val_loss: 1.3683\n",
      "Epoch 9/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5075\n",
      "Epoch 9: val_loss did not improve from 1.36833\n",
      "31938/31938 [==============================] - 29s 910us/sample - loss: 1.5075 - val_loss: 1.3687\n",
      "Epoch 10/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.6537\n",
      "Epoch 10: val_loss did not improve from 1.36833\n",
      "31938/31938 [==============================] - 30s 934us/sample - loss: 1.6537 - val_loss: 1.4044\n",
      "Epoch 11/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5141\n",
      "Epoch 11: val_loss did not improve from 1.36833\n",
      "31938/31938 [==============================] - 29s 916us/sample - loss: 1.5141 - val_loss: 1.3823\n",
      "Epoch 12/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5348\n",
      "Epoch 12: val_loss did not improve from 1.36833\n",
      "31938/31938 [==============================] - 32s 993us/sample - loss: 1.5348 - val_loss: 1.3815\n",
      "Epoch 13/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5073\n",
      "Epoch 13: val_loss did not improve from 1.36833\n",
      "31938/31938 [==============================] - 31s 968us/sample - loss: 1.5073 - val_loss: 1.3766\n",
      "Epoch 14/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5256\n",
      "Epoch 14: val_loss improved from 1.36833 to 1.36288, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 30s 939us/sample - loss: 1.5256 - val_loss: 1.3629\n",
      "Epoch 15/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4991\n",
      "Epoch 15: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 31s 957us/sample - loss: 1.4991 - val_loss: 1.3633\n",
      "Epoch 16/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5459\n",
      "Epoch 16: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 31s 971us/sample - loss: 1.5459 - val_loss: 1.3839\n",
      "Epoch 17/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.6187\n",
      "Epoch 17: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 32s 992us/sample - loss: 1.6187 - val_loss: 1.3722\n",
      "Epoch 18/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5250\n",
      "Epoch 18: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 29s 894us/sample - loss: 1.5250 - val_loss: 1.3697\n",
      "Epoch 19/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5065\n",
      "Epoch 19: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 30s 931us/sample - loss: 1.5065 - val_loss: 1.3648\n",
      "Epoch 20/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5340\n",
      "Epoch 20: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 30s 933us/sample - loss: 1.5340 - val_loss: 1.3652\n",
      "Epoch 21/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.6744\n",
      "Epoch 21: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 30s 937us/sample - loss: 1.6744 - val_loss: 1.4055\n",
      "Epoch 22/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5530\n",
      "Epoch 22: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 28s 877us/sample - loss: 1.5530 - val_loss: 1.3719\n",
      "Epoch 23/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5816\n",
      "Epoch 23: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 31s 982us/sample - loss: 1.5816 - val_loss: 1.3732\n",
      "Epoch 24/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5206\n",
      "Epoch 24: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 30s 929us/sample - loss: 1.5206 - val_loss: 1.3643\n",
      "Epoch 25/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5086\n",
      "Epoch 25: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 31s 975us/sample - loss: 1.5086 - val_loss: 1.3638\n",
      "Epoch 26/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5021\n",
      "Epoch 26: val_loss did not improve from 1.36288\n",
      "31938/31938 [==============================] - 31s 981us/sample - loss: 1.5021 - val_loss: 1.3635\n",
      "Epoch 27/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.5003\n",
      "Epoch 27: val_loss improved from 1.36288 to 1.36166, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 958us/sample - loss: 1.5003 - val_loss: 1.3617\n",
      "Epoch 28/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4953\n",
      "Epoch 28: val_loss did not improve from 1.36166\n",
      "31938/31938 [==============================] - 31s 980us/sample - loss: 1.4953 - val_loss: 1.3617\n",
      "Epoch 29/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4919\n",
      "Epoch 29: val_loss improved from 1.36166 to 1.35733, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 980us/sample - loss: 1.4919 - val_loss: 1.3573\n",
      "Epoch 30/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4859\n",
      "Epoch 30: val_loss did not improve from 1.35733\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4859 - val_loss: 1.3605\n",
      "Epoch 31/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4823\n",
      "Epoch 31: val_loss improved from 1.35733 to 1.35633, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 959us/sample - loss: 1.4823 - val_loss: 1.3563\n",
      "Epoch 32/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4807\n",
      "Epoch 32: val_loss improved from 1.35633 to 1.35531, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 990us/sample - loss: 1.4807 - val_loss: 1.3553\n",
      "Epoch 33/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4800\n",
      "Epoch 33: val_loss did not improve from 1.35531\n",
      "31938/31938 [==============================] - 30s 939us/sample - loss: 1.4800 - val_loss: 1.3575\n",
      "Epoch 34/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4746\n",
      "Epoch 34: val_loss improved from 1.35531 to 1.35304, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 984us/sample - loss: 1.4746 - val_loss: 1.3530\n",
      "Epoch 35/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4743\n",
      "Epoch 35: val_loss improved from 1.35304 to 1.35243, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4743 - val_loss: 1.3524\n",
      "Epoch 36/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4713\n",
      "Epoch 36: val_loss improved from 1.35243 to 1.35131, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 28s 884us/sample - loss: 1.4713 - val_loss: 1.3513\n",
      "Epoch 37/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4701\n",
      "Epoch 37: val_loss improved from 1.35131 to 1.35013, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 29s 911us/sample - loss: 1.4701 - val_loss: 1.3501\n",
      "Epoch 38/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 38: val_loss did not improve from 1.35013\n",
      "31938/31938 [==============================] - 30s 927us/sample - loss: 1.4689 - val_loss: 1.3512\n",
      "Epoch 39/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4756\n",
      "Epoch 39: val_loss did not improve from 1.35013\n",
      "31938/31938 [==============================] - 29s 909us/sample - loss: 1.4756 - val_loss: 1.3532\n",
      "Epoch 40/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4711\n",
      "Epoch 40: val_loss did not improve from 1.35013\n",
      "31938/31938 [==============================] - 31s 974us/sample - loss: 1.4711 - val_loss: 1.3553\n",
      "Epoch 41/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4690\n",
      "Epoch 41: val_loss did not improve from 1.35013\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4690 - val_loss: 1.3531\n",
      "Epoch 42/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4660\n",
      "Epoch 42: val_loss improved from 1.35013 to 1.34933, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4660 - val_loss: 1.3493\n",
      "Epoch 43/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4653\n",
      "Epoch 43: val_loss did not improve from 1.34933\n",
      "31938/31938 [==============================] - 32s 988us/sample - loss: 1.4653 - val_loss: 1.3508\n",
      "Epoch 44/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4616\n",
      "Epoch 44: val_loss did not improve from 1.34933\n",
      "31938/31938 [==============================] - 32s 991us/sample - loss: 1.4616 - val_loss: 1.3500\n",
      "Epoch 45/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4626\n",
      "Epoch 45: val_loss did not improve from 1.34933\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4626 - val_loss: 1.3531\n",
      "Epoch 46/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4578\n",
      "Epoch 46: val_loss improved from 1.34933 to 1.34223, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 999us/sample - loss: 1.4578 - val_loss: 1.3422\n",
      "Epoch 47/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4570\n",
      "Epoch 47: val_loss improved from 1.34223 to 1.34081, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4570 - val_loss: 1.3408\n",
      "Epoch 48/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4536\n",
      "Epoch 48: val_loss did not improve from 1.34081\n",
      "31938/31938 [==============================] - 36s 1ms/sample - loss: 1.4536 - val_loss: 1.3411\n",
      "Epoch 49/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 49: val_loss did not improve from 1.34081\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 1.4535 - val_loss: 1.3411\n",
      "Epoch 50/50\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4545\n",
      "Epoch 50: val_loss improved from 1.34081 to 1.33682, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_32.h5\n",
      "31938/31938 [==============================] - 30s 951us/sample - loss: 1.4545 - val_loss: 1.3368\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:25:15.916662: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_93_1/lstm_cell_278/recurrent_kernel/Assign' id:135784 op device:{requested: '', assigned: ''} def:{{{node lstm_93_1/lstm_cell_278/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_93_1/lstm_cell_278/recurrent_kernel, lstm_93_1/lstm_cell_278/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 06:25:26.946771: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_93_1/lstm_cell_278/bias/m/Assign' id:139631 op device:{requested: '', assigned: ''} def:{{{node lstm_93_1/lstm_cell_278/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_93_1/lstm_cell_278/bias/m, lstm_93_1/lstm_cell_278/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 06:25:37.376742: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_14_1/cond/Merge' id:138675 op device:{requested: '', assigned: ''} def:{{{node dropout_14_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_14_1/cond/Identity, dropout_14_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1502)\n",
      "(1632, 1502)\n",
      "(1752, 1502)\n",
      "(1872, 1502)\n",
      "(1687, 1502)\n",
      "(1345, 1502)\n",
      "(1826, 1502)\n",
      "(1595, 1502)\n",
      "(1764, 1502)\n",
      "(1502, 1502)\n",
      "(1932, 1502)\n",
      "(1728, 1502)\n",
      "(1788, 1502)\n",
      "(1836, 1502)\n",
      "(1728, 1502)\n",
      "(1812, 1502)\n",
      "(947, 1502)\n",
      "(1680, 1502)\n",
      "(1872, 1502)\n",
      "{1: 7.1207414542819825, 4: 7.904834004552006, 5: 3.89141611067568, 6: 3.3302341198784045, 8: 8.481144953923351, 9: 9.619363657666176, 10: 6.62503809917068, 11: 6.842682430674696, 12: 10.0, 13: 7.279064522796403, 17: 9.532047875793742, 19: 6.919342745834377, 21: 8.802503770432129, 22: 1.8767456330035786, 25: 8.583052547317765, 26: 9.23131933308721, 27: 6.942599983082221, 28: 6.583465924268796, 29: 1.0}\n",
      "Train on 31938 samples, validate on 3561 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:31:46.642151: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3852\n",
      "Epoch 1: val_loss improved from inf to 1.36238, saving model to ./checkpoints/unknown_person_few_shot_p2_32.h5\n",
      "31938/31938 [==============================] - 56s 2ms/sample - loss: 10.3852 - val_loss: 1.3624\n",
      "Epoch 2/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.3076\n",
      "Epoch 2: val_loss improved from 1.36238 to 1.34562, saving model to ./checkpoints/unknown_person_few_shot_p2_32.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 10.3076 - val_loss: 1.3456\n",
      "Epoch 3/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2455\n",
      "Epoch 3: val_loss did not improve from 1.34562\n",
      "31938/31938 [==============================] - 30s 942us/sample - loss: 10.2455 - val_loss: 1.3522\n",
      "Epoch 4/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.2140\n",
      "Epoch 4: val_loss did not improve from 1.34562\n",
      "31938/31938 [==============================] - 31s 969us/sample - loss: 10.2140 - val_loss: 1.3470\n",
      "Epoch 5/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1776\n",
      "Epoch 5: val_loss did not improve from 1.34562\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 10.1776 - val_loss: 1.3553\n",
      "Epoch 6/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1494\n",
      "Epoch 6: val_loss did not improve from 1.34562\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 10.1494 - val_loss: 1.3513\n",
      "Epoch 7/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.1289\n",
      "Epoch 7: val_loss improved from 1.34562 to 1.34316, saving model to ./checkpoints/unknown_person_few_shot_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 965us/sample - loss: 10.1289 - val_loss: 1.3432\n",
      "Epoch 8/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0993\n",
      "Epoch 8: val_loss did not improve from 1.34316\n",
      "31938/31938 [==============================] - 30s 941us/sample - loss: 10.0993 - val_loss: 1.3471\n",
      "Epoch 9/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0869\n",
      "Epoch 9: val_loss did not improve from 1.34316\n",
      "31938/31938 [==============================] - 31s 960us/sample - loss: 10.0869 - val_loss: 1.3447\n",
      "Epoch 10/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0409\n",
      "Epoch 10: val_loss improved from 1.34316 to 1.33746, saving model to ./checkpoints/unknown_person_few_shot_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 10.0409 - val_loss: 1.3375\n",
      "Epoch 11/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0638\n",
      "Epoch 11: val_loss did not improve from 1.33746\n",
      "31938/31938 [==============================] - 31s 974us/sample - loss: 10.0638 - val_loss: 1.3401\n",
      "Epoch 12/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0640\n",
      "Epoch 12: val_loss improved from 1.33746 to 1.33735, saving model to ./checkpoints/unknown_person_few_shot_p2_32.h5\n",
      "31938/31938 [==============================] - 31s 974us/sample - loss: 10.0640 - val_loss: 1.3374\n",
      "Epoch 13/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0075\n",
      "Epoch 13: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 29s 911us/sample - loss: 10.0075 - val_loss: 1.3429\n",
      "Epoch 14/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 10.0130\n",
      "Epoch 14: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 10.0130 - val_loss: 1.3375\n",
      "Epoch 15/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 9.9988 \n",
      "Epoch 15: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 9.9988 - val_loss: 1.3398\n",
      "Epoch 16/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 9.9939\n",
      "Epoch 16: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 34s 1ms/sample - loss: 9.9939 - val_loss: 1.3443\n",
      "Epoch 17/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 9.9852\n",
      "Epoch 17: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 9.9852 - val_loss: 1.3402\n",
      "Epoch 18/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 9.9819\n",
      "Epoch 18: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 32s 1ms/sample - loss: 9.9819 - val_loss: 1.3431\n",
      "Epoch 19/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 9.9760\n",
      "Epoch 19: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 32s 989us/sample - loss: 9.9760 - val_loss: 1.3530\n",
      "Epoch 20/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 9.9603\n",
      "Epoch 20: val_loss did not improve from 1.33735\n",
      "31938/31938 [==============================] - 35s 1ms/sample - loss: 9.9603 - val_loss: 1.3475\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:42:48.528489: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_11_2/bias/Assign' id:158130 op device:{requested: '', assigned: ''} def:{{{node dense_11_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_11_2/bias, dense_11_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 06:43:00.342359: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_10_2/kernel/v/Assign' id:159958 op device:{requested: '', assigned: ''} def:{{{node dense_10_2/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_10_2/kernel/v, dense_10_2/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31938 samples, validate on 3561 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:43:16.502250: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:44:19.784193: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:44:53.548405: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.33941, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_32.h5\n",
      "31938/31938 [==============================] - 59s 2ms/sample - loss: 1.4467 - val_loss: 1.3394\n",
      "Epoch 2/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4433\n",
      "Epoch 2: val_loss improved from 1.33941 to 1.33418, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_32.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4433 - val_loss: 1.3342\n",
      "Epoch 3/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4406\n",
      "Epoch 3: val_loss improved from 1.33418 to 1.33391, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 987us/sample - loss: 1.4406 - val_loss: 1.3339\n",
      "Epoch 4/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4381\n",
      "Epoch 4: val_loss did not improve from 1.33391\n",
      "31938/31938 [==============================] - 30s 931us/sample - loss: 1.4381 - val_loss: 1.3353\n",
      "Epoch 5/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4360\n",
      "Epoch 5: val_loss did not improve from 1.33391\n",
      "31938/31938 [==============================] - 31s 963us/sample - loss: 1.4360 - val_loss: 1.3405\n",
      "Epoch 6/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4345\n",
      "Epoch 6: val_loss did not improve from 1.33391\n",
      "31938/31938 [==============================] - 31s 961us/sample - loss: 1.4345 - val_loss: 1.3341\n",
      "Epoch 7/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4329\n",
      "Epoch 7: val_loss improved from 1.33391 to 1.32968, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_32.h5\n",
      "31938/31938 [==============================] - 28s 883us/sample - loss: 1.4329 - val_loss: 1.3297\n",
      "Epoch 8/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4320\n",
      "Epoch 8: val_loss did not improve from 1.32968\n",
      "31938/31938 [==============================] - 31s 976us/sample - loss: 1.4320 - val_loss: 1.3299\n",
      "Epoch 9/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4302\n",
      "Epoch 9: val_loss improved from 1.32968 to 1.32398, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_32.h5\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4302 - val_loss: 1.3240\n",
      "Epoch 10/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 10: val_loss did not improve from 1.32398\n",
      "31938/31938 [==============================] - 31s 977us/sample - loss: 1.4280 - val_loss: 1.3255\n",
      "Epoch 11/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4287\n",
      "Epoch 11: val_loss improved from 1.32398 to 1.32194, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_32.h5\n",
      "31938/31938 [==============================] - 32s 1000us/sample - loss: 1.4287 - val_loss: 1.3219\n",
      "Epoch 12/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4263\n",
      "Epoch 12: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 30s 936us/sample - loss: 1.4263 - val_loss: 1.3248\n",
      "Epoch 13/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 13: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 31s 955us/sample - loss: 1.4250 - val_loss: 1.3223\n",
      "Epoch 14/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4234\n",
      "Epoch 14: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 32s 997us/sample - loss: 1.4234 - val_loss: 1.3266\n",
      "Epoch 15/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 15: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 32s 994us/sample - loss: 1.4207 - val_loss: 1.3290\n",
      "Epoch 16/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 16: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 30s 945us/sample - loss: 1.4212 - val_loss: 1.3304\n",
      "Epoch 17/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 17: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 30s 944us/sample - loss: 1.4206 - val_loss: 1.3268\n",
      "Epoch 18/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 18: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 29s 918us/sample - loss: 1.4210 - val_loss: 1.3316\n",
      "Epoch 19/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 19: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 33s 1ms/sample - loss: 1.4159 - val_loss: 1.3220\n",
      "Epoch 20/20\n",
      "31938/31938 [==============================] - ETA: 0s - loss: 1.4175\n",
      "Epoch 20: val_loss did not improve from 1.32194\n",
      "31938/31938 [==============================] - 26s 817us/sample - loss: 1.4175 - val_loss: 1.3263\n",
      "35661\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:55:23.053386: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_123/lstm_cell_345/recurrent_kernel/Assign' id:173144 op device:{requested: '', assigned: ''} def:{{{node lstm_123/lstm_cell_345/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_123/lstm_cell_345/recurrent_kernel, lstm_123/lstm_cell_345/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 06:55:29.678338: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_1' id:174762 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 06:55:35.110711: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_2' id:174763 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32088, 95)\n",
      "Train on 32088 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:55:52.274695: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_147/lstm_cell_369/recurrent_kernel/Assign' id:177333 op device:{requested: '', assigned: ''} def:{{{node lstm_147/lstm_cell_369/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_147/lstm_cell_369/recurrent_kernel, lstm_147/lstm_cell_369/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:56:56.290313: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 3.6030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 06:57:32.432084: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_19/mul' id:177603 op device:{requested: '', assigned: ''} def:{{{node loss_19/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_19/mul/x, loss_19/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.07186, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 103s 3ms/sample - loss: 3.6030 - val_loss: 2.0719\n",
      "Epoch 2/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.8365\n",
      "Epoch 2: val_loss improved from 2.07186 to 1.64901, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.8365 - val_loss: 1.6490\n",
      "Epoch 3/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.6115\n",
      "Epoch 3: val_loss improved from 1.64901 to 1.57026, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 31s 981us/sample - loss: 1.6115 - val_loss: 1.5703\n",
      "Epoch 4/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5550\n",
      "Epoch 4: val_loss improved from 1.57026 to 1.54362, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 31s 976us/sample - loss: 1.5550 - val_loss: 1.5436\n",
      "Epoch 5/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5264\n",
      "Epoch 5: val_loss improved from 1.54362 to 1.53131, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.5264 - val_loss: 1.5313\n",
      "Epoch 6/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5087\n",
      "Epoch 6: val_loss improved from 1.53131 to 1.51755, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 30s 946us/sample - loss: 1.5087 - val_loss: 1.5176\n",
      "Epoch 7/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4965\n",
      "Epoch 7: val_loss improved from 1.51755 to 1.51244, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 29s 908us/sample - loss: 1.4965 - val_loss: 1.5124\n",
      "Epoch 8/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4904\n",
      "Epoch 8: val_loss improved from 1.51244 to 1.50570, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4904 - val_loss: 1.5057\n",
      "Epoch 9/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5283\n",
      "Epoch 9: val_loss improved from 1.50570 to 1.50440, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.5283 - val_loss: 1.5044\n",
      "Epoch 10/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5099\n",
      "Epoch 10: val_loss improved from 1.50440 to 1.49665, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 31s 975us/sample - loss: 1.5099 - val_loss: 1.4967\n",
      "Epoch 11/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 11: val_loss improved from 1.49665 to 1.49588, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 30s 940us/sample - loss: 1.4787 - val_loss: 1.4959\n",
      "Epoch 12/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4743\n",
      "Epoch 12: val_loss improved from 1.49588 to 1.49523, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4743 - val_loss: 1.4952\n",
      "Epoch 13/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5758\n",
      "Epoch 13: val_loss did not improve from 1.49523\n",
      "32088/32088 [==============================] - 31s 967us/sample - loss: 1.5758 - val_loss: 1.5011\n",
      "Epoch 14/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5691\n",
      "Epoch 14: val_loss did not improve from 1.49523\n",
      "32088/32088 [==============================] - 32s 986us/sample - loss: 1.5691 - val_loss: 1.5102\n",
      "Epoch 15/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5199\n",
      "Epoch 15: val_loss did not improve from 1.49523\n",
      "32088/32088 [==============================] - 31s 977us/sample - loss: 1.5199 - val_loss: 1.5011\n",
      "Epoch 16/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4828\n",
      "Epoch 16: val_loss improved from 1.49523 to 1.49287, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 997us/sample - loss: 1.4828 - val_loss: 1.4929\n",
      "Epoch 17/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5449\n",
      "Epoch 17: val_loss did not improve from 1.49287\n",
      "32088/32088 [==============================] - 32s 989us/sample - loss: 1.5449 - val_loss: 1.5084\n",
      "Epoch 18/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5278\n",
      "Epoch 18: val_loss improved from 1.49287 to 1.48898, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 31s 962us/sample - loss: 1.5278 - val_loss: 1.4890\n",
      "Epoch 19/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4741\n",
      "Epoch 19: val_loss improved from 1.48898 to 1.48512, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4741 - val_loss: 1.4851\n",
      "Epoch 20/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4778\n",
      "Epoch 20: val_loss improved from 1.48512 to 1.48247, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 1000us/sample - loss: 1.4778 - val_loss: 1.4825\n",
      "Epoch 21/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4752\n",
      "Epoch 21: val_loss did not improve from 1.48247\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4752 - val_loss: 1.4866\n",
      "Epoch 22/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4771\n",
      "Epoch 22: val_loss did not improve from 1.48247\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4771 - val_loss: 1.4875\n",
      "Epoch 23/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4620\n",
      "Epoch 23: val_loss did not improve from 1.48247\n",
      "32088/32088 [==============================] - 32s 982us/sample - loss: 1.4620 - val_loss: 1.4836\n",
      "Epoch 24/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4588\n",
      "Epoch 24: val_loss improved from 1.48247 to 1.47565, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4588 - val_loss: 1.4757\n",
      "Epoch 25/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4509\n",
      "Epoch 25: val_loss improved from 1.47565 to 1.47254, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4509 - val_loss: 1.4725\n",
      "Epoch 26/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4535\n",
      "Epoch 26: val_loss did not improve from 1.47254\n",
      "32088/32088 [==============================] - 32s 991us/sample - loss: 1.4535 - val_loss: 1.4746\n",
      "Epoch 27/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4455\n",
      "Epoch 27: val_loss did not improve from 1.47254\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4455 - val_loss: 1.4763\n",
      "Epoch 28/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4422\n",
      "Epoch 28: val_loss improved from 1.47254 to 1.46882, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4422 - val_loss: 1.4688\n",
      "Epoch 29/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 29: val_loss did not improve from 1.46882\n",
      "32088/32088 [==============================] - 31s 973us/sample - loss: 1.4379 - val_loss: 1.4713\n",
      "Epoch 30/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4397\n",
      "Epoch 30: val_loss did not improve from 1.46882\n",
      "32088/32088 [==============================] - 31s 959us/sample - loss: 1.4397 - val_loss: 1.4707\n",
      "Epoch 31/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4340\n",
      "Epoch 31: val_loss improved from 1.46882 to 1.45791, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 31s 968us/sample - loss: 1.4340 - val_loss: 1.4579\n",
      "Epoch 32/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 32: val_loss did not improve from 1.45791\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4334 - val_loss: 1.4599\n",
      "Epoch 33/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4320\n",
      "Epoch 33: val_loss did not improve from 1.45791\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4320 - val_loss: 1.4624\n",
      "Epoch 34/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 34: val_loss improved from 1.45791 to 1.45683, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4280 - val_loss: 1.4568\n",
      "Epoch 35/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4226\n",
      "Epoch 35: val_loss improved from 1.45683 to 1.45251, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4226 - val_loss: 1.4525\n",
      "Epoch 36/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 36: val_loss did not improve from 1.45251\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4211 - val_loss: 1.4547\n",
      "Epoch 37/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 37: val_loss improved from 1.45251 to 1.44954, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4164 - val_loss: 1.4495\n",
      "Epoch 38/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4179\n",
      "Epoch 38: val_loss did not improve from 1.44954\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4179 - val_loss: 1.4516\n",
      "Epoch 39/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4152\n",
      "Epoch 39: val_loss improved from 1.44954 to 1.44310, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4152 - val_loss: 1.4431\n",
      "Epoch 40/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4140\n",
      "Epoch 40: val_loss did not improve from 1.44310\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4140 - val_loss: 1.4476\n",
      "Epoch 41/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4107\n",
      "Epoch 41: val_loss did not improve from 1.44310\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4107 - val_loss: 1.4471\n",
      "Epoch 42/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 42: val_loss did not improve from 1.44310\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4088 - val_loss: 1.4471\n",
      "Epoch 43/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 43: val_loss improved from 1.44310 to 1.43866, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4078 - val_loss: 1.4387\n",
      "Epoch 44/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4068\n",
      "Epoch 44: val_loss did not improve from 1.43866\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4068 - val_loss: 1.4428\n",
      "Epoch 45/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 45: val_loss improved from 1.43866 to 1.43806, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4050 - val_loss: 1.4381\n",
      "Epoch 46/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4024\n",
      "Epoch 46: val_loss did not improve from 1.43806\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4024 - val_loss: 1.4402\n",
      "Epoch 47/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 47: val_loss did not improve from 1.43806\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4042 - val_loss: 1.4392\n",
      "Epoch 48/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 48: val_loss improved from 1.43806 to 1.43262, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_33.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.3983 - val_loss: 1.4326\n",
      "Epoch 49/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4000\n",
      "Epoch 49: val_loss did not improve from 1.43262\n",
      "32088/32088 [==============================] - 32s 996us/sample - loss: 1.4000 - val_loss: 1.4364\n",
      "Epoch 50/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 50: val_loss did not improve from 1.43262\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.3986 - val_loss: 1.4391\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:25:14.507900: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_113_1/lstm_cell_372/recurrent_kernel/Assign' id:190106 op device:{requested: '', assigned: ''} def:{{{node lstm_113_1/lstm_cell_372/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_113_1/lstm_cell_372/recurrent_kernel, lstm_113_1/lstm_cell_372/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 07:25:28.096369: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_13_1/bias/v/Assign' id:196996 op device:{requested: '', assigned: ''} def:{{{node conv2d_13_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_13_1/bias/v, conv2d_13_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 07:25:41.844236: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_19_1/cond/Merge' id:195717 op device:{requested: '', assigned: ''} def:{{{node dropout_19_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_19_1/cond/Identity, dropout_19_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1340)\n",
      "(1644, 1340)\n",
      "(1716, 1340)\n",
      "(1884, 1340)\n",
      "(1688, 1340)\n",
      "(1370, 1340)\n",
      "(1802, 1340)\n",
      "(1606, 1340)\n",
      "(1752, 1340)\n",
      "(1502, 1340)\n",
      "(1932, 1340)\n",
      "(1715, 1340)\n",
      "(1776, 1340)\n",
      "(1860, 1340)\n",
      "(1728, 1340)\n",
      "(1824, 1340)\n",
      "(947, 1340)\n",
      "(1668, 1340)\n",
      "(1884, 1340)\n",
      "{1: 8.0756400952051, 4: 8.568038559334003, 5: 4.9168508878065875, 6: 3.615399436585944, 8: 9.413193365617907, 9: 10.0, 10: 6.934939338164298, 11: 7.0048447037407024, 12: 9.350462969100999, 13: 7.734567072154929, 17: 9.305247175291866, 19: 7.113805143127577, 21: 9.886056510879472, 22: 1.2960660452241521, 25: 7.909918024234759, 26: 8.372936987435303, 27: 6.765204368735881, 28: 5.861402102052074, 29: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907579/3261308647.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32088 samples, validate on 3573 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:32:40.732981: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 10.4983\n",
      "Epoch 1: val_loss improved from inf to 1.46801, saving model to ./checkpoints/unknown_person_few_shot_p2_33.h5\n",
      "32088/32088 [==============================] - 67s 2ms/sample - loss: 10.4983 - val_loss: 1.4680\n",
      "Epoch 2/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.4669\n",
      "Epoch 2: val_loss did not improve from 1.46801\n",
      "32088/32088 [==============================] - 31s 954us/sample - loss: 10.4669 - val_loss: 1.4727\n",
      "Epoch 3/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.3657\n",
      "Epoch 3: val_loss improved from 1.46801 to 1.44781, saving model to ./checkpoints/unknown_person_few_shot_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.3657 - val_loss: 1.4478\n",
      "Epoch 4/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.3128\n",
      "Epoch 4: val_loss did not improve from 1.44781\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.3128 - val_loss: 1.4501\n",
      "Epoch 5/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2925\n",
      "Epoch 5: val_loss improved from 1.44781 to 1.43630, saving model to ./checkpoints/unknown_person_few_shot_p2_33.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.2925 - val_loss: 1.4363\n",
      "Epoch 6/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2626\n",
      "Epoch 6: val_loss did not improve from 1.43630\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.2626 - val_loss: 1.4490\n",
      "Epoch 7/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2419\n",
      "Epoch 7: val_loss improved from 1.43630 to 1.43454, saving model to ./checkpoints/unknown_person_few_shot_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.2419 - val_loss: 1.4345\n",
      "Epoch 8/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2379\n",
      "Epoch 8: val_loss did not improve from 1.43454\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.2379 - val_loss: 1.4355\n",
      "Epoch 9/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2043\n",
      "Epoch 9: val_loss did not improve from 1.43454\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.2043 - val_loss: 1.4394\n",
      "Epoch 10/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1909\n",
      "Epoch 10: val_loss did not improve from 1.43454\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.1909 - val_loss: 1.4534\n",
      "Epoch 11/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1831\n",
      "Epoch 11: val_loss did not improve from 1.43454\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.1831 - val_loss: 1.4369\n",
      "Epoch 12/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1893\n",
      "Epoch 12: val_loss improved from 1.43454 to 1.43175, saving model to ./checkpoints/unknown_person_few_shot_p2_33.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.1893 - val_loss: 1.4318\n",
      "Epoch 13/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1549\n",
      "Epoch 13: val_loss did not improve from 1.43175\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.1549 - val_loss: 1.4506\n",
      "Epoch 14/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1174\n",
      "Epoch 14: val_loss did not improve from 1.43175\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.1174 - val_loss: 1.4379\n",
      "Epoch 15/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1202\n",
      "Epoch 15: val_loss did not improve from 1.43175\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.1202 - val_loss: 1.4339\n",
      "Epoch 16/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1143\n",
      "Epoch 16: val_loss improved from 1.43175 to 1.43063, saving model to ./checkpoints/unknown_person_few_shot_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.1143 - val_loss: 1.4306\n",
      "Epoch 17/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1256\n",
      "Epoch 17: val_loss did not improve from 1.43063\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.1256 - val_loss: 1.4412\n",
      "Epoch 18/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0972\n",
      "Epoch 18: val_loss did not improve from 1.43063\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.0972 - val_loss: 1.4445\n",
      "Epoch 19/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1054\n",
      "Epoch 19: val_loss did not improve from 1.43063\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.1054 - val_loss: 1.4369\n",
      "Epoch 20/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0632\n",
      "Epoch 20: val_loss did not improve from 1.43063\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.0632 - val_loss: 1.4423\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:44:34.302225: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_132_2/lstm_cell_428/recurrent_kernel/Assign' id:212544 op device:{requested: '', assigned: ''} def:{{{node lstm_132_2/lstm_cell_428/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_132_2/lstm_cell_428/recurrent_kernel, lstm_132_2/lstm_cell_428/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 07:44:50.511180: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_12_2/kernel/v/Assign' id:216377 op device:{requested: '', assigned: ''} def:{{{node conv2d_12_2/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_12_2/kernel/v, conv2d_12_2/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32088 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:45:10.515471: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:46:36.328416: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:47:13.539207: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.44025, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 69s 2ms/sample - loss: 1.3975 - val_loss: 1.4402\n",
      "Epoch 2/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3962\n",
      "Epoch 2: val_loss improved from 1.44025 to 1.43920, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.3962 - val_loss: 1.4392\n",
      "Epoch 3/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 3: val_loss improved from 1.43920 to 1.42815, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3953 - val_loss: 1.4281\n",
      "Epoch 4/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3943\n",
      "Epoch 4: val_loss did not improve from 1.42815\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3943 - val_loss: 1.4304\n",
      "Epoch 5/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3920\n",
      "Epoch 5: val_loss improved from 1.42815 to 1.42537, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3920 - val_loss: 1.4254\n",
      "Epoch 6/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3898\n",
      "Epoch 6: val_loss did not improve from 1.42537\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3898 - val_loss: 1.4377\n",
      "Epoch 7/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 7: val_loss did not improve from 1.42537\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3896 - val_loss: 1.4286\n",
      "Epoch 8/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 8: val_loss did not improve from 1.42537\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3887 - val_loss: 1.4364\n",
      "Epoch 9/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3897\n",
      "Epoch 9: val_loss did not improve from 1.42537\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3897 - val_loss: 1.4259\n",
      "Epoch 10/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3859\n",
      "Epoch 10: val_loss did not improve from 1.42537\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.3859 - val_loss: 1.4311\n",
      "Epoch 11/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3849\n",
      "Epoch 11: val_loss improved from 1.42537 to 1.42435, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3849 - val_loss: 1.4243\n",
      "Epoch 12/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3848\n",
      "Epoch 12: val_loss did not improve from 1.42435\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3848 - val_loss: 1.4244\n",
      "Epoch 13/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3811\n",
      "Epoch 13: val_loss improved from 1.42435 to 1.42314, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3811 - val_loss: 1.4231\n",
      "Epoch 14/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3810\n",
      "Epoch 14: val_loss did not improve from 1.42314\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3810 - val_loss: 1.4282\n",
      "Epoch 15/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3808\n",
      "Epoch 15: val_loss did not improve from 1.42314\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3808 - val_loss: 1.4272\n",
      "Epoch 16/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3789\n",
      "Epoch 16: val_loss improved from 1.42314 to 1.42084, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3789 - val_loss: 1.4208\n",
      "Epoch 17/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3777\n",
      "Epoch 17: val_loss improved from 1.42084 to 1.41843, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3777 - val_loss: 1.4184\n",
      "Epoch 18/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3760\n",
      "Epoch 18: val_loss did not improve from 1.41843\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3760 - val_loss: 1.4202\n",
      "Epoch 19/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3748\n",
      "Epoch 19: val_loss improved from 1.41843 to 1.41841, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_33.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3748 - val_loss: 1.4184\n",
      "Epoch 20/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3738\n",
      "Epoch 20: val_loss did not improve from 1.41841\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3738 - val_loss: 1.4225\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:58:36.941304: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_163/lstm_cell_459/recurrent_kernel/Assign' id:230681 op device:{requested: '', assigned: ''} def:{{{node lstm_163/lstm_cell_459/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_163/lstm_cell_459/recurrent_kernel, lstm_163/lstm_cell_459/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 07:58:46.101325: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_1' id:231804 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 07:58:53.475292: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_2' id:231805 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32088, 95)\n",
      "Train on 32088 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 07:59:14.827616: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_18/bias/Assign' id:231967 op device:{requested: '', assigned: ''} def:{{{node conv2d_18/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_18/bias, conv2d_18/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:00:47.016951: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 3.3626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:01:27.623139: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_25/mul' id:234645 op device:{requested: '', assigned: ''} def:{{{node loss_25/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_25/mul/x, loss_25/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.93932, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 128s 4ms/sample - loss: 3.3626 - val_loss: 1.9393\n",
      "Epoch 2/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.7991\n",
      "Epoch 2: val_loss improved from 1.93932 to 1.61573, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 40s 1ms/sample - loss: 1.7991 - val_loss: 1.6157\n",
      "Epoch 3/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5855\n",
      "Epoch 3: val_loss improved from 1.61573 to 1.55207, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.5855 - val_loss: 1.5521\n",
      "Epoch 4/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5360\n",
      "Epoch 4: val_loss improved from 1.55207 to 1.52904, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.5360 - val_loss: 1.5290\n",
      "Epoch 5/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5178\n",
      "Epoch 5: val_loss improved from 1.52904 to 1.52037, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.5178 - val_loss: 1.5204\n",
      "Epoch 6/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5005\n",
      "Epoch 6: val_loss improved from 1.52037 to 1.50464, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.5005 - val_loss: 1.5046\n",
      "Epoch 7/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4891\n",
      "Epoch 7: val_loss improved from 1.50464 to 1.49986, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4891 - val_loss: 1.4999\n",
      "Epoch 8/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4866\n",
      "Epoch 8: val_loss improved from 1.49986 to 1.49947, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4866 - val_loss: 1.4995\n",
      "Epoch 9/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 9: val_loss improved from 1.49947 to 1.49575, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4865 - val_loss: 1.4958\n",
      "Epoch 10/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4788\n",
      "Epoch 10: val_loss improved from 1.49575 to 1.49309, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4788 - val_loss: 1.4931\n",
      "Epoch 11/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4747\n",
      "Epoch 11: val_loss improved from 1.49309 to 1.48460, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4747 - val_loss: 1.4846\n",
      "Epoch 12/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4709\n",
      "Epoch 12: val_loss did not improve from 1.48460\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4709 - val_loss: 1.4850\n",
      "Epoch 13/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5571\n",
      "Epoch 13: val_loss did not improve from 1.48460\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.5571 - val_loss: 1.4993\n",
      "Epoch 14/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4942\n",
      "Epoch 14: val_loss did not improve from 1.48460\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4942 - val_loss: 1.4920\n",
      "Epoch 15/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4722\n",
      "Epoch 15: val_loss did not improve from 1.48460\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4722 - val_loss: 1.4918\n",
      "Epoch 16/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4702\n",
      "Epoch 16: val_loss improved from 1.48460 to 1.48242, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4702 - val_loss: 1.4824\n",
      "Epoch 17/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4641\n",
      "Epoch 17: val_loss did not improve from 1.48242\n",
      "32088/32088 [==============================] - 30s 940us/sample - loss: 1.4641 - val_loss: 1.4830\n",
      "Epoch 18/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4871\n",
      "Epoch 18: val_loss did not improve from 1.48242\n",
      "32088/32088 [==============================] - 30s 940us/sample - loss: 1.4871 - val_loss: 1.4870\n",
      "Epoch 19/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4707\n",
      "Epoch 19: val_loss improved from 1.48242 to 1.47740, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 31s 968us/sample - loss: 1.4707 - val_loss: 1.4774\n",
      "Epoch 20/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4660\n",
      "Epoch 20: val_loss did not improve from 1.47740\n",
      "32088/32088 [==============================] - 31s 969us/sample - loss: 1.4660 - val_loss: 1.4829\n",
      "Epoch 21/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4776\n",
      "Epoch 21: val_loss did not improve from 1.47740\n",
      "32088/32088 [==============================] - 30s 950us/sample - loss: 1.4776 - val_loss: 1.4782\n",
      "Epoch 22/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4978\n",
      "Epoch 22: val_loss did not improve from 1.47740\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4978 - val_loss: 1.4849\n",
      "Epoch 23/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4675\n",
      "Epoch 23: val_loss did not improve from 1.47740\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4675 - val_loss: 1.4788\n",
      "Epoch 24/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4577\n",
      "Epoch 24: val_loss did not improve from 1.47740\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4577 - val_loss: 1.4785\n",
      "Epoch 25/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4566\n",
      "Epoch 25: val_loss improved from 1.47740 to 1.47363, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4566 - val_loss: 1.4736\n",
      "Epoch 26/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4515\n",
      "Epoch 26: val_loss improved from 1.47363 to 1.46775, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4515 - val_loss: 1.4678\n",
      "Epoch 27/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4475\n",
      "Epoch 27: val_loss improved from 1.46775 to 1.46761, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4475 - val_loss: 1.4676\n",
      "Epoch 28/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4423\n",
      "Epoch 28: val_loss improved from 1.46761 to 1.45929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4423 - val_loss: 1.4593\n",
      "Epoch 29/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4418\n",
      "Epoch 29: val_loss did not improve from 1.45929\n",
      "32088/32088 [==============================] - 32s 993us/sample - loss: 1.4418 - val_loss: 1.4649\n",
      "Epoch 30/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4365\n",
      "Epoch 30: val_loss improved from 1.45929 to 1.45855, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4365 - val_loss: 1.4585\n",
      "Epoch 31/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4337\n",
      "Epoch 31: val_loss did not improve from 1.45855\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4337 - val_loss: 1.4597\n",
      "Epoch 32/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 32: val_loss improved from 1.45855 to 1.45475, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.4312 - val_loss: 1.4547\n",
      "Epoch 33/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4289\n",
      "Epoch 33: val_loss improved from 1.45475 to 1.45411, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4289 - val_loss: 1.4541\n",
      "Epoch 34/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4273\n",
      "Epoch 34: val_loss improved from 1.45411 to 1.45282, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4273 - val_loss: 1.4528\n",
      "Epoch 35/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4230\n",
      "Epoch 35: val_loss improved from 1.45282 to 1.45277, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 985us/sample - loss: 1.4230 - val_loss: 1.4528\n",
      "Epoch 36/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4245\n",
      "Epoch 36: val_loss improved from 1.45277 to 1.44630, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 31s 973us/sample - loss: 1.4245 - val_loss: 1.4463\n",
      "Epoch 37/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 37: val_loss did not improve from 1.44630\n",
      "32088/32088 [==============================] - 31s 975us/sample - loss: 1.4210 - val_loss: 1.4480\n",
      "Epoch 38/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4189\n",
      "Epoch 38: val_loss did not improve from 1.44630\n",
      "32088/32088 [==============================] - 31s 968us/sample - loss: 1.4189 - val_loss: 1.4483\n",
      "Epoch 39/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 39: val_loss did not improve from 1.44630\n",
      "32088/32088 [==============================] - 31s 968us/sample - loss: 1.4166 - val_loss: 1.4484\n",
      "Epoch 40/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4171\n",
      "Epoch 40: val_loss improved from 1.44630 to 1.44008, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4171 - val_loss: 1.4401\n",
      "Epoch 41/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4128\n",
      "Epoch 41: val_loss did not improve from 1.44008\n",
      "32088/32088 [==============================] - 32s 984us/sample - loss: 1.4128 - val_loss: 1.4457\n",
      "Epoch 42/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4116\n",
      "Epoch 42: val_loss did not improve from 1.44008\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4116 - val_loss: 1.4411\n",
      "Epoch 43/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 43: val_loss did not improve from 1.44008\n",
      "32088/32088 [==============================] - 32s 987us/sample - loss: 1.4132 - val_loss: 1.4430\n",
      "Epoch 44/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 44: val_loss improved from 1.44008 to 1.43779, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 31s 956us/sample - loss: 1.4097 - val_loss: 1.4378\n",
      "Epoch 45/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4052\n",
      "Epoch 45: val_loss did not improve from 1.43779\n",
      "32088/32088 [==============================] - 32s 992us/sample - loss: 1.4052 - val_loss: 1.4416\n",
      "Epoch 46/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 46: val_loss improved from 1.43779 to 1.43538, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4070 - val_loss: 1.4354\n",
      "Epoch 47/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4064\n",
      "Epoch 47: val_loss did not improve from 1.43538\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4064 - val_loss: 1.4406\n",
      "Epoch 48/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 48: val_loss did not improve from 1.43538\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4026 - val_loss: 1.4441\n",
      "Epoch 49/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 49: val_loss improved from 1.43538 to 1.43168, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4055 - val_loss: 1.4317\n",
      "Epoch 50/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4056\n",
      "Epoch 50: val_loss did not improve from 1.43168\n",
      "32088/32088 [==============================] - 32s 991us/sample - loss: 1.4056 - val_loss: 1.4354\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:29:48.592653: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_149_1/lstm_cell_482/kernel/Assign' id:246968 op device:{requested: '', assigned: ''} def:{{{node lstm_149_1/lstm_cell_482/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_149_1/lstm_cell_482/kernel, lstm_149_1/lstm_cell_482/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 08:30:07.744585: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_176_1/lstm_cell_509/recurrent_kernel/v/Assign' id:254488 op device:{requested: '', assigned: ''} def:{{{node lstm_176_1/lstm_cell_509/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_176_1/lstm_cell_509/recurrent_kernel/v, lstm_176_1/lstm_cell_509/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 08:30:26.657311: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_24_1/cond/Merge' id:252759 op device:{requested: '', assigned: ''} def:{{{node dropout_24_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_24_1/cond/Identity, dropout_24_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1340)\n",
      "(1644, 1340)\n",
      "(1716, 1340)\n",
      "(1884, 1340)\n",
      "(1688, 1340)\n",
      "(1370, 1340)\n",
      "(1802, 1340)\n",
      "(1606, 1340)\n",
      "(1752, 1340)\n",
      "(1502, 1340)\n",
      "(1932, 1340)\n",
      "(1715, 1340)\n",
      "(1776, 1340)\n",
      "(1860, 1340)\n",
      "(1728, 1340)\n",
      "(1824, 1340)\n",
      "(947, 1340)\n",
      "(1668, 1340)\n",
      "(1884, 1340)\n",
      "{1: 7.965053239196025, 4: 8.421937760692481, 5: 4.527675308040924, 6: 3.0478548470846674, 8: 9.12715686861371, 9: 10.0, 10: 6.68190540600226, 11: 6.732405602729812, 12: 9.753656354616314, 13: 7.452219629701672, 17: 9.35354326633038, 19: 7.0031644724594715, 21: 9.626892181785117, 22: 1.7952636307389045, 25: 8.132214835851771, 26: 8.926809883987062, 27: 6.278867411198297, 28: 6.175698395465028, 29: 1.0}\n",
      "Train on 32088 samples, validate on 3573 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:37:44.617137: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 10.4706\n",
      "Epoch 1: val_loss improved from inf to 1.47552, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 71s 2ms/sample - loss: 10.4706 - val_loss: 1.4755\n",
      "Epoch 2/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.3752\n",
      "Epoch 2: val_loss improved from 1.47552 to 1.45173, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.3752 - val_loss: 1.4517\n",
      "Epoch 3/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2990\n",
      "Epoch 3: val_loss improved from 1.45173 to 1.44629, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.2990 - val_loss: 1.4463\n",
      "Epoch 4/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2649\n",
      "Epoch 4: val_loss improved from 1.44629 to 1.44237, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.2649 - val_loss: 1.4424\n",
      "Epoch 5/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2480\n",
      "Epoch 5: val_loss improved from 1.44237 to 1.44220, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.2480 - val_loss: 1.4422\n",
      "Epoch 6/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2011\n",
      "Epoch 6: val_loss improved from 1.44220 to 1.44150, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.2011 - val_loss: 1.4415\n",
      "Epoch 7/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1900\n",
      "Epoch 7: val_loss did not improve from 1.44150\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.1900 - val_loss: 1.4523\n",
      "Epoch 8/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1729\n",
      "Epoch 8: val_loss improved from 1.44150 to 1.43764, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.1729 - val_loss: 1.4376\n",
      "Epoch 9/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1441\n",
      "Epoch 9: val_loss did not improve from 1.43764\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.1441 - val_loss: 1.4472\n",
      "Epoch 10/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1255\n",
      "Epoch 10: val_loss improved from 1.43764 to 1.43389, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.1255 - val_loss: 1.4339\n",
      "Epoch 11/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1154\n",
      "Epoch 11: val_loss improved from 1.43389 to 1.43121, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.1154 - val_loss: 1.4312\n",
      "Epoch 12/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1179\n",
      "Epoch 12: val_loss did not improve from 1.43121\n",
      "32088/32088 [==============================] - 32s 999us/sample - loss: 10.1179 - val_loss: 1.4411\n",
      "Epoch 13/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0972\n",
      "Epoch 13: val_loss did not improve from 1.43121\n",
      "32088/32088 [==============================] - 30s 942us/sample - loss: 10.0972 - val_loss: 1.4371\n",
      "Epoch 14/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0898\n",
      "Epoch 14: val_loss did not improve from 1.43121\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.0898 - val_loss: 1.4337\n",
      "Epoch 15/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0647\n",
      "Epoch 15: val_loss did not improve from 1.43121\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.0647 - val_loss: 1.4343\n",
      "Epoch 16/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0644\n",
      "Epoch 16: val_loss did not improve from 1.43121\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.0644 - val_loss: 1.4355\n",
      "Epoch 17/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0389\n",
      "Epoch 17: val_loss improved from 1.43121 to 1.42384, saving model to ./checkpoints/unknown_person_few_shot_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.0389 - val_loss: 1.4238\n",
      "Epoch 18/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0583\n",
      "Epoch 18: val_loss did not improve from 1.42384\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.0583 - val_loss: 1.4354\n",
      "Epoch 19/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0363\n",
      "Epoch 19: val_loss did not improve from 1.42384\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 10.0363 - val_loss: 1.4342\n",
      "Epoch 20/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0402\n",
      "Epoch 20: val_loss did not improve from 1.42384\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 10.0402 - val_loss: 1.4291\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:49:35.671235: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_177_2/lstm_cell_547/kernel/Assign' id:270848 op device:{requested: '', assigned: ''} def:{{{node lstm_177_2/lstm_cell_547/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_177_2/lstm_cell_547/kernel, lstm_177_2/lstm_cell_547/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 08:49:56.532748: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_177_2/lstm_cell_547/bias/m/Assign' id:273263 op device:{requested: '', assigned: ''} def:{{{node lstm_177_2/lstm_cell_547/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_177_2/lstm_cell_547/bias/m, lstm_177_2/lstm_cell_547/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32088 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:50:20.772879: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:52:06.838690: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 08:52:45.018809: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.43130, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_34.h5\n",
      "32088/32088 [==============================] - 77s 2ms/sample - loss: 1.4040 - val_loss: 1.4313\n",
      "Epoch 2/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3998\n",
      "Epoch 2: val_loss did not improve from 1.43130\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3998 - val_loss: 1.4369\n",
      "Epoch 3/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3978\n",
      "Epoch 3: val_loss improved from 1.43130 to 1.42524, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_34.h5\n",
      "32088/32088 [==============================] - 36s 1ms/sample - loss: 1.3978 - val_loss: 1.4252\n",
      "Epoch 4/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3966\n",
      "Epoch 4: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3966 - val_loss: 1.4290\n",
      "Epoch 5/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3946\n",
      "Epoch 5: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3946 - val_loss: 1.4256\n",
      "Epoch 6/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 6: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3939 - val_loss: 1.4332\n",
      "Epoch 7/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3931\n",
      "Epoch 7: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3931 - val_loss: 1.4298\n",
      "Epoch 8/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 8: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3914 - val_loss: 1.4257\n",
      "Epoch 9/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3898\n",
      "Epoch 9: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3898 - val_loss: 1.4280\n",
      "Epoch 10/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3905\n",
      "Epoch 10: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3905 - val_loss: 1.4256\n",
      "Epoch 11/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3878\n",
      "Epoch 11: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3878 - val_loss: 1.4298\n",
      "Epoch 12/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3856\n",
      "Epoch 12: val_loss did not improve from 1.42524\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3856 - val_loss: 1.4255\n",
      "Epoch 13/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3840\n",
      "Epoch 13: val_loss improved from 1.42524 to 1.42020, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3840 - val_loss: 1.4202\n",
      "Epoch 14/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3867\n",
      "Epoch 14: val_loss did not improve from 1.42020\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3867 - val_loss: 1.4211\n",
      "Epoch 15/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3841\n",
      "Epoch 15: val_loss did not improve from 1.42020\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3841 - val_loss: 1.4259\n",
      "Epoch 16/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 16: val_loss did not improve from 1.42020\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3830 - val_loss: 1.4209\n",
      "Epoch 17/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3840\n",
      "Epoch 17: val_loss did not improve from 1.42020\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3840 - val_loss: 1.4270\n",
      "Epoch 18/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3827\n",
      "Epoch 18: val_loss improved from 1.42020 to 1.41466, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_34.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.3827 - val_loss: 1.4147\n",
      "Epoch 19/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3786\n",
      "Epoch 19: val_loss did not improve from 1.41466\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3786 - val_loss: 1.4190\n",
      "Epoch 20/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3767\n",
      "Epoch 20: val_loss did not improve from 1.41466\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.3767 - val_loss: 1.4211\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:04:27.811344: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_191/lstm_cell_561/bias/Assign' id:286247 op device:{requested: '', assigned: ''} def:{{{node lstm_191/lstm_cell_561/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_191/lstm_cell_561/bias, lstm_191/lstm_cell_561/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:04:39.153106: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_1' id:288846 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:04:48.382493: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_2' id:288847 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32088, 95)\n",
      "Train on 32088 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:05:14.333632: W tensorflow/c/c_api.cc:304] Operation '{name:'training_30/Adam/lstm_221/lstm_cell_591/recurrent_kernel/v/Assign' id:302792 op device:{requested: '', assigned: ''} def:{{{node training_30/Adam/lstm_221/lstm_cell_591/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_30/Adam/lstm_221/lstm_cell_591/recurrent_kernel/v, training_30/Adam/lstm_221/lstm_cell_591/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:07:06.684814: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 3.5253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:07:44.682043: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_31/mul' id:291687 op device:{requested: '', assigned: ''} def:{{{node loss_31/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_31/mul/x, loss_31/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.02392, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 141s 4ms/sample - loss: 3.5253 - val_loss: 2.0239\n",
      "Epoch 2/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.8140\n",
      "Epoch 2: val_loss improved from 2.02392 to 1.64677, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.8140 - val_loss: 1.6468\n",
      "Epoch 3/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5958\n",
      "Epoch 3: val_loss improved from 1.64677 to 1.56841, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.5958 - val_loss: 1.5684\n",
      "Epoch 4/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5398\n",
      "Epoch 4: val_loss improved from 1.56841 to 1.54837, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.5398 - val_loss: 1.5484\n",
      "Epoch 5/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5166\n",
      "Epoch 5: val_loss improved from 1.54837 to 1.52863, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.5166 - val_loss: 1.5286\n",
      "Epoch 6/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5026\n",
      "Epoch 6: val_loss improved from 1.52863 to 1.52039, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 35s 1ms/sample - loss: 1.5026 - val_loss: 1.5204\n",
      "Epoch 7/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4938\n",
      "Epoch 7: val_loss improved from 1.52039 to 1.51168, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4938 - val_loss: 1.5117\n",
      "Epoch 8/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5009\n",
      "Epoch 8: val_loss did not improve from 1.51168\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.5009 - val_loss: 1.5157\n",
      "Epoch 9/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4889\n",
      "Epoch 9: val_loss did not improve from 1.51168\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4889 - val_loss: 1.5119\n",
      "Epoch 10/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5011\n",
      "Epoch 10: val_loss improved from 1.51168 to 1.50764, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.5011 - val_loss: 1.5076\n",
      "Epoch 11/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5274\n",
      "Epoch 11: val_loss improved from 1.50764 to 1.50504, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 31s 969us/sample - loss: 1.5274 - val_loss: 1.5050\n",
      "Epoch 12/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4920\n",
      "Epoch 12: val_loss did not improve from 1.50504\n",
      "32088/32088 [==============================] - 31s 973us/sample - loss: 1.4920 - val_loss: 1.5073\n",
      "Epoch 13/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5111\n",
      "Epoch 13: val_loss improved from 1.50504 to 1.49451, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.5111 - val_loss: 1.4945\n",
      "Epoch 14/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4874\n",
      "Epoch 14: val_loss did not improve from 1.49451\n",
      "32088/32088 [==============================] - 31s 966us/sample - loss: 1.4874 - val_loss: 1.4972\n",
      "Epoch 15/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5003\n",
      "Epoch 15: val_loss did not improve from 1.49451\n",
      "32088/32088 [==============================] - 32s 991us/sample - loss: 1.5003 - val_loss: 1.4947\n",
      "Epoch 16/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4875\n",
      "Epoch 16: val_loss improved from 1.49451 to 1.49268, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 996us/sample - loss: 1.4875 - val_loss: 1.4927\n",
      "Epoch 17/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5419\n",
      "Epoch 17: val_loss did not improve from 1.49268\n",
      "32088/32088 [==============================] - 31s 966us/sample - loss: 1.5419 - val_loss: 1.4954\n",
      "Epoch 18/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5025\n",
      "Epoch 18: val_loss improved from 1.49268 to 1.49238, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 985us/sample - loss: 1.5025 - val_loss: 1.4924\n",
      "Epoch 19/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 19: val_loss improved from 1.49238 to 1.49064, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4745 - val_loss: 1.4906\n",
      "Epoch 20/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.6467\n",
      "Epoch 20: val_loss did not improve from 1.49064\n",
      "32088/32088 [==============================] - 32s 986us/sample - loss: 1.6467 - val_loss: 1.5177\n",
      "Epoch 21/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5435\n",
      "Epoch 21: val_loss did not improve from 1.49064\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.5435 - val_loss: 1.5063\n",
      "Epoch 22/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5251\n",
      "Epoch 22: val_loss did not improve from 1.49064\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.5251 - val_loss: 1.4960\n",
      "Epoch 23/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.5132\n",
      "Epoch 23: val_loss did not improve from 1.49064\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.5132 - val_loss: 1.4918\n",
      "Epoch 24/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4849\n",
      "Epoch 24: val_loss improved from 1.49064 to 1.48607, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4849 - val_loss: 1.4861\n",
      "Epoch 25/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4755\n",
      "Epoch 25: val_loss did not improve from 1.48607\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4755 - val_loss: 1.4894\n",
      "Epoch 26/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4734\n",
      "Epoch 26: val_loss did not improve from 1.48607\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4734 - val_loss: 1.4890\n",
      "Epoch 27/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4654\n",
      "Epoch 27: val_loss improved from 1.48607 to 1.48296, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4654 - val_loss: 1.4830\n",
      "Epoch 28/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4646\n",
      "Epoch 28: val_loss improved from 1.48296 to 1.48137, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4646 - val_loss: 1.4814\n",
      "Epoch 29/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4584\n",
      "Epoch 29: val_loss improved from 1.48137 to 1.47614, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4584 - val_loss: 1.4761\n",
      "Epoch 30/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4558\n",
      "Epoch 30: val_loss did not improve from 1.47614\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4558 - val_loss: 1.4786\n",
      "Epoch 31/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4522\n",
      "Epoch 31: val_loss did not improve from 1.47614\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4522 - val_loss: 1.4771\n",
      "Epoch 32/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4543\n",
      "Epoch 32: val_loss improved from 1.47614 to 1.47499, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4543 - val_loss: 1.4750\n",
      "Epoch 33/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4484\n",
      "Epoch 33: val_loss improved from 1.47499 to 1.47158, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4484 - val_loss: 1.4716\n",
      "Epoch 34/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4447\n",
      "Epoch 34: val_loss improved from 1.47158 to 1.47007, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4447 - val_loss: 1.4701\n",
      "Epoch 35/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4422\n",
      "Epoch 35: val_loss did not improve from 1.47007\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4422 - val_loss: 1.4746\n",
      "Epoch 36/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4423\n",
      "Epoch 36: val_loss improved from 1.47007 to 1.46696, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4423 - val_loss: 1.4670\n",
      "Epoch 37/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4400\n",
      "Epoch 37: val_loss improved from 1.46696 to 1.46438, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4400 - val_loss: 1.4644\n",
      "Epoch 38/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4385\n",
      "Epoch 38: val_loss did not improve from 1.46438\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4385 - val_loss: 1.4670\n",
      "Epoch 39/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4365\n",
      "Epoch 39: val_loss improved from 1.46438 to 1.46199, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4365 - val_loss: 1.4620\n",
      "Epoch 40/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 40: val_loss improved from 1.46199 to 1.45825, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4354 - val_loss: 1.4583\n",
      "Epoch 41/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4339\n",
      "Epoch 41: val_loss did not improve from 1.45825\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4339 - val_loss: 1.4596\n",
      "Epoch 42/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4325\n",
      "Epoch 42: val_loss did not improve from 1.45825\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4325 - val_loss: 1.4618\n",
      "Epoch 43/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 43: val_loss improved from 1.45825 to 1.45785, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4283 - val_loss: 1.4579\n",
      "Epoch 44/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 44: val_loss improved from 1.45785 to 1.45587, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4324 - val_loss: 1.4559\n",
      "Epoch 45/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4274\n",
      "Epoch 45: val_loss did not improve from 1.45587\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4274 - val_loss: 1.4564\n",
      "Epoch 46/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 46: val_loss did not improve from 1.45587\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4277 - val_loss: 1.4572\n",
      "Epoch 47/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4263\n",
      "Epoch 47: val_loss did not improve from 1.45587\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4263 - val_loss: 1.4598\n",
      "Epoch 48/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4233\n",
      "Epoch 48: val_loss improved from 1.45587 to 1.45275, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4233 - val_loss: 1.4527\n",
      "Epoch 49/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4214\n",
      "Epoch 49: val_loss did not improve from 1.45275\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4214 - val_loss: 1.4564\n",
      "Epoch 50/50\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 50: val_loss did not improve from 1.45275\n",
      "32088/32088 [==============================] - 34s 1ms/sample - loss: 1.4164 - val_loss: 1.4582\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:36:46.606880: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_206_1/lstm_cell_613/bias/Assign' id:307239 op device:{requested: '', assigned: ''} def:{{{node lstm_206_1/lstm_cell_613/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_206_1/lstm_cell_613/bias, lstm_206_1/lstm_cell_613/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:37:09.735917: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_204_1/lstm_cell_611/kernel/m/Assign' id:310747 op device:{requested: '', assigned: ''} def:{{{node lstm_204_1/lstm_cell_611/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_204_1/lstm_cell_611/kernel/m, lstm_204_1/lstm_cell_611/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:37:32.350999: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_29_1/cond/Merge' id:309801 op device:{requested: '', assigned: ''} def:{{{node dropout_29_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_29_1/cond/Identity, dropout_29_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1340)\n",
      "(1644, 1340)\n",
      "(1716, 1340)\n",
      "(1884, 1340)\n",
      "(1688, 1340)\n",
      "(1370, 1340)\n",
      "(1802, 1340)\n",
      "(1606, 1340)\n",
      "(1752, 1340)\n",
      "(1502, 1340)\n",
      "(1932, 1340)\n",
      "(1715, 1340)\n",
      "(1776, 1340)\n",
      "(1860, 1340)\n",
      "(1728, 1340)\n",
      "(1824, 1340)\n",
      "(947, 1340)\n",
      "(1668, 1340)\n",
      "(1884, 1340)\n",
      "{1: 7.552543564092203, 4: 8.033608513790963, 5: 4.553386675825088, 6: 3.420757012543113, 8: 8.949740361418321, 9: 10.0, 10: 6.478921100232044, 11: 6.617048029043761, 12: 9.970322467002466, 13: 7.692048681846809, 17: 9.575201804657429, 19: 6.808903082867925, 21: 9.300626204089689, 22: 1.0, 25: 8.204203874596313, 26: 8.782549313184807, 27: 6.446885509852458, 28: 6.1339065017855825, 29: 1.139529016984829}\n",
      "Train on 32088 samples, validate on 3573 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:45:09.422880: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 10.4962\n",
      "Epoch 1: val_loss improved from inf to 1.49037, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 77s 2ms/sample - loss: 10.4962 - val_loss: 1.4904\n",
      "Epoch 2/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.3663\n",
      "Epoch 2: val_loss improved from 1.49037 to 1.47352, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.3663 - val_loss: 1.4735\n",
      "Epoch 3/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.3394\n",
      "Epoch 3: val_loss did not improve from 1.47352\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.3394 - val_loss: 1.4820\n",
      "Epoch 4/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2568\n",
      "Epoch 4: val_loss improved from 1.47352 to 1.45917, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.2568 - val_loss: 1.4592\n",
      "Epoch 5/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2266\n",
      "Epoch 5: val_loss improved from 1.45917 to 1.45822, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.2266 - val_loss: 1.4582\n",
      "Epoch 6/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2234\n",
      "Epoch 6: val_loss improved from 1.45822 to 1.45687, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.2234 - val_loss: 1.4569\n",
      "Epoch 7/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1976\n",
      "Epoch 7: val_loss did not improve from 1.45687\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.1976 - val_loss: 1.4686\n",
      "Epoch 8/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.2001\n",
      "Epoch 8: val_loss did not improve from 1.45687\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.2001 - val_loss: 1.4584\n",
      "Epoch 9/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1891\n",
      "Epoch 9: val_loss improved from 1.45687 to 1.45432, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.1891 - val_loss: 1.4543\n",
      "Epoch 10/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1357\n",
      "Epoch 10: val_loss did not improve from 1.45432\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.1357 - val_loss: 1.4588\n",
      "Epoch 11/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1500\n",
      "Epoch 11: val_loss did not improve from 1.45432\n",
      "32088/32088 [==============================] - 32s 1000us/sample - loss: 10.1500 - val_loss: 1.4625\n",
      "Epoch 12/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1269\n",
      "Epoch 12: val_loss did not improve from 1.45432\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.1269 - val_loss: 1.4545\n",
      "Epoch 13/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1032\n",
      "Epoch 13: val_loss did not improve from 1.45432\n",
      "32088/32088 [==============================] - 32s 988us/sample - loss: 10.1032 - val_loss: 1.4588\n",
      "Epoch 14/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0844\n",
      "Epoch 14: val_loss did not improve from 1.45432\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.0844 - val_loss: 1.4772\n",
      "Epoch 15/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.1002\n",
      "Epoch 15: val_loss improved from 1.45432 to 1.44842, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.1002 - val_loss: 1.4484\n",
      "Epoch 16/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0927\n",
      "Epoch 16: val_loss did not improve from 1.44842\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.0927 - val_loss: 1.4580\n",
      "Epoch 17/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0390\n",
      "Epoch 17: val_loss did not improve from 1.44842\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.0390 - val_loss: 1.4595\n",
      "Epoch 18/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0332\n",
      "Epoch 18: val_loss did not improve from 1.44842\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 10.0332 - val_loss: 1.4561\n",
      "Epoch 19/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0680\n",
      "Epoch 19: val_loss improved from 1.44842 to 1.44754, saving model to ./checkpoints/unknown_person_few_shot_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 10.0680 - val_loss: 1.4475\n",
      "Epoch 20/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 10.0235\n",
      "Epoch 20: val_loss did not improve from 1.44754\n",
      "32088/32088 [==============================] - 32s 999us/sample - loss: 10.0235 - val_loss: 1.4520\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:56:53.392979: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_21_2/kernel/Assign' id:329209 op device:{requested: '', assigned: ''} def:{{{node dense_21_2/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_21_2/kernel, dense_21_2/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 09:57:18.448949: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_189_2/lstm_cell_633/kernel/v/Assign' id:330563 op device:{requested: '', assigned: ''} def:{{{node lstm_189_2/lstm_cell_633/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_189_2/lstm_cell_633/kernel/v, lstm_189_2/lstm_cell_633/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32088 samples, validate on 3573 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:57:47.449344: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 09:59:52.106000: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:00:27.557565: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.45001, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 80s 2ms/sample - loss: 1.4181 - val_loss: 1.4500\n",
      "Epoch 2/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 2: val_loss improved from 1.45001 to 1.44939, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 999us/sample - loss: 1.4176 - val_loss: 1.4494\n",
      "Epoch 3/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4175\n",
      "Epoch 3: val_loss did not improve from 1.44939\n",
      "32088/32088 [==============================] - 32s 999us/sample - loss: 1.4175 - val_loss: 1.4509\n",
      "Epoch 4/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4114\n",
      "Epoch 4: val_loss did not improve from 1.44939\n",
      "32088/32088 [==============================] - 32s 985us/sample - loss: 1.4114 - val_loss: 1.4535\n",
      "Epoch 5/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4104\n",
      "Epoch 5: val_loss did not improve from 1.44939\n",
      "32088/32088 [==============================] - 32s 990us/sample - loss: 1.4104 - val_loss: 1.4513\n",
      "Epoch 6/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4130\n",
      "Epoch 6: val_loss improved from 1.44939 to 1.44302, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4130 - val_loss: 1.4430\n",
      "Epoch 7/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4136\n",
      "Epoch 7: val_loss did not improve from 1.44302\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4136 - val_loss: 1.4492\n",
      "Epoch 8/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4074\n",
      "Epoch 8: val_loss improved from 1.44302 to 1.44199, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4074 - val_loss: 1.4420\n",
      "Epoch 9/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4060\n",
      "Epoch 9: val_loss did not improve from 1.44199\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4060 - val_loss: 1.4498\n",
      "Epoch 10/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 10: val_loss did not improve from 1.44199\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4049 - val_loss: 1.4453\n",
      "Epoch 11/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4047\n",
      "Epoch 11: val_loss improved from 1.44199 to 1.44187, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.4047 - val_loss: 1.4419\n",
      "Epoch 12/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4032\n",
      "Epoch 12: val_loss improved from 1.44187 to 1.43964, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4032 - val_loss: 1.4396\n",
      "Epoch 13/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4030\n",
      "Epoch 13: val_loss improved from 1.43964 to 1.43821, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 33s 1ms/sample - loss: 1.4030 - val_loss: 1.4382\n",
      "Epoch 14/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 14: val_loss improved from 1.43821 to 1.43724, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 999us/sample - loss: 1.3997 - val_loss: 1.4372\n",
      "Epoch 15/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 15: val_loss did not improve from 1.43724\n",
      "32088/32088 [==============================] - 32s 995us/sample - loss: 1.3986 - val_loss: 1.4423\n",
      "Epoch 16/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.4000\n",
      "Epoch 16: val_loss did not improve from 1.43724\n",
      "32088/32088 [==============================] - 32s 988us/sample - loss: 1.4000 - val_loss: 1.4381\n",
      "Epoch 17/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 17: val_loss improved from 1.43724 to 1.43089, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.3965 - val_loss: 1.4309\n",
      "Epoch 18/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 18: val_loss did not improve from 1.43089\n",
      "32088/32088 [==============================] - 32s 989us/sample - loss: 1.3957 - val_loss: 1.4385\n",
      "Epoch 19/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3941\n",
      "Epoch 19: val_loss did not improve from 1.43089\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.3941 - val_loss: 1.4313\n",
      "Epoch 20/20\n",
      "32088/32088 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 20: val_loss improved from 1.43089 to 1.42987, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_35.h5\n",
      "32088/32088 [==============================] - 32s 1ms/sample - loss: 1.3953 - val_loss: 1.4299\n",
      "35822\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:11:49.824203: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_242/lstm_cell_686/bias/Assign' id:345599 op device:{requested: '', assigned: ''} def:{{{node lstm_242/lstm_cell_686/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_242/lstm_cell_686/bias, lstm_242/lstm_cell_686/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:12:04.555677: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_1' id:345888 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:12:16.677932: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_2' id:345889 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32238, 95)\n",
      "Train on 32238 samples, validate on 3584 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:12:47.211888: W tensorflow/c/c_api.cc:304] Operation '{name:'training_36/Adam/lstm_240/lstm_cell_684/bias/m/Assign' id:358926 op device:{requested: '', assigned: ''} def:{{{node training_36/Adam/lstm_240/lstm_cell_684/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_36/Adam/lstm_240/lstm_cell_684/bias/m, training_36/Adam/lstm_240/lstm_cell_684/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:15:03.028532: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 3.3943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 10:15:39.262311: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_37/mul' id:348729 op device:{requested: '', assigned: ''} def:{{{node loss_37/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_37/mul/x, loss_37/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.06298, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 157s 5ms/sample - loss: 3.3943 - val_loss: 2.0630\n",
      "Epoch 2/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.8237\n",
      "Epoch 2: val_loss improved from 2.06298 to 1.53744, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.8237 - val_loss: 1.5374\n",
      "Epoch 3/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5876\n",
      "Epoch 3: val_loss improved from 1.53744 to 1.47142, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.5876 - val_loss: 1.4714\n",
      "Epoch 4/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5442\n",
      "Epoch 4: val_loss improved from 1.47142 to 1.44456, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 993us/sample - loss: 1.5442 - val_loss: 1.4446\n",
      "Epoch 5/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5237\n",
      "Epoch 5: val_loss improved from 1.44456 to 1.43157, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.5237 - val_loss: 1.4316\n",
      "Epoch 6/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5088\n",
      "Epoch 6: val_loss improved from 1.43157 to 1.40763, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 31s 973us/sample - loss: 1.5088 - val_loss: 1.4076\n",
      "Epoch 7/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5014\n",
      "Epoch 7: val_loss did not improve from 1.40763\n",
      "32238/32238 [==============================] - 32s 983us/sample - loss: 1.5014 - val_loss: 1.4158\n",
      "Epoch 8/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4995\n",
      "Epoch 8: val_loss improved from 1.40763 to 1.39569, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 998us/sample - loss: 1.4995 - val_loss: 1.3957\n",
      "Epoch 9/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4909\n",
      "Epoch 9: val_loss improved from 1.39569 to 1.38293, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 988us/sample - loss: 1.4909 - val_loss: 1.3829\n",
      "Epoch 10/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4857\n",
      "Epoch 10: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 997us/sample - loss: 1.4857 - val_loss: 1.3948\n",
      "Epoch 11/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5010\n",
      "Epoch 11: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.5010 - val_loss: 1.3878\n",
      "Epoch 12/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 12: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 982us/sample - loss: 1.4854 - val_loss: 1.3965\n",
      "Epoch 13/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4804\n",
      "Epoch 13: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 991us/sample - loss: 1.4804 - val_loss: 1.3843\n",
      "Epoch 14/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4759\n",
      "Epoch 14: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4759 - val_loss: 1.3836\n",
      "Epoch 15/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5131\n",
      "Epoch 15: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 992us/sample - loss: 1.5131 - val_loss: 1.4113\n",
      "Epoch 16/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4819\n",
      "Epoch 16: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 987us/sample - loss: 1.4819 - val_loss: 1.3900\n",
      "Epoch 17/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4727\n",
      "Epoch 17: val_loss did not improve from 1.38293\n",
      "32238/32238 [==============================] - 32s 980us/sample - loss: 1.4727 - val_loss: 1.3954\n",
      "Epoch 18/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4678\n",
      "Epoch 18: val_loss improved from 1.38293 to 1.38059, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 994us/sample - loss: 1.4678 - val_loss: 1.3806\n",
      "Epoch 19/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4696\n",
      "Epoch 19: val_loss improved from 1.38059 to 1.37473, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4696 - val_loss: 1.3747\n",
      "Epoch 20/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4643\n",
      "Epoch 20: val_loss did not improve from 1.37473\n",
      "32238/32238 [==============================] - 32s 985us/sample - loss: 1.4643 - val_loss: 1.3761\n",
      "Epoch 21/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4672\n",
      "Epoch 21: val_loss did not improve from 1.37473\n",
      "32238/32238 [==============================] - 32s 989us/sample - loss: 1.4672 - val_loss: 1.3760\n",
      "Epoch 22/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4695\n",
      "Epoch 22: val_loss did not improve from 1.37473\n",
      "32238/32238 [==============================] - 32s 1000us/sample - loss: 1.4695 - val_loss: 1.3800\n",
      "Epoch 23/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4587\n",
      "Epoch 23: val_loss improved from 1.37473 to 1.37115, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4587 - val_loss: 1.3711\n",
      "Epoch 24/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4527\n",
      "Epoch 24: val_loss did not improve from 1.37115\n",
      "32238/32238 [==============================] - 32s 979us/sample - loss: 1.4527 - val_loss: 1.3738\n",
      "Epoch 25/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4496\n",
      "Epoch 25: val_loss improved from 1.37115 to 1.35729, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4496 - val_loss: 1.3573\n",
      "Epoch 26/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4446\n",
      "Epoch 26: val_loss improved from 1.35729 to 1.35369, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4446 - val_loss: 1.3537\n",
      "Epoch 27/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4429\n",
      "Epoch 27: val_loss did not improve from 1.35369\n",
      "32238/32238 [==============================] - 32s 988us/sample - loss: 1.4429 - val_loss: 1.3650\n",
      "Epoch 28/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4441\n",
      "Epoch 28: val_loss did not improve from 1.35369\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4441 - val_loss: 1.3598\n",
      "Epoch 29/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4376\n",
      "Epoch 29: val_loss improved from 1.35369 to 1.35109, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4376 - val_loss: 1.3511\n",
      "Epoch 30/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 30: val_loss improved from 1.35109 to 1.34805, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 997us/sample - loss: 1.4330 - val_loss: 1.3480\n",
      "Epoch 31/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 31: val_loss did not improve from 1.34805\n",
      "32238/32238 [==============================] - 32s 991us/sample - loss: 1.4324 - val_loss: 1.3508\n",
      "Epoch 32/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4304\n",
      "Epoch 32: val_loss improved from 1.34805 to 1.34778, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4304 - val_loss: 1.3478\n",
      "Epoch 33/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4268\n",
      "Epoch 33: val_loss improved from 1.34778 to 1.34238, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4268 - val_loss: 1.3424\n",
      "Epoch 34/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4263\n",
      "Epoch 34: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 984us/sample - loss: 1.4263 - val_loss: 1.3516\n",
      "Epoch 35/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 35: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 978us/sample - loss: 1.4243 - val_loss: 1.3530\n",
      "Epoch 36/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 36: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 990us/sample - loss: 1.4211 - val_loss: 1.3506\n",
      "Epoch 37/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 37: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 984us/sample - loss: 1.4220 - val_loss: 1.3514\n",
      "Epoch 38/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4175\n",
      "Epoch 38: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4175 - val_loss: 1.3441\n",
      "Epoch 39/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4134\n",
      "Epoch 39: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4134 - val_loss: 1.3599\n",
      "Epoch 40/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 40: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 989us/sample - loss: 1.4149 - val_loss: 1.3488\n",
      "Epoch 41/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4120\n",
      "Epoch 41: val_loss did not improve from 1.34238\n",
      "32238/32238 [==============================] - 32s 981us/sample - loss: 1.4120 - val_loss: 1.3459\n",
      "Epoch 42/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4114\n",
      "Epoch 42: val_loss improved from 1.34238 to 1.34037, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4114 - val_loss: 1.3404\n",
      "Epoch 43/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4107\n",
      "Epoch 43: val_loss improved from 1.34037 to 1.34034, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 997us/sample - loss: 1.4107 - val_loss: 1.3403\n",
      "Epoch 44/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 44: val_loss did not improve from 1.34034\n",
      "32238/32238 [==============================] - 32s 998us/sample - loss: 1.4082 - val_loss: 1.3437\n",
      "Epoch 45/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4086\n",
      "Epoch 45: val_loss improved from 1.34034 to 1.33659, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 992us/sample - loss: 1.4086 - val_loss: 1.3366\n",
      "Epoch 46/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4056\n",
      "Epoch 46: val_loss did not improve from 1.33659\n",
      "32238/32238 [==============================] - 32s 993us/sample - loss: 1.4056 - val_loss: 1.3369\n",
      "Epoch 47/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4046\n",
      "Epoch 47: val_loss did not improve from 1.33659\n",
      "32238/32238 [==============================] - 32s 979us/sample - loss: 1.4046 - val_loss: 1.3521\n",
      "Epoch 48/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 48: val_loss did not improve from 1.33659\n",
      "32238/32238 [==============================] - 32s 997us/sample - loss: 1.4045 - val_loss: 1.3367\n",
      "Epoch 49/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4028\n",
      "Epoch 49: val_loss did not improve from 1.33659\n",
      "32238/32238 [==============================] - 31s 976us/sample - loss: 1.4028 - val_loss: 1.3376\n",
      "Epoch 50/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 50: val_loss improved from 1.33659 to 1.33032, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 995us/sample - loss: 1.4026 - val_loss: 1.3303\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:44:07.330599: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_234_1/lstm_cell_715/kernel/Assign' id:362812 op device:{requested: '', assigned: ''} def:{{{node lstm_234_1/lstm_cell_715/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_234_1/lstm_cell_715/kernel, lstm_234_1/lstm_cell_715/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 10:44:36.213870: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_26_1/kernel/v/Assign' id:368127 op device:{requested: '', assigned: ''} def:{{{node conv2d_26_1/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_26_1/kernel/v, conv2d_26_1/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 10:45:03.823056: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_34_1/cond/Merge' id:366843 op device:{requested: '', assigned: ''} def:{{{node dropout_34_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_34_1/cond/Identity, dropout_34_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1179)\n",
      "(1644, 1179)\n",
      "(1716, 1179)\n",
      "(1848, 1179)\n",
      "(1723, 1179)\n",
      "(1381, 1179)\n",
      "(1790, 1179)\n",
      "(1606, 1179)\n",
      "(1740, 1179)\n",
      "(1526, 1179)\n",
      "(1908, 1179)\n",
      "(1715, 1179)\n",
      "(1764, 1179)\n",
      "(1872, 1179)\n",
      "(1728, 1179)\n",
      "(1812, 1179)\n",
      "(970, 1179)\n",
      "(1668, 1179)\n",
      "(1884, 1179)\n",
      "{1: 8.57729302086948, 4: 7.886180718036746, 5: 4.360683027113122, 6: 3.1370559886293092, 8: 8.700330038110621, 9: 8.94801325390198, 10: 7.191580070102595, 11: 6.674192924387644, 12: 10.0, 13: 7.999526221215409, 17: 9.461924910824239, 19: 7.006018538082945, 21: 9.757789286290354, 22: 1.9601380624709468, 25: 8.412438716773734, 26: 9.316166510625203, 27: 5.969116527558628, 28: 6.699536994325963, 29: 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907579/3261308647.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32238 samples, validate on 3584 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 10:53:13.186365: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7067\n",
      "Epoch 1: val_loss improved from inf to 1.37236, saving model to ./checkpoints/unknown_person_few_shot_p2_36.h5\n",
      "32238/32238 [==============================] - 85s 3ms/sample - loss: 10.7067 - val_loss: 1.3724\n",
      "Epoch 2/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.6221\n",
      "Epoch 2: val_loss did not improve from 1.37236\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.6221 - val_loss: 1.3774\n",
      "Epoch 3/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.5487\n",
      "Epoch 3: val_loss improved from 1.37236 to 1.35161, saving model to ./checkpoints/unknown_person_few_shot_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 10.5487 - val_loss: 1.3516\n",
      "Epoch 4/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.5201\n",
      "Epoch 4: val_loss did not improve from 1.35161\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.5201 - val_loss: 1.3583\n",
      "Epoch 5/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.4694\n",
      "Epoch 5: val_loss improved from 1.35161 to 1.34617, saving model to ./checkpoints/unknown_person_few_shot_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.4694 - val_loss: 1.3462\n",
      "Epoch 6/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.4684\n",
      "Epoch 6: val_loss improved from 1.34617 to 1.34602, saving model to ./checkpoints/unknown_person_few_shot_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 996us/sample - loss: 10.4684 - val_loss: 1.3460\n",
      "Epoch 7/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.4086\n",
      "Epoch 7: val_loss did not improve from 1.34602\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 10.4086 - val_loss: 1.3464\n",
      "Epoch 8/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.4055\n",
      "Epoch 8: val_loss improved from 1.34602 to 1.33683, saving model to ./checkpoints/unknown_person_few_shot_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.4055 - val_loss: 1.3368\n",
      "Epoch 9/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.3906\n",
      "Epoch 9: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 997us/sample - loss: 10.3906 - val_loss: 1.3410\n",
      "Epoch 10/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.3674\n",
      "Epoch 10: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 10.3674 - val_loss: 1.3540\n",
      "Epoch 11/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.3726\n",
      "Epoch 11: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.3726 - val_loss: 1.3559\n",
      "Epoch 12/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.3312\n",
      "Epoch 12: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 10.3312 - val_loss: 1.3450\n",
      "Epoch 13/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2987\n",
      "Epoch 13: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.2987 - val_loss: 1.3515\n",
      "Epoch 14/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2970\n",
      "Epoch 14: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 981us/sample - loss: 10.2970 - val_loss: 1.3388\n",
      "Epoch 15/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.3018\n",
      "Epoch 15: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 994us/sample - loss: 10.3018 - val_loss: 1.3514\n",
      "Epoch 16/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2548\n",
      "Epoch 16: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 997us/sample - loss: 10.2548 - val_loss: 1.3468\n",
      "Epoch 17/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2645\n",
      "Epoch 17: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 977us/sample - loss: 10.2645 - val_loss: 1.3691\n",
      "Epoch 18/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2456\n",
      "Epoch 18: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 10.2456 - val_loss: 1.3437\n",
      "Epoch 19/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2436\n",
      "Epoch 19: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 992us/sample - loss: 10.2436 - val_loss: 1.3383\n",
      "Epoch 20/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.2398\n",
      "Epoch 20: val_loss did not improve from 1.33683\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 10.2398 - val_loss: 1.3483\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:05:04.349603: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_25_2/kernel/Assign' id:386251 op device:{requested: '', assigned: ''} def:{{{node dense_25_2/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_25_2/kernel, dense_25_2/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:05:32.957244: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_234_2/lstm_cell_752/kernel/v/Assign' id:387725 op device:{requested: '', assigned: ''} def:{{{node lstm_234_2/lstm_cell_752/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_234_2/lstm_cell_752/kernel/v, lstm_234_2/lstm_cell_752/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32238 samples, validate on 3584 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:06:07.467384: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:08:33.073762: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:09:08.444646: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.33727, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_36.h5\n",
      "32238/32238 [==============================] - 86s 3ms/sample - loss: 1.3981 - val_loss: 1.3373\n",
      "Epoch 2/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3979\n",
      "Epoch 2: val_loss improved from 1.33727 to 1.33620, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_36.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3979 - val_loss: 1.3362\n",
      "Epoch 3/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 3: val_loss did not improve from 1.33620\n",
      "32238/32238 [==============================] - 32s 994us/sample - loss: 1.3948 - val_loss: 1.3381\n",
      "Epoch 4/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3961\n",
      "Epoch 4: val_loss improved from 1.33620 to 1.33119, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.3961 - val_loss: 1.3312\n",
      "Epoch 5/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3964\n",
      "Epoch 5: val_loss did not improve from 1.33119\n",
      "32238/32238 [==============================] - 32s 989us/sample - loss: 1.3964 - val_loss: 1.3463\n",
      "Epoch 6/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 6: val_loss did not improve from 1.33119\n",
      "32238/32238 [==============================] - 32s 999us/sample - loss: 1.3907 - val_loss: 1.3356\n",
      "Epoch 7/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3910\n",
      "Epoch 7: val_loss did not improve from 1.33119\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3910 - val_loss: 1.3329\n",
      "Epoch 8/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3897\n",
      "Epoch 8: val_loss improved from 1.33119 to 1.32760, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_36.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.3897 - val_loss: 1.3276\n",
      "Epoch 9/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3869\n",
      "Epoch 9: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3869 - val_loss: 1.3379\n",
      "Epoch 10/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3870\n",
      "Epoch 10: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 32s 992us/sample - loss: 1.3870 - val_loss: 1.3303\n",
      "Epoch 11/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3850\n",
      "Epoch 11: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3850 - val_loss: 1.3509\n",
      "Epoch 12/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3892\n",
      "Epoch 12: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 34s 1ms/sample - loss: 1.3892 - val_loss: 1.3326\n",
      "Epoch 13/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3862\n",
      "Epoch 13: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.3862 - val_loss: 1.3328\n",
      "Epoch 14/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3799\n",
      "Epoch 14: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3799 - val_loss: 1.3328\n",
      "Epoch 15/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3821\n",
      "Epoch 15: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 32s 989us/sample - loss: 1.3821 - val_loss: 1.3385\n",
      "Epoch 16/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3798\n",
      "Epoch 16: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3798 - val_loss: 1.3294\n",
      "Epoch 17/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3779\n",
      "Epoch 17: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 32s 993us/sample - loss: 1.3779 - val_loss: 1.3446\n",
      "Epoch 18/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3767\n",
      "Epoch 18: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.3767 - val_loss: 1.3380\n",
      "Epoch 19/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3773\n",
      "Epoch 19: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 32s 977us/sample - loss: 1.3773 - val_loss: 1.3329\n",
      "Epoch 20/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3778\n",
      "Epoch 20: val_loss did not improve from 1.32760\n",
      "32238/32238 [==============================] - 32s 993us/sample - loss: 1.3778 - val_loss: 1.3346\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:20:27.541447: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_263/lstm_cell_781/bias/Assign' id:400001 op device:{requested: '', assigned: ''} def:{{{node lstm_263/lstm_cell_781/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_263/lstm_cell_781/bias, lstm_263/lstm_cell_781/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:20:43.336792: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_1' id:402930 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:20:56.360840: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_2' id:402931 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32238, 95)\n",
      "Train on 32238 samples, validate on 3584 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:21:27.624985: W tensorflow/c/c_api.cc:304] Operation '{name:'training_42/Adam/lstm_270/lstm_cell_788/bias/m/Assign' id:415863 op device:{requested: '', assigned: ''} def:{{{node training_42/Adam/lstm_270/lstm_cell_788/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_42/Adam/lstm_270/lstm_cell_788/bias/m, training_42/Adam/lstm_270/lstm_cell_788/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:24:01.796142: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 3.1222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:24:35.605692: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_43/mul' id:405771 op device:{requested: '', assigned: ''} def:{{{node loss_43/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_43/mul/x, loss_43/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.92775, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 161s 5ms/sample - loss: 3.1222 - val_loss: 1.9277\n",
      "Epoch 2/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.7743\n",
      "Epoch 2: val_loss improved from 1.92775 to 1.57155, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 32s 994us/sample - loss: 1.7743 - val_loss: 1.5716\n",
      "Epoch 3/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5882\n",
      "Epoch 3: val_loss improved from 1.57155 to 1.48543, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.5882 - val_loss: 1.4854\n",
      "Epoch 4/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5432\n",
      "Epoch 4: val_loss improved from 1.48543 to 1.45802, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 34s 1ms/sample - loss: 1.5432 - val_loss: 1.4580\n",
      "Epoch 5/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5208\n",
      "Epoch 5: val_loss improved from 1.45802 to 1.42725, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.5208 - val_loss: 1.4273\n",
      "Epoch 6/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5054\n",
      "Epoch 6: val_loss improved from 1.42725 to 1.42018, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.5054 - val_loss: 1.4202\n",
      "Epoch 7/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4947\n",
      "Epoch 7: val_loss did not improve from 1.42018\n",
      "32238/32238 [==============================] - 32s 999us/sample - loss: 1.4947 - val_loss: 1.4211\n",
      "Epoch 8/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4966\n",
      "Epoch 8: val_loss improved from 1.42018 to 1.40865, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4966 - val_loss: 1.4086\n",
      "Epoch 9/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4879\n",
      "Epoch 9: val_loss improved from 1.40865 to 1.40242, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 32s 992us/sample - loss: 1.4879 - val_loss: 1.4024\n",
      "Epoch 10/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4846\n",
      "Epoch 10: val_loss improved from 1.40242 to 1.39753, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.4846 - val_loss: 1.3975\n",
      "Epoch 11/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4804\n",
      "Epoch 11: val_loss improved from 1.39753 to 1.38855, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 34s 1ms/sample - loss: 1.4804 - val_loss: 1.3886\n",
      "Epoch 12/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5368\n",
      "Epoch 12: val_loss improved from 1.38855 to 1.38732, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 33s 1ms/sample - loss: 1.5368 - val_loss: 1.3873\n",
      "Epoch 13/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4802\n",
      "Epoch 13: val_loss improved from 1.38732 to 1.38520, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 32s 1ms/sample - loss: 1.4802 - val_loss: 1.3852\n",
      "Epoch 14/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4849\n",
      "Epoch 14: val_loss did not improve from 1.38520\n",
      "32238/32238 [==============================] - 28s 874us/sample - loss: 1.4849 - val_loss: 1.3862\n",
      "Epoch 15/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4761\n",
      "Epoch 15: val_loss improved from 1.38520 to 1.38208, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 20s 631us/sample - loss: 1.4761 - val_loss: 1.3821\n",
      "Epoch 16/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 16: val_loss did not improve from 1.38208\n",
      "32238/32238 [==============================] - 20s 617us/sample - loss: 1.4731 - val_loss: 1.3828\n",
      "Epoch 17/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 17: val_loss did not improve from 1.38208\n",
      "32238/32238 [==============================] - 20s 616us/sample - loss: 1.4772 - val_loss: 1.3828\n",
      "Epoch 18/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5017\n",
      "Epoch 18: val_loss did not improve from 1.38208\n",
      "32238/32238 [==============================] - 21s 655us/sample - loss: 1.5017 - val_loss: 1.3891\n",
      "Epoch 19/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4800\n",
      "Epoch 19: val_loss improved from 1.38208 to 1.37657, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 23s 714us/sample - loss: 1.4800 - val_loss: 1.3766\n",
      "Epoch 20/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4890\n",
      "Epoch 20: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 22s 695us/sample - loss: 1.4890 - val_loss: 1.3967\n",
      "Epoch 21/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4949\n",
      "Epoch 21: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 23s 703us/sample - loss: 1.4949 - val_loss: 1.3979\n",
      "Epoch 22/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5065\n",
      "Epoch 22: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 1.5065 - val_loss: 1.3849\n",
      "Epoch 23/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4853\n",
      "Epoch 23: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 1.4853 - val_loss: 1.3914\n",
      "Epoch 24/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4719\n",
      "Epoch 24: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 23s 701us/sample - loss: 1.4719 - val_loss: 1.3900\n",
      "Epoch 25/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4624\n",
      "Epoch 25: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 20s 636us/sample - loss: 1.4624 - val_loss: 1.3832\n",
      "Epoch 26/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4627\n",
      "Epoch 26: val_loss did not improve from 1.37657\n",
      "32238/32238 [==============================] - 20s 607us/sample - loss: 1.4627 - val_loss: 1.3791\n",
      "Epoch 27/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4544\n",
      "Epoch 27: val_loss improved from 1.37657 to 1.37340, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 21s 653us/sample - loss: 1.4544 - val_loss: 1.3734\n",
      "Epoch 28/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4473\n",
      "Epoch 28: val_loss improved from 1.37340 to 1.36785, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 21s 656us/sample - loss: 1.4473 - val_loss: 1.3678\n",
      "Epoch 29/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4444\n",
      "Epoch 29: val_loss improved from 1.36785 to 1.36365, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 21s 660us/sample - loss: 1.4444 - val_loss: 1.3637\n",
      "Epoch 30/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4442\n",
      "Epoch 30: val_loss did not improve from 1.36365\n",
      "32238/32238 [==============================] - 21s 653us/sample - loss: 1.4442 - val_loss: 1.3681\n",
      "Epoch 31/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4379\n",
      "Epoch 31: val_loss improved from 1.36365 to 1.35549, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 21s 659us/sample - loss: 1.4379 - val_loss: 1.3555\n",
      "Epoch 32/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4366\n",
      "Epoch 32: val_loss did not improve from 1.35549\n",
      "32238/32238 [==============================] - 20s 621us/sample - loss: 1.4366 - val_loss: 1.3766\n",
      "Epoch 33/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4344\n",
      "Epoch 33: val_loss did not improve from 1.35549\n",
      "32238/32238 [==============================] - 23s 702us/sample - loss: 1.4344 - val_loss: 1.3612\n",
      "Epoch 34/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4332\n",
      "Epoch 34: val_loss did not improve from 1.35549\n",
      "32238/32238 [==============================] - 20s 626us/sample - loss: 1.4332 - val_loss: 1.3618\n",
      "Epoch 35/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4298\n",
      "Epoch 35: val_loss did not improve from 1.35549\n",
      "32238/32238 [==============================] - 22s 692us/sample - loss: 1.4298 - val_loss: 1.3576\n",
      "Epoch 36/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 36: val_loss improved from 1.35549 to 1.35488, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 22s 681us/sample - loss: 1.4277 - val_loss: 1.3549\n",
      "Epoch 37/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4256\n",
      "Epoch 37: val_loss improved from 1.35488 to 1.35297, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 20s 613us/sample - loss: 1.4256 - val_loss: 1.3530\n",
      "Epoch 38/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 38: val_loss improved from 1.35297 to 1.34730, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 20s 616us/sample - loss: 1.4246 - val_loss: 1.3473\n",
      "Epoch 39/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4219\n",
      "Epoch 39: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 21s 654us/sample - loss: 1.4219 - val_loss: 1.3573\n",
      "Epoch 40/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4221\n",
      "Epoch 40: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 23s 701us/sample - loss: 1.4221 - val_loss: 1.3565\n",
      "Epoch 41/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4199\n",
      "Epoch 41: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 23s 701us/sample - loss: 1.4199 - val_loss: 1.3483\n",
      "Epoch 42/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 42: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 20s 617us/sample - loss: 1.4191 - val_loss: 1.3523\n",
      "Epoch 43/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4159\n",
      "Epoch 43: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 20s 609us/sample - loss: 1.4159 - val_loss: 1.3482\n",
      "Epoch 44/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 44: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 20s 609us/sample - loss: 1.4148 - val_loss: 1.3574\n",
      "Epoch 45/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 45: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 21s 662us/sample - loss: 1.4155 - val_loss: 1.3627\n",
      "Epoch 46/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4136\n",
      "Epoch 46: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 23s 702us/sample - loss: 1.4136 - val_loss: 1.3571\n",
      "Epoch 47/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 47: val_loss did not improve from 1.34730\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 1.4093 - val_loss: 1.3548\n",
      "Epoch 48/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4111\n",
      "Epoch 48: val_loss improved from 1.34730 to 1.34240, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_37.h5\n",
      "32238/32238 [==============================] - 22s 689us/sample - loss: 1.4111 - val_loss: 1.3424\n",
      "Epoch 49/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 49: val_loss did not improve from 1.34240\n",
      "32238/32238 [==============================] - 20s 613us/sample - loss: 1.4087 - val_loss: 1.3450\n",
      "Epoch 50/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 50: val_loss did not improve from 1.34240\n",
      "32238/32238 [==============================] - 20s 608us/sample - loss: 1.4082 - val_loss: 1.3481\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:46:33.851077: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_28_1/kernel/Assign' id:417634 op device:{requested: '', assigned: ''} def:{{{node conv2d_28_1/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_28_1/kernel, conv2d_28_1/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:46:54.242732: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_261_1/lstm_cell_816/kernel/v/Assign' id:425219 op device:{requested: '', assigned: ''} def:{{{node lstm_261_1/lstm_cell_816/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_261_1/lstm_cell_816/kernel/v, lstm_261_1/lstm_cell_816/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 11:47:14.522017: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_39_1/cond/Merge' id:423885 op device:{requested: '', assigned: ''} def:{{{node dropout_39_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_39_1/cond/Identity, dropout_39_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1179)\n",
      "(1644, 1179)\n",
      "(1716, 1179)\n",
      "(1848, 1179)\n",
      "(1723, 1179)\n",
      "(1381, 1179)\n",
      "(1790, 1179)\n",
      "(1606, 1179)\n",
      "(1740, 1179)\n",
      "(1526, 1179)\n",
      "(1908, 1179)\n",
      "(1715, 1179)\n",
      "(1764, 1179)\n",
      "(1872, 1179)\n",
      "(1728, 1179)\n",
      "(1812, 1179)\n",
      "(970, 1179)\n",
      "(1668, 1179)\n",
      "(1884, 1179)\n",
      "{1: 8.150790214830113, 4: 8.279794889823002, 5: 4.913560144547373, 6: 4.309202497200382, 8: 9.192682079067014, 9: 9.316686705674384, 10: 7.3432381397180215, 11: 7.202260190664323, 12: 9.953063509244569, 13: 8.036834229152863, 17: 9.63967955143928, 19: 7.255133346521692, 21: 10.0, 22: 1.0, 25: 8.445024929646664, 26: 9.426679203539472, 27: 6.596294874990065, 28: 6.411270240415741, 29: 1.7071370542801434}\n",
      "Train on 32238 samples, validate on 3584 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:53:08.490632: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1353\n",
      "Epoch 1: val_loss improved from inf to 1.39083, saving model to ./checkpoints/unknown_person_few_shot_p2_37.h5\n",
      "32238/32238 [==============================] - 60s 2ms/sample - loss: 11.1353 - val_loss: 1.3908\n",
      "Epoch 2/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.0100\n",
      "Epoch 2: val_loss improved from 1.39083 to 1.36901, saving model to ./checkpoints/unknown_person_few_shot_p2_37.h5\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 11.0100 - val_loss: 1.3690\n",
      "Epoch 3/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.9539\n",
      "Epoch 3: val_loss improved from 1.36901 to 1.34666, saving model to ./checkpoints/unknown_person_few_shot_p2_37.h5\n",
      "32238/32238 [==============================] - 22s 676us/sample - loss: 10.9539 - val_loss: 1.3467\n",
      "Epoch 4/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.9365\n",
      "Epoch 4: val_loss did not improve from 1.34666\n",
      "32238/32238 [==============================] - 20s 632us/sample - loss: 10.9365 - val_loss: 1.3647\n",
      "Epoch 5/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.8708\n",
      "Epoch 5: val_loss did not improve from 1.34666\n",
      "32238/32238 [==============================] - 22s 697us/sample - loss: 10.8708 - val_loss: 1.3588\n",
      "Epoch 6/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.8879\n",
      "Epoch 6: val_loss did not improve from 1.34666\n",
      "32238/32238 [==============================] - 20s 631us/sample - loss: 10.8879 - val_loss: 1.3556\n",
      "Epoch 7/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.8464\n",
      "Epoch 7: val_loss did not improve from 1.34666\n",
      "32238/32238 [==============================] - 21s 664us/sample - loss: 10.8464 - val_loss: 1.3694\n",
      "Epoch 8/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.8125\n",
      "Epoch 8: val_loss did not improve from 1.34666\n",
      "32238/32238 [==============================] - 20s 635us/sample - loss: 10.8125 - val_loss: 1.3553\n",
      "Epoch 9/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7891\n",
      "Epoch 9: val_loss did not improve from 1.34666\n",
      "32238/32238 [==============================] - 22s 697us/sample - loss: 10.7891 - val_loss: 1.3492\n",
      "Epoch 10/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7728\n",
      "Epoch 10: val_loss improved from 1.34666 to 1.34142, saving model to ./checkpoints/unknown_person_few_shot_p2_37.h5\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 10.7728 - val_loss: 1.3414\n",
      "Epoch 11/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7808\n",
      "Epoch 11: val_loss did not improve from 1.34142\n",
      "32238/32238 [==============================] - 20s 620us/sample - loss: 10.7808 - val_loss: 1.3638\n",
      "Epoch 12/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7212\n",
      "Epoch 12: val_loss did not improve from 1.34142\n",
      "32238/32238 [==============================] - 22s 688us/sample - loss: 10.7212 - val_loss: 1.3449\n",
      "Epoch 13/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7409\n",
      "Epoch 13: val_loss did not improve from 1.34142\n",
      "32238/32238 [==============================] - 23s 702us/sample - loss: 10.7409 - val_loss: 1.3546\n",
      "Epoch 14/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7593\n",
      "Epoch 14: val_loss did not improve from 1.34142\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 10.7593 - val_loss: 1.3634\n",
      "Epoch 15/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.6980\n",
      "Epoch 15: val_loss improved from 1.34142 to 1.33906, saving model to ./checkpoints/unknown_person_few_shot_p2_37.h5\n",
      "32238/32238 [==============================] - 19s 599us/sample - loss: 10.6980 - val_loss: 1.3391\n",
      "Epoch 16/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.7073\n",
      "Epoch 16: val_loss improved from 1.33906 to 1.33675, saving model to ./checkpoints/unknown_person_few_shot_p2_37.h5\n",
      "32238/32238 [==============================] - 21s 639us/sample - loss: 10.7073 - val_loss: 1.3368\n",
      "Epoch 17/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.6784\n",
      "Epoch 17: val_loss did not improve from 1.33675\n",
      "32238/32238 [==============================] - 22s 689us/sample - loss: 10.6784 - val_loss: 1.3578\n",
      "Epoch 18/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.6739\n",
      "Epoch 18: val_loss did not improve from 1.33675\n",
      "32238/32238 [==============================] - 22s 672us/sample - loss: 10.6739 - val_loss: 1.3603\n",
      "Epoch 19/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.6676\n",
      "Epoch 19: val_loss did not improve from 1.33675\n",
      "32238/32238 [==============================] - 23s 701us/sample - loss: 10.6676 - val_loss: 1.3459\n",
      "Epoch 20/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 10.6882\n",
      "Epoch 20: val_loss did not improve from 1.33675\n",
      "32238/32238 [==============================] - 20s 628us/sample - loss: 10.6882 - val_loss: 1.3603\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:01:07.072088: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_283_2/lstm_cell_875/bias/Assign' id:441203 op device:{requested: '', assigned: ''} def:{{{node lstm_283_2/lstm_cell_875/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_283_2/lstm_cell_875/bias, lstm_283_2/lstm_cell_875/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:01:29.054446: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_262_2/lstm_cell_854/recurrent_kernel/m/Assign' id:443994 op device:{requested: '', assigned: ''} def:{{{node lstm_262_2/lstm_cell_854/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_262_2/lstm_cell_854/recurrent_kernel/m, lstm_262_2/lstm_cell_854/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32238 samples, validate on 3584 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:01:53.402281: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:03:47.218756: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:04:09.776776: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.34165, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_37.h5\n",
      "32238/32238 [==============================] - 62s 2ms/sample - loss: 1.4061 - val_loss: 1.3416\n",
      "Epoch 2/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4073\n",
      "Epoch 2: val_loss did not improve from 1.34165\n",
      "32238/32238 [==============================] - 22s 675us/sample - loss: 1.4073 - val_loss: 1.3471\n",
      "Epoch 3/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4041\n",
      "Epoch 3: val_loss did not improve from 1.34165\n",
      "32238/32238 [==============================] - 19s 600us/sample - loss: 1.4041 - val_loss: 1.3452\n",
      "Epoch 4/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4023\n",
      "Epoch 4: val_loss did not improve from 1.34165\n",
      "32238/32238 [==============================] - 21s 643us/sample - loss: 1.4023 - val_loss: 1.3540\n",
      "Epoch 5/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 5: val_loss did not improve from 1.34165\n",
      "32238/32238 [==============================] - 22s 672us/sample - loss: 1.4015 - val_loss: 1.3495\n",
      "Epoch 6/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 6: val_loss did not improve from 1.34165\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 1.4010 - val_loss: 1.3446\n",
      "Epoch 7/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3988\n",
      "Epoch 7: val_loss improved from 1.34165 to 1.33816, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_37.h5\n",
      "32238/32238 [==============================] - 23s 711us/sample - loss: 1.3988 - val_loss: 1.3382\n",
      "Epoch 8/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3963\n",
      "Epoch 8: val_loss did not improve from 1.33816\n",
      "32238/32238 [==============================] - 23s 707us/sample - loss: 1.3963 - val_loss: 1.3522\n",
      "Epoch 9/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3976\n",
      "Epoch 9: val_loss did not improve from 1.33816\n",
      "32238/32238 [==============================] - 23s 710us/sample - loss: 1.3976 - val_loss: 1.3431\n",
      "Epoch 10/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3956\n",
      "Epoch 10: val_loss did not improve from 1.33816\n",
      "32238/32238 [==============================] - 23s 709us/sample - loss: 1.3956 - val_loss: 1.3424\n",
      "Epoch 11/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 11: val_loss improved from 1.33816 to 1.33500, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_37.h5\n",
      "32238/32238 [==============================] - 21s 648us/sample - loss: 1.3947 - val_loss: 1.3350\n",
      "Epoch 12/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 12: val_loss did not improve from 1.33500\n",
      "32238/32238 [==============================] - 19s 599us/sample - loss: 1.3936 - val_loss: 1.3479\n",
      "Epoch 13/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 13: val_loss improved from 1.33500 to 1.33363, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_37.h5\n",
      "32238/32238 [==============================] - 20s 608us/sample - loss: 1.3928 - val_loss: 1.3336\n",
      "Epoch 14/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3940\n",
      "Epoch 14: val_loss did not improve from 1.33363\n",
      "32238/32238 [==============================] - 19s 601us/sample - loss: 1.3940 - val_loss: 1.3364\n",
      "Epoch 15/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3915\n",
      "Epoch 15: val_loss improved from 1.33363 to 1.32990, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_37.h5\n",
      "32238/32238 [==============================] - 20s 609us/sample - loss: 1.3915 - val_loss: 1.3299\n",
      "Epoch 16/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3904\n",
      "Epoch 16: val_loss did not improve from 1.32990\n",
      "32238/32238 [==============================] - 21s 651us/sample - loss: 1.3904 - val_loss: 1.3391\n",
      "Epoch 17/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3871\n",
      "Epoch 17: val_loss did not improve from 1.32990\n",
      "32238/32238 [==============================] - 20s 608us/sample - loss: 1.3871 - val_loss: 1.3382\n",
      "Epoch 18/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 18: val_loss did not improve from 1.32990\n",
      "32238/32238 [==============================] - 21s 655us/sample - loss: 1.3882 - val_loss: 1.3375\n",
      "Epoch 19/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3851\n",
      "Epoch 19: val_loss did not improve from 1.32990\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 1.3851 - val_loss: 1.3456\n",
      "Epoch 20/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.3874\n",
      "Epoch 20: val_loss did not improve from 1.32990\n",
      "32238/32238 [==============================] - 23s 703us/sample - loss: 1.3874 - val_loss: 1.3469\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:11:40.898607: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_299/lstm_cell_891/recurrent_kernel/Assign' id:456869 op device:{requested: '', assigned: ''} def:{{{node lstm_299/lstm_cell_891/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_299/lstm_cell_891/recurrent_kernel, lstm_299/lstm_cell_891/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:11:53.270436: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_1' id:459972 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:12:03.350486: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_2' id:459973 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32238, 95)\n",
      "Train on 32238 samples, validate on 3584 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:12:27.854316: W tensorflow/c/c_api.cc:304] Operation '{name:'training_48/Adam/lstm_308/lstm_cell_900/bias/v/Assign' id:473563 op device:{requested: '', assigned: ''} def:{{{node training_48/Adam/lstm_308/lstm_cell_900/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_48/Adam/lstm_308/lstm_cell_900/bias/v, training_48/Adam/lstm_308/lstm_cell_900/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:14:27.419182: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 3.2928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:14:50.448677: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_49/mul' id:462813 op device:{requested: '', assigned: ''} def:{{{node loss_49/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_49/mul/x, loss_49/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.88762, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 131s 4ms/sample - loss: 3.2928 - val_loss: 1.8876\n",
      "Epoch 2/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.7874\n",
      "Epoch 2: val_loss improved from 1.88762 to 1.60225, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 628us/sample - loss: 1.7874 - val_loss: 1.6023\n",
      "Epoch 3/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.6018\n",
      "Epoch 3: val_loss improved from 1.60225 to 1.50325, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 624us/sample - loss: 1.6018 - val_loss: 1.5033\n",
      "Epoch 4/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5523\n",
      "Epoch 4: val_loss improved from 1.50325 to 1.45709, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 629us/sample - loss: 1.5523 - val_loss: 1.4571\n",
      "Epoch 5/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5296\n",
      "Epoch 5: val_loss improved from 1.45709 to 1.45423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 627us/sample - loss: 1.5296 - val_loss: 1.4542\n",
      "Epoch 6/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5149\n",
      "Epoch 6: val_loss improved from 1.45423 to 1.43187, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 1.5149 - val_loss: 1.4319\n",
      "Epoch 7/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5051\n",
      "Epoch 7: val_loss improved from 1.43187 to 1.41266, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 712us/sample - loss: 1.5051 - val_loss: 1.4127\n",
      "Epoch 8/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4996\n",
      "Epoch 8: val_loss did not improve from 1.41266\n",
      "32238/32238 [==============================] - 23s 706us/sample - loss: 1.4996 - val_loss: 1.4278\n",
      "Epoch 9/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5039\n",
      "Epoch 9: val_loss improved from 1.41266 to 1.39825, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 709us/sample - loss: 1.5039 - val_loss: 1.3982\n",
      "Epoch 10/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5369\n",
      "Epoch 10: val_loss did not improve from 1.39825\n",
      "32238/32238 [==============================] - 20s 634us/sample - loss: 1.5369 - val_loss: 1.4112\n",
      "Epoch 11/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4994\n",
      "Epoch 11: val_loss improved from 1.39825 to 1.39774, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 699us/sample - loss: 1.4994 - val_loss: 1.3977\n",
      "Epoch 12/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4950\n",
      "Epoch 12: val_loss did not improve from 1.39774\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 1.4950 - val_loss: 1.3979\n",
      "Epoch 13/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5101\n",
      "Epoch 13: val_loss did not improve from 1.39774\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 1.5101 - val_loss: 1.3992\n",
      "Epoch 14/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4959\n",
      "Epoch 14: val_loss improved from 1.39774 to 1.38957, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 625us/sample - loss: 1.4959 - val_loss: 1.3896\n",
      "Epoch 15/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4918\n",
      "Epoch 15: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 22s 682us/sample - loss: 1.4918 - val_loss: 1.3904\n",
      "Epoch 16/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5289\n",
      "Epoch 16: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 20s 606us/sample - loss: 1.5289 - val_loss: 1.4101\n",
      "Epoch 17/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4999\n",
      "Epoch 17: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 19s 600us/sample - loss: 1.4999 - val_loss: 1.4202\n",
      "Epoch 18/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5012\n",
      "Epoch 18: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 19s 604us/sample - loss: 1.5012 - val_loss: 1.4124\n",
      "Epoch 19/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5625\n",
      "Epoch 19: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 20s 606us/sample - loss: 1.5625 - val_loss: 1.4415\n",
      "Epoch 20/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5406\n",
      "Epoch 20: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 20s 607us/sample - loss: 1.5406 - val_loss: 1.4232\n",
      "Epoch 21/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5383\n",
      "Epoch 21: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 19s 604us/sample - loss: 1.5383 - val_loss: 1.4177\n",
      "Epoch 22/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.6076\n",
      "Epoch 22: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 20s 625us/sample - loss: 1.6076 - val_loss: 1.4156\n",
      "Epoch 23/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.5382\n",
      "Epoch 23: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 1.5382 - val_loss: 1.3968\n",
      "Epoch 24/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4975\n",
      "Epoch 24: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 23s 699us/sample - loss: 1.4975 - val_loss: 1.3979\n",
      "Epoch 25/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4912\n",
      "Epoch 25: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 20s 627us/sample - loss: 1.4912 - val_loss: 1.3926\n",
      "Epoch 26/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4791\n",
      "Epoch 26: val_loss did not improve from 1.38957\n",
      "32238/32238 [==============================] - 21s 646us/sample - loss: 1.4791 - val_loss: 1.3924\n",
      "Epoch 27/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4792\n",
      "Epoch 27: val_loss improved from 1.38957 to 1.38571, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 22s 694us/sample - loss: 1.4792 - val_loss: 1.3857\n",
      "Epoch 28/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4756\n",
      "Epoch 28: val_loss improved from 1.38571 to 1.38569, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 613us/sample - loss: 1.4756 - val_loss: 1.3857\n",
      "Epoch 29/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4737\n",
      "Epoch 29: val_loss did not improve from 1.38569\n",
      "32238/32238 [==============================] - 20s 611us/sample - loss: 1.4737 - val_loss: 1.3867\n",
      "Epoch 30/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4715\n",
      "Epoch 30: val_loss did not improve from 1.38569\n",
      "32238/32238 [==============================] - 20s 620us/sample - loss: 1.4715 - val_loss: 1.3937\n",
      "Epoch 31/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4692\n",
      "Epoch 31: val_loss improved from 1.38569 to 1.38200, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 626us/sample - loss: 1.4692 - val_loss: 1.3820\n",
      "Epoch 32/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4710\n",
      "Epoch 32: val_loss did not improve from 1.38200\n",
      "32238/32238 [==============================] - 20s 624us/sample - loss: 1.4710 - val_loss: 1.3858\n",
      "Epoch 33/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4680\n",
      "Epoch 33: val_loss did not improve from 1.38200\n",
      "32238/32238 [==============================] - 20s 617us/sample - loss: 1.4680 - val_loss: 1.3937\n",
      "Epoch 34/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4647\n",
      "Epoch 34: val_loss did not improve from 1.38200\n",
      "32238/32238 [==============================] - 20s 634us/sample - loss: 1.4647 - val_loss: 1.3824\n",
      "Epoch 35/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4622\n",
      "Epoch 35: val_loss improved from 1.38200 to 1.37335, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 631us/sample - loss: 1.4622 - val_loss: 1.3734\n",
      "Epoch 36/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4610\n",
      "Epoch 36: val_loss did not improve from 1.37335\n",
      "32238/32238 [==============================] - 23s 698us/sample - loss: 1.4610 - val_loss: 1.3798\n",
      "Epoch 37/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4584\n",
      "Epoch 37: val_loss did not improve from 1.37335\n",
      "32238/32238 [==============================] - 22s 698us/sample - loss: 1.4584 - val_loss: 1.3911\n",
      "Epoch 38/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4571\n",
      "Epoch 38: val_loss did not improve from 1.37335\n",
      "32238/32238 [==============================] - 22s 697us/sample - loss: 1.4571 - val_loss: 1.3734\n",
      "Epoch 39/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4537\n",
      "Epoch 39: val_loss improved from 1.37335 to 1.37234, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 706us/sample - loss: 1.4537 - val_loss: 1.3723\n",
      "Epoch 40/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4526\n",
      "Epoch 40: val_loss improved from 1.37234 to 1.36766, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 1.4526 - val_loss: 1.3677\n",
      "Epoch 41/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4515\n",
      "Epoch 41: val_loss improved from 1.36766 to 1.36520, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 1.4515 - val_loss: 1.3652\n",
      "Epoch 42/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4504\n",
      "Epoch 42: val_loss improved from 1.36520 to 1.36412, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 1.4504 - val_loss: 1.3641\n",
      "Epoch 43/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4476\n",
      "Epoch 43: val_loss improved from 1.36412 to 1.36299, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 716us/sample - loss: 1.4476 - val_loss: 1.3630\n",
      "Epoch 44/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4463\n",
      "Epoch 44: val_loss improved from 1.36299 to 1.35810, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 714us/sample - loss: 1.4463 - val_loss: 1.3581\n",
      "Epoch 45/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4436\n",
      "Epoch 45: val_loss did not improve from 1.35810\n",
      "32238/32238 [==============================] - 21s 662us/sample - loss: 1.4436 - val_loss: 1.3620\n",
      "Epoch 46/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4449\n",
      "Epoch 46: val_loss improved from 1.35810 to 1.35448, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 618us/sample - loss: 1.4449 - val_loss: 1.3545\n",
      "Epoch 47/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 47: val_loss did not improve from 1.35448\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 1.4420 - val_loss: 1.3570\n",
      "Epoch 48/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4407\n",
      "Epoch 48: val_loss did not improve from 1.35448\n",
      "32238/32238 [==============================] - 21s 658us/sample - loss: 1.4407 - val_loss: 1.3625\n",
      "Epoch 49/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4398\n",
      "Epoch 49: val_loss did not improve from 1.35448\n",
      "32238/32238 [==============================] - 20s 610us/sample - loss: 1.4398 - val_loss: 1.3608\n",
      "Epoch 50/50\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4406\n",
      "Epoch 50: val_loss did not improve from 1.35448\n",
      "32238/32238 [==============================] - 20s 624us/sample - loss: 1.4406 - val_loss: 1.3590\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:34:06.366533: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_300_1/lstm_cell_929/bias/Assign' id:475645 op device:{requested: '', assigned: ''} def:{{{node lstm_300_1/lstm_cell_929/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_300_1/lstm_cell_929/bias, lstm_300_1/lstm_cell_929/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:34:31.290805: W tensorflow/c/c_api.cc:304] Operation '{name:'iter_16/Assign' id:481521 op device:{requested: '', assigned: ''} def:{{{node iter_16/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_INT64, validate_shape=false](iter_16, iter_16/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:34:56.005354: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_44_1/cond/Merge' id:480927 op device:{requested: '', assigned: ''} def:{{{node dropout_44_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_44_1/cond/Identity, dropout_44_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1179)\n",
      "(1644, 1179)\n",
      "(1716, 1179)\n",
      "(1848, 1179)\n",
      "(1723, 1179)\n",
      "(1381, 1179)\n",
      "(1790, 1179)\n",
      "(1606, 1179)\n",
      "(1740, 1179)\n",
      "(1526, 1179)\n",
      "(1908, 1179)\n",
      "(1715, 1179)\n",
      "(1764, 1179)\n",
      "(1872, 1179)\n",
      "(1728, 1179)\n",
      "(1812, 1179)\n",
      "(970, 1179)\n",
      "(1668, 1179)\n",
      "(1884, 1179)\n",
      "{1: 8.335462592170817, 4: 8.727897889296854, 5: 5.1637658250219864, 6: 4.445643607113267, 8: 9.06263959690252, 9: 9.653536697245853, 10: 7.108152681290652, 11: 6.925388144529175, 12: 10.0, 13: 8.980832024806993, 17: 9.939774124182819, 19: 7.836458580344191, 21: 9.914187670753092, 22: 1.0, 25: 9.089447655781964, 26: 9.049349184041082, 27: 7.419971108061586, 28: 6.926317073673231, 29: 1.716740640316777}\n",
      "Train on 32238 samples, validate on 3584 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:40:44.155502: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 11.6263\n",
      "Epoch 1: val_loss improved from inf to 1.38226, saving model to ./checkpoints/unknown_person_few_shot_p2_38.h5\n",
      "32238/32238 [==============================] - 66s 2ms/sample - loss: 11.6263 - val_loss: 1.3823\n",
      "Epoch 2/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.4539\n",
      "Epoch 2: val_loss improved from 1.38226 to 1.38224, saving model to ./checkpoints/unknown_person_few_shot_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 717us/sample - loss: 11.4539 - val_loss: 1.3822\n",
      "Epoch 3/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.4349\n",
      "Epoch 3: val_loss did not improve from 1.38224\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 11.4349 - val_loss: 1.3824\n",
      "Epoch 4/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.3504\n",
      "Epoch 4: val_loss did not improve from 1.38224\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 11.3504 - val_loss: 1.3912\n",
      "Epoch 5/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.3450\n",
      "Epoch 5: val_loss improved from 1.38224 to 1.36028, saving model to ./checkpoints/unknown_person_few_shot_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 707us/sample - loss: 11.3450 - val_loss: 1.3603\n",
      "Epoch 6/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.3062\n",
      "Epoch 6: val_loss did not improve from 1.36028\n",
      "32238/32238 [==============================] - 20s 634us/sample - loss: 11.3062 - val_loss: 1.3840\n",
      "Epoch 7/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.2607\n",
      "Epoch 7: val_loss did not improve from 1.36028\n",
      "32238/32238 [==============================] - 21s 647us/sample - loss: 11.2607 - val_loss: 1.3609\n",
      "Epoch 8/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.2314\n",
      "Epoch 8: val_loss did not improve from 1.36028\n",
      "32238/32238 [==============================] - 23s 705us/sample - loss: 11.2314 - val_loss: 1.3627\n",
      "Epoch 9/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.2050\n",
      "Epoch 9: val_loss did not improve from 1.36028\n",
      "32238/32238 [==============================] - 23s 703us/sample - loss: 11.2050 - val_loss: 1.3640\n",
      "Epoch 10/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1685\n",
      "Epoch 10: val_loss did not improve from 1.36028\n",
      "32238/32238 [==============================] - 22s 694us/sample - loss: 11.1685 - val_loss: 1.3747\n",
      "Epoch 11/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1425\n",
      "Epoch 11: val_loss improved from 1.36028 to 1.35814, saving model to ./checkpoints/unknown_person_few_shot_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 607us/sample - loss: 11.1425 - val_loss: 1.3581\n",
      "Epoch 12/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1674\n",
      "Epoch 12: val_loss did not improve from 1.35814\n",
      "32238/32238 [==============================] - 19s 601us/sample - loss: 11.1674 - val_loss: 1.3675\n",
      "Epoch 13/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1451\n",
      "Epoch 13: val_loss did not improve from 1.35814\n",
      "32238/32238 [==============================] - 19s 603us/sample - loss: 11.1451 - val_loss: 1.3596\n",
      "Epoch 14/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1402\n",
      "Epoch 14: val_loss improved from 1.35814 to 1.35185, saving model to ./checkpoints/unknown_person_few_shot_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 614us/sample - loss: 11.1402 - val_loss: 1.3519\n",
      "Epoch 15/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1030\n",
      "Epoch 15: val_loss did not improve from 1.35185\n",
      "32238/32238 [==============================] - 21s 636us/sample - loss: 11.1030 - val_loss: 1.3626\n",
      "Epoch 16/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1121\n",
      "Epoch 16: val_loss did not improve from 1.35185\n",
      "32238/32238 [==============================] - 22s 669us/sample - loss: 11.1121 - val_loss: 1.3623\n",
      "Epoch 17/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.0859\n",
      "Epoch 17: val_loss did not improve from 1.35185\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 11.0859 - val_loss: 1.3748\n",
      "Epoch 18/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.0974\n",
      "Epoch 18: val_loss did not improve from 1.35185\n",
      "32238/32238 [==============================] - 21s 660us/sample - loss: 11.0974 - val_loss: 1.3668\n",
      "Epoch 19/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.1146\n",
      "Epoch 19: val_loss did not improve from 1.35185\n",
      "32238/32238 [==============================] - 20s 632us/sample - loss: 11.1146 - val_loss: 1.3616\n",
      "Epoch 20/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 11.0661\n",
      "Epoch 20: val_loss did not improve from 1.35185\n",
      "32238/32238 [==============================] - 23s 704us/sample - loss: 11.0661 - val_loss: 1.3631\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:48:48.118509: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_328_2/lstm_cell_994/recurrent_kernel/Assign' id:499516 op device:{requested: '', assigned: ''} def:{{{node lstm_328_2/lstm_cell_994/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_328_2/lstm_cell_994/recurrent_kernel, lstm_328_2/lstm_cell_994/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 12:49:14.418389: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_309_2/lstm_cell_975/kernel/v/Assign' id:501824 op device:{requested: '', assigned: ''} def:{{{node lstm_309_2/lstm_cell_975/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_309_2/lstm_cell_975/kernel/v, lstm_309_2/lstm_cell_975/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32238 samples, validate on 3584 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:49:43.366514: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:51:55.143215: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 12:52:20.156423: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36476, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 70s 2ms/sample - loss: 1.4407 - val_loss: 1.3648\n",
      "Epoch 2/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4390\n",
      "Epoch 2: val_loss improved from 1.36476 to 1.35573, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 22s 692us/sample - loss: 1.4390 - val_loss: 1.3557\n",
      "Epoch 3/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4390\n",
      "Epoch 3: val_loss did not improve from 1.35573\n",
      "32238/32238 [==============================] - 20s 634us/sample - loss: 1.4390 - val_loss: 1.3654\n",
      "Epoch 4/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4332\n",
      "Epoch 4: val_loss improved from 1.35573 to 1.35524, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 21s 642us/sample - loss: 1.4332 - val_loss: 1.3552\n",
      "Epoch 5/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4328\n",
      "Epoch 5: val_loss improved from 1.35524 to 1.35296, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 22s 686us/sample - loss: 1.4328 - val_loss: 1.3530\n",
      "Epoch 6/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4318\n",
      "Epoch 6: val_loss did not improve from 1.35296\n",
      "32238/32238 [==============================] - 22s 671us/sample - loss: 1.4318 - val_loss: 1.3588\n",
      "Epoch 7/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4288\n",
      "Epoch 7: val_loss improved from 1.35296 to 1.35282, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 620us/sample - loss: 1.4288 - val_loss: 1.3528\n",
      "Epoch 8/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4267\n",
      "Epoch 8: val_loss did not improve from 1.35282\n",
      "32238/32238 [==============================] - 22s 683us/sample - loss: 1.4267 - val_loss: 1.3570\n",
      "Epoch 9/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 9: val_loss improved from 1.35282 to 1.34724, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 20s 609us/sample - loss: 1.4243 - val_loss: 1.3472\n",
      "Epoch 10/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 10: val_loss improved from 1.34724 to 1.34386, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 22s 671us/sample - loss: 1.4243 - val_loss: 1.3439\n",
      "Epoch 11/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4216\n",
      "Epoch 11: val_loss improved from 1.34386 to 1.34151, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 703us/sample - loss: 1.4216 - val_loss: 1.3415\n",
      "Epoch 12/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4208\n",
      "Epoch 12: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 23s 702us/sample - loss: 1.4208 - val_loss: 1.3417\n",
      "Epoch 13/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 13: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 22s 697us/sample - loss: 1.4163 - val_loss: 1.3541\n",
      "Epoch 14/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4194\n",
      "Epoch 14: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 1.4194 - val_loss: 1.3527\n",
      "Epoch 15/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4147\n",
      "Epoch 15: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 23s 700us/sample - loss: 1.4147 - val_loss: 1.3469\n",
      "Epoch 16/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4137\n",
      "Epoch 16: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 22s 681us/sample - loss: 1.4137 - val_loss: 1.3475\n",
      "Epoch 17/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 17: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 23s 701us/sample - loss: 1.4145 - val_loss: 1.3452\n",
      "Epoch 18/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4095\n",
      "Epoch 18: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 22s 683us/sample - loss: 1.4095 - val_loss: 1.3470\n",
      "Epoch 19/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4089\n",
      "Epoch 19: val_loss did not improve from 1.34151\n",
      "32238/32238 [==============================] - 22s 697us/sample - loss: 1.4089 - val_loss: 1.3444\n",
      "Epoch 20/20\n",
      "32238/32238 [==============================] - ETA: 0s - loss: 1.4074\n",
      "Epoch 20: val_loss improved from 1.34151 to 1.33894, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_38.h5\n",
      "32238/32238 [==============================] - 23s 712us/sample - loss: 1.4074 - val_loss: 1.3389\n",
      "35988\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:00:19.867280: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_336/lstm_cell_1002/bias/Assign' id:513920 op device:{requested: '', assigned: ''} def:{{{node lstm_336/lstm_cell_1002/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_336/lstm_cell_1002/bias, lstm_336/lstm_cell_1002/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:00:34.081354: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_1' id:517014 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:00:45.573563: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_2' id:517015 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32380, 95)\n",
      "Train on 32380 samples, validate on 3608 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:01:13.010826: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_362/lstm_cell_1028/bias/Assign' id:518439 op device:{requested: '', assigned: ''} def:{{{node lstm_362/lstm_cell_1028/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_362/lstm_cell_1028/bias, lstm_362/lstm_cell_1028/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:03:28.874484: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 4.0568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 13:03:53.766180: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_55/mul' id:519855 op device:{requested: '', assigned: ''} def:{{{node loss_55/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_55/mul/x, loss_55/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.35142, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 150s 5ms/sample - loss: 4.0568 - val_loss: 2.3514\n",
      "Epoch 2/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.9114\n",
      "Epoch 2: val_loss improved from 2.35142 to 1.69548, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 23s 708us/sample - loss: 1.9114 - val_loss: 1.6955\n",
      "Epoch 3/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5945\n",
      "Epoch 3: val_loss improved from 1.69548 to 1.60837, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.5945 - val_loss: 1.6084\n",
      "Epoch 4/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5398\n",
      "Epoch 4: val_loss improved from 1.60837 to 1.58229, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.5398 - val_loss: 1.5823\n",
      "Epoch 5/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5146\n",
      "Epoch 5: val_loss improved from 1.58229 to 1.56018, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 22s 688us/sample - loss: 1.5146 - val_loss: 1.5602\n",
      "Epoch 6/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5016\n",
      "Epoch 6: val_loss improved from 1.56018 to 1.54895, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 22s 694us/sample - loss: 1.5016 - val_loss: 1.5490\n",
      "Epoch 7/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4848\n",
      "Epoch 7: val_loss improved from 1.54895 to 1.53022, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 23s 702us/sample - loss: 1.4848 - val_loss: 1.5302\n",
      "Epoch 8/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4830\n",
      "Epoch 8: val_loss improved from 1.53022 to 1.51480, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 22s 686us/sample - loss: 1.4830 - val_loss: 1.5148\n",
      "Epoch 9/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4741\n",
      "Epoch 9: val_loss improved from 1.51480 to 1.50604, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 612us/sample - loss: 1.4741 - val_loss: 1.5060\n",
      "Epoch 10/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4710\n",
      "Epoch 10: val_loss did not improve from 1.50604\n",
      "32380/32380 [==============================] - 22s 675us/sample - loss: 1.4710 - val_loss: 1.5089\n",
      "Epoch 11/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4822\n",
      "Epoch 11: val_loss did not improve from 1.50604\n",
      "32380/32380 [==============================] - 22s 694us/sample - loss: 1.4822 - val_loss: 1.5129\n",
      "Epoch 12/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4663\n",
      "Epoch 12: val_loss improved from 1.50604 to 1.50487, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 23s 700us/sample - loss: 1.4663 - val_loss: 1.5049\n",
      "Epoch 13/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5176\n",
      "Epoch 13: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 23s 698us/sample - loss: 1.5176 - val_loss: 1.5361\n",
      "Epoch 14/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.6256\n",
      "Epoch 14: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 23s 695us/sample - loss: 1.6256 - val_loss: 1.5396\n",
      "Epoch 15/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4761\n",
      "Epoch 15: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 20s 614us/sample - loss: 1.4761 - val_loss: 1.5117\n",
      "Epoch 16/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.6037\n",
      "Epoch 16: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 19s 597us/sample - loss: 1.6037 - val_loss: 1.5596\n",
      "Epoch 17/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4979\n",
      "Epoch 17: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 21s 647us/sample - loss: 1.4979 - val_loss: 1.5229\n",
      "Epoch 18/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4715\n",
      "Epoch 18: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 22s 692us/sample - loss: 1.4715 - val_loss: 1.5144\n",
      "Epoch 19/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4721\n",
      "Epoch 19: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 22s 694us/sample - loss: 1.4721 - val_loss: 1.5200\n",
      "Epoch 20/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4738\n",
      "Epoch 20: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 22s 693us/sample - loss: 1.4738 - val_loss: 1.5184\n",
      "Epoch 21/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4707\n",
      "Epoch 21: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 22s 692us/sample - loss: 1.4707 - val_loss: 1.5135\n",
      "Epoch 22/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4709\n",
      "Epoch 22: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 20s 627us/sample - loss: 1.4709 - val_loss: 1.5225\n",
      "Epoch 23/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4657\n",
      "Epoch 23: val_loss did not improve from 1.50487\n",
      "32380/32380 [==============================] - 19s 590us/sample - loss: 1.4657 - val_loss: 1.5205\n",
      "Epoch 24/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4529\n",
      "Epoch 24: val_loss improved from 1.50487 to 1.49641, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 599us/sample - loss: 1.4529 - val_loss: 1.4964\n",
      "Epoch 25/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4468\n",
      "Epoch 25: val_loss did not improve from 1.49641\n",
      "32380/32380 [==============================] - 19s 585us/sample - loss: 1.4468 - val_loss: 1.5030\n",
      "Epoch 26/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4423\n",
      "Epoch 26: val_loss did not improve from 1.49641\n",
      "32380/32380 [==============================] - 19s 585us/sample - loss: 1.4423 - val_loss: 1.4978\n",
      "Epoch 27/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 27: val_loss improved from 1.49641 to 1.49466, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 596us/sample - loss: 1.4404 - val_loss: 1.4947\n",
      "Epoch 28/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 28: val_loss improved from 1.49466 to 1.49218, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 594us/sample - loss: 1.4354 - val_loss: 1.4922\n",
      "Epoch 29/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4348\n",
      "Epoch 29: val_loss improved from 1.49218 to 1.48983, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 601us/sample - loss: 1.4348 - val_loss: 1.4898\n",
      "Epoch 30/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4310\n",
      "Epoch 30: val_loss improved from 1.48983 to 1.48472, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 599us/sample - loss: 1.4310 - val_loss: 1.4847\n",
      "Epoch 31/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4315\n",
      "Epoch 31: val_loss did not improve from 1.48472\n",
      "32380/32380 [==============================] - 20s 606us/sample - loss: 1.4315 - val_loss: 1.4959\n",
      "Epoch 32/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4285\n",
      "Epoch 32: val_loss did not improve from 1.48472\n",
      "32380/32380 [==============================] - 19s 596us/sample - loss: 1.4285 - val_loss: 1.4975\n",
      "Epoch 33/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4248\n",
      "Epoch 33: val_loss did not improve from 1.48472\n",
      "32380/32380 [==============================] - 19s 593us/sample - loss: 1.4248 - val_loss: 1.4907\n",
      "Epoch 34/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 34: val_loss improved from 1.48472 to 1.48361, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 21s 656us/sample - loss: 1.4246 - val_loss: 1.4836\n",
      "Epoch 35/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 35: val_loss improved from 1.48361 to 1.48209, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 601us/sample - loss: 1.4202 - val_loss: 1.4821\n",
      "Epoch 36/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4192\n",
      "Epoch 36: val_loss did not improve from 1.48209\n",
      "32380/32380 [==============================] - 19s 595us/sample - loss: 1.4192 - val_loss: 1.4836\n",
      "Epoch 37/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4157\n",
      "Epoch 37: val_loss improved from 1.48209 to 1.48195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 603us/sample - loss: 1.4157 - val_loss: 1.4820\n",
      "Epoch 38/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 38: val_loss improved from 1.48195 to 1.47734, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 603us/sample - loss: 1.4158 - val_loss: 1.4773\n",
      "Epoch 39/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4120\n",
      "Epoch 39: val_loss did not improve from 1.47734\n",
      "32380/32380 [==============================] - 19s 596us/sample - loss: 1.4120 - val_loss: 1.4779\n",
      "Epoch 40/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4118\n",
      "Epoch 40: val_loss improved from 1.47734 to 1.47597, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 602us/sample - loss: 1.4118 - val_loss: 1.4760\n",
      "Epoch 41/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 41: val_loss did not improve from 1.47597\n",
      "32380/32380 [==============================] - 19s 596us/sample - loss: 1.4088 - val_loss: 1.4761\n",
      "Epoch 42/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 42: val_loss did not improve from 1.47597\n",
      "32380/32380 [==============================] - 19s 600us/sample - loss: 1.4100 - val_loss: 1.4788\n",
      "Epoch 43/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4113\n",
      "Epoch 43: val_loss improved from 1.47597 to 1.47041, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 19s 599us/sample - loss: 1.4113 - val_loss: 1.4704\n",
      "Epoch 44/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 44: val_loss did not improve from 1.47041\n",
      "32380/32380 [==============================] - 19s 593us/sample - loss: 1.4067 - val_loss: 1.4866\n",
      "Epoch 45/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 45: val_loss improved from 1.47041 to 1.46902, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_39.h5\n",
      "32380/32380 [==============================] - 21s 637us/sample - loss: 1.4088 - val_loss: 1.4690\n",
      "Epoch 46/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4039\n",
      "Epoch 46: val_loss did not improve from 1.46902\n",
      "32380/32380 [==============================] - 22s 694us/sample - loss: 1.4039 - val_loss: 1.4767\n",
      "Epoch 47/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3993\n",
      "Epoch 47: val_loss did not improve from 1.46902\n",
      "32380/32380 [==============================] - 22s 676us/sample - loss: 1.3993 - val_loss: 1.4693\n",
      "Epoch 48/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4017\n",
      "Epoch 48: val_loss did not improve from 1.46902\n",
      "32380/32380 [==============================] - 21s 662us/sample - loss: 1.4017 - val_loss: 1.4846\n",
      "Epoch 49/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3982\n",
      "Epoch 49: val_loss did not improve from 1.46902\n",
      "32380/32380 [==============================] - 21s 642us/sample - loss: 1.3982 - val_loss: 1.4791\n",
      "Epoch 50/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 50: val_loss did not improve from 1.46902\n",
      "32380/32380 [==============================] - 23s 697us/sample - loss: 1.3972 - val_loss: 1.4722\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:23:07.721553: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_348_1/lstm_cell_1051/bias/Assign' id:534447 op device:{requested: '', assigned: ''} def:{{{node lstm_348_1/lstm_cell_1051/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_348_1/lstm_cell_1051/bias, lstm_348_1/lstm_cell_1051/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:23:35.406075: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_340_1/lstm_cell_1043/bias/m/Assign' id:538745 op device:{requested: '', assigned: ''} def:{{{node lstm_340_1/lstm_cell_1043/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_340_1/lstm_cell_1043/bias/m, lstm_340_1/lstm_cell_1043/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 13:24:02.715240: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_49_1/cond/Merge' id:537969 op device:{requested: '', assigned: ''} def:{{{node dropout_49_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_49_1/cond/Identity, dropout_49_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1013)\n",
      "(1632, 1013)\n",
      "(1716, 1013)\n",
      "(1848, 1013)\n",
      "(1735, 1013)\n",
      "(1393, 1013)\n",
      "(1790, 1013)\n",
      "(1595, 1013)\n",
      "(1740, 1013)\n",
      "(1526, 1013)\n",
      "(1896, 1013)\n",
      "(1739, 1013)\n",
      "(1752, 1013)\n",
      "(1872, 1013)\n",
      "(1740, 1013)\n",
      "(1788, 1013)\n",
      "(982, 1013)\n",
      "(1668, 1013)\n",
      "(1872, 1013)\n",
      "{1: 8.318321119130626, 4: 8.234162555282918, 5: 4.584070567341676, 6: 3.4194902860179255, 8: 9.10575330711212, 9: 9.58769368092621, 10: 6.774952403290915, 11: 6.588214262707944, 12: 10.0, 13: 7.887033445144889, 17: 9.317771564768973, 19: 6.8837808107205944, 21: 9.625051665199031, 22: 1.0, 25: 7.886363993617402, 26: 7.808088096368965, 27: 6.1442495439130305, 28: 5.668768822545106, 29: 1.0315899751174853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907579/3261308647.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32380 samples, validate on 3608 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:30:19.678333: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7486\n",
      "Epoch 1: val_loss improved from inf to 1.50496, saving model to ./checkpoints/unknown_person_few_shot_p2_39.h5\n",
      "32380/32380 [==============================] - 74s 2ms/sample - loss: 10.7486 - val_loss: 1.5050\n",
      "Epoch 2/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6757\n",
      "Epoch 2: val_loss improved from 1.50496 to 1.47662, saving model to ./checkpoints/unknown_person_few_shot_p2_39.h5\n",
      "32380/32380 [==============================] - 22s 665us/sample - loss: 10.6757 - val_loss: 1.4766\n",
      "Epoch 3/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5996\n",
      "Epoch 3: val_loss did not improve from 1.47662\n",
      "32380/32380 [==============================] - 21s 649us/sample - loss: 10.5996 - val_loss: 1.4811\n",
      "Epoch 4/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5417\n",
      "Epoch 4: val_loss did not improve from 1.47662\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 10.5417 - val_loss: 1.4770\n",
      "Epoch 5/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5105\n",
      "Epoch 5: val_loss improved from 1.47662 to 1.47349, saving model to ./checkpoints/unknown_person_few_shot_p2_39.h5\n",
      "32380/32380 [==============================] - 22s 690us/sample - loss: 10.5105 - val_loss: 1.4735\n",
      "Epoch 6/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4794\n",
      "Epoch 6: val_loss improved from 1.47349 to 1.45633, saving model to ./checkpoints/unknown_person_few_shot_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 622us/sample - loss: 10.4794 - val_loss: 1.4563\n",
      "Epoch 7/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4595\n",
      "Epoch 7: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 21s 642us/sample - loss: 10.4595 - val_loss: 1.4566\n",
      "Epoch 8/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4737\n",
      "Epoch 8: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 20s 623us/sample - loss: 10.4737 - val_loss: 1.4860\n",
      "Epoch 9/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4455\n",
      "Epoch 9: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 20s 613us/sample - loss: 10.4455 - val_loss: 1.4670\n",
      "Epoch 10/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4343\n",
      "Epoch 10: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 20s 617us/sample - loss: 10.4343 - val_loss: 1.4731\n",
      "Epoch 11/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4295\n",
      "Epoch 11: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 20s 618us/sample - loss: 10.4295 - val_loss: 1.4845\n",
      "Epoch 12/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3967\n",
      "Epoch 12: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 20s 625us/sample - loss: 10.3967 - val_loss: 1.4613\n",
      "Epoch 13/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3491\n",
      "Epoch 13: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 20s 623us/sample - loss: 10.3491 - val_loss: 1.4638\n",
      "Epoch 14/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3839\n",
      "Epoch 14: val_loss did not improve from 1.45633\n",
      "32380/32380 [==============================] - 21s 642us/sample - loss: 10.3839 - val_loss: 1.4642\n",
      "Epoch 15/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3295\n",
      "Epoch 15: val_loss improved from 1.45633 to 1.44939, saving model to ./checkpoints/unknown_person_few_shot_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 604us/sample - loss: 10.3295 - val_loss: 1.4494\n",
      "Epoch 16/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3453\n",
      "Epoch 16: val_loss did not improve from 1.44939\n",
      "32380/32380 [==============================] - 19s 595us/sample - loss: 10.3453 - val_loss: 1.4503\n",
      "Epoch 17/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3607\n",
      "Epoch 17: val_loss did not improve from 1.44939\n",
      "32380/32380 [==============================] - 19s 598us/sample - loss: 10.3607 - val_loss: 1.4770\n",
      "Epoch 18/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3470\n",
      "Epoch 18: val_loss did not improve from 1.44939\n",
      "32380/32380 [==============================] - 20s 604us/sample - loss: 10.3470 - val_loss: 1.4550\n",
      "Epoch 19/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3366\n",
      "Epoch 19: val_loss did not improve from 1.44939\n",
      "32380/32380 [==============================] - 19s 600us/sample - loss: 10.3366 - val_loss: 1.4634\n",
      "Epoch 20/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3225\n",
      "Epoch 20: val_loss did not improve from 1.44939\n",
      "32380/32380 [==============================] - 20s 617us/sample - loss: 10.3225 - val_loss: 1.4605\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:38:12.071317: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_364_2/lstm_cell_1104/bias/Assign' id:556407 op device:{requested: '', assigned: ''} def:{{{node lstm_364_2/lstm_cell_1104/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_364_2/lstm_cell_1104/bias, lstm_364_2/lstm_cell_1104/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:38:41.020148: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_345_2/lstm_cell_1085/bias/v/Assign' id:558861 op device:{requested: '', assigned: ''} def:{{{node lstm_345_2/lstm_cell_1085/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_345_2/lstm_cell_1085/bias/v, lstm_345_2/lstm_cell_1085/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32380 samples, validate on 3608 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:39:12.557332: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:41:41.166065: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:42:06.022757: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.47213, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 77s 2ms/sample - loss: 1.4041 - val_loss: 1.4721\n",
      "Epoch 2/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 2: val_loss did not improve from 1.47213\n",
      "32380/32380 [==============================] - 22s 679us/sample - loss: 1.4010 - val_loss: 1.4858\n",
      "Epoch 3/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3999\n",
      "Epoch 3: val_loss improved from 1.47213 to 1.46209, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 628us/sample - loss: 1.3999 - val_loss: 1.4621\n",
      "Epoch 4/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 4: val_loss did not improve from 1.46209\n",
      "32380/32380 [==============================] - 21s 649us/sample - loss: 1.3977 - val_loss: 1.4695\n",
      "Epoch 5/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3967\n",
      "Epoch 5: val_loss did not improve from 1.46209\n",
      "32380/32380 [==============================] - 20s 606us/sample - loss: 1.3967 - val_loss: 1.4643\n",
      "Epoch 6/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 6: val_loss did not improve from 1.46209\n",
      "32380/32380 [==============================] - 20s 611us/sample - loss: 1.3948 - val_loss: 1.4681\n",
      "Epoch 7/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3924\n",
      "Epoch 7: val_loss improved from 1.46209 to 1.45715, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 612us/sample - loss: 1.3924 - val_loss: 1.4572\n",
      "Epoch 8/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 8: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 21s 643us/sample - loss: 1.3918 - val_loss: 1.4623\n",
      "Epoch 9/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3906\n",
      "Epoch 9: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 19s 601us/sample - loss: 1.3906 - val_loss: 1.4736\n",
      "Epoch 10/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3893\n",
      "Epoch 10: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 19s 602us/sample - loss: 1.3893 - val_loss: 1.4611\n",
      "Epoch 11/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3875\n",
      "Epoch 11: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 19s 602us/sample - loss: 1.3875 - val_loss: 1.4598\n",
      "Epoch 12/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3877\n",
      "Epoch 12: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 20s 615us/sample - loss: 1.3877 - val_loss: 1.4593\n",
      "Epoch 13/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3837\n",
      "Epoch 13: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 23s 699us/sample - loss: 1.3837 - val_loss: 1.4647\n",
      "Epoch 14/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3852\n",
      "Epoch 14: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 23s 696us/sample - loss: 1.3852 - val_loss: 1.4685\n",
      "Epoch 15/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 15: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 22s 668us/sample - loss: 1.3812 - val_loss: 1.4606\n",
      "Epoch 16/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 16: val_loss did not improve from 1.45715\n",
      "32380/32380 [==============================] - 21s 641us/sample - loss: 1.3812 - val_loss: 1.4578\n",
      "Epoch 17/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3809\n",
      "Epoch 17: val_loss improved from 1.45715 to 1.45529, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 21s 645us/sample - loss: 1.3809 - val_loss: 1.4553\n",
      "Epoch 18/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3786\n",
      "Epoch 18: val_loss improved from 1.45529 to 1.45401, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 20s 609us/sample - loss: 1.3786 - val_loss: 1.4540\n",
      "Epoch 19/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3767\n",
      "Epoch 19: val_loss improved from 1.45401 to 1.45096, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 21s 662us/sample - loss: 1.3767 - val_loss: 1.4510\n",
      "Epoch 20/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3765\n",
      "Epoch 20: val_loss improved from 1.45096 to 1.44777, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_39.h5\n",
      "32380/32380 [==============================] - 22s 679us/sample - loss: 1.3765 - val_loss: 1.4478\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:49:41.744623: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_391/lstm_cell_1131/bias/Assign' id:573932 op device:{requested: '', assigned: ''} def:{{{node lstm_391/lstm_cell_1131/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_391/lstm_cell_1131/bias, lstm_391/lstm_cell_1131/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:49:57.638943: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_1' id:574056 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 13:50:10.538336: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_2' id:574057 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32380, 95)\n",
      "Train on 32380 samples, validate on 3608 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:50:40.617592: W tensorflow/c/c_api.cc:304] Operation '{name:'training_60/Adam/lstm_378/lstm_cell_1118/bias/m/Assign' id:586944 op device:{requested: '', assigned: ''} def:{{{node training_60/Adam/lstm_378/lstm_cell_1118/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_60/Adam/lstm_378/lstm_cell_1118/bias/m, training_60/Adam/lstm_378/lstm_cell_1118/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:53:14.000336: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 3.1933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 13:53:38.194559: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_61/mul' id:576897 op device:{requested: '', assigned: ''} def:{{{node loss_61/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_61/mul/x, loss_61/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.06304, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 163s 5ms/sample - loss: 3.1933 - val_loss: 2.0630\n",
      "Epoch 2/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.8116\n",
      "Epoch 2: val_loss improved from 2.06304 to 1.69910, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 21s 639us/sample - loss: 1.8116 - val_loss: 1.6991\n",
      "Epoch 3/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5836\n",
      "Epoch 3: val_loss improved from 1.69910 to 1.59423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 614us/sample - loss: 1.5836 - val_loss: 1.5942\n",
      "Epoch 4/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5320\n",
      "Epoch 4: val_loss improved from 1.59423 to 1.56308, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 19s 601us/sample - loss: 1.5320 - val_loss: 1.5631\n",
      "Epoch 5/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5110\n",
      "Epoch 5: val_loss improved from 1.56308 to 1.55586, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 21s 644us/sample - loss: 1.5110 - val_loss: 1.5559\n",
      "Epoch 6/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4927\n",
      "Epoch 6: val_loss improved from 1.55586 to 1.52408, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.4927 - val_loss: 1.5241\n",
      "Epoch 7/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4841\n",
      "Epoch 7: val_loss improved from 1.52408 to 1.52357, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 710us/sample - loss: 1.4841 - val_loss: 1.5236\n",
      "Epoch 8/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4870\n",
      "Epoch 8: val_loss improved from 1.52357 to 1.51476, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 713us/sample - loss: 1.4870 - val_loss: 1.5148\n",
      "Epoch 9/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4767\n",
      "Epoch 9: val_loss improved from 1.51476 to 1.50996, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 22s 686us/sample - loss: 1.4767 - val_loss: 1.5100\n",
      "Epoch 10/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4766\n",
      "Epoch 10: val_loss improved from 1.50996 to 1.50806, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 708us/sample - loss: 1.4766 - val_loss: 1.5081\n",
      "Epoch 11/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4735\n",
      "Epoch 11: val_loss did not improve from 1.50806\n",
      "32380/32380 [==============================] - 23s 697us/sample - loss: 1.4735 - val_loss: 1.5183\n",
      "Epoch 12/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4631\n",
      "Epoch 12: val_loss improved from 1.50806 to 1.50370, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.4631 - val_loss: 1.5037\n",
      "Epoch 13/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4611\n",
      "Epoch 13: val_loss improved from 1.50370 to 1.49689, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.4611 - val_loss: 1.4969\n",
      "Epoch 14/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4590\n",
      "Epoch 14: val_loss did not improve from 1.49689\n",
      "32380/32380 [==============================] - 21s 647us/sample - loss: 1.4590 - val_loss: 1.5005\n",
      "Epoch 15/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4579\n",
      "Epoch 15: val_loss did not improve from 1.49689\n",
      "32380/32380 [==============================] - 22s 677us/sample - loss: 1.4579 - val_loss: 1.5061\n",
      "Epoch 16/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4675\n",
      "Epoch 16: val_loss improved from 1.49689 to 1.49001, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 702us/sample - loss: 1.4675 - val_loss: 1.4900\n",
      "Epoch 17/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4554\n",
      "Epoch 17: val_loss improved from 1.49001 to 1.48945, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 722us/sample - loss: 1.4554 - val_loss: 1.4894\n",
      "Epoch 18/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4654\n",
      "Epoch 18: val_loss did not improve from 1.48945\n",
      "32380/32380 [==============================] - 23s 710us/sample - loss: 1.4654 - val_loss: 1.4977\n",
      "Epoch 19/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4646\n",
      "Epoch 19: val_loss improved from 1.48945 to 1.48781, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 721us/sample - loss: 1.4646 - val_loss: 1.4878\n",
      "Epoch 20/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 20: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 23s 708us/sample - loss: 1.4751 - val_loss: 1.4925\n",
      "Epoch 21/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4822\n",
      "Epoch 21: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 23s 708us/sample - loss: 1.4822 - val_loss: 1.5127\n",
      "Epoch 22/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4991\n",
      "Epoch 22: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 22s 671us/sample - loss: 1.4991 - val_loss: 1.5136\n",
      "Epoch 23/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4667\n",
      "Epoch 23: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 20s 606us/sample - loss: 1.4667 - val_loss: 1.5104\n",
      "Epoch 24/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4481\n",
      "Epoch 24: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 22s 681us/sample - loss: 1.4481 - val_loss: 1.5041\n",
      "Epoch 25/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4434\n",
      "Epoch 25: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 23s 704us/sample - loss: 1.4434 - val_loss: 1.5131\n",
      "Epoch 26/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4338\n",
      "Epoch 26: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 23s 705us/sample - loss: 1.4338 - val_loss: 1.4946\n",
      "Epoch 27/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4316\n",
      "Epoch 27: val_loss did not improve from 1.48781\n",
      "32380/32380 [==============================] - 21s 644us/sample - loss: 1.4316 - val_loss: 1.4906\n",
      "Epoch 28/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4272\n",
      "Epoch 28: val_loss improved from 1.48781 to 1.48726, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 21s 659us/sample - loss: 1.4272 - val_loss: 1.4873\n",
      "Epoch 29/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4273\n",
      "Epoch 29: val_loss improved from 1.48726 to 1.48382, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.4273 - val_loss: 1.4838\n",
      "Epoch 30/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 30: val_loss did not improve from 1.48382\n",
      "32380/32380 [==============================] - 22s 690us/sample - loss: 1.4249 - val_loss: 1.4891\n",
      "Epoch 31/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4227\n",
      "Epoch 31: val_loss did not improve from 1.48382\n",
      "32380/32380 [==============================] - 20s 627us/sample - loss: 1.4227 - val_loss: 1.4878\n",
      "Epoch 32/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4214\n",
      "Epoch 32: val_loss improved from 1.48382 to 1.48181, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 613us/sample - loss: 1.4214 - val_loss: 1.4818\n",
      "Epoch 33/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4182\n",
      "Epoch 33: val_loss did not improve from 1.48181\n",
      "32380/32380 [==============================] - 22s 669us/sample - loss: 1.4182 - val_loss: 1.4840\n",
      "Epoch 34/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 34: val_loss improved from 1.48181 to 1.48174, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 614us/sample - loss: 1.4163 - val_loss: 1.4817\n",
      "Epoch 35/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4152\n",
      "Epoch 35: val_loss improved from 1.48174 to 1.47458, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 706us/sample - loss: 1.4152 - val_loss: 1.4746\n",
      "Epoch 36/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 36: val_loss did not improve from 1.47458\n",
      "32380/32380 [==============================] - 23s 701us/sample - loss: 1.4132 - val_loss: 1.4779\n",
      "Epoch 37/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4077\n",
      "Epoch 37: val_loss did not improve from 1.47458\n",
      "32380/32380 [==============================] - 23s 701us/sample - loss: 1.4077 - val_loss: 1.4792\n",
      "Epoch 38/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4081\n",
      "Epoch 38: val_loss improved from 1.47458 to 1.47452, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 22s 677us/sample - loss: 1.4081 - val_loss: 1.4745\n",
      "Epoch 39/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 39: val_loss did not improve from 1.47452\n",
      "32380/32380 [==============================] - 22s 671us/sample - loss: 1.4070 - val_loss: 1.4772\n",
      "Epoch 40/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4090\n",
      "Epoch 40: val_loss improved from 1.47452 to 1.47215, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 709us/sample - loss: 1.4090 - val_loss: 1.4722\n",
      "Epoch 41/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 41: val_loss improved from 1.47215 to 1.47203, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 22s 685us/sample - loss: 1.4055 - val_loss: 1.4720\n",
      "Epoch 42/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 42: val_loss did not improve from 1.47203\n",
      "32380/32380 [==============================] - 22s 668us/sample - loss: 1.4070 - val_loss: 1.4780\n",
      "Epoch 43/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 43: val_loss did not improve from 1.47203\n",
      "32380/32380 [==============================] - 23s 700us/sample - loss: 1.4055 - val_loss: 1.4756\n",
      "Epoch 44/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4013\n",
      "Epoch 44: val_loss improved from 1.47203 to 1.46979, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 716us/sample - loss: 1.4013 - val_loss: 1.4698\n",
      "Epoch 45/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 45: val_loss improved from 1.46979 to 1.46443, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 713us/sample - loss: 1.4015 - val_loss: 1.4644\n",
      "Epoch 46/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4004\n",
      "Epoch 46: val_loss did not improve from 1.46443\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.4004 - val_loss: 1.4820\n",
      "Epoch 47/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 47: val_loss did not improve from 1.46443\n",
      "32380/32380 [==============================] - 22s 673us/sample - loss: 1.3996 - val_loss: 1.4796\n",
      "Epoch 48/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 48: val_loss did not improve from 1.46443\n",
      "32380/32380 [==============================] - 23s 714us/sample - loss: 1.3983 - val_loss: 1.4668\n",
      "Epoch 49/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3976\n",
      "Epoch 49: val_loss did not improve from 1.46443\n",
      "32380/32380 [==============================] - 22s 687us/sample - loss: 1.3976 - val_loss: 1.4771\n",
      "Epoch 50/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 50: val_loss did not improve from 1.46443\n",
      "32380/32380 [==============================] - 23s 710us/sample - loss: 1.3935 - val_loss: 1.4785\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:14:12.681493: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_384_1/lstm_cell_1161/recurrent_kernel/Assign' id:591320 op device:{requested: '', assigned: ''} def:{{{node lstm_384_1/lstm_cell_1161/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_384_1/lstm_cell_1161/recurrent_kernel, lstm_384_1/lstm_cell_1161/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:14:44.521176: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_386_1/lstm_cell_1163/bias/m/Assign' id:595922 op device:{requested: '', assigned: ''} def:{{{node lstm_386_1/lstm_cell_1163/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_386_1/lstm_cell_1163/bias/m, lstm_386_1/lstm_cell_1163/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:15:15.822361: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_54_1/cond/Merge' id:595011 op device:{requested: '', assigned: ''} def:{{{node dropout_54_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_54_1/cond/Identity, dropout_54_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1013)\n",
      "(1632, 1013)\n",
      "(1716, 1013)\n",
      "(1848, 1013)\n",
      "(1735, 1013)\n",
      "(1393, 1013)\n",
      "(1790, 1013)\n",
      "(1595, 1013)\n",
      "(1740, 1013)\n",
      "(1526, 1013)\n",
      "(1896, 1013)\n",
      "(1739, 1013)\n",
      "(1752, 1013)\n",
      "(1872, 1013)\n",
      "(1740, 1013)\n",
      "(1788, 1013)\n",
      "(982, 1013)\n",
      "(1668, 1013)\n",
      "(1872, 1013)\n",
      "{1: 8.408636580520888, 4: 8.24553004037352, 5: 4.774368474169401, 6: 3.850315159915537, 8: 9.431547228135468, 9: 9.789791417008844, 10: 6.587052389097, 11: 6.480880967130423, 12: 10.0, 13: 8.29982366137635, 17: 9.392064475361549, 19: 6.832077581352429, 21: 9.903156566440543, 22: 1.0, 25: 8.203919474575859, 26: 8.540599675502545, 27: 5.63726543309234, 28: 6.039295285520985, 29: 1.6158600161723342}\n",
      "Train on 32380 samples, validate on 3608 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:22:17.592009: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 10.9855\n",
      "Epoch 1: val_loss improved from inf to 1.48111, saving model to ./checkpoints/unknown_person_few_shot_p2_40.h5\n",
      "32380/32380 [==============================] - 79s 2ms/sample - loss: 10.9855 - val_loss: 1.4811\n",
      "Epoch 2/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.9118\n",
      "Epoch 2: val_loss improved from 1.48111 to 1.47737, saving model to ./checkpoints/unknown_person_few_shot_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 627us/sample - loss: 10.9118 - val_loss: 1.4774\n",
      "Epoch 3/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.8566\n",
      "Epoch 3: val_loss improved from 1.47737 to 1.46345, saving model to ./checkpoints/unknown_person_few_shot_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 625us/sample - loss: 10.8566 - val_loss: 1.4634\n",
      "Epoch 4/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7985\n",
      "Epoch 4: val_loss did not improve from 1.46345\n",
      "32380/32380 [==============================] - 20s 611us/sample - loss: 10.7985 - val_loss: 1.4675\n",
      "Epoch 5/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7499\n",
      "Epoch 5: val_loss did not improve from 1.46345\n",
      "32380/32380 [==============================] - 20s 613us/sample - loss: 10.7499 - val_loss: 1.4702\n",
      "Epoch 6/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7452\n",
      "Epoch 6: val_loss did not improve from 1.46345\n",
      "32380/32380 [==============================] - 20s 630us/sample - loss: 10.7452 - val_loss: 1.4653\n",
      "Epoch 7/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7254\n",
      "Epoch 7: val_loss did not improve from 1.46345\n",
      "32380/32380 [==============================] - 23s 714us/sample - loss: 10.7254 - val_loss: 1.4760\n",
      "Epoch 8/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6620\n",
      "Epoch 8: val_loss did not improve from 1.46345\n",
      "32380/32380 [==============================] - 22s 673us/sample - loss: 10.6620 - val_loss: 1.4754\n",
      "Epoch 9/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6747\n",
      "Epoch 9: val_loss improved from 1.46345 to 1.46322, saving model to ./checkpoints/unknown_person_few_shot_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 618us/sample - loss: 10.6747 - val_loss: 1.4632\n",
      "Epoch 10/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6911\n",
      "Epoch 10: val_loss did not improve from 1.46322\n",
      "32380/32380 [==============================] - 20s 611us/sample - loss: 10.6911 - val_loss: 1.4673\n",
      "Epoch 11/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6433\n",
      "Epoch 11: val_loss did not improve from 1.46322\n",
      "32380/32380 [==============================] - 20s 616us/sample - loss: 10.6433 - val_loss: 1.4779\n",
      "Epoch 12/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6486\n",
      "Epoch 12: val_loss improved from 1.46322 to 1.45902, saving model to ./checkpoints/unknown_person_few_shot_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 625us/sample - loss: 10.6486 - val_loss: 1.4590\n",
      "Epoch 13/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6383\n",
      "Epoch 13: val_loss did not improve from 1.45902\n",
      "32380/32380 [==============================] - 20s 621us/sample - loss: 10.6383 - val_loss: 1.4895\n",
      "Epoch 14/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6052\n",
      "Epoch 14: val_loss did not improve from 1.45902\n",
      "32380/32380 [==============================] - 20s 621us/sample - loss: 10.6052 - val_loss: 1.4829\n",
      "Epoch 15/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6299\n",
      "Epoch 15: val_loss did not improve from 1.45902\n",
      "32380/32380 [==============================] - 20s 616us/sample - loss: 10.6299 - val_loss: 1.4853\n",
      "Epoch 16/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5821\n",
      "Epoch 16: val_loss did not improve from 1.45902\n",
      "32380/32380 [==============================] - 23s 697us/sample - loss: 10.5821 - val_loss: 1.4755\n",
      "Epoch 17/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5935\n",
      "Epoch 17: val_loss improved from 1.45902 to 1.45821, saving model to ./checkpoints/unknown_person_few_shot_p2_40.h5\n",
      "32380/32380 [==============================] - 22s 671us/sample - loss: 10.5935 - val_loss: 1.4582\n",
      "Epoch 18/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5579\n",
      "Epoch 18: val_loss did not improve from 1.45821\n",
      "32380/32380 [==============================] - 21s 653us/sample - loss: 10.5579 - val_loss: 1.4684\n",
      "Epoch 19/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5652\n",
      "Epoch 19: val_loss did not improve from 1.45821\n",
      "32380/32380 [==============================] - 21s 641us/sample - loss: 10.5652 - val_loss: 1.4727\n",
      "Epoch 20/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5312\n",
      "Epoch 20: val_loss did not improve from 1.45821\n",
      "32380/32380 [==============================] - 22s 686us/sample - loss: 10.5312 - val_loss: 1.4584\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:30:23.162543: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_381_2/lstm_cell_1195/kernel/Assign' id:610218 op device:{requested: '', assigned: ''} def:{{{node lstm_381_2/lstm_cell_1195/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_381_2/lstm_cell_1195/kernel, lstm_381_2/lstm_cell_1195/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:30:55.374267: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_370_2/lstm_cell_1184/recurrent_kernel/m/Assign' id:615075 op device:{requested: '', assigned: ''} def:{{{node lstm_370_2/lstm_cell_1184/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_370_2/lstm_cell_1184/recurrent_kernel/m, lstm_370_2/lstm_cell_1184/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32380 samples, validate on 3608 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:31:30.163208: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:34:13.434799: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:34:35.856874: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.47904, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 79s 2ms/sample - loss: 1.4007 - val_loss: 1.4790\n",
      "Epoch 2/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3976\n",
      "Epoch 2: val_loss improved from 1.47904 to 1.47588, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 22s 670us/sample - loss: 1.3976 - val_loss: 1.4759\n",
      "Epoch 3/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3976\n",
      "Epoch 3: val_loss improved from 1.47588 to 1.46575, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 21s 643us/sample - loss: 1.3976 - val_loss: 1.4658\n",
      "Epoch 4/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3966\n",
      "Epoch 4: val_loss did not improve from 1.46575\n",
      "32380/32380 [==============================] - 22s 677us/sample - loss: 1.3966 - val_loss: 1.4717\n",
      "Epoch 5/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3920\n",
      "Epoch 5: val_loss improved from 1.46575 to 1.45920, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 696us/sample - loss: 1.3920 - val_loss: 1.4592\n",
      "Epoch 6/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 6: val_loss did not improve from 1.45920\n",
      "32380/32380 [==============================] - 20s 618us/sample - loss: 1.3928 - val_loss: 1.4620\n",
      "Epoch 7/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3906\n",
      "Epoch 7: val_loss did not improve from 1.45920\n",
      "32380/32380 [==============================] - 22s 686us/sample - loss: 1.3906 - val_loss: 1.4644\n",
      "Epoch 8/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3893\n",
      "Epoch 8: val_loss improved from 1.45920 to 1.45765, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 628us/sample - loss: 1.3893 - val_loss: 1.4576\n",
      "Epoch 9/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3856\n",
      "Epoch 9: val_loss did not improve from 1.45765\n",
      "32380/32380 [==============================] - 20s 619us/sample - loss: 1.3856 - val_loss: 1.4649\n",
      "Epoch 10/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3870\n",
      "Epoch 10: val_loss did not improve from 1.45765\n",
      "32380/32380 [==============================] - 20s 631us/sample - loss: 1.3870 - val_loss: 1.4664\n",
      "Epoch 11/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3853\n",
      "Epoch 11: val_loss did not improve from 1.45765\n",
      "32380/32380 [==============================] - 20s 619us/sample - loss: 1.3853 - val_loss: 1.4611\n",
      "Epoch 12/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3849\n",
      "Epoch 12: val_loss did not improve from 1.45765\n",
      "32380/32380 [==============================] - 20s 616us/sample - loss: 1.3849 - val_loss: 1.4602\n",
      "Epoch 13/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 13: val_loss did not improve from 1.45765\n",
      "32380/32380 [==============================] - 20s 617us/sample - loss: 1.3830 - val_loss: 1.4672\n",
      "Epoch 14/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3816\n",
      "Epoch 14: val_loss did not improve from 1.45765\n",
      "32380/32380 [==============================] - 20s 617us/sample - loss: 1.3816 - val_loss: 1.4642\n",
      "Epoch 15/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3805\n",
      "Epoch 15: val_loss improved from 1.45765 to 1.45387, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 20s 624us/sample - loss: 1.3805 - val_loss: 1.4539\n",
      "Epoch 16/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3815\n",
      "Epoch 16: val_loss improved from 1.45387 to 1.45359, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 21s 652us/sample - loss: 1.3815 - val_loss: 1.4536\n",
      "Epoch 17/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3794\n",
      "Epoch 17: val_loss did not improve from 1.45359\n",
      "32380/32380 [==============================] - 20s 629us/sample - loss: 1.3794 - val_loss: 1.4642\n",
      "Epoch 18/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3775\n",
      "Epoch 18: val_loss improved from 1.45359 to 1.44875, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_40.h5\n",
      "32380/32380 [==============================] - 23s 705us/sample - loss: 1.3775 - val_loss: 1.4488\n",
      "Epoch 19/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3779\n",
      "Epoch 19: val_loss did not improve from 1.44875\n",
      "32380/32380 [==============================] - 22s 691us/sample - loss: 1.3779 - val_loss: 1.4571\n",
      "Epoch 20/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3753\n",
      "Epoch 20: val_loss did not improve from 1.44875\n",
      "32380/32380 [==============================] - 20s 613us/sample - loss: 1.3753 - val_loss: 1.4543\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:42:20.803340: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_425/lstm_cell_1239/bias/Assign' id:630479 op device:{requested: '', assigned: ''} def:{{{node lstm_425/lstm_cell_1239/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_425/lstm_cell_1239/bias, lstm_425/lstm_cell_1239/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:42:38.501381: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_1' id:631098 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 14:42:52.915626: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_2' id:631099 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32380, 95)\n",
      "Train on 32380 samples, validate on 3608 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:43:27.977611: W tensorflow/c/c_api.cc:304] Operation '{name:'training_66/Adam/lstm_435/lstm_cell_1249/recurrent_kernel/v/Assign' id:644924 op device:{requested: '', assigned: ''} def:{{{node training_66/Adam/lstm_435/lstm_cell_1249/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_66/Adam/lstm_435/lstm_cell_1249/recurrent_kernel/v, training_66/Adam/lstm_435/lstm_cell_1249/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:46:16.712825: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 3.0438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:46:38.202946: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_67/mul' id:633939 op device:{requested: '', assigned: ''} def:{{{node loss_67/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_67/mul/x, loss_67/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.97471, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 172s 5ms/sample - loss: 3.0438 - val_loss: 1.9747\n",
      "Epoch 2/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.7636\n",
      "Epoch 2: val_loss improved from 1.97471 to 1.69120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.7636 - val_loss: 1.6912\n",
      "Epoch 3/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5942\n",
      "Epoch 3: val_loss improved from 1.69120 to 1.60464, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 22s 678us/sample - loss: 1.5942 - val_loss: 1.6046\n",
      "Epoch 4/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5389\n",
      "Epoch 4: val_loss improved from 1.60464 to 1.56553, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 710us/sample - loss: 1.5389 - val_loss: 1.5655\n",
      "Epoch 5/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5126\n",
      "Epoch 5: val_loss improved from 1.56553 to 1.53681, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 719us/sample - loss: 1.5126 - val_loss: 1.5368\n",
      "Epoch 6/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5009\n",
      "Epoch 6: val_loss improved from 1.53681 to 1.53492, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 716us/sample - loss: 1.5009 - val_loss: 1.5349\n",
      "Epoch 7/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4896\n",
      "Epoch 7: val_loss improved from 1.53492 to 1.52570, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 696us/sample - loss: 1.4896 - val_loss: 1.5257\n",
      "Epoch 8/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4995\n",
      "Epoch 8: val_loss improved from 1.52570 to 1.51261, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 20s 605us/sample - loss: 1.4995 - val_loss: 1.5126\n",
      "Epoch 9/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 9: val_loss did not improve from 1.51261\n",
      "32380/32380 [==============================] - 20s 622us/sample - loss: 1.4794 - val_loss: 1.5201\n",
      "Epoch 10/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5349\n",
      "Epoch 10: val_loss did not improve from 1.51261\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.5349 - val_loss: 1.5365\n",
      "Epoch 11/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4957\n",
      "Epoch 11: val_loss did not improve from 1.51261\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.4957 - val_loss: 1.5208\n",
      "Epoch 12/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4956\n",
      "Epoch 12: val_loss did not improve from 1.51261\n",
      "32380/32380 [==============================] - 20s 605us/sample - loss: 1.4956 - val_loss: 1.5191\n",
      "Epoch 13/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5013\n",
      "Epoch 13: val_loss improved from 1.51261 to 1.50484, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 20s 624us/sample - loss: 1.5013 - val_loss: 1.5048\n",
      "Epoch 14/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5251\n",
      "Epoch 14: val_loss did not improve from 1.50484\n",
      "32380/32380 [==============================] - 21s 636us/sample - loss: 1.5251 - val_loss: 1.5111\n",
      "Epoch 15/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4739\n",
      "Epoch 15: val_loss did not improve from 1.50484\n",
      "32380/32380 [==============================] - 20s 609us/sample - loss: 1.4739 - val_loss: 1.5056\n",
      "Epoch 16/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4874\n",
      "Epoch 16: val_loss did not improve from 1.50484\n",
      "32380/32380 [==============================] - 20s 613us/sample - loss: 1.4874 - val_loss: 1.5053\n",
      "Epoch 17/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4747\n",
      "Epoch 17: val_loss did not improve from 1.50484\n",
      "32380/32380 [==============================] - 20s 609us/sample - loss: 1.4747 - val_loss: 1.5053\n",
      "Epoch 18/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4834\n",
      "Epoch 18: val_loss improved from 1.50484 to 1.50387, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 22s 671us/sample - loss: 1.4834 - val_loss: 1.5039\n",
      "Epoch 19/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5029\n",
      "Epoch 19: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 23s 701us/sample - loss: 1.5029 - val_loss: 1.5310\n",
      "Epoch 20/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4974\n",
      "Epoch 20: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.4974 - val_loss: 1.5193\n",
      "Epoch 21/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.5088\n",
      "Epoch 21: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.5088 - val_loss: 1.5170\n",
      "Epoch 22/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4908\n",
      "Epoch 22: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 20s 629us/sample - loss: 1.4908 - val_loss: 1.5095\n",
      "Epoch 23/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4734\n",
      "Epoch 23: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 20s 621us/sample - loss: 1.4734 - val_loss: 1.5174\n",
      "Epoch 24/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4700\n",
      "Epoch 24: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 22s 667us/sample - loss: 1.4700 - val_loss: 1.5059\n",
      "Epoch 25/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4653\n",
      "Epoch 25: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.4653 - val_loss: 1.5122\n",
      "Epoch 26/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4566\n",
      "Epoch 26: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 23s 706us/sample - loss: 1.4566 - val_loss: 1.5043\n",
      "Epoch 27/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4552\n",
      "Epoch 27: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 23s 697us/sample - loss: 1.4552 - val_loss: 1.5080\n",
      "Epoch 28/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4500\n",
      "Epoch 28: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 21s 657us/sample - loss: 1.4500 - val_loss: 1.5045\n",
      "Epoch 29/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4468\n",
      "Epoch 29: val_loss did not improve from 1.50387\n",
      "32380/32380 [==============================] - 20s 617us/sample - loss: 1.4468 - val_loss: 1.5065\n",
      "Epoch 30/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4437\n",
      "Epoch 30: val_loss improved from 1.50387 to 1.50023, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 713us/sample - loss: 1.4437 - val_loss: 1.5002\n",
      "Epoch 31/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 31: val_loss improved from 1.50023 to 1.49778, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 22s 676us/sample - loss: 1.4411 - val_loss: 1.4978\n",
      "Epoch 32/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4402\n",
      "Epoch 32: val_loss improved from 1.49778 to 1.49617, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 21s 636us/sample - loss: 1.4402 - val_loss: 1.4962\n",
      "Epoch 33/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4359\n",
      "Epoch 33: val_loss did not improve from 1.49617\n",
      "32380/32380 [==============================] - 20s 623us/sample - loss: 1.4359 - val_loss: 1.5020\n",
      "Epoch 34/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4342\n",
      "Epoch 34: val_loss did not improve from 1.49617\n",
      "32380/32380 [==============================] - 20s 628us/sample - loss: 1.4342 - val_loss: 1.4972\n",
      "Epoch 35/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 35: val_loss did not improve from 1.49617\n",
      "32380/32380 [==============================] - 20s 631us/sample - loss: 1.4305 - val_loss: 1.5009\n",
      "Epoch 36/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4336\n",
      "Epoch 36: val_loss improved from 1.49617 to 1.48258, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 20s 629us/sample - loss: 1.4336 - val_loss: 1.4826\n",
      "Epoch 37/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 37: val_loss did not improve from 1.48258\n",
      "32380/32380 [==============================] - 20s 624us/sample - loss: 1.4283 - val_loss: 1.4857\n",
      "Epoch 38/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4240\n",
      "Epoch 38: val_loss did not improve from 1.48258\n",
      "32380/32380 [==============================] - 20s 622us/sample - loss: 1.4240 - val_loss: 1.4880\n",
      "Epoch 39/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4217\n",
      "Epoch 39: val_loss did not improve from 1.48258\n",
      "32380/32380 [==============================] - 22s 672us/sample - loss: 1.4217 - val_loss: 1.4924\n",
      "Epoch 40/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4208\n",
      "Epoch 40: val_loss did not improve from 1.48258\n",
      "32380/32380 [==============================] - 21s 656us/sample - loss: 1.4208 - val_loss: 1.4847\n",
      "Epoch 41/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4185\n",
      "Epoch 41: val_loss did not improve from 1.48258\n",
      "32380/32380 [==============================] - 20s 621us/sample - loss: 1.4185 - val_loss: 1.4858\n",
      "Epoch 42/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4175\n",
      "Epoch 42: val_loss did not improve from 1.48258\n",
      "32380/32380 [==============================] - 20s 626us/sample - loss: 1.4175 - val_loss: 1.4831\n",
      "Epoch 43/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 43: val_loss improved from 1.48258 to 1.47508, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_41.h5\n",
      "32380/32380 [==============================] - 22s 665us/sample - loss: 1.4176 - val_loss: 1.4751\n",
      "Epoch 44/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4139\n",
      "Epoch 44: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 23s 707us/sample - loss: 1.4139 - val_loss: 1.4815\n",
      "Epoch 45/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4129\n",
      "Epoch 45: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 22s 671us/sample - loss: 1.4129 - val_loss: 1.4878\n",
      "Epoch 46/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4102\n",
      "Epoch 46: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 20s 613us/sample - loss: 1.4102 - val_loss: 1.4809\n",
      "Epoch 47/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4105\n",
      "Epoch 47: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 20s 614us/sample - loss: 1.4105 - val_loss: 1.4776\n",
      "Epoch 48/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4089\n",
      "Epoch 48: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 20s 619us/sample - loss: 1.4089 - val_loss: 1.4763\n",
      "Epoch 49/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 49: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 22s 667us/sample - loss: 1.4087 - val_loss: 1.4890\n",
      "Epoch 50/50\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4054\n",
      "Epoch 50: val_loss did not improve from 1.47508\n",
      "32380/32380 [==============================] - 20s 618us/sample - loss: 1.4054 - val_loss: 1.4775\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:06:44.346744: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_44_1/kernel/Assign' id:645802 op device:{requested: '', assigned: ''} def:{{{node conv2d_44_1/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_44_1/kernel, conv2d_44_1/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:07:18.569688: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_420_1/lstm_cell_1271/kernel/v/Assign' id:653552 op device:{requested: '', assigned: ''} def:{{{node lstm_420_1/lstm_cell_1271/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_420_1/lstm_cell_1271/kernel/v, lstm_420_1/lstm_cell_1271/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:07:52.595422: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_59_1/cond/Merge' id:652053 op device:{requested: '', assigned: ''} def:{{{node dropout_59_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_59_1/cond/Identity, dropout_59_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1013)\n",
      "(1632, 1013)\n",
      "(1716, 1013)\n",
      "(1848, 1013)\n",
      "(1735, 1013)\n",
      "(1393, 1013)\n",
      "(1790, 1013)\n",
      "(1595, 1013)\n",
      "(1740, 1013)\n",
      "(1526, 1013)\n",
      "(1896, 1013)\n",
      "(1739, 1013)\n",
      "(1752, 1013)\n",
      "(1872, 1013)\n",
      "(1740, 1013)\n",
      "(1788, 1013)\n",
      "(982, 1013)\n",
      "(1668, 1013)\n",
      "(1872, 1013)\n",
      "{1: 7.911050071711106, 4: 8.05187327180369, 5: 4.198363612503772, 6: 3.7620374427034466, 8: 9.011768526057791, 9: 10.0, 10: 6.782999766473922, 11: 6.701120460191037, 12: 9.600754103239193, 13: 7.6027181505561225, 17: 9.161621745617769, 19: 6.742460000909305, 21: 9.570218501878541, 22: 1.0125150861979888, 25: 8.10579299669757, 26: 8.762682739322898, 27: 7.148408664437492, 28: 5.939169556465779, 29: 1.0}\n",
      "Train on 32380 samples, validate on 3608 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:14:49.766000: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 10.9813\n",
      "Epoch 1: val_loss improved from inf to 1.49332, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 87s 3ms/sample - loss: 10.9813 - val_loss: 1.4933\n",
      "Epoch 2/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7126\n",
      "Epoch 2: val_loss improved from 1.49332 to 1.47909, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 705us/sample - loss: 10.7126 - val_loss: 1.4791\n",
      "Epoch 3/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.7104\n",
      "Epoch 3: val_loss did not improve from 1.47909\n",
      "32380/32380 [==============================] - 23s 705us/sample - loss: 10.7104 - val_loss: 1.4798\n",
      "Epoch 4/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.6609\n",
      "Epoch 4: val_loss improved from 1.47909 to 1.47056, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 715us/sample - loss: 10.6609 - val_loss: 1.4706\n",
      "Epoch 5/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5785\n",
      "Epoch 5: val_loss did not improve from 1.47056\n",
      "32380/32380 [==============================] - 23s 706us/sample - loss: 10.5785 - val_loss: 1.4967\n",
      "Epoch 6/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5673\n",
      "Epoch 6: val_loss did not improve from 1.47056\n",
      "32380/32380 [==============================] - 23s 705us/sample - loss: 10.5673 - val_loss: 1.5121\n",
      "Epoch 7/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5750\n",
      "Epoch 7: val_loss did not improve from 1.47056\n",
      "32380/32380 [==============================] - 23s 705us/sample - loss: 10.5750 - val_loss: 1.4750\n",
      "Epoch 8/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5312\n",
      "Epoch 8: val_loss did not improve from 1.47056\n",
      "32380/32380 [==============================] - 22s 689us/sample - loss: 10.5312 - val_loss: 1.4947\n",
      "Epoch 9/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4935\n",
      "Epoch 9: val_loss did not improve from 1.47056\n",
      "32380/32380 [==============================] - 20s 606us/sample - loss: 10.4935 - val_loss: 1.4914\n",
      "Epoch 10/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.5051\n",
      "Epoch 10: val_loss improved from 1.47056 to 1.47047, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 20s 611us/sample - loss: 10.5051 - val_loss: 1.4705\n",
      "Epoch 11/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4959\n",
      "Epoch 11: val_loss improved from 1.47047 to 1.46874, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 20s 610us/sample - loss: 10.4959 - val_loss: 1.4687\n",
      "Epoch 12/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4593\n",
      "Epoch 12: val_loss improved from 1.46874 to 1.46429, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 21s 636us/sample - loss: 10.4593 - val_loss: 1.4643\n",
      "Epoch 13/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4506\n",
      "Epoch 13: val_loss did not improve from 1.46429\n",
      "32380/32380 [==============================] - 21s 644us/sample - loss: 10.4506 - val_loss: 1.4718\n",
      "Epoch 14/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4386\n",
      "Epoch 14: val_loss did not improve from 1.46429\n",
      "32380/32380 [==============================] - 22s 679us/sample - loss: 10.4386 - val_loss: 1.4650\n",
      "Epoch 15/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4374\n",
      "Epoch 15: val_loss did not improve from 1.46429\n",
      "32380/32380 [==============================] - 20s 611us/sample - loss: 10.4374 - val_loss: 1.4787\n",
      "Epoch 16/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4108\n",
      "Epoch 16: val_loss improved from 1.46429 to 1.46279, saving model to ./checkpoints/unknown_person_few_shot_p2_41.h5\n",
      "32380/32380 [==============================] - 20s 612us/sample - loss: 10.4108 - val_loss: 1.4628\n",
      "Epoch 17/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.4211\n",
      "Epoch 17: val_loss did not improve from 1.46279\n",
      "32380/32380 [==============================] - 20s 607us/sample - loss: 10.4211 - val_loss: 1.4923\n",
      "Epoch 18/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3874\n",
      "Epoch 18: val_loss did not improve from 1.46279\n",
      "32380/32380 [==============================] - 20s 608us/sample - loss: 10.3874 - val_loss: 1.4855\n",
      "Epoch 19/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3900\n",
      "Epoch 19: val_loss did not improve from 1.46279\n",
      "32380/32380 [==============================] - 20s 607us/sample - loss: 10.3900 - val_loss: 1.4788\n",
      "Epoch 20/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 10.3578\n",
      "Epoch 20: val_loss did not improve from 1.46279\n",
      "32380/32380 [==============================] - 20s 610us/sample - loss: 10.3578 - val_loss: 1.4795\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:23:10.689136: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_415_2/lstm_cell_1303/kernel/Assign' id:666780 op device:{requested: '', assigned: ''} def:{{{node lstm_415_2/lstm_cell_1303/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_415_2/lstm_cell_1303/kernel, lstm_415_2/lstm_cell_1303/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:23:45.892347: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_441_2/lstm_cell_1329/kernel/m/Assign' id:672622 op device:{requested: '', assigned: ''} def:{{{node lstm_441_2/lstm_cell_1329/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_441_2/lstm_cell_1329/kernel/m, lstm_441_2/lstm_cell_1329/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32380 samples, validate on 3608 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:24:23.659366: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:27:21.709606: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:27:44.716103: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.48801, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 84s 3ms/sample - loss: 1.4142 - val_loss: 1.4880\n",
      "Epoch 2/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4110\n",
      "Epoch 2: val_loss improved from 1.48801 to 1.47663, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 21s 650us/sample - loss: 1.4110 - val_loss: 1.4766\n",
      "Epoch 3/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4101\n",
      "Epoch 3: val_loss did not improve from 1.47663\n",
      "32380/32380 [==============================] - 19s 601us/sample - loss: 1.4101 - val_loss: 1.4770\n",
      "Epoch 4/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 4: val_loss improved from 1.47663 to 1.47570, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 706us/sample - loss: 1.4062 - val_loss: 1.4757\n",
      "Epoch 5/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4073\n",
      "Epoch 5: val_loss did not improve from 1.47570\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.4073 - val_loss: 1.4813\n",
      "Epoch 6/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4057\n",
      "Epoch 6: val_loss did not improve from 1.47570\n",
      "32380/32380 [==============================] - 21s 634us/sample - loss: 1.4057 - val_loss: 1.4774\n",
      "Epoch 7/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.4014\n",
      "Epoch 7: val_loss did not improve from 1.47570\n",
      "32380/32380 [==============================] - 23s 703us/sample - loss: 1.4014 - val_loss: 1.4764\n",
      "Epoch 8/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 8: val_loss improved from 1.47570 to 1.47167, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 711us/sample - loss: 1.3997 - val_loss: 1.4717\n",
      "Epoch 9/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 9: val_loss did not improve from 1.47167\n",
      "32380/32380 [==============================] - 23s 704us/sample - loss: 1.3997 - val_loss: 1.4891\n",
      "Epoch 10/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3950\n",
      "Epoch 10: val_loss improved from 1.47167 to 1.46711, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 23s 712us/sample - loss: 1.3950 - val_loss: 1.4671\n",
      "Epoch 11/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3966\n",
      "Epoch 11: val_loss did not improve from 1.46711\n",
      "32380/32380 [==============================] - 23s 700us/sample - loss: 1.3966 - val_loss: 1.4703\n",
      "Epoch 12/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3950\n",
      "Epoch 12: val_loss improved from 1.46711 to 1.45967, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 22s 666us/sample - loss: 1.3950 - val_loss: 1.4597\n",
      "Epoch 13/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3942\n",
      "Epoch 13: val_loss did not improve from 1.45967\n",
      "32380/32380 [==============================] - 20s 610us/sample - loss: 1.3942 - val_loss: 1.4707\n",
      "Epoch 14/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3921\n",
      "Epoch 14: val_loss did not improve from 1.45967\n",
      "32380/32380 [==============================] - 19s 601us/sample - loss: 1.3921 - val_loss: 1.4668\n",
      "Epoch 15/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 15: val_loss did not improve from 1.45967\n",
      "32380/32380 [==============================] - 19s 600us/sample - loss: 1.3902 - val_loss: 1.4759\n",
      "Epoch 16/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3903\n",
      "Epoch 16: val_loss did not improve from 1.45967\n",
      "32380/32380 [==============================] - 20s 623us/sample - loss: 1.3903 - val_loss: 1.4635\n",
      "Epoch 17/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3876\n",
      "Epoch 17: val_loss did not improve from 1.45967\n",
      "32380/32380 [==============================] - 22s 665us/sample - loss: 1.3876 - val_loss: 1.4687\n",
      "Epoch 18/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3837\n",
      "Epoch 18: val_loss improved from 1.45967 to 1.45812, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_41.h5\n",
      "32380/32380 [==============================] - 21s 648us/sample - loss: 1.3837 - val_loss: 1.4581\n",
      "Epoch 19/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3857\n",
      "Epoch 19: val_loss did not improve from 1.45812\n",
      "32380/32380 [==============================] - 22s 686us/sample - loss: 1.3857 - val_loss: 1.4656\n",
      "Epoch 20/20\n",
      "32380/32380 [==============================] - ETA: 0s - loss: 1.3859\n",
      "Epoch 20: val_loss did not improve from 1.45812\n",
      "32380/32380 [==============================] - 22s 677us/sample - loss: 1.3859 - val_loss: 1.4655\n",
      "36162\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:35:57.409014: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_452/lstm_cell_1340/bias/Assign' id:685871 op device:{requested: '', assigned: ''} def:{{{node lstm_452/lstm_cell_1340/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_452/lstm_cell_1340/bias, lstm_452/lstm_cell_1340/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:36:16.869302: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_1' id:688140 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 15:36:32.650435: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_2' id:688141 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32553, 95)\n",
      "Train on 32553 samples, validate on 3609 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:37:08.611698: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_476/lstm_cell_1364/recurrent_kernel/Assign' id:690051 op device:{requested: '', assigned: ''} def:{{{node lstm_476/lstm_cell_1364/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_476/lstm_cell_1364/recurrent_kernel, lstm_476/lstm_cell_1364/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:40:16.599808: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 3.3501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 15:40:42.312837: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_73/mul' id:690981 op device:{requested: '', assigned: ''} def:{{{node loss_73/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_73/mul/x, loss_73/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.95799, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 201s 6ms/sample - loss: 3.3501 - val_loss: 1.9580\n",
      "Epoch 2/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.8297\n",
      "Epoch 2: val_loss improved from 1.95799 to 1.58500, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 714us/sample - loss: 1.8297 - val_loss: 1.5850\n",
      "Epoch 3/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.6108\n",
      "Epoch 3: val_loss improved from 1.58500 to 1.49656, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 630us/sample - loss: 1.6108 - val_loss: 1.4966\n",
      "Epoch 4/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5523\n",
      "Epoch 4: val_loss improved from 1.49656 to 1.46885, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 22s 670us/sample - loss: 1.5523 - val_loss: 1.4689\n",
      "Epoch 5/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5252\n",
      "Epoch 5: val_loss improved from 1.46885 to 1.44910, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 605us/sample - loss: 1.5252 - val_loss: 1.4491\n",
      "Epoch 6/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5071\n",
      "Epoch 6: val_loss improved from 1.44910 to 1.43412, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 22s 685us/sample - loss: 1.5071 - val_loss: 1.4341\n",
      "Epoch 7/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4949\n",
      "Epoch 7: val_loss did not improve from 1.43412\n",
      "32553/32553 [==============================] - 22s 674us/sample - loss: 1.4949 - val_loss: 1.4377\n",
      "Epoch 8/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4924\n",
      "Epoch 8: val_loss improved from 1.43412 to 1.41632, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 630us/sample - loss: 1.4924 - val_loss: 1.4163\n",
      "Epoch 9/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4815\n",
      "Epoch 9: val_loss improved from 1.41632 to 1.41257, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 22s 663us/sample - loss: 1.4815 - val_loss: 1.4126\n",
      "Epoch 10/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 10: val_loss did not improve from 1.41257\n",
      "32553/32553 [==============================] - 20s 605us/sample - loss: 1.4772 - val_loss: 1.4172\n",
      "Epoch 11/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5370\n",
      "Epoch 11: val_loss did not improve from 1.41257\n",
      "32553/32553 [==============================] - 20s 601us/sample - loss: 1.5370 - val_loss: 1.4126\n",
      "Epoch 12/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4946\n",
      "Epoch 12: val_loss improved from 1.41257 to 1.40906, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 609us/sample - loss: 1.4946 - val_loss: 1.4091\n",
      "Epoch 13/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4751\n",
      "Epoch 13: val_loss improved from 1.40906 to 1.40576, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 618us/sample - loss: 1.4751 - val_loss: 1.4058\n",
      "Epoch 14/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 14: val_loss did not improve from 1.40576\n",
      "32553/32553 [==============================] - 20s 625us/sample - loss: 1.4794 - val_loss: 1.4072\n",
      "Epoch 15/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4788\n",
      "Epoch 15: val_loss improved from 1.40576 to 1.40316, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 660us/sample - loss: 1.4788 - val_loss: 1.4032\n",
      "Epoch 16/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4711\n",
      "Epoch 16: val_loss improved from 1.40316 to 1.39900, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 702us/sample - loss: 1.4711 - val_loss: 1.3990\n",
      "Epoch 17/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4693\n",
      "Epoch 17: val_loss improved from 1.39900 to 1.39823, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 700us/sample - loss: 1.4693 - val_loss: 1.3982\n",
      "Epoch 18/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4578\n",
      "Epoch 18: val_loss improved from 1.39823 to 1.39403, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 631us/sample - loss: 1.4578 - val_loss: 1.3940\n",
      "Epoch 19/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4886\n",
      "Epoch 19: val_loss did not improve from 1.39403\n",
      "32553/32553 [==============================] - 20s 629us/sample - loss: 1.4886 - val_loss: 1.3963\n",
      "Epoch 20/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4658\n",
      "Epoch 20: val_loss improved from 1.39403 to 1.39324, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 710us/sample - loss: 1.4658 - val_loss: 1.3932\n",
      "Epoch 21/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4587\n",
      "Epoch 21: val_loss did not improve from 1.39324\n",
      "32553/32553 [==============================] - 22s 673us/sample - loss: 1.4587 - val_loss: 1.3951\n",
      "Epoch 22/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4680\n",
      "Epoch 22: val_loss improved from 1.39324 to 1.38914, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 658us/sample - loss: 1.4680 - val_loss: 1.3891\n",
      "Epoch 23/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 23: val_loss improved from 1.38914 to 1.38886, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 619us/sample - loss: 1.4483 - val_loss: 1.3889\n",
      "Epoch 24/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4422\n",
      "Epoch 24: val_loss improved from 1.38886 to 1.38574, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 613us/sample - loss: 1.4422 - val_loss: 1.3857\n",
      "Epoch 25/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4425\n",
      "Epoch 25: val_loss did not improve from 1.38574\n",
      "32553/32553 [==============================] - 20s 602us/sample - loss: 1.4425 - val_loss: 1.3878\n",
      "Epoch 26/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 26: val_loss did not improve from 1.38574\n",
      "32553/32553 [==============================] - 20s 607us/sample - loss: 1.4330 - val_loss: 1.3892\n",
      "Epoch 27/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4328\n",
      "Epoch 27: val_loss improved from 1.38574 to 1.38076, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 657us/sample - loss: 1.4328 - val_loss: 1.3808\n",
      "Epoch 28/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4331\n",
      "Epoch 28: val_loss did not improve from 1.38076\n",
      "32553/32553 [==============================] - 23s 707us/sample - loss: 1.4331 - val_loss: 1.3829\n",
      "Epoch 29/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4270\n",
      "Epoch 29: val_loss did not improve from 1.38076\n",
      "32553/32553 [==============================] - 23s 707us/sample - loss: 1.4270 - val_loss: 1.3843\n",
      "Epoch 30/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4256\n",
      "Epoch 30: val_loss improved from 1.38076 to 1.37973, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 24s 722us/sample - loss: 1.4256 - val_loss: 1.3797\n",
      "Epoch 31/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 31: val_loss improved from 1.37973 to 1.37458, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 709us/sample - loss: 1.4255 - val_loss: 1.3746\n",
      "Epoch 32/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 32: val_loss improved from 1.37458 to 1.37423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 713us/sample - loss: 1.4191 - val_loss: 1.3742\n",
      "Epoch 33/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 33: val_loss improved from 1.37423 to 1.37188, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 721us/sample - loss: 1.4178 - val_loss: 1.3719\n",
      "Epoch 34/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 34: val_loss did not improve from 1.37188\n",
      "32553/32553 [==============================] - 23s 697us/sample - loss: 1.4174 - val_loss: 1.3737\n",
      "Epoch 35/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 35: val_loss did not improve from 1.37188\n",
      "32553/32553 [==============================] - 23s 693us/sample - loss: 1.4124 - val_loss: 1.3723\n",
      "Epoch 36/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 36: val_loss did not improve from 1.37188\n",
      "32553/32553 [==============================] - 21s 647us/sample - loss: 1.4148 - val_loss: 1.3758\n",
      "Epoch 37/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4105\n",
      "Epoch 37: val_loss did not improve from 1.37188\n",
      "32553/32553 [==============================] - 22s 679us/sample - loss: 1.4105 - val_loss: 1.3752\n",
      "Epoch 38/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4122\n",
      "Epoch 38: val_loss improved from 1.37188 to 1.36965, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 1.4122 - val_loss: 1.3696\n",
      "Epoch 39/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 39: val_loss did not improve from 1.36965\n",
      "32553/32553 [==============================] - 23s 693us/sample - loss: 1.4083 - val_loss: 1.3698\n",
      "Epoch 40/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4072\n",
      "Epoch 40: val_loss improved from 1.36965 to 1.36701, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 636us/sample - loss: 1.4072 - val_loss: 1.3670\n",
      "Epoch 41/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4073\n",
      "Epoch 41: val_loss did not improve from 1.36701\n",
      "32553/32553 [==============================] - 20s 600us/sample - loss: 1.4073 - val_loss: 1.3702\n",
      "Epoch 42/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4034\n",
      "Epoch 42: val_loss improved from 1.36701 to 1.36543, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 626us/sample - loss: 1.4034 - val_loss: 1.3654\n",
      "Epoch 43/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4019\n",
      "Epoch 43: val_loss improved from 1.36543 to 1.36385, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 1.4019 - val_loss: 1.3639\n",
      "Epoch 44/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 44: val_loss improved from 1.36385 to 1.35915, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 649us/sample - loss: 1.3983 - val_loss: 1.3592\n",
      "Epoch 45/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 45: val_loss did not improve from 1.35915\n",
      "32553/32553 [==============================] - 23s 697us/sample - loss: 1.3986 - val_loss: 1.3654\n",
      "Epoch 46/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3994\n",
      "Epoch 46: val_loss did not improve from 1.35915\n",
      "32553/32553 [==============================] - 22s 690us/sample - loss: 1.3994 - val_loss: 1.3634\n",
      "Epoch 47/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3983\n",
      "Epoch 47: val_loss did not improve from 1.35915\n",
      "32553/32553 [==============================] - 23s 694us/sample - loss: 1.3983 - val_loss: 1.3593\n",
      "Epoch 48/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 48: val_loss improved from 1.35915 to 1.35891, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 696us/sample - loss: 1.3939 - val_loss: 1.3589\n",
      "Epoch 49/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 49: val_loss improved from 1.35891 to 1.35752, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 618us/sample - loss: 1.3953 - val_loss: 1.3575\n",
      "Epoch 50/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3926\n",
      "Epoch 50: val_loss improved from 1.35752 to 1.35655, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 615us/sample - loss: 1.3926 - val_loss: 1.3565\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:01:28.113602: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_454_1/lstm_cell_1379/kernel/Assign' id:704744 op device:{requested: '', assigned: ''} def:{{{node lstm_454_1/lstm_cell_1379/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_454_1/lstm_cell_1379/kernel, lstm_454_1/lstm_cell_1379/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:02:05.547179: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_455_1/lstm_cell_1380/bias/v/Assign' id:710574 op device:{requested: '', assigned: ''} def:{{{node lstm_455_1/lstm_cell_1380/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_455_1/lstm_cell_1380/bias/v, lstm_455_1/lstm_cell_1380/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 16:02:42.824332: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_64_1/cond/Merge' id:709095 op device:{requested: '', assigned: ''} def:{{{node dropout_64_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_64_1/cond/Identity, dropout_64_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 839)\n",
      "(1692, 839)\n",
      "(1704, 839)\n",
      "(1860, 839)\n",
      "(1725, 839)\n",
      "(1370, 839)\n",
      "(1823, 839)\n",
      "(1570, 839)\n",
      "(1728, 839)\n",
      "(1538, 839)\n",
      "(1896, 839)\n",
      "(1727, 839)\n",
      "(1776, 839)\n",
      "(1848, 839)\n",
      "(1776, 839)\n",
      "(1788, 839)\n",
      "(958, 839)\n",
      "(1704, 839)\n",
      "(1860, 839)\n",
      "{1: 7.9427549317121295, 4: 9.047897657514966, 5: 5.429208297633393, 6: 4.424400895257796, 8: 9.411305417402, 9: 9.998102071677517, 10: 7.184564426587837, 11: 7.21372971361536, 12: 10.0, 13: 7.7766520680932985, 17: 9.819505651115715, 19: 7.605656463595163, 21: 9.960644157782928, 22: 1.0, 25: 8.074772459102945, 26: 8.013701950155486, 27: 6.321314258470984, 28: 5.829077217691696, 29: 1.7907920892344908}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907579/3261308647.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32553 samples, validate on 3609 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:10:25.478371: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 11.3721\n",
      "Epoch 1: val_loss improved from inf to 1.39659, saving model to ./checkpoints/unknown_person_few_shot_p2_42.h5\n",
      "32553/32553 [==============================] - 88s 3ms/sample - loss: 11.3721 - val_loss: 1.3966\n",
      "Epoch 2/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.2945\n",
      "Epoch 2: val_loss improved from 1.39659 to 1.36940, saving model to ./checkpoints/unknown_person_few_shot_p2_42.h5\n",
      "32553/32553 [==============================] - 22s 661us/sample - loss: 11.2945 - val_loss: 1.3694\n",
      "Epoch 3/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.2049\n",
      "Epoch 3: val_loss improved from 1.36940 to 1.36617, saving model to ./checkpoints/unknown_person_few_shot_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 709us/sample - loss: 11.2049 - val_loss: 1.3662\n",
      "Epoch 4/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.1728\n",
      "Epoch 4: val_loss did not improve from 1.36617\n",
      "32553/32553 [==============================] - 21s 658us/sample - loss: 11.1728 - val_loss: 1.3700\n",
      "Epoch 5/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.1578\n",
      "Epoch 5: val_loss did not improve from 1.36617\n",
      "32553/32553 [==============================] - 23s 707us/sample - loss: 11.1578 - val_loss: 1.4003\n",
      "Epoch 6/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.1095\n",
      "Epoch 6: val_loss did not improve from 1.36617\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 11.1095 - val_loss: 1.3705\n",
      "Epoch 7/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0873\n",
      "Epoch 7: val_loss did not improve from 1.36617\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 11.0873 - val_loss: 1.3686\n",
      "Epoch 8/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0779\n",
      "Epoch 8: val_loss improved from 1.36617 to 1.36189, saving model to ./checkpoints/unknown_person_few_shot_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 707us/sample - loss: 11.0779 - val_loss: 1.3619\n",
      "Epoch 9/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0264\n",
      "Epoch 9: val_loss did not improve from 1.36189\n",
      "32553/32553 [==============================] - 21s 630us/sample - loss: 11.0264 - val_loss: 1.3744\n",
      "Epoch 10/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0240\n",
      "Epoch 10: val_loss did not improve from 1.36189\n",
      "32553/32553 [==============================] - 20s 626us/sample - loss: 11.0240 - val_loss: 1.3621\n",
      "Epoch 11/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0062\n",
      "Epoch 11: val_loss did not improve from 1.36189\n",
      "32553/32553 [==============================] - 23s 705us/sample - loss: 11.0062 - val_loss: 1.3637\n",
      "Epoch 12/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9892\n",
      "Epoch 12: val_loss improved from 1.36189 to 1.35753, saving model to ./checkpoints/unknown_person_few_shot_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 712us/sample - loss: 10.9892 - val_loss: 1.3575\n",
      "Epoch 13/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9692\n",
      "Epoch 13: val_loss did not improve from 1.35753\n",
      "32553/32553 [==============================] - 23s 702us/sample - loss: 10.9692 - val_loss: 1.3634\n",
      "Epoch 14/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9441\n",
      "Epoch 14: val_loss did not improve from 1.35753\n",
      "32553/32553 [==============================] - 23s 702us/sample - loss: 10.9441 - val_loss: 1.3614\n",
      "Epoch 15/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9374\n",
      "Epoch 15: val_loss improved from 1.35753 to 1.35463, saving model to ./checkpoints/unknown_person_few_shot_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 711us/sample - loss: 10.9374 - val_loss: 1.3546\n",
      "Epoch 16/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9319\n",
      "Epoch 16: val_loss did not improve from 1.35463\n",
      "32553/32553 [==============================] - 23s 693us/sample - loss: 10.9319 - val_loss: 1.3637\n",
      "Epoch 17/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9277\n",
      "Epoch 17: val_loss did not improve from 1.35463\n",
      "32553/32553 [==============================] - 20s 601us/sample - loss: 10.9277 - val_loss: 1.3684\n",
      "Epoch 18/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9205\n",
      "Epoch 18: val_loss did not improve from 1.35463\n",
      "32553/32553 [==============================] - 20s 605us/sample - loss: 10.9205 - val_loss: 1.3727\n",
      "Epoch 19/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9073\n",
      "Epoch 19: val_loss did not improve from 1.35463\n",
      "32553/32553 [==============================] - 20s 603us/sample - loss: 10.9073 - val_loss: 1.3612\n",
      "Epoch 20/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9057\n",
      "Epoch 20: val_loss did not improve from 1.35463\n",
      "32553/32553 [==============================] - 20s 603us/sample - loss: 10.9057 - val_loss: 1.3805\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:19:03.941069: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_476_2/lstm_cell_1438/kernel/Assign' id:727664 op device:{requested: '', assigned: ''} def:{{{node lstm_476_2/lstm_cell_1438/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_476_2/lstm_cell_1438/kernel, lstm_476_2/lstm_cell_1438/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:19:42.932858: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_474_2/lstm_cell_1436/kernel/m/Assign' id:729604 op device:{requested: '', assigned: ''} def:{{{node lstm_474_2/lstm_cell_1436/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_474_2/lstm_cell_1436/kernel/m, lstm_474_2/lstm_cell_1436/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32553 samples, validate on 3609 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:20:24.446688: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:23:43.027404: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:24:05.757624: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36386, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 91s 3ms/sample - loss: 1.3907 - val_loss: 1.3639\n",
      "Epoch 2/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3881\n",
      "Epoch 2: val_loss improved from 1.36386 to 1.35968, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 22s 674us/sample - loss: 1.3881 - val_loss: 1.3597\n",
      "Epoch 3/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3879\n",
      "Epoch 3: val_loss improved from 1.35968 to 1.35762, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 21s 633us/sample - loss: 1.3879 - val_loss: 1.3576\n",
      "Epoch 4/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3883\n",
      "Epoch 4: val_loss improved from 1.35762 to 1.35136, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 22s 689us/sample - loss: 1.3883 - val_loss: 1.3514\n",
      "Epoch 5/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3885\n",
      "Epoch 5: val_loss did not improve from 1.35136\n",
      "32553/32553 [==============================] - 20s 599us/sample - loss: 1.3885 - val_loss: 1.3547\n",
      "Epoch 6/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3837\n",
      "Epoch 6: val_loss did not improve from 1.35136\n",
      "32553/32553 [==============================] - 20s 603us/sample - loss: 1.3837 - val_loss: 1.3540\n",
      "Epoch 7/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3820\n",
      "Epoch 7: val_loss did not improve from 1.35136\n",
      "32553/32553 [==============================] - 20s 600us/sample - loss: 1.3820 - val_loss: 1.3537\n",
      "Epoch 8/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3855\n",
      "Epoch 8: val_loss improved from 1.35136 to 1.34986, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 616us/sample - loss: 1.3855 - val_loss: 1.3499\n",
      "Epoch 9/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3814\n",
      "Epoch 9: val_loss did not improve from 1.34986\n",
      "32553/32553 [==============================] - 23s 710us/sample - loss: 1.3814 - val_loss: 1.3536\n",
      "Epoch 10/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3793\n",
      "Epoch 10: val_loss improved from 1.34986 to 1.34925, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 713us/sample - loss: 1.3793 - val_loss: 1.3493\n",
      "Epoch 11/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3801\n",
      "Epoch 11: val_loss did not improve from 1.34925\n",
      "32553/32553 [==============================] - 22s 665us/sample - loss: 1.3801 - val_loss: 1.3561\n",
      "Epoch 12/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3808\n",
      "Epoch 12: val_loss improved from 1.34925 to 1.34552, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 20s 624us/sample - loss: 1.3808 - val_loss: 1.3455\n",
      "Epoch 13/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3758\n",
      "Epoch 13: val_loss did not improve from 1.34552\n",
      "32553/32553 [==============================] - 20s 612us/sample - loss: 1.3758 - val_loss: 1.3469\n",
      "Epoch 14/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3758\n",
      "Epoch 14: val_loss improved from 1.34552 to 1.33845, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_42.h5\n",
      "32553/32553 [==============================] - 23s 699us/sample - loss: 1.3758 - val_loss: 1.3384\n",
      "Epoch 15/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3739\n",
      "Epoch 15: val_loss did not improve from 1.33845\n",
      "32553/32553 [==============================] - 23s 697us/sample - loss: 1.3739 - val_loss: 1.3470\n",
      "Epoch 16/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3773\n",
      "Epoch 16: val_loss did not improve from 1.33845\n",
      "32553/32553 [==============================] - 20s 615us/sample - loss: 1.3773 - val_loss: 1.3499\n",
      "Epoch 17/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3766\n",
      "Epoch 17: val_loss did not improve from 1.33845\n",
      "32553/32553 [==============================] - 22s 689us/sample - loss: 1.3766 - val_loss: 1.3525\n",
      "Epoch 18/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3717\n",
      "Epoch 18: val_loss did not improve from 1.33845\n",
      "32553/32553 [==============================] - 23s 699us/sample - loss: 1.3717 - val_loss: 1.3439\n",
      "Epoch 19/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3729\n",
      "Epoch 19: val_loss did not improve from 1.33845\n",
      "32553/32553 [==============================] - 23s 707us/sample - loss: 1.3729 - val_loss: 1.3413\n",
      "Epoch 20/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3719\n",
      "Epoch 20: val_loss did not improve from 1.33845\n",
      "32553/32553 [==============================] - 21s 632us/sample - loss: 1.3719 - val_loss: 1.3438\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:32:14.445630: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_493/lstm_cell_1455/bias/Assign' id:743573 op device:{requested: '', assigned: ''} def:{{{node lstm_493/lstm_cell_1455/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_493/lstm_cell_1455/bias, lstm_493/lstm_cell_1455/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:32:35.750831: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_1' id:745182 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:32:53.002422: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_2' id:745183 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32553, 95)\n",
      "Train on 32553 samples, validate on 3609 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:33:33.861639: W tensorflow/c/c_api.cc:304] Operation '{name:'training_78/Adam/dense_55/bias/v/Assign' id:759179 op device:{requested: '', assigned: ''} def:{{{node training_78/Adam/dense_55/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_78/Adam/dense_55/bias/v, training_78/Adam/dense_55/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:37:01.214339: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 3.5510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:37:23.518261: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_79/mul' id:748023 op device:{requested: '', assigned: ''} def:{{{node loss_79/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_79/mul/x, loss_79/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.94619, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 206s 6ms/sample - loss: 3.5510 - val_loss: 1.9462\n",
      "Epoch 2/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.8188\n",
      "Epoch 2: val_loss improved from 1.94619 to 1.56552, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 643us/sample - loss: 1.8188 - val_loss: 1.5655\n",
      "Epoch 3/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5962\n",
      "Epoch 3: val_loss improved from 1.56552 to 1.48906, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 634us/sample - loss: 1.5962 - val_loss: 1.4891\n",
      "Epoch 4/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5485\n",
      "Epoch 4: val_loss improved from 1.48906 to 1.46965, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 652us/sample - loss: 1.5485 - val_loss: 1.4697\n",
      "Epoch 5/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5263\n",
      "Epoch 5: val_loss improved from 1.46965 to 1.44817, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 657us/sample - loss: 1.5263 - val_loss: 1.4482\n",
      "Epoch 6/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5135\n",
      "Epoch 6: val_loss improved from 1.44817 to 1.43562, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 23s 717us/sample - loss: 1.5135 - val_loss: 1.4356\n",
      "Epoch 7/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5003\n",
      "Epoch 7: val_loss improved from 1.43562 to 1.42657, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 24s 724us/sample - loss: 1.5003 - val_loss: 1.4266\n",
      "Epoch 8/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4923\n",
      "Epoch 8: val_loss improved from 1.42657 to 1.42510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 635us/sample - loss: 1.4923 - val_loss: 1.4251\n",
      "Epoch 9/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5184\n",
      "Epoch 9: val_loss improved from 1.42510 to 1.42148, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 617us/sample - loss: 1.5184 - val_loss: 1.4215\n",
      "Epoch 10/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4871\n",
      "Epoch 10: val_loss improved from 1.42148 to 1.41414, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 647us/sample - loss: 1.4871 - val_loss: 1.4141\n",
      "Epoch 11/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4783\n",
      "Epoch 11: val_loss improved from 1.41414 to 1.40965, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 626us/sample - loss: 1.4783 - val_loss: 1.4096\n",
      "Epoch 12/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4784\n",
      "Epoch 12: val_loss improved from 1.40965 to 1.40842, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 23s 704us/sample - loss: 1.4784 - val_loss: 1.4084\n",
      "Epoch 13/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5083\n",
      "Epoch 13: val_loss did not improve from 1.40842\n",
      "32553/32553 [==============================] - 23s 718us/sample - loss: 1.5083 - val_loss: 1.4172\n",
      "Epoch 14/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 14: val_loss did not improve from 1.40842\n",
      "32553/32553 [==============================] - 23s 718us/sample - loss: 1.4827 - val_loss: 1.4174\n",
      "Epoch 15/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4741\n",
      "Epoch 15: val_loss did not improve from 1.40842\n",
      "32553/32553 [==============================] - 23s 720us/sample - loss: 1.4741 - val_loss: 1.4098\n",
      "Epoch 16/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 16: val_loss improved from 1.40842 to 1.40718, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 24s 727us/sample - loss: 1.4745 - val_loss: 1.4072\n",
      "Epoch 17/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4722\n",
      "Epoch 17: val_loss improved from 1.40718 to 1.40156, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 24s 722us/sample - loss: 1.4722 - val_loss: 1.4016\n",
      "Epoch 18/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4790\n",
      "Epoch 18: val_loss did not improve from 1.40156\n",
      "32553/32553 [==============================] - 22s 667us/sample - loss: 1.4790 - val_loss: 1.4093\n",
      "Epoch 19/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4761\n",
      "Epoch 19: val_loss did not improve from 1.40156\n",
      "32553/32553 [==============================] - 20s 622us/sample - loss: 1.4761 - val_loss: 1.4048\n",
      "Epoch 20/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4735\n",
      "Epoch 20: val_loss improved from 1.40156 to 1.39922, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 625us/sample - loss: 1.4735 - val_loss: 1.3992\n",
      "Epoch 21/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4640\n",
      "Epoch 21: val_loss improved from 1.39922 to 1.39635, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 624us/sample - loss: 1.4640 - val_loss: 1.3963\n",
      "Epoch 22/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4771\n",
      "Epoch 22: val_loss did not improve from 1.39635\n",
      "32553/32553 [==============================] - 20s 617us/sample - loss: 1.4771 - val_loss: 1.4028\n",
      "Epoch 23/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4706\n",
      "Epoch 23: val_loss did not improve from 1.39635\n",
      "32553/32553 [==============================] - 21s 654us/sample - loss: 1.4706 - val_loss: 1.4068\n",
      "Epoch 24/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4687\n",
      "Epoch 24: val_loss did not improve from 1.39635\n",
      "32553/32553 [==============================] - 20s 614us/sample - loss: 1.4687 - val_loss: 1.4044\n",
      "Epoch 25/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4596\n",
      "Epoch 25: val_loss did not improve from 1.39635\n",
      "32553/32553 [==============================] - 20s 617us/sample - loss: 1.4596 - val_loss: 1.3966\n",
      "Epoch 26/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4566\n",
      "Epoch 26: val_loss improved from 1.39635 to 1.39570, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 622us/sample - loss: 1.4566 - val_loss: 1.3957\n",
      "Epoch 27/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4499\n",
      "Epoch 27: val_loss improved from 1.39570 to 1.38949, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 22s 678us/sample - loss: 1.4499 - val_loss: 1.3895\n",
      "Epoch 28/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4484\n",
      "Epoch 28: val_loss did not improve from 1.38949\n",
      "32553/32553 [==============================] - 20s 616us/sample - loss: 1.4484 - val_loss: 1.3921\n",
      "Epoch 29/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 29: val_loss improved from 1.38949 to 1.38678, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 621us/sample - loss: 1.4420 - val_loss: 1.3868\n",
      "Epoch 30/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4402\n",
      "Epoch 30: val_loss did not improve from 1.38678\n",
      "32553/32553 [==============================] - 20s 612us/sample - loss: 1.4402 - val_loss: 1.3886\n",
      "Epoch 31/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4392\n",
      "Epoch 31: val_loss did not improve from 1.38678\n",
      "32553/32553 [==============================] - 20s 616us/sample - loss: 1.4392 - val_loss: 1.3901\n",
      "Epoch 32/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4362\n",
      "Epoch 32: val_loss improved from 1.38678 to 1.38414, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 628us/sample - loss: 1.4362 - val_loss: 1.3841\n",
      "Epoch 33/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 33: val_loss did not improve from 1.38414\n",
      "32553/32553 [==============================] - 22s 674us/sample - loss: 1.4334 - val_loss: 1.3911\n",
      "Epoch 34/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4298\n",
      "Epoch 34: val_loss improved from 1.38414 to 1.38316, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 652us/sample - loss: 1.4298 - val_loss: 1.3832\n",
      "Epoch 35/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 35: val_loss improved from 1.38316 to 1.38071, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 624us/sample - loss: 1.4269 - val_loss: 1.3807\n",
      "Epoch 36/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4256\n",
      "Epoch 36: val_loss did not improve from 1.38071\n",
      "32553/32553 [==============================] - 20s 614us/sample - loss: 1.4256 - val_loss: 1.3817\n",
      "Epoch 37/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4235\n",
      "Epoch 37: val_loss improved from 1.38071 to 1.37679, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 22s 680us/sample - loss: 1.4235 - val_loss: 1.3768\n",
      "Epoch 38/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 38: val_loss did not improve from 1.37679\n",
      "32553/32553 [==============================] - 20s 620us/sample - loss: 1.4246 - val_loss: 1.3806\n",
      "Epoch 39/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4181\n",
      "Epoch 39: val_loss improved from 1.37679 to 1.37027, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 658us/sample - loss: 1.4181 - val_loss: 1.3703\n",
      "Epoch 40/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 40: val_loss improved from 1.37027 to 1.37019, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 639us/sample - loss: 1.4206 - val_loss: 1.3702\n",
      "Epoch 41/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4169\n",
      "Epoch 41: val_loss did not improve from 1.37019\n",
      "32553/32553 [==============================] - 22s 671us/sample - loss: 1.4169 - val_loss: 1.3706\n",
      "Epoch 42/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 42: val_loss improved from 1.37019 to 1.37002, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 23s 702us/sample - loss: 1.4155 - val_loss: 1.3700\n",
      "Epoch 43/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 43: val_loss improved from 1.37002 to 1.36709, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 638us/sample - loss: 1.4117 - val_loss: 1.3671\n",
      "Epoch 44/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4104\n",
      "Epoch 44: val_loss did not improve from 1.36709\n",
      "32553/32553 [==============================] - 23s 714us/sample - loss: 1.4104 - val_loss: 1.3698\n",
      "Epoch 45/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4119\n",
      "Epoch 45: val_loss did not improve from 1.36709\n",
      "32553/32553 [==============================] - 22s 680us/sample - loss: 1.4119 - val_loss: 1.3741\n",
      "Epoch 46/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4112\n",
      "Epoch 46: val_loss did not improve from 1.36709\n",
      "32553/32553 [==============================] - 20s 608us/sample - loss: 1.4112 - val_loss: 1.3674\n",
      "Epoch 47/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 47: val_loss improved from 1.36709 to 1.36510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_43.h5\n",
      "32553/32553 [==============================] - 21s 630us/sample - loss: 1.4097 - val_loss: 1.3651\n",
      "Epoch 48/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4071\n",
      "Epoch 48: val_loss did not improve from 1.36510\n",
      "32553/32553 [==============================] - 20s 610us/sample - loss: 1.4071 - val_loss: 1.3672\n",
      "Epoch 49/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 49: val_loss did not improve from 1.36510\n",
      "32553/32553 [==============================] - 20s 614us/sample - loss: 1.4050 - val_loss: 1.3687\n",
      "Epoch 50/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4053\n",
      "Epoch 50: val_loss did not improve from 1.36510\n",
      "32553/32553 [==============================] - 20s 613us/sample - loss: 1.4053 - val_loss: 1.3687\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:58:04.010869: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_496_1/lstm_cell_1495/kernel/Assign' id:762586 op device:{requested: '', assigned: ''} def:{{{node lstm_496_1/lstm_cell_1495/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_496_1/lstm_cell_1495/kernel, lstm_496_1/lstm_cell_1495/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:58:46.040430: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_498_1/lstm_cell_1497/bias/m/Assign' id:767063 op device:{requested: '', assigned: ''} def:{{{node lstm_498_1/lstm_cell_1497/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_498_1/lstm_cell_1497/bias/m, lstm_498_1/lstm_cell_1497/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 16:59:28.206742: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_69_1/cond/Merge' id:766137 op device:{requested: '', assigned: ''} def:{{{node dropout_69_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_69_1/cond/Identity, dropout_69_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 839)\n",
      "(1692, 839)\n",
      "(1704, 839)\n",
      "(1860, 839)\n",
      "(1725, 839)\n",
      "(1370, 839)\n",
      "(1823, 839)\n",
      "(1570, 839)\n",
      "(1728, 839)\n",
      "(1538, 839)\n",
      "(1896, 839)\n",
      "(1727, 839)\n",
      "(1776, 839)\n",
      "(1848, 839)\n",
      "(1776, 839)\n",
      "(1788, 839)\n",
      "(958, 839)\n",
      "(1704, 839)\n",
      "(1860, 839)\n",
      "{1: 7.463813802955038, 4: 8.138481473547472, 5: 4.732298150686923, 6: 3.958561835234761, 8: 9.040315990006802, 9: 10.0, 10: 6.575800032705224, 11: 6.867608724563786, 12: 9.173830810258714, 13: 7.465175444150545, 17: 8.979593486395478, 19: 6.811684552927318, 21: 9.19670391624018, 22: 1.0, 25: 7.503230937537034, 26: 7.573826660942437, 27: 6.464402633993802, 28: 5.341240651438741, 29: 1.8063839971048732}\n",
      "Train on 32553 samples, validate on 3609 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:07:37.952646: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 10.7942\n",
      "Epoch 1: val_loss improved from inf to 1.39659, saving model to ./checkpoints/unknown_person_few_shot_p2_43.h5\n",
      "32553/32553 [==============================] - 97s 3ms/sample - loss: 10.7942 - val_loss: 1.3966\n",
      "Epoch 2/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.6794\n",
      "Epoch 2: val_loss improved from 1.39659 to 1.36975, saving model to ./checkpoints/unknown_person_few_shot_p2_43.h5\n",
      "32553/32553 [==============================] - 23s 721us/sample - loss: 10.6794 - val_loss: 1.3698\n",
      "Epoch 3/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.6410\n",
      "Epoch 3: val_loss did not improve from 1.36975\n",
      "32553/32553 [==============================] - 22s 691us/sample - loss: 10.6410 - val_loss: 1.3700\n",
      "Epoch 4/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.5603\n",
      "Epoch 4: val_loss did not improve from 1.36975\n",
      "32553/32553 [==============================] - 20s 610us/sample - loss: 10.5603 - val_loss: 1.3814\n",
      "Epoch 5/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.5153\n",
      "Epoch 5: val_loss improved from 1.36975 to 1.36411, saving model to ./checkpoints/unknown_person_few_shot_p2_43.h5\n",
      "32553/32553 [==============================] - 23s 696us/sample - loss: 10.5153 - val_loss: 1.3641\n",
      "Epoch 6/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4901\n",
      "Epoch 6: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 626us/sample - loss: 10.4901 - val_loss: 1.3688\n",
      "Epoch 7/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4747\n",
      "Epoch 7: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 23s 692us/sample - loss: 10.4747 - val_loss: 1.3712\n",
      "Epoch 8/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4515\n",
      "Epoch 8: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 10.4515 - val_loss: 1.3728\n",
      "Epoch 9/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4651\n",
      "Epoch 9: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 22s 687us/sample - loss: 10.4651 - val_loss: 1.3668\n",
      "Epoch 10/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4196\n",
      "Epoch 10: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 623us/sample - loss: 10.4196 - val_loss: 1.3683\n",
      "Epoch 11/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4213\n",
      "Epoch 11: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 614us/sample - loss: 10.4213 - val_loss: 1.3735\n",
      "Epoch 12/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.4036\n",
      "Epoch 12: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 611us/sample - loss: 10.4036 - val_loss: 1.3779\n",
      "Epoch 13/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3925\n",
      "Epoch 13: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 615us/sample - loss: 10.3925 - val_loss: 1.3742\n",
      "Epoch 14/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3854\n",
      "Epoch 14: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 621us/sample - loss: 10.3854 - val_loss: 1.3693\n",
      "Epoch 15/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3777\n",
      "Epoch 15: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 619us/sample - loss: 10.3777 - val_loss: 1.3682\n",
      "Epoch 16/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3494\n",
      "Epoch 16: val_loss did not improve from 1.36411\n",
      "32553/32553 [==============================] - 20s 619us/sample - loss: 10.3494 - val_loss: 1.3683\n",
      "Epoch 17/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3534\n",
      "Epoch 17: val_loss improved from 1.36411 to 1.35708, saving model to ./checkpoints/unknown_person_few_shot_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 616us/sample - loss: 10.3534 - val_loss: 1.3571\n",
      "Epoch 18/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3460\n",
      "Epoch 18: val_loss improved from 1.35708 to 1.35403, saving model to ./checkpoints/unknown_person_few_shot_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 613us/sample - loss: 10.3460 - val_loss: 1.3540\n",
      "Epoch 19/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3200\n",
      "Epoch 19: val_loss did not improve from 1.35403\n",
      "32553/32553 [==============================] - 22s 676us/sample - loss: 10.3200 - val_loss: 1.3584\n",
      "Epoch 20/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.3061\n",
      "Epoch 20: val_loss did not improve from 1.35403\n",
      "32553/32553 [==============================] - 23s 701us/sample - loss: 10.3061 - val_loss: 1.3622\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:16:13.855021: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_491_2/lstm_cell_1527/kernel/Assign' id:781184 op device:{requested: '', assigned: ''} def:{{{node lstm_491_2/lstm_cell_1527/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_491_2/lstm_cell_1527/kernel, lstm_491_2/lstm_cell_1527/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:16:56.045076: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_502_2/lstm_cell_1538/kernel/m/Assign' id:786511 op device:{requested: '', assigned: ''} def:{{{node lstm_502_2/lstm_cell_1538/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_502_2/lstm_cell_1538/kernel/m, lstm_502_2/lstm_cell_1538/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32553 samples, validate on 3609 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:17:40.743271: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:21:19.213569: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:21:44.401374: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36772, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 99s 3ms/sample - loss: 1.4072 - val_loss: 1.3677\n",
      "Epoch 2/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4039\n",
      "Epoch 2: val_loss improved from 1.36772 to 1.36586, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 621us/sample - loss: 1.4039 - val_loss: 1.3659\n",
      "Epoch 3/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4043\n",
      "Epoch 3: val_loss improved from 1.36586 to 1.36417, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 622us/sample - loss: 1.4043 - val_loss: 1.3642\n",
      "Epoch 4/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4016\n",
      "Epoch 4: val_loss improved from 1.36417 to 1.36125, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 628us/sample - loss: 1.4016 - val_loss: 1.3613\n",
      "Epoch 5/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 5: val_loss did not improve from 1.36125\n",
      "32553/32553 [==============================] - 20s 608us/sample - loss: 1.3996 - val_loss: 1.3631\n",
      "Epoch 6/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 6: val_loss did not improve from 1.36125\n",
      "32553/32553 [==============================] - 20s 617us/sample - loss: 1.4001 - val_loss: 1.3697\n",
      "Epoch 7/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 7: val_loss improved from 1.36125 to 1.35601, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 629us/sample - loss: 1.3975 - val_loss: 1.3560\n",
      "Epoch 8/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 8: val_loss did not improve from 1.35601\n",
      "32553/32553 [==============================] - 23s 696us/sample - loss: 1.3977 - val_loss: 1.3634\n",
      "Epoch 9/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 9: val_loss did not improve from 1.35601\n",
      "32553/32553 [==============================] - 23s 705us/sample - loss: 1.3949 - val_loss: 1.3589\n",
      "Epoch 10/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 10: val_loss did not improve from 1.35601\n",
      "32553/32553 [==============================] - 23s 712us/sample - loss: 1.3935 - val_loss: 1.3575\n",
      "Epoch 11/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3915\n",
      "Epoch 11: val_loss improved from 1.35601 to 1.35380, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 627us/sample - loss: 1.3915 - val_loss: 1.3538\n",
      "Epoch 12/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3920\n",
      "Epoch 12: val_loss did not improve from 1.35380\n",
      "32553/32553 [==============================] - 19s 595us/sample - loss: 1.3920 - val_loss: 1.3608\n",
      "Epoch 13/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3916\n",
      "Epoch 13: val_loss did not improve from 1.35380\n",
      "32553/32553 [==============================] - 20s 601us/sample - loss: 1.3916 - val_loss: 1.3558\n",
      "Epoch 14/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3883\n",
      "Epoch 14: val_loss did not improve from 1.35380\n",
      "32553/32553 [==============================] - 22s 663us/sample - loss: 1.3883 - val_loss: 1.3569\n",
      "Epoch 15/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3848\n",
      "Epoch 15: val_loss did not improve from 1.35380\n",
      "32553/32553 [==============================] - 19s 594us/sample - loss: 1.3848 - val_loss: 1.3551\n",
      "Epoch 16/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3871\n",
      "Epoch 16: val_loss did not improve from 1.35380\n",
      "32553/32553 [==============================] - 19s 596us/sample - loss: 1.3871 - val_loss: 1.3584\n",
      "Epoch 17/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3878\n",
      "Epoch 17: val_loss improved from 1.35380 to 1.34978, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_43.h5\n",
      "32553/32553 [==============================] - 20s 608us/sample - loss: 1.3878 - val_loss: 1.3498\n",
      "Epoch 18/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3851\n",
      "Epoch 18: val_loss did not improve from 1.34978\n",
      "32553/32553 [==============================] - 22s 669us/sample - loss: 1.3851 - val_loss: 1.3575\n",
      "Epoch 19/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3851\n",
      "Epoch 19: val_loss did not improve from 1.34978\n",
      "32553/32553 [==============================] - 22s 682us/sample - loss: 1.3851 - val_loss: 1.3577\n",
      "Epoch 20/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3831\n",
      "Epoch 20: val_loss did not improve from 1.34978\n",
      "32553/32553 [==============================] - 23s 702us/sample - loss: 1.3831 - val_loss: 1.3518\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:29:50.627410: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_522/lstm_cell_1558/bias/Assign' id:799295 op device:{requested: '', assigned: ''} def:{{{node lstm_522/lstm_cell_1558/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_522/lstm_cell_1558/bias, lstm_522/lstm_cell_1558/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:30:14.304599: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_1' id:802224 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:30:33.295354: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_2' id:802225 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32553, 95)\n",
      "Train on 32553 samples, validate on 3609 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:31:15.887545: W tensorflow/c/c_api.cc:304] Operation '{name:'training_84/Adam/conv2d_57/bias/m/Assign' id:814957 op device:{requested: '', assigned: ''} def:{{{node training_84/Adam/conv2d_57/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_84/Adam/conv2d_57/bias/m, training_84/Adam/conv2d_57/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:35:02.912417: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 2.8241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:35:28.504723: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_85/mul' id:805065 op device:{requested: '', assigned: ''} def:{{{node loss_85/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_85/mul/x, loss_85/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.78969, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 235s 7ms/sample - loss: 2.8241 - val_loss: 1.7897\n",
      "Epoch 2/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.7579\n",
      "Epoch 2: val_loss improved from 1.78969 to 1.57256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 746us/sample - loss: 1.7579 - val_loss: 1.5726\n",
      "Epoch 3/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.6120\n",
      "Epoch 3: val_loss improved from 1.57256 to 1.49926, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 737us/sample - loss: 1.6120 - val_loss: 1.4993\n",
      "Epoch 4/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5562\n",
      "Epoch 4: val_loss improved from 1.49926 to 1.47030, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 22s 685us/sample - loss: 1.5562 - val_loss: 1.4703\n",
      "Epoch 5/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5275\n",
      "Epoch 5: val_loss improved from 1.47030 to 1.45068, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 22s 671us/sample - loss: 1.5275 - val_loss: 1.4507\n",
      "Epoch 6/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5135\n",
      "Epoch 6: val_loss improved from 1.45068 to 1.44374, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 22s 666us/sample - loss: 1.5135 - val_loss: 1.4437\n",
      "Epoch 7/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4996\n",
      "Epoch 7: val_loss improved from 1.44374 to 1.42502, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 648us/sample - loss: 1.4996 - val_loss: 1.4250\n",
      "Epoch 8/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4929\n",
      "Epoch 8: val_loss improved from 1.42502 to 1.42457, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 635us/sample - loss: 1.4929 - val_loss: 1.4246\n",
      "Epoch 9/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4875\n",
      "Epoch 9: val_loss improved from 1.42457 to 1.41948, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 639us/sample - loss: 1.4875 - val_loss: 1.4195\n",
      "Epoch 10/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4851\n",
      "Epoch 10: val_loss improved from 1.41948 to 1.41072, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 636us/sample - loss: 1.4851 - val_loss: 1.4107\n",
      "Epoch 11/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 11: val_loss did not improve from 1.41072\n",
      "32553/32553 [==============================] - 22s 691us/sample - loss: 1.4836 - val_loss: 1.4123\n",
      "Epoch 12/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5524\n",
      "Epoch 12: val_loss did not improve from 1.41072\n",
      "32553/32553 [==============================] - 23s 709us/sample - loss: 1.5524 - val_loss: 1.4234\n",
      "Epoch 13/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4932\n",
      "Epoch 13: val_loss did not improve from 1.41072\n",
      "32553/32553 [==============================] - 23s 710us/sample - loss: 1.4932 - val_loss: 1.4153\n",
      "Epoch 14/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5013\n",
      "Epoch 14: val_loss improved from 1.41072 to 1.40985, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 721us/sample - loss: 1.5013 - val_loss: 1.4098\n",
      "Epoch 15/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5111\n",
      "Epoch 15: val_loss improved from 1.40985 to 1.40749, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 720us/sample - loss: 1.5111 - val_loss: 1.4075\n",
      "Epoch 16/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4858\n",
      "Epoch 16: val_loss improved from 1.40749 to 1.40718, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 692us/sample - loss: 1.4858 - val_loss: 1.4072\n",
      "Epoch 17/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4809\n",
      "Epoch 17: val_loss improved from 1.40718 to 1.40149, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 644us/sample - loss: 1.4809 - val_loss: 1.4015\n",
      "Epoch 18/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4931\n",
      "Epoch 18: val_loss did not improve from 1.40149\n",
      "32553/32553 [==============================] - 21s 634us/sample - loss: 1.4931 - val_loss: 1.4058\n",
      "Epoch 19/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5011\n",
      "Epoch 19: val_loss did not improve from 1.40149\n",
      "32553/32553 [==============================] - 20s 625us/sample - loss: 1.5011 - val_loss: 1.4028\n",
      "Epoch 20/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.5214\n",
      "Epoch 20: val_loss improved from 1.40149 to 1.40070, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 633us/sample - loss: 1.5214 - val_loss: 1.4007\n",
      "Epoch 21/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4997\n",
      "Epoch 21: val_loss did not improve from 1.40070\n",
      "32553/32553 [==============================] - 20s 619us/sample - loss: 1.4997 - val_loss: 1.4012\n",
      "Epoch 22/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4883\n",
      "Epoch 22: val_loss did not improve from 1.40070\n",
      "32553/32553 [==============================] - 20s 618us/sample - loss: 1.4883 - val_loss: 1.4022\n",
      "Epoch 23/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4970\n",
      "Epoch 23: val_loss did not improve from 1.40070\n",
      "32553/32553 [==============================] - 20s 620us/sample - loss: 1.4970 - val_loss: 1.4047\n",
      "Epoch 24/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4930\n",
      "Epoch 24: val_loss did not improve from 1.40070\n",
      "32553/32553 [==============================] - 20s 618us/sample - loss: 1.4930 - val_loss: 1.4093\n",
      "Epoch 25/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4713\n",
      "Epoch 25: val_loss did not improve from 1.40070\n",
      "32553/32553 [==============================] - 23s 706us/sample - loss: 1.4713 - val_loss: 1.4039\n",
      "Epoch 26/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4589\n",
      "Epoch 26: val_loss improved from 1.40070 to 1.39798, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 644us/sample - loss: 1.4589 - val_loss: 1.3980\n",
      "Epoch 27/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4588\n",
      "Epoch 27: val_loss did not improve from 1.39798\n",
      "32553/32553 [==============================] - 23s 709us/sample - loss: 1.4588 - val_loss: 1.4011\n",
      "Epoch 28/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4524\n",
      "Epoch 28: val_loss improved from 1.39798 to 1.39633, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 20s 617us/sample - loss: 1.4524 - val_loss: 1.3963\n",
      "Epoch 29/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4497\n",
      "Epoch 29: val_loss did not improve from 1.39633\n",
      "32553/32553 [==============================] - 20s 610us/sample - loss: 1.4497 - val_loss: 1.4007\n",
      "Epoch 30/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4502\n",
      "Epoch 30: val_loss did not improve from 1.39633\n",
      "32553/32553 [==============================] - 20s 605us/sample - loss: 1.4502 - val_loss: 1.3968\n",
      "Epoch 31/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4456\n",
      "Epoch 31: val_loss improved from 1.39633 to 1.39623, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 20s 616us/sample - loss: 1.4456 - val_loss: 1.3962\n",
      "Epoch 32/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4422\n",
      "Epoch 32: val_loss improved from 1.39623 to 1.39489, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 20s 613us/sample - loss: 1.4422 - val_loss: 1.3949\n",
      "Epoch 33/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4431\n",
      "Epoch 33: val_loss improved from 1.39489 to 1.39134, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 633us/sample - loss: 1.4431 - val_loss: 1.3913\n",
      "Epoch 34/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4365\n",
      "Epoch 34: val_loss improved from 1.39134 to 1.38993, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 739us/sample - loss: 1.4365 - val_loss: 1.3899\n",
      "Epoch 35/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 35: val_loss improved from 1.38993 to 1.38974, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 735us/sample - loss: 1.4354 - val_loss: 1.3897\n",
      "Epoch 36/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 36: val_loss improved from 1.38974 to 1.38779, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 735us/sample - loss: 1.4349 - val_loss: 1.3878\n",
      "Epoch 37/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4314\n",
      "Epoch 37: val_loss did not improve from 1.38779\n",
      "32553/32553 [==============================] - 24s 726us/sample - loss: 1.4314 - val_loss: 1.3922\n",
      "Epoch 38/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 38: val_loss did not improve from 1.38779\n",
      "32553/32553 [==============================] - 24s 725us/sample - loss: 1.4346 - val_loss: 1.3891\n",
      "Epoch 39/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4313\n",
      "Epoch 39: val_loss improved from 1.38779 to 1.38674, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 735us/sample - loss: 1.4313 - val_loss: 1.3867\n",
      "Epoch 40/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 40: val_loss improved from 1.38674 to 1.38607, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 737us/sample - loss: 1.4305 - val_loss: 1.3861\n",
      "Epoch 41/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 41: val_loss did not improve from 1.38607\n",
      "32553/32553 [==============================] - 23s 714us/sample - loss: 1.4275 - val_loss: 1.3876\n",
      "Epoch 42/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4264\n",
      "Epoch 42: val_loss improved from 1.38607 to 1.38352, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 730us/sample - loss: 1.4264 - val_loss: 1.3835\n",
      "Epoch 43/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 43: val_loss did not improve from 1.38352\n",
      "32553/32553 [==============================] - 21s 642us/sample - loss: 1.4242 - val_loss: 1.3862\n",
      "Epoch 44/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4221\n",
      "Epoch 44: val_loss did not improve from 1.38352\n",
      "32553/32553 [==============================] - 21s 642us/sample - loss: 1.4221 - val_loss: 1.3872\n",
      "Epoch 45/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4200\n",
      "Epoch 45: val_loss improved from 1.38352 to 1.37942, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 653us/sample - loss: 1.4200 - val_loss: 1.3794\n",
      "Epoch 46/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4212\n",
      "Epoch 46: val_loss did not improve from 1.37942\n",
      "32553/32553 [==============================] - 22s 666us/sample - loss: 1.4212 - val_loss: 1.3849\n",
      "Epoch 47/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 47: val_loss did not improve from 1.37942\n",
      "32553/32553 [==============================] - 23s 711us/sample - loss: 1.4186 - val_loss: 1.3807\n",
      "Epoch 48/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4160\n",
      "Epoch 48: val_loss did not improve from 1.37942\n",
      "32553/32553 [==============================] - 23s 714us/sample - loss: 1.4160 - val_loss: 1.3862\n",
      "Epoch 49/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 49: val_loss improved from 1.37942 to 1.37751, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 22s 671us/sample - loss: 1.4176 - val_loss: 1.3775\n",
      "Epoch 50/50\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4152\n",
      "Epoch 50: val_loss improved from 1.37751 to 1.37716, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 1.4152 - val_loss: 1.3772\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:57:11.798501: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_522_1/lstm_cell_1595/bias/Assign' id:817897 op device:{requested: '', assigned: ''} def:{{{node lstm_522_1/lstm_cell_1595/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_522_1/lstm_cell_1595/bias, lstm_522_1/lstm_cell_1595/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:57:57.205992: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_58_1/kernel/m/Assign' id:823820 op device:{requested: '', assigned: ''} def:{{{node conv2d_58_1/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_58_1/kernel/m, conv2d_58_1/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 17:58:42.433212: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_74_1/cond/Merge' id:823179 op device:{requested: '', assigned: ''} def:{{{node dropout_74_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_74_1/cond/Identity, dropout_74_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 839)\n",
      "(1692, 839)\n",
      "(1704, 839)\n",
      "(1860, 839)\n",
      "(1725, 839)\n",
      "(1370, 839)\n",
      "(1823, 839)\n",
      "(1570, 839)\n",
      "(1728, 839)\n",
      "(1538, 839)\n",
      "(1896, 839)\n",
      "(1727, 839)\n",
      "(1776, 839)\n",
      "(1848, 839)\n",
      "(1776, 839)\n",
      "(1788, 839)\n",
      "(958, 839)\n",
      "(1704, 839)\n",
      "(1860, 839)\n",
      "{1: 8.139931221312658, 4: 8.534493237708167, 5: 5.0881702938713085, 6: 3.5297463789381336, 8: 9.07127909832771, 9: 10.0, 10: 6.760331893466748, 11: 7.10952434333266, 12: 9.977797552106267, 13: 8.034271402380355, 17: 9.793715676372438, 19: 7.358684776588876, 21: 9.732048515038487, 22: 1.0, 25: 8.3979823138134, 26: 8.46222805005495, 27: 6.620052411551682, 28: 6.071718874695446, 29: 1.245702305613143}\n",
      "Train on 32553 samples, validate on 3609 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:06:35.004231: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 11.3104\n",
      "Epoch 1: val_loss improved from inf to 1.39451, saving model to ./checkpoints/unknown_person_few_shot_p2_44.h5\n",
      "32553/32553 [==============================] - 101s 3ms/sample - loss: 11.3104 - val_loss: 1.3945\n",
      "Epoch 2/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.2270\n",
      "Epoch 2: val_loss did not improve from 1.39451\n",
      "32553/32553 [==============================] - 20s 626us/sample - loss: 11.2270 - val_loss: 1.3961\n",
      "Epoch 3/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.2002\n",
      "Epoch 3: val_loss did not improve from 1.39451\n",
      "32553/32553 [==============================] - 20s 624us/sample - loss: 11.2002 - val_loss: 1.4225\n",
      "Epoch 4/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0939\n",
      "Epoch 4: val_loss improved from 1.39451 to 1.38079, saving model to ./checkpoints/unknown_person_few_shot_p2_44.h5\n",
      "32553/32553 [==============================] - 20s 626us/sample - loss: 11.0939 - val_loss: 1.3808\n",
      "Epoch 5/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0690\n",
      "Epoch 5: val_loss did not improve from 1.38079\n",
      "32553/32553 [==============================] - 20s 614us/sample - loss: 11.0690 - val_loss: 1.3842\n",
      "Epoch 6/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0544\n",
      "Epoch 6: val_loss improved from 1.38079 to 1.37491, saving model to ./checkpoints/unknown_person_few_shot_p2_44.h5\n",
      "32553/32553 [==============================] - 20s 624us/sample - loss: 11.0544 - val_loss: 1.3749\n",
      "Epoch 7/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9911\n",
      "Epoch 7: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 21s 655us/sample - loss: 10.9911 - val_loss: 1.3793\n",
      "Epoch 8/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 11.0045\n",
      "Epoch 8: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 20s 624us/sample - loss: 11.0045 - val_loss: 1.3827\n",
      "Epoch 9/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9837\n",
      "Epoch 9: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 21s 657us/sample - loss: 10.9837 - val_loss: 1.3772\n",
      "Epoch 10/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9520\n",
      "Epoch 10: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 23s 712us/sample - loss: 10.9520 - val_loss: 1.3882\n",
      "Epoch 11/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9427\n",
      "Epoch 11: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 23s 720us/sample - loss: 10.9427 - val_loss: 1.3760\n",
      "Epoch 12/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9763\n",
      "Epoch 12: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 23s 719us/sample - loss: 10.9763 - val_loss: 1.3873\n",
      "Epoch 13/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9218\n",
      "Epoch 13: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 23s 712us/sample - loss: 10.9218 - val_loss: 1.3815\n",
      "Epoch 14/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.9122\n",
      "Epoch 14: val_loss did not improve from 1.37491\n",
      "32553/32553 [==============================] - 23s 717us/sample - loss: 10.9122 - val_loss: 1.3853\n",
      "Epoch 15/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.8893\n",
      "Epoch 15: val_loss improved from 1.37491 to 1.36956, saving model to ./checkpoints/unknown_person_few_shot_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 718us/sample - loss: 10.8893 - val_loss: 1.3696\n",
      "Epoch 16/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.8994\n",
      "Epoch 16: val_loss did not improve from 1.36956\n",
      "32553/32553 [==============================] - 23s 719us/sample - loss: 10.8994 - val_loss: 1.3716\n",
      "Epoch 17/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.8769\n",
      "Epoch 17: val_loss did not improve from 1.36956\n",
      "32553/32553 [==============================] - 23s 716us/sample - loss: 10.8769 - val_loss: 1.3747\n",
      "Epoch 18/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.8811\n",
      "Epoch 18: val_loss did not improve from 1.36956\n",
      "32553/32553 [==============================] - 23s 708us/sample - loss: 10.8811 - val_loss: 1.3705\n",
      "Epoch 19/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.8664\n",
      "Epoch 19: val_loss did not improve from 1.36956\n",
      "32553/32553 [==============================] - 23s 716us/sample - loss: 10.8664 - val_loss: 1.3735\n",
      "Epoch 20/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 10.8354\n",
      "Epoch 20: val_loss did not improve from 1.36956\n",
      "32553/32553 [==============================] - 23s 707us/sample - loss: 10.8354 - val_loss: 1.3706\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:15:33.915057: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_541_2/lstm_cell_1651/recurrent_kernel/Assign' id:840328 op device:{requested: '', assigned: ''} def:{{{node lstm_541_2/lstm_cell_1651/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_541_2/lstm_cell_1651/recurrent_kernel, lstm_541_2/lstm_cell_1651/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:16:18.824968: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_548_2/lstm_cell_1658/bias/v/Assign' id:844341 op device:{requested: '', assigned: ''} def:{{{node lstm_548_2/lstm_cell_1658/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_548_2/lstm_cell_1658/bias/v, lstm_548_2/lstm_cell_1658/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32553 samples, validate on 3609 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:17:06.354770: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:21:02.201574: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:21:28.492989: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.37686, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 108s 3ms/sample - loss: 1.4137 - val_loss: 1.3769\n",
      "Epoch 2/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4089\n",
      "Epoch 2: val_loss improved from 1.37686 to 1.37478, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 736us/sample - loss: 1.4089 - val_loss: 1.3748\n",
      "Epoch 3/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4077\n",
      "Epoch 3: val_loss improved from 1.37478 to 1.37460, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 655us/sample - loss: 1.4077 - val_loss: 1.3746\n",
      "Epoch 4/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 4: val_loss did not improve from 1.37460\n",
      "32553/32553 [==============================] - 21s 635us/sample - loss: 1.4080 - val_loss: 1.3750\n",
      "Epoch 5/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4052\n",
      "Epoch 5: val_loss improved from 1.37460 to 1.37098, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 634us/sample - loss: 1.4052 - val_loss: 1.3710\n",
      "Epoch 6/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4035\n",
      "Epoch 6: val_loss did not improve from 1.37098\n",
      "32553/32553 [==============================] - 23s 696us/sample - loss: 1.4035 - val_loss: 1.3715\n",
      "Epoch 7/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4022\n",
      "Epoch 7: val_loss improved from 1.37098 to 1.37034, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 634us/sample - loss: 1.4022 - val_loss: 1.3703\n",
      "Epoch 8/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4027\n",
      "Epoch 8: val_loss improved from 1.37034 to 1.36782, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 24s 723us/sample - loss: 1.4027 - val_loss: 1.3678\n",
      "Epoch 9/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 9: val_loss improved from 1.36782 to 1.36702, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 713us/sample - loss: 1.4008 - val_loss: 1.3670\n",
      "Epoch 10/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 10: val_loss improved from 1.36702 to 1.36601, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 705us/sample - loss: 1.3975 - val_loss: 1.3660\n",
      "Epoch 11/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3955\n",
      "Epoch 11: val_loss improved from 1.36601 to 1.36572, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 694us/sample - loss: 1.3955 - val_loss: 1.3657\n",
      "Epoch 12/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3944\n",
      "Epoch 12: val_loss improved from 1.36572 to 1.36049, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 720us/sample - loss: 1.3944 - val_loss: 1.3605\n",
      "Epoch 13/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 13: val_loss did not improve from 1.36049\n",
      "32553/32553 [==============================] - 23s 709us/sample - loss: 1.3965 - val_loss: 1.3620\n",
      "Epoch 14/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3916\n",
      "Epoch 14: val_loss did not improve from 1.36049\n",
      "32553/32553 [==============================] - 23s 703us/sample - loss: 1.3916 - val_loss: 1.3613\n",
      "Epoch 15/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3899\n",
      "Epoch 15: val_loss improved from 1.36049 to 1.36025, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 23s 715us/sample - loss: 1.3899 - val_loss: 1.3603\n",
      "Epoch 16/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 16: val_loss did not improve from 1.36025\n",
      "32553/32553 [==============================] - 23s 705us/sample - loss: 1.3917 - val_loss: 1.3611\n",
      "Epoch 17/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3897\n",
      "Epoch 17: val_loss did not improve from 1.36025\n",
      "32553/32553 [==============================] - 23s 705us/sample - loss: 1.3897 - val_loss: 1.3614\n",
      "Epoch 18/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 18: val_loss improved from 1.36025 to 1.35914, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 22s 686us/sample - loss: 1.3887 - val_loss: 1.3591\n",
      "Epoch 19/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3867\n",
      "Epoch 19: val_loss improved from 1.35914 to 1.35599, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_44.h5\n",
      "32553/32553 [==============================] - 21s 635us/sample - loss: 1.3867 - val_loss: 1.3560\n",
      "Epoch 20/20\n",
      "32553/32553 [==============================] - ETA: 0s - loss: 1.3840\n",
      "Epoch 20: val_loss did not improve from 1.35599\n",
      "32553/32553 [==============================] - 20s 623us/sample - loss: 1.3840 - val_loss: 1.3620\n",
      "36327\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:30:20.617894: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_575/lstm_cell_1685/recurrent_kernel/Assign' id:858968 op device:{requested: '', assigned: ''} def:{{{node lstm_575/lstm_cell_1685/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_575/lstm_cell_1685/recurrent_kernel, lstm_575/lstm_cell_1685/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:30:45.574488: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_1' id:859266 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:31:05.812108: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_2' id:859267 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32683, 95)\n",
      "Train on 32683 samples, validate on 3644 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:31:50.719296: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_590/lstm_cell_1700/recurrent_kernel/Assign' id:861672 op device:{requested: '', assigned: ''} def:{{{node lstm_590/lstm_cell_1700/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_590/lstm_cell_1700/recurrent_kernel, lstm_590/lstm_cell_1700/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:35:51.643653: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 2.7208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-18 18:36:14.642034: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_91/mul' id:862107 op device:{requested: '', assigned: ''} def:{{{node loss_91/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_91/mul/x, loss_91/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.81720, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 239s 7ms/sample - loss: 2.7208 - val_loss: 1.8172\n",
      "Epoch 2/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.7310\n",
      "Epoch 2: val_loss improved from 1.81720 to 1.53412, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 612us/sample - loss: 1.7310 - val_loss: 1.5341\n",
      "Epoch 3/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5931\n",
      "Epoch 3: val_loss improved from 1.53412 to 1.47733, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 22s 674us/sample - loss: 1.5931 - val_loss: 1.4773\n",
      "Epoch 4/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5438\n",
      "Epoch 4: val_loss improved from 1.47733 to 1.44645, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 711us/sample - loss: 1.5438 - val_loss: 1.4465\n",
      "Epoch 5/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5213\n",
      "Epoch 5: val_loss improved from 1.44645 to 1.43226, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.5213 - val_loss: 1.4323\n",
      "Epoch 6/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5065\n",
      "Epoch 6: val_loss improved from 1.43226 to 1.42188, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 612us/sample - loss: 1.5065 - val_loss: 1.4219\n",
      "Epoch 7/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4991\n",
      "Epoch 7: val_loss improved from 1.42188 to 1.41702, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 607us/sample - loss: 1.4991 - val_loss: 1.4170\n",
      "Epoch 8/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4981\n",
      "Epoch 8: val_loss improved from 1.41702 to 1.41289, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 640us/sample - loss: 1.4981 - val_loss: 1.4129\n",
      "Epoch 9/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4899\n",
      "Epoch 9: val_loss improved from 1.41289 to 1.40892, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 708us/sample - loss: 1.4899 - val_loss: 1.4089\n",
      "Epoch 10/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 10: val_loss improved from 1.40892 to 1.40852, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 22s 688us/sample - loss: 1.4829 - val_loss: 1.4085\n",
      "Epoch 11/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4830\n",
      "Epoch 11: val_loss improved from 1.40852 to 1.40122, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 22s 665us/sample - loss: 1.4830 - val_loss: 1.4012\n",
      "Epoch 12/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4740\n",
      "Epoch 12: val_loss improved from 1.40122 to 1.39541, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 698us/sample - loss: 1.4740 - val_loss: 1.3954\n",
      "Epoch 13/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4852\n",
      "Epoch 13: val_loss did not improve from 1.39541\n",
      "32683/32683 [==============================] - 20s 617us/sample - loss: 1.4852 - val_loss: 1.3957\n",
      "Epoch 14/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5372\n",
      "Epoch 14: val_loss did not improve from 1.39541\n",
      "32683/32683 [==============================] - 20s 618us/sample - loss: 1.5372 - val_loss: 1.3976\n",
      "Epoch 15/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 15: val_loss improved from 1.39541 to 1.39003, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 628us/sample - loss: 1.4745 - val_loss: 1.3900\n",
      "Epoch 16/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4649\n",
      "Epoch 16: val_loss did not improve from 1.39003\n",
      "32683/32683 [==============================] - 21s 649us/sample - loss: 1.4649 - val_loss: 1.3924\n",
      "Epoch 17/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4643\n",
      "Epoch 17: val_loss did not improve from 1.39003\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 1.4643 - val_loss: 1.3913\n",
      "Epoch 18/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4719\n",
      "Epoch 18: val_loss improved from 1.39003 to 1.38906, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 24s 733us/sample - loss: 1.4719 - val_loss: 1.3891\n",
      "Epoch 19/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4577\n",
      "Epoch 19: val_loss improved from 1.38906 to 1.38485, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 24s 732us/sample - loss: 1.4577 - val_loss: 1.3848\n",
      "Epoch 20/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4910\n",
      "Epoch 20: val_loss did not improve from 1.38485\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 1.4910 - val_loss: 1.3920\n",
      "Epoch 21/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4636\n",
      "Epoch 21: val_loss did not improve from 1.38485\n",
      "32683/32683 [==============================] - 23s 698us/sample - loss: 1.4636 - val_loss: 1.3855\n",
      "Epoch 22/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4975\n",
      "Epoch 22: val_loss did not improve from 1.38485\n",
      "32683/32683 [==============================] - 21s 629us/sample - loss: 1.4975 - val_loss: 1.3879\n",
      "Epoch 23/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4638\n",
      "Epoch 23: val_loss did not improve from 1.38485\n",
      "32683/32683 [==============================] - 20s 619us/sample - loss: 1.4638 - val_loss: 1.3887\n",
      "Epoch 24/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4501\n",
      "Epoch 24: val_loss improved from 1.38485 to 1.37652, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 638us/sample - loss: 1.4501 - val_loss: 1.3765\n",
      "Epoch 25/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4480\n",
      "Epoch 25: val_loss improved from 1.37652 to 1.37327, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 621us/sample - loss: 1.4480 - val_loss: 1.3733\n",
      "Epoch 26/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4402\n",
      "Epoch 26: val_loss did not improve from 1.37327\n",
      "32683/32683 [==============================] - 20s 606us/sample - loss: 1.4402 - val_loss: 1.3746\n",
      "Epoch 27/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4350\n",
      "Epoch 27: val_loss did not improve from 1.37327\n",
      "32683/32683 [==============================] - 21s 636us/sample - loss: 1.4350 - val_loss: 1.3777\n",
      "Epoch 28/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4345\n",
      "Epoch 28: val_loss improved from 1.37327 to 1.37310, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 24s 719us/sample - loss: 1.4345 - val_loss: 1.3731\n",
      "Epoch 29/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4319\n",
      "Epoch 29: val_loss improved from 1.37310 to 1.37012, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 22s 681us/sample - loss: 1.4319 - val_loss: 1.3701\n",
      "Epoch 30/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 30: val_loss improved from 1.37012 to 1.36961, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 640us/sample - loss: 1.4308 - val_loss: 1.3696\n",
      "Epoch 31/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 31: val_loss improved from 1.36961 to 1.36513, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 618us/sample - loss: 1.4294 - val_loss: 1.3651\n",
      "Epoch 32/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4250\n",
      "Epoch 32: val_loss did not improve from 1.36513\n",
      "32683/32683 [==============================] - 20s 609us/sample - loss: 1.4250 - val_loss: 1.3721\n",
      "Epoch 33/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4229\n",
      "Epoch 33: val_loss did not improve from 1.36513\n",
      "32683/32683 [==============================] - 22s 686us/sample - loss: 1.4229 - val_loss: 1.3672\n",
      "Epoch 34/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4205\n",
      "Epoch 34: val_loss improved from 1.36513 to 1.36251, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 709us/sample - loss: 1.4205 - val_loss: 1.3625\n",
      "Epoch 35/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4201\n",
      "Epoch 35: val_loss did not improve from 1.36251\n",
      "32683/32683 [==============================] - 23s 700us/sample - loss: 1.4201 - val_loss: 1.3678\n",
      "Epoch 36/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 36: val_loss improved from 1.36251 to 1.36186, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 638us/sample - loss: 1.4173 - val_loss: 1.3619\n",
      "Epoch 37/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 37: val_loss did not improve from 1.36186\n",
      "32683/32683 [==============================] - 20s 616us/sample - loss: 1.4174 - val_loss: 1.3661\n",
      "Epoch 38/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 38: val_loss did not improve from 1.36186\n",
      "32683/32683 [==============================] - 20s 605us/sample - loss: 1.4158 - val_loss: 1.3657\n",
      "Epoch 39/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 39: val_loss improved from 1.36186 to 1.35611, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 635us/sample - loss: 1.4132 - val_loss: 1.3561\n",
      "Epoch 40/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4106\n",
      "Epoch 40: val_loss did not improve from 1.35611\n",
      "32683/32683 [==============================] - 23s 697us/sample - loss: 1.4106 - val_loss: 1.3602\n",
      "Epoch 41/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 41: val_loss did not improve from 1.35611\n",
      "32683/32683 [==============================] - 20s 621us/sample - loss: 1.4117 - val_loss: 1.3605\n",
      "Epoch 42/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4060\n",
      "Epoch 42: val_loss improved from 1.35611 to 1.35385, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 609us/sample - loss: 1.4060 - val_loss: 1.3539\n",
      "Epoch 43/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4047\n",
      "Epoch 43: val_loss did not improve from 1.35385\n",
      "32683/32683 [==============================] - 20s 616us/sample - loss: 1.4047 - val_loss: 1.3566\n",
      "Epoch 44/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4059\n",
      "Epoch 44: val_loss did not improve from 1.35385\n",
      "32683/32683 [==============================] - 20s 599us/sample - loss: 1.4059 - val_loss: 1.3586\n",
      "Epoch 45/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4028\n",
      "Epoch 45: val_loss improved from 1.35385 to 1.35184, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 609us/sample - loss: 1.4028 - val_loss: 1.3518\n",
      "Epoch 46/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4023\n",
      "Epoch 46: val_loss did not improve from 1.35184\n",
      "32683/32683 [==============================] - 20s 603us/sample - loss: 1.4023 - val_loss: 1.3547\n",
      "Epoch 47/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4012\n",
      "Epoch 47: val_loss did not improve from 1.35184\n",
      "32683/32683 [==============================] - 20s 602us/sample - loss: 1.4012 - val_loss: 1.3562\n",
      "Epoch 48/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 48: val_loss did not improve from 1.35184\n",
      "32683/32683 [==============================] - 20s 611us/sample - loss: 1.3995 - val_loss: 1.3535\n",
      "Epoch 49/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3982\n",
      "Epoch 49: val_loss improved from 1.35184 to 1.35111, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 617us/sample - loss: 1.3982 - val_loss: 1.3511\n",
      "Epoch 50/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 50: val_loss did not improve from 1.35111\n",
      "32683/32683 [==============================] - 20s 602us/sample - loss: 1.3984 - val_loss: 1.3540\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:57:28.624768: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_564_1/lstm_cell_1711/bias/Assign' id:875739 op device:{requested: '', assigned: ''} def:{{{node lstm_564_1/lstm_cell_1711/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_564_1/lstm_cell_1711/bias, lstm_564_1/lstm_cell_1711/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 18:58:15.821692: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_584_1/lstm_cell_1731/bias/v/Assign' id:881970 op device:{requested: '', assigned: ''} def:{{{node lstm_584_1/lstm_cell_1731/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_584_1/lstm_cell_1731/bias/v, lstm_584_1/lstm_cell_1731/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-18 18:59:02.824294: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_79_1/cond/Merge' id:880221 op device:{requested: '', assigned: ''} def:{{{node dropout_79_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_79_1/cond/Identity, dropout_79_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 674)\n",
      "(1704, 674)\n",
      "(1704, 674)\n",
      "(1848, 674)\n",
      "(1735, 674)\n",
      "(1346, 674)\n",
      "(1814, 674)\n",
      "(1570, 674)\n",
      "(1728, 674)\n",
      "(1538, 674)\n",
      "(1920, 674)\n",
      "(1727, 674)\n",
      "(1764, 674)\n",
      "(1848, 674)\n",
      "(1752, 674)\n",
      "(1800, 674)\n",
      "(946, 674)\n",
      "(1680, 674)\n",
      "(1896, 674)\n",
      "{1: 8.23845800282864, 4: 8.646133905051375, 5: 5.0185479335122904, 6: 3.3632146871519817, 8: 9.347054119972665, 9: 9.840609116443344, 10: 7.108490280764475, 11: 6.844673233418031, 12: 9.517196899728454, 13: 7.933946651552944, 17: 9.54714902712608, 19: 7.1827368769369135, 21: 10.0, 22: 1.0, 25: 8.097023233029244, 26: 8.019361145693928, 27: 6.405270392510413, 28: 5.929601528190924, 29: 1.4036568197075114}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2907579/3261308647.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32683 samples, validate on 3644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:07:49.544641: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 11.3509\n",
      "Epoch 1: val_loss improved from inf to 1.37884, saving model to ./checkpoints/unknown_person_few_shot_p2_45.h5\n",
      "32683/32683 [==============================] - 108s 3ms/sample - loss: 11.3509 - val_loss: 1.3788\n",
      "Epoch 2/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.3281\n",
      "Epoch 2: val_loss did not improve from 1.37884\n",
      "32683/32683 [==============================] - 20s 614us/sample - loss: 11.3281 - val_loss: 1.4090\n",
      "Epoch 3/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.1523\n",
      "Epoch 3: val_loss improved from 1.37884 to 1.37302, saving model to ./checkpoints/unknown_person_few_shot_p2_45.h5\n",
      "32683/32683 [==============================] - 20s 617us/sample - loss: 11.1523 - val_loss: 1.3730\n",
      "Epoch 4/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.1563\n",
      "Epoch 4: val_loss improved from 1.37302 to 1.36469, saving model to ./checkpoints/unknown_person_few_shot_p2_45.h5\n",
      "32683/32683 [==============================] - 21s 629us/sample - loss: 11.1563 - val_loss: 1.3647\n",
      "Epoch 5/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.1041\n",
      "Epoch 5: val_loss improved from 1.36469 to 1.36341, saving model to ./checkpoints/unknown_person_few_shot_p2_45.h5\n",
      "32683/32683 [==============================] - 22s 674us/sample - loss: 11.1041 - val_loss: 1.3634\n",
      "Epoch 6/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0602\n",
      "Epoch 6: val_loss did not improve from 1.36341\n",
      "32683/32683 [==============================] - 23s 695us/sample - loss: 11.0602 - val_loss: 1.3788\n",
      "Epoch 7/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0766\n",
      "Epoch 7: val_loss did not improve from 1.36341\n",
      "32683/32683 [==============================] - 23s 703us/sample - loss: 11.0766 - val_loss: 1.3684\n",
      "Epoch 8/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0002\n",
      "Epoch 8: val_loss did not improve from 1.36341\n",
      "32683/32683 [==============================] - 21s 654us/sample - loss: 11.0002 - val_loss: 1.3834\n",
      "Epoch 9/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0010\n",
      "Epoch 9: val_loss improved from 1.36341 to 1.35554, saving model to ./checkpoints/unknown_person_few_shot_p2_45.h5\n",
      "32683/32683 [==============================] - 24s 720us/sample - loss: 11.0010 - val_loss: 1.3555\n",
      "Epoch 10/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9995\n",
      "Epoch 10: val_loss did not improve from 1.35554\n",
      "32683/32683 [==============================] - 23s 693us/sample - loss: 10.9995 - val_loss: 1.3653\n",
      "Epoch 11/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9596\n",
      "Epoch 11: val_loss did not improve from 1.35554\n",
      "32683/32683 [==============================] - 21s 650us/sample - loss: 10.9596 - val_loss: 1.3676\n",
      "Epoch 12/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9638\n",
      "Epoch 12: val_loss did not improve from 1.35554\n",
      "32683/32683 [==============================] - 23s 705us/sample - loss: 10.9638 - val_loss: 1.3640\n",
      "Epoch 13/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9142\n",
      "Epoch 13: val_loss did not improve from 1.35554\n",
      "32683/32683 [==============================] - 23s 709us/sample - loss: 10.9142 - val_loss: 1.3691\n",
      "Epoch 14/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9468\n",
      "Epoch 14: val_loss improved from 1.35554 to 1.35007, saving model to ./checkpoints/unknown_person_few_shot_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 699us/sample - loss: 10.9468 - val_loss: 1.3501\n",
      "Epoch 15/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9044\n",
      "Epoch 15: val_loss did not improve from 1.35007\n",
      "32683/32683 [==============================] - 20s 613us/sample - loss: 10.9044 - val_loss: 1.3631\n",
      "Epoch 16/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8996\n",
      "Epoch 16: val_loss did not improve from 1.35007\n",
      "32683/32683 [==============================] - 20s 610us/sample - loss: 10.8996 - val_loss: 1.3678\n",
      "Epoch 17/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9028\n",
      "Epoch 17: val_loss did not improve from 1.35007\n",
      "32683/32683 [==============================] - 22s 669us/sample - loss: 10.9028 - val_loss: 1.3741\n",
      "Epoch 18/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8758\n",
      "Epoch 18: val_loss did not improve from 1.35007\n",
      "32683/32683 [==============================] - 23s 707us/sample - loss: 10.8758 - val_loss: 1.3553\n",
      "Epoch 19/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8617\n",
      "Epoch 19: val_loss did not improve from 1.35007\n",
      "32683/32683 [==============================] - 23s 711us/sample - loss: 10.8617 - val_loss: 1.3691\n",
      "Epoch 20/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8215\n",
      "Epoch 20: val_loss did not improve from 1.35007\n",
      "32683/32683 [==============================] - 23s 711us/sample - loss: 10.8215 - val_loss: 1.3642\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:16:54.481210: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_590_2/lstm_cell_1774/bias/Assign' id:899299 op device:{requested: '', assigned: ''} def:{{{node lstm_590_2/lstm_cell_1774/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_590_2/lstm_cell_1774/bias, lstm_590_2/lstm_cell_1774/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:17:44.264010: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_577_2/lstm_cell_1761/kernel/m/Assign' id:900610 op device:{requested: '', assigned: ''} def:{{{node lstm_577_2/lstm_cell_1761/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_577_2/lstm_cell_1761/kernel/m, lstm_577_2/lstm_cell_1761/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32683 samples, validate on 3644 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:18:36.674091: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:22:46.525102: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:23:12.356524: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.34404, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_45.h5\n",
      "32683/32683 [==============================] - 110s 3ms/sample - loss: 1.3962 - val_loss: 1.3440\n",
      "Epoch 2/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3956\n",
      "Epoch 2: val_loss improved from 1.34404 to 1.34231, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 716us/sample - loss: 1.3956 - val_loss: 1.3423\n",
      "Epoch 3/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3963\n",
      "Epoch 3: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 713us/sample - loss: 1.3963 - val_loss: 1.3469\n",
      "Epoch 4/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3937\n",
      "Epoch 4: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 708us/sample - loss: 1.3937 - val_loss: 1.3473\n",
      "Epoch 5/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3921\n",
      "Epoch 5: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 707us/sample - loss: 1.3921 - val_loss: 1.3512\n",
      "Epoch 6/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3910\n",
      "Epoch 6: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.3910 - val_loss: 1.3518\n",
      "Epoch 7/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3895\n",
      "Epoch 7: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 20s 622us/sample - loss: 1.3895 - val_loss: 1.3536\n",
      "Epoch 8/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3873\n",
      "Epoch 8: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 20s 623us/sample - loss: 1.3873 - val_loss: 1.3502\n",
      "Epoch 9/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3900\n",
      "Epoch 9: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 706us/sample - loss: 1.3900 - val_loss: 1.3431\n",
      "Epoch 10/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3852\n",
      "Epoch 10: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.3852 - val_loss: 1.3502\n",
      "Epoch 11/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3841\n",
      "Epoch 11: val_loss did not improve from 1.34231\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.3841 - val_loss: 1.3482\n",
      "Epoch 12/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3814\n",
      "Epoch 12: val_loss improved from 1.34231 to 1.33975, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_45.h5\n",
      "32683/32683 [==============================] - 23s 697us/sample - loss: 1.3814 - val_loss: 1.3397\n",
      "Epoch 13/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3831\n",
      "Epoch 13: val_loss did not improve from 1.33975\n",
      "32683/32683 [==============================] - 20s 612us/sample - loss: 1.3831 - val_loss: 1.3512\n",
      "Epoch 14/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3813\n",
      "Epoch 14: val_loss did not improve from 1.33975\n",
      "32683/32683 [==============================] - 23s 692us/sample - loss: 1.3813 - val_loss: 1.3442\n",
      "Epoch 15/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3838\n",
      "Epoch 15: val_loss did not improve from 1.33975\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 1.3838 - val_loss: 1.3398\n",
      "Epoch 16/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3816\n",
      "Epoch 16: val_loss did not improve from 1.33975\n",
      "32683/32683 [==============================] - 23s 718us/sample - loss: 1.3816 - val_loss: 1.3462\n",
      "Epoch 17/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3765\n",
      "Epoch 17: val_loss did not improve from 1.33975\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 1.3765 - val_loss: 1.3439\n",
      "Epoch 18/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3773\n",
      "Epoch 18: val_loss did not improve from 1.33975\n",
      "32683/32683 [==============================] - 23s 715us/sample - loss: 1.3773 - val_loss: 1.3459\n",
      "Epoch 19/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3752\n",
      "Epoch 19: val_loss improved from 1.33975 to 1.33749, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_45.h5\n",
      "32683/32683 [==============================] - 24s 720us/sample - loss: 1.3752 - val_loss: 1.3375\n",
      "Epoch 20/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3737\n",
      "Epoch 20: val_loss did not improve from 1.33749\n",
      "32683/32683 [==============================] - 22s 675us/sample - loss: 1.3737 - val_loss: 1.3404\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:32:04.586053: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_611/lstm_cell_1795/recurrent_kernel/Assign' id:915845 op device:{requested: '', assigned: ''} def:{{{node lstm_611/lstm_cell_1795/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_611/lstm_cell_1795/recurrent_kernel, lstm_611/lstm_cell_1795/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:32:30.955091: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_1' id:916308 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 19:32:52.268747: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_2' id:916309 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32683, 95)\n",
      "Train on 32683 samples, validate on 3644 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:33:41.030760: W tensorflow/c/c_api.cc:304] Operation '{name:'training_96/Adam/lstm_606/lstm_cell_1790/kernel/m/Assign' id:929276 op device:{requested: '', assigned: ''} def:{{{node training_96/Adam/lstm_606/lstm_cell_1790/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_96/Adam/lstm_606/lstm_cell_1790/kernel/m, training_96/Adam/lstm_606/lstm_cell_1790/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:37:54.486157: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 3.2073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 19:38:19.627563: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_97/mul' id:919149 op device:{requested: '', assigned: ''} def:{{{node loss_97/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_97/mul/x, loss_97/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.96120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 261s 8ms/sample - loss: 3.2073 - val_loss: 1.9612\n",
      "Epoch 2/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.7914\n",
      "Epoch 2: val_loss improved from 1.96120 to 1.55413, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 718us/sample - loss: 1.7914 - val_loss: 1.5541\n",
      "Epoch 3/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5955\n",
      "Epoch 3: val_loss improved from 1.55413 to 1.48612, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 716us/sample - loss: 1.5955 - val_loss: 1.4861\n",
      "Epoch 4/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5501\n",
      "Epoch 4: val_loss improved from 1.48612 to 1.45483, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 713us/sample - loss: 1.5501 - val_loss: 1.4548\n",
      "Epoch 5/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5252\n",
      "Epoch 5: val_loss improved from 1.45483 to 1.43962, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 717us/sample - loss: 1.5252 - val_loss: 1.4396\n",
      "Epoch 6/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5097\n",
      "Epoch 6: val_loss improved from 1.43962 to 1.42644, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 719us/sample - loss: 1.5097 - val_loss: 1.4264\n",
      "Epoch 7/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4953\n",
      "Epoch 7: val_loss improved from 1.42644 to 1.41551, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 716us/sample - loss: 1.4953 - val_loss: 1.4155\n",
      "Epoch 8/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4949\n",
      "Epoch 8: val_loss improved from 1.41551 to 1.40566, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 718us/sample - loss: 1.4949 - val_loss: 1.4057\n",
      "Epoch 9/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4884\n",
      "Epoch 9: val_loss improved from 1.40566 to 1.40292, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 724us/sample - loss: 1.4884 - val_loss: 1.4029\n",
      "Epoch 10/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4864\n",
      "Epoch 10: val_loss improved from 1.40292 to 1.39576, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 731us/sample - loss: 1.4864 - val_loss: 1.3958\n",
      "Epoch 11/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4766\n",
      "Epoch 11: val_loss improved from 1.39576 to 1.39161, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 719us/sample - loss: 1.4766 - val_loss: 1.3916\n",
      "Epoch 12/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4705\n",
      "Epoch 12: val_loss improved from 1.39161 to 1.38743, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 731us/sample - loss: 1.4705 - val_loss: 1.3874\n",
      "Epoch 13/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5096\n",
      "Epoch 13: val_loss did not improve from 1.38743\n",
      "32683/32683 [==============================] - 23s 713us/sample - loss: 1.5096 - val_loss: 1.3898\n",
      "Epoch 14/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4743\n",
      "Epoch 14: val_loss improved from 1.38743 to 1.38521, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 724us/sample - loss: 1.4743 - val_loss: 1.3852\n",
      "Epoch 15/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4732\n",
      "Epoch 15: val_loss did not improve from 1.38521\n",
      "32683/32683 [==============================] - 22s 672us/sample - loss: 1.4732 - val_loss: 1.3857\n",
      "Epoch 16/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4620\n",
      "Epoch 16: val_loss improved from 1.38521 to 1.38423, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 728us/sample - loss: 1.4620 - val_loss: 1.3842\n",
      "Epoch 17/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4632\n",
      "Epoch 17: val_loss did not improve from 1.38423\n",
      "32683/32683 [==============================] - 22s 685us/sample - loss: 1.4632 - val_loss: 1.3847\n",
      "Epoch 18/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4798\n",
      "Epoch 18: val_loss improved from 1.38423 to 1.38261, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 636us/sample - loss: 1.4798 - val_loss: 1.3826\n",
      "Epoch 19/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4631\n",
      "Epoch 19: val_loss improved from 1.38261 to 1.38146, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 20s 620us/sample - loss: 1.4631 - val_loss: 1.3815\n",
      "Epoch 20/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4723\n",
      "Epoch 20: val_loss did not improve from 1.38146\n",
      "32683/32683 [==============================] - 20s 611us/sample - loss: 1.4723 - val_loss: 1.3870\n",
      "Epoch 21/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4672\n",
      "Epoch 21: val_loss improved from 1.38146 to 1.38018, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 22s 675us/sample - loss: 1.4672 - val_loss: 1.3802\n",
      "Epoch 22/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4725\n",
      "Epoch 22: val_loss improved from 1.38018 to 1.37937, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 706us/sample - loss: 1.4725 - val_loss: 1.3794\n",
      "Epoch 23/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4846\n",
      "Epoch 23: val_loss did not improve from 1.37937\n",
      "32683/32683 [==============================] - 20s 623us/sample - loss: 1.4846 - val_loss: 1.3830\n",
      "Epoch 24/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4648\n",
      "Epoch 24: val_loss improved from 1.37937 to 1.37723, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 642us/sample - loss: 1.4648 - val_loss: 1.3772\n",
      "Epoch 25/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4486\n",
      "Epoch 25: val_loss did not improve from 1.37723\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.4486 - val_loss: 1.3777\n",
      "Epoch 26/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4477\n",
      "Epoch 26: val_loss improved from 1.37723 to 1.37428, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 719us/sample - loss: 1.4477 - val_loss: 1.3743\n",
      "Epoch 27/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 27: val_loss did not improve from 1.37428\n",
      "32683/32683 [==============================] - 23s 705us/sample - loss: 1.4411 - val_loss: 1.3763\n",
      "Epoch 28/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4385\n",
      "Epoch 28: val_loss improved from 1.37428 to 1.37031, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 22s 686us/sample - loss: 1.4385 - val_loss: 1.3703\n",
      "Epoch 29/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 29: val_loss did not improve from 1.37031\n",
      "32683/32683 [==============================] - 21s 630us/sample - loss: 1.4349 - val_loss: 1.3768\n",
      "Epoch 30/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4310\n",
      "Epoch 30: val_loss improved from 1.37031 to 1.36946, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 22s 682us/sample - loss: 1.4310 - val_loss: 1.3695\n",
      "Epoch 31/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4304\n",
      "Epoch 31: val_loss improved from 1.36946 to 1.36929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 713us/sample - loss: 1.4304 - val_loss: 1.3693\n",
      "Epoch 32/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 32: val_loss improved from 1.36929 to 1.36421, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 715us/sample - loss: 1.4283 - val_loss: 1.3642\n",
      "Epoch 33/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 33: val_loss did not improve from 1.36421\n",
      "32683/32683 [==============================] - 23s 708us/sample - loss: 1.4252 - val_loss: 1.3662\n",
      "Epoch 34/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4252\n",
      "Epoch 34: val_loss improved from 1.36421 to 1.36401, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 1.4252 - val_loss: 1.3640\n",
      "Epoch 35/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4232\n",
      "Epoch 35: val_loss improved from 1.36401 to 1.36337, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 22s 688us/sample - loss: 1.4232 - val_loss: 1.3634\n",
      "Epoch 36/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4213\n",
      "Epoch 36: val_loss improved from 1.36337 to 1.36127, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 23s 719us/sample - loss: 1.4213 - val_loss: 1.3613\n",
      "Epoch 37/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 37: val_loss did not improve from 1.36127\n",
      "32683/32683 [==============================] - 23s 705us/sample - loss: 1.4164 - val_loss: 1.3644\n",
      "Epoch 38/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4172\n",
      "Epoch 38: val_loss did not improve from 1.36127\n",
      "32683/32683 [==============================] - 22s 665us/sample - loss: 1.4172 - val_loss: 1.3639\n",
      "Epoch 39/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4153\n",
      "Epoch 39: val_loss improved from 1.36127 to 1.35546, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 650us/sample - loss: 1.4153 - val_loss: 1.3555\n",
      "Epoch 40/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 40: val_loss did not improve from 1.35546\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.4155 - val_loss: 1.3572\n",
      "Epoch 41/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4122\n",
      "Epoch 41: val_loss did not improve from 1.35546\n",
      "32683/32683 [==============================] - 23s 707us/sample - loss: 1.4122 - val_loss: 1.3566\n",
      "Epoch 42/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 42: val_loss did not improve from 1.35546\n",
      "32683/32683 [==============================] - 21s 635us/sample - loss: 1.4087 - val_loss: 1.3639\n",
      "Epoch 43/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4115\n",
      "Epoch 43: val_loss improved from 1.35546 to 1.35425, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 645us/sample - loss: 1.4115 - val_loss: 1.3543\n",
      "Epoch 44/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 44: val_loss did not improve from 1.35425\n",
      "32683/32683 [==============================] - 23s 695us/sample - loss: 1.4087 - val_loss: 1.3563\n",
      "Epoch 45/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 45: val_loss improved from 1.35425 to 1.35225, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 649us/sample - loss: 1.4055 - val_loss: 1.3522\n",
      "Epoch 46/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4077\n",
      "Epoch 46: val_loss did not improve from 1.35225\n",
      "32683/32683 [==============================] - 20s 625us/sample - loss: 1.4077 - val_loss: 1.3544\n",
      "Epoch 47/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4025\n",
      "Epoch 47: val_loss improved from 1.35225 to 1.34929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 637us/sample - loss: 1.4025 - val_loss: 1.3493\n",
      "Epoch 48/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 48: val_loss did not improve from 1.34929\n",
      "32683/32683 [==============================] - 20s 621us/sample - loss: 1.4045 - val_loss: 1.3525\n",
      "Epoch 49/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 49: val_loss improved from 1.34929 to 1.34663, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_46.h5\n",
      "32683/32683 [==============================] - 21s 630us/sample - loss: 1.4051 - val_loss: 1.3466\n",
      "Epoch 50/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 50: val_loss did not improve from 1.34663\n",
      "32683/32683 [==============================] - 20s 612us/sample - loss: 1.4015 - val_loss: 1.3501\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:00:52.219992: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_628_1/lstm_cell_1849/bias/Assign' id:937103 op device:{requested: '', assigned: ''} def:{{{node lstm_628_1/lstm_cell_1849/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_628_1/lstm_cell_1849/bias, lstm_628_1/lstm_cell_1849/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:01:44.493144: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_602_1/lstm_cell_1823/recurrent_kernel/m/Assign' id:938079 op device:{requested: '', assigned: ''} def:{{{node lstm_602_1/lstm_cell_1823/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_602_1/lstm_cell_1823/recurrent_kernel/m, lstm_602_1/lstm_cell_1823/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:02:37.285317: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_84_1/cond/Merge' id:937263 op device:{requested: '', assigned: ''} def:{{{node dropout_84_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_84_1/cond/Identity, dropout_84_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 674)\n",
      "(1704, 674)\n",
      "(1704, 674)\n",
      "(1848, 674)\n",
      "(1735, 674)\n",
      "(1346, 674)\n",
      "(1814, 674)\n",
      "(1570, 674)\n",
      "(1728, 674)\n",
      "(1538, 674)\n",
      "(1920, 674)\n",
      "(1727, 674)\n",
      "(1764, 674)\n",
      "(1848, 674)\n",
      "(1752, 674)\n",
      "(1800, 674)\n",
      "(946, 674)\n",
      "(1680, 674)\n",
      "(1896, 674)\n",
      "{1: 8.384953597837253, 4: 8.446438233141553, 5: 5.049061277199756, 6: 3.9996971564094816, 8: 9.1916439790447, 9: 9.581673284701905, 10: 6.850845838455104, 11: 6.831572798490214, 12: 9.639887578550056, 13: 8.247942725629247, 17: 9.386411186500561, 19: 7.201112149998677, 21: 10.0, 22: 1.0, 25: 8.007697274592346, 26: 8.185267028642725, 27: 6.011213830349729, 28: 5.891058789204242, 29: 1.4409393444913552}\n",
      "Train on 32683 samples, validate on 3644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:11:13.579912: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 11.4497\n",
      "Epoch 1: val_loss improved from inf to 1.36373, saving model to ./checkpoints/unknown_person_few_shot_p2_46.h5\n",
      "32683/32683 [==============================] - 110s 3ms/sample - loss: 11.4497 - val_loss: 1.3637\n",
      "Epoch 2/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.2958\n",
      "Epoch 2: val_loss did not improve from 1.36373\n",
      "32683/32683 [==============================] - 20s 625us/sample - loss: 11.2958 - val_loss: 1.3993\n",
      "Epoch 3/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.2439\n",
      "Epoch 3: val_loss did not improve from 1.36373\n",
      "32683/32683 [==============================] - 20s 610us/sample - loss: 11.2439 - val_loss: 1.3753\n",
      "Epoch 4/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.2384\n",
      "Epoch 4: val_loss did not improve from 1.36373\n",
      "32683/32683 [==============================] - 20s 609us/sample - loss: 11.2384 - val_loss: 1.3662\n",
      "Epoch 5/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0944\n",
      "Epoch 5: val_loss improved from 1.36373 to 1.35141, saving model to ./checkpoints/unknown_person_few_shot_p2_46.h5\n",
      "32683/32683 [==============================] - 20s 623us/sample - loss: 11.0944 - val_loss: 1.3514\n",
      "Epoch 6/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.1036\n",
      "Epoch 6: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 612us/sample - loss: 11.1036 - val_loss: 1.3652\n",
      "Epoch 7/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0938\n",
      "Epoch 7: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 610us/sample - loss: 11.0938 - val_loss: 1.3703\n",
      "Epoch 8/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0568\n",
      "Epoch 8: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 615us/sample - loss: 11.0568 - val_loss: 1.3732\n",
      "Epoch 9/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0377\n",
      "Epoch 9: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 23s 714us/sample - loss: 11.0377 - val_loss: 1.3684\n",
      "Epoch 10/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0437\n",
      "Epoch 10: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 23s 719us/sample - loss: 11.0437 - val_loss: 1.3624\n",
      "Epoch 11/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0169\n",
      "Epoch 11: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 23s 715us/sample - loss: 11.0169 - val_loss: 1.3714\n",
      "Epoch 12/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0233\n",
      "Epoch 12: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 23s 714us/sample - loss: 11.0233 - val_loss: 1.3753\n",
      "Epoch 13/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9972\n",
      "Epoch 13: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 23s 714us/sample - loss: 10.9972 - val_loss: 1.3561\n",
      "Epoch 14/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9829\n",
      "Epoch 14: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 24s 722us/sample - loss: 10.9829 - val_loss: 1.3681\n",
      "Epoch 15/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9579\n",
      "Epoch 15: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 22s 666us/sample - loss: 10.9579 - val_loss: 1.3636\n",
      "Epoch 16/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9476\n",
      "Epoch 16: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 23s 689us/sample - loss: 10.9476 - val_loss: 1.3701\n",
      "Epoch 17/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9308\n",
      "Epoch 17: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 621us/sample - loss: 10.9308 - val_loss: 1.3699\n",
      "Epoch 18/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9381\n",
      "Epoch 18: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 618us/sample - loss: 10.9381 - val_loss: 1.3598\n",
      "Epoch 19/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9397\n",
      "Epoch 19: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 624us/sample - loss: 10.9397 - val_loss: 1.3605\n",
      "Epoch 20/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9178\n",
      "Epoch 20: val_loss did not improve from 1.35141\n",
      "32683/32683 [==============================] - 20s 620us/sample - loss: 10.9178 - val_loss: 1.3635\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:20:11.844994: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_596_2/lstm_cell_1854/bias/Assign' id:951379 op device:{requested: '', assigned: ''} def:{{{node lstm_596_2/lstm_cell_1854/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_596_2/lstm_cell_1854/bias, lstm_596_2/lstm_cell_1854/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:21:05.365515: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_617_2/lstm_cell_1875/kernel/m/Assign' id:957697 op device:{requested: '', assigned: ''} def:{{{node lstm_617_2/lstm_cell_1875/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_617_2/lstm_cell_1875/kernel/m, lstm_617_2/lstm_cell_1875/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32683 samples, validate on 3644 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:22:01.155705: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:26:19.337922: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:26:41.530260: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.34839, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_46.h5\n",
      "32683/32683 [==============================] - 111s 3ms/sample - loss: 1.4020 - val_loss: 1.3484\n",
      "Epoch 2/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3990\n",
      "Epoch 2: val_loss did not improve from 1.34839\n",
      "32683/32683 [==============================] - 19s 593us/sample - loss: 1.3990 - val_loss: 1.3509\n",
      "Epoch 3/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 3: val_loss did not improve from 1.34839\n",
      "32683/32683 [==============================] - 19s 591us/sample - loss: 1.3965 - val_loss: 1.3501\n",
      "Epoch 4/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3943\n",
      "Epoch 4: val_loss did not improve from 1.34839\n",
      "32683/32683 [==============================] - 20s 598us/sample - loss: 1.3943 - val_loss: 1.3503\n",
      "Epoch 5/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 5: val_loss improved from 1.34839 to 1.34535, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_46.h5\n",
      "32683/32683 [==============================] - 20s 621us/sample - loss: 1.3980 - val_loss: 1.3454\n",
      "Epoch 6/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 6: val_loss did not improve from 1.34535\n",
      "32683/32683 [==============================] - 20s 600us/sample - loss: 1.3935 - val_loss: 1.3489\n",
      "Epoch 7/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 7: val_loss did not improve from 1.34535\n",
      "32683/32683 [==============================] - 20s 598us/sample - loss: 1.3918 - val_loss: 1.3476\n",
      "Epoch 8/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3932\n",
      "Epoch 8: val_loss did not improve from 1.34535\n",
      "32683/32683 [==============================] - 20s 604us/sample - loss: 1.3932 - val_loss: 1.3498\n",
      "Epoch 9/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3923\n",
      "Epoch 9: val_loss did not improve from 1.34535\n",
      "32683/32683 [==============================] - 20s 599us/sample - loss: 1.3923 - val_loss: 1.3481\n",
      "Epoch 10/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3864\n",
      "Epoch 10: val_loss improved from 1.34535 to 1.34230, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_46.h5\n",
      "32683/32683 [==============================] - 20s 617us/sample - loss: 1.3864 - val_loss: 1.3423\n",
      "Epoch 11/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3893\n",
      "Epoch 11: val_loss improved from 1.34230 to 1.33867, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_46.h5\n",
      "32683/32683 [==============================] - 24s 720us/sample - loss: 1.3893 - val_loss: 1.3387\n",
      "Epoch 12/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3867\n",
      "Epoch 12: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 22s 683us/sample - loss: 1.3867 - val_loss: 1.3437\n",
      "Epoch 13/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3835\n",
      "Epoch 13: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 19s 594us/sample - loss: 1.3835 - val_loss: 1.3410\n",
      "Epoch 14/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3809\n",
      "Epoch 14: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 19s 595us/sample - loss: 1.3809 - val_loss: 1.3422\n",
      "Epoch 15/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3840\n",
      "Epoch 15: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 21s 638us/sample - loss: 1.3840 - val_loss: 1.3428\n",
      "Epoch 16/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3822\n",
      "Epoch 16: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 22s 686us/sample - loss: 1.3822 - val_loss: 1.3479\n",
      "Epoch 17/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3857\n",
      "Epoch 17: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 21s 645us/sample - loss: 1.3857 - val_loss: 1.3447\n",
      "Epoch 18/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3809\n",
      "Epoch 18: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 23s 703us/sample - loss: 1.3809 - val_loss: 1.3408\n",
      "Epoch 19/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3783\n",
      "Epoch 19: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 20s 606us/sample - loss: 1.3783 - val_loss: 1.3428\n",
      "Epoch 20/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3789\n",
      "Epoch 20: val_loss did not improve from 1.33867\n",
      "32683/32683 [==============================] - 20s 601us/sample - loss: 1.3789 - val_loss: 1.3408\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:34:59.361246: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_632/lstm_cell_1890/bias/Assign' id:970256 op device:{requested: '', assigned: ''} def:{{{node lstm_632/lstm_cell_1890/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_632/lstm_cell_1890/bias, lstm_632/lstm_cell_1890/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:35:28.775653: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_1' id:973350 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 20:35:52.919353: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_2' id:973351 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32683, 95)\n",
      "Train on 32683 samples, validate on 3644 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:36:45.538489: W tensorflow/c/c_api.cc:304] Operation '{name:'training_102/Adam/dense_68/kernel/v/Assign' id:987308 op device:{requested: '', assigned: ''} def:{{{node training_102/Adam/dense_68/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_102/Adam/dense_68/kernel/v, training_102/Adam/dense_68/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:41:13.892498: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 2.9060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:41:36.544999: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_103/mul' id:976191 op device:{requested: '', assigned: ''} def:{{{node loss_103/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_103/mul/x, loss_103/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.77279, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 282s 9ms/sample - loss: 2.9060 - val_loss: 1.7728\n",
      "Epoch 2/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.7225\n",
      "Epoch 2: val_loss improved from 1.77279 to 1.52814, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 646us/sample - loss: 1.7225 - val_loss: 1.5281\n",
      "Epoch 3/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5928\n",
      "Epoch 3: val_loss improved from 1.52814 to 1.47362, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 642us/sample - loss: 1.5928 - val_loss: 1.4736\n",
      "Epoch 4/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5472\n",
      "Epoch 4: val_loss improved from 1.47362 to 1.44252, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 634us/sample - loss: 1.5472 - val_loss: 1.4425\n",
      "Epoch 5/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5203\n",
      "Epoch 5: val_loss improved from 1.44252 to 1.43102, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 22s 667us/sample - loss: 1.5203 - val_loss: 1.4310\n",
      "Epoch 6/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5055\n",
      "Epoch 6: val_loss improved from 1.43102 to 1.41470, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 732us/sample - loss: 1.5055 - val_loss: 1.4147\n",
      "Epoch 7/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4924\n",
      "Epoch 7: val_loss improved from 1.41470 to 1.40918, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 716us/sample - loss: 1.4924 - val_loss: 1.4092\n",
      "Epoch 8/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4945\n",
      "Epoch 8: val_loss improved from 1.40918 to 1.39891, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 719us/sample - loss: 1.4945 - val_loss: 1.3989\n",
      "Epoch 9/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4927\n",
      "Epoch 9: val_loss did not improve from 1.39891\n",
      "32683/32683 [==============================] - 23s 707us/sample - loss: 1.4927 - val_loss: 1.4000\n",
      "Epoch 10/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5047\n",
      "Epoch 10: val_loss improved from 1.39891 to 1.39228, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 706us/sample - loss: 1.5047 - val_loss: 1.3923\n",
      "Epoch 11/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 11: val_loss improved from 1.39228 to 1.38712, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 22s 681us/sample - loss: 1.4903 - val_loss: 1.3871\n",
      "Epoch 12/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4804\n",
      "Epoch 12: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 22s 670us/sample - loss: 1.4804 - val_loss: 1.3922\n",
      "Epoch 13/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4962\n",
      "Epoch 13: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 22s 675us/sample - loss: 1.4962 - val_loss: 1.3934\n",
      "Epoch 14/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4787\n",
      "Epoch 14: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 22s 666us/sample - loss: 1.4787 - val_loss: 1.3889\n",
      "Epoch 15/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5102\n",
      "Epoch 15: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 704us/sample - loss: 1.5102 - val_loss: 1.3989\n",
      "Epoch 16/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5143\n",
      "Epoch 16: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 708us/sample - loss: 1.5143 - val_loss: 1.3962\n",
      "Epoch 17/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4996\n",
      "Epoch 17: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 705us/sample - loss: 1.4996 - val_loss: 1.3934\n",
      "Epoch 18/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5326\n",
      "Epoch 18: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 689us/sample - loss: 1.5326 - val_loss: 1.4049\n",
      "Epoch 19/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5260\n",
      "Epoch 19: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 20s 613us/sample - loss: 1.5260 - val_loss: 1.4033\n",
      "Epoch 20/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5041\n",
      "Epoch 20: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 22s 668us/sample - loss: 1.5041 - val_loss: 1.3926\n",
      "Epoch 21/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5163\n",
      "Epoch 21: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 714us/sample - loss: 1.5163 - val_loss: 1.3944\n",
      "Epoch 22/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5883\n",
      "Epoch 22: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 707us/sample - loss: 1.5883 - val_loss: 1.4126\n",
      "Epoch 23/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5531\n",
      "Epoch 23: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 20s 613us/sample - loss: 1.5531 - val_loss: 1.4044\n",
      "Epoch 24/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.5149\n",
      "Epoch 24: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 20s 623us/sample - loss: 1.5149 - val_loss: 1.4015\n",
      "Epoch 25/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4881\n",
      "Epoch 25: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 22s 665us/sample - loss: 1.4881 - val_loss: 1.3963\n",
      "Epoch 26/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4735\n",
      "Epoch 26: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 21s 638us/sample - loss: 1.4735 - val_loss: 1.3970\n",
      "Epoch 27/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4722\n",
      "Epoch 27: val_loss did not improve from 1.38712\n",
      "32683/32683 [==============================] - 23s 703us/sample - loss: 1.4722 - val_loss: 1.3879\n",
      "Epoch 28/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4669\n",
      "Epoch 28: val_loss improved from 1.38712 to 1.38647, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 714us/sample - loss: 1.4669 - val_loss: 1.3865\n",
      "Epoch 29/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4638\n",
      "Epoch 29: val_loss improved from 1.38647 to 1.38442, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 724us/sample - loss: 1.4638 - val_loss: 1.3844\n",
      "Epoch 30/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 30: val_loss did not improve from 1.38442\n",
      "32683/32683 [==============================] - 23s 710us/sample - loss: 1.4623 - val_loss: 1.3856\n",
      "Epoch 31/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4594\n",
      "Epoch 31: val_loss did not improve from 1.38442\n",
      "32683/32683 [==============================] - 23s 706us/sample - loss: 1.4594 - val_loss: 1.3849\n",
      "Epoch 32/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4581\n",
      "Epoch 32: val_loss improved from 1.38442 to 1.38208, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 698us/sample - loss: 1.4581 - val_loss: 1.3821\n",
      "Epoch 33/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4556\n",
      "Epoch 33: val_loss improved from 1.38208 to 1.38030, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 634us/sample - loss: 1.4556 - val_loss: 1.3803\n",
      "Epoch 34/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4520\n",
      "Epoch 34: val_loss did not improve from 1.38030\n",
      "32683/32683 [==============================] - 20s 618us/sample - loss: 1.4520 - val_loss: 1.3823\n",
      "Epoch 35/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4498\n",
      "Epoch 35: val_loss did not improve from 1.38030\n",
      "32683/32683 [==============================] - 20s 618us/sample - loss: 1.4498 - val_loss: 1.3804\n",
      "Epoch 36/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4476\n",
      "Epoch 36: val_loss did not improve from 1.38030\n",
      "32683/32683 [==============================] - 20s 620us/sample - loss: 1.4476 - val_loss: 1.3815\n",
      "Epoch 37/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4507\n",
      "Epoch 37: val_loss improved from 1.38030 to 1.37687, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 633us/sample - loss: 1.4507 - val_loss: 1.3769\n",
      "Epoch 38/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4453\n",
      "Epoch 38: val_loss improved from 1.37687 to 1.37286, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 20s 627us/sample - loss: 1.4453 - val_loss: 1.3729\n",
      "Epoch 39/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4429\n",
      "Epoch 39: val_loss did not improve from 1.37286\n",
      "32683/32683 [==============================] - 22s 667us/sample - loss: 1.4429 - val_loss: 1.3830\n",
      "Epoch 40/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 40: val_loss improved from 1.37286 to 1.37282, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 20s 624us/sample - loss: 1.4420 - val_loss: 1.3728\n",
      "Epoch 41/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4401\n",
      "Epoch 41: val_loss improved from 1.37282 to 1.37023, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 632us/sample - loss: 1.4401 - val_loss: 1.3702\n",
      "Epoch 42/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4372\n",
      "Epoch 42: val_loss did not improve from 1.37023\n",
      "32683/32683 [==============================] - 21s 632us/sample - loss: 1.4372 - val_loss: 1.3742\n",
      "Epoch 43/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4378\n",
      "Epoch 43: val_loss did not improve from 1.37023\n",
      "32683/32683 [==============================] - 20s 610us/sample - loss: 1.4378 - val_loss: 1.3706\n",
      "Epoch 44/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4355\n",
      "Epoch 44: val_loss did not improve from 1.37023\n",
      "32683/32683 [==============================] - 20s 610us/sample - loss: 1.4355 - val_loss: 1.3740\n",
      "Epoch 45/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4357\n",
      "Epoch 45: val_loss improved from 1.37023 to 1.37015, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 704us/sample - loss: 1.4357 - val_loss: 1.3701\n",
      "Epoch 46/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4340\n",
      "Epoch 46: val_loss improved from 1.37015 to 1.36683, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 722us/sample - loss: 1.4340 - val_loss: 1.3668\n",
      "Epoch 47/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4342\n",
      "Epoch 47: val_loss did not improve from 1.36683\n",
      "32683/32683 [==============================] - 23s 705us/sample - loss: 1.4342 - val_loss: 1.3698\n",
      "Epoch 48/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 48: val_loss did not improve from 1.36683\n",
      "32683/32683 [==============================] - 21s 654us/sample - loss: 1.4308 - val_loss: 1.3687\n",
      "Epoch 49/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 49: val_loss did not improve from 1.36683\n",
      "32683/32683 [==============================] - 23s 702us/sample - loss: 1.4294 - val_loss: 1.3687\n",
      "Epoch 50/50\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4292\n",
      "Epoch 50: val_loss improved from 1.36683 to 1.36259, saving model to ./checkpoints/unknown_person_few_shot_baseline_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 703us/sample - loss: 1.4292 - val_loss: 1.3626\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:04:12.601898: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_647_1/lstm_cell_1942/bias/Assign' id:991263 op device:{requested: '', assigned: ''} def:{{{node lstm_647_1/lstm_cell_1942/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_647_1/lstm_cell_1942/bias, lstm_647_1/lstm_cell_1942/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:05:08.150726: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_638_1/lstm_cell_1933/bias/v/Assign' id:995754 op device:{requested: '', assigned: ''} def:{{{node lstm_638_1/lstm_cell_1933/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_638_1/lstm_cell_1933/bias/v, lstm_638_1/lstm_cell_1933/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:06:03.593256: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_89_1/cond/Merge' id:994305 op device:{requested: '', assigned: ''} def:{{{node dropout_89_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_89_1/cond/Identity, dropout_89_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 674)\n",
      "(1704, 674)\n",
      "(1704, 674)\n",
      "(1848, 674)\n",
      "(1735, 674)\n",
      "(1346, 674)\n",
      "(1814, 674)\n",
      "(1570, 674)\n",
      "(1728, 674)\n",
      "(1538, 674)\n",
      "(1920, 674)\n",
      "(1727, 674)\n",
      "(1764, 674)\n",
      "(1848, 674)\n",
      "(1752, 674)\n",
      "(1800, 674)\n",
      "(946, 674)\n",
      "(1680, 674)\n",
      "(1896, 674)\n",
      "{1: 7.308234577070249, 4: 8.288811615028173, 5: 4.195967273196958, 6: 3.544365645736797, 8: 8.409948818961203, 9: 10.0, 10: 6.559839029982078, 11: 7.010339134927427, 12: 9.362917157757076, 13: 7.633988972665773, 17: 9.339120800167912, 19: 7.397252450070233, 21: 9.168863118975734, 22: 1.2314529279752007, 25: 8.553869254242214, 26: 8.888634822480908, 27: 7.139201930994398, 28: 6.359524597574955, 29: 1.0}\n",
      "Train on 32683 samples, validate on 3644 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:15:09.136211: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 11.4035\n",
      "Epoch 1: val_loss improved from inf to 1.42318, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 122s 4ms/sample - loss: 11.4035 - val_loss: 1.4232\n",
      "Epoch 2/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.1936\n",
      "Epoch 2: val_loss improved from 1.42318 to 1.39796, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 25s 763us/sample - loss: 11.1936 - val_loss: 1.3980\n",
      "Epoch 3/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.1527\n",
      "Epoch 3: val_loss improved from 1.39796 to 1.38348, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 735us/sample - loss: 11.1527 - val_loss: 1.3835\n",
      "Epoch 4/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0778\n",
      "Epoch 4: val_loss did not improve from 1.38348\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 11.0778 - val_loss: 1.3889\n",
      "Epoch 5/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0657\n",
      "Epoch 5: val_loss did not improve from 1.38348\n",
      "32683/32683 [==============================] - 22s 684us/sample - loss: 11.0657 - val_loss: 1.3861\n",
      "Epoch 6/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0062\n",
      "Epoch 6: val_loss improved from 1.38348 to 1.37640, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 705us/sample - loss: 11.0062 - val_loss: 1.3764\n",
      "Epoch 7/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 11.0116\n",
      "Epoch 7: val_loss improved from 1.37640 to 1.37422, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 723us/sample - loss: 11.0116 - val_loss: 1.3742\n",
      "Epoch 8/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9715\n",
      "Epoch 8: val_loss did not improve from 1.37422\n",
      "32683/32683 [==============================] - 23s 694us/sample - loss: 10.9715 - val_loss: 1.3820\n",
      "Epoch 9/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9652\n",
      "Epoch 9: val_loss did not improve from 1.37422\n",
      "32683/32683 [==============================] - 20s 620us/sample - loss: 10.9652 - val_loss: 1.3806\n",
      "Epoch 10/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9411\n",
      "Epoch 10: val_loss did not improve from 1.37422\n",
      "32683/32683 [==============================] - 22s 671us/sample - loss: 10.9411 - val_loss: 1.3854\n",
      "Epoch 11/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9536\n",
      "Epoch 11: val_loss improved from 1.37422 to 1.37322, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 644us/sample - loss: 10.9536 - val_loss: 1.3732\n",
      "Epoch 12/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9259\n",
      "Epoch 12: val_loss did not improve from 1.37322\n",
      "32683/32683 [==============================] - 21s 637us/sample - loss: 10.9259 - val_loss: 1.3810\n",
      "Epoch 13/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9143\n",
      "Epoch 13: val_loss did not improve from 1.37322\n",
      "32683/32683 [==============================] - 20s 615us/sample - loss: 10.9143 - val_loss: 1.3862\n",
      "Epoch 14/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.9055\n",
      "Epoch 14: val_loss did not improve from 1.37322\n",
      "32683/32683 [==============================] - 20s 612us/sample - loss: 10.9055 - val_loss: 1.3861\n",
      "Epoch 15/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8670\n",
      "Epoch 15: val_loss improved from 1.37322 to 1.36881, saving model to ./checkpoints/unknown_person_few_shot_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 629us/sample - loss: 10.8670 - val_loss: 1.3688\n",
      "Epoch 16/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8761\n",
      "Epoch 16: val_loss did not improve from 1.36881\n",
      "32683/32683 [==============================] - 20s 620us/sample - loss: 10.8761 - val_loss: 1.3803\n",
      "Epoch 17/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8559\n",
      "Epoch 17: val_loss did not improve from 1.36881\n",
      "32683/32683 [==============================] - 20s 613us/sample - loss: 10.8559 - val_loss: 1.3819\n",
      "Epoch 18/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8372\n",
      "Epoch 18: val_loss did not improve from 1.36881\n",
      "32683/32683 [==============================] - 20s 610us/sample - loss: 10.8372 - val_loss: 1.3806\n",
      "Epoch 19/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8452\n",
      "Epoch 19: val_loss did not improve from 1.36881\n",
      "32683/32683 [==============================] - 20s 611us/sample - loss: 10.8452 - val_loss: 1.3819\n",
      "Epoch 20/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 10.8416\n",
      "Epoch 20: val_loss did not improve from 1.36881\n",
      "32683/32683 [==============================] - 21s 629us/sample - loss: 10.8416 - val_loss: 1.3834\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:24:23.302241: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_659_2/lstm_cell_1991/recurrent_kernel/Assign' id:1012574 op device:{requested: '', assigned: ''} def:{{{node lstm_659_2/lstm_cell_1991/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_659_2/lstm_cell_1991/recurrent_kernel, lstm_659_2/lstm_cell_1991/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-18 21:25:20.203523: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_634_2/lstm_cell_1966/bias/v/Assign' id:1015092 op device:{requested: '', assigned: ''} def:{{{node lstm_634_2/lstm_cell_1966/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_634_2/lstm_cell_1966/bias/v, lstm_634_2/lstm_cell_1966/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32683 samples, validate on 3644 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:26:19.333284: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:30:55.973053: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:31:21.955850: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.36483, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 122s 4ms/sample - loss: 1.4243 - val_loss: 1.3648\n",
      "Epoch 2/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4247\n",
      "Epoch 2: val_loss did not improve from 1.36483\n",
      "32683/32683 [==============================] - 22s 678us/sample - loss: 1.4247 - val_loss: 1.3673\n",
      "Epoch 3/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4221\n",
      "Epoch 3: val_loss improved from 1.36483 to 1.36177, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 732us/sample - loss: 1.4221 - val_loss: 1.3618\n",
      "Epoch 4/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 4: val_loss did not improve from 1.36177\n",
      "32683/32683 [==============================] - 23s 715us/sample - loss: 1.4211 - val_loss: 1.3672\n",
      "Epoch 5/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4188\n",
      "Epoch 5: val_loss improved from 1.36177 to 1.36143, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 728us/sample - loss: 1.4188 - val_loss: 1.3614\n",
      "Epoch 6/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4162\n",
      "Epoch 6: val_loss improved from 1.36143 to 1.35967, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 727us/sample - loss: 1.4162 - val_loss: 1.3597\n",
      "Epoch 7/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4149\n",
      "Epoch 7: val_loss improved from 1.35967 to 1.35735, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 22s 670us/sample - loss: 1.4149 - val_loss: 1.3573\n",
      "Epoch 8/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 8: val_loss did not improve from 1.35735\n",
      "32683/32683 [==============================] - 21s 647us/sample - loss: 1.4123 - val_loss: 1.3586\n",
      "Epoch 9/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4072\n",
      "Epoch 9: val_loss did not improve from 1.35735\n",
      "32683/32683 [==============================] - 23s 716us/sample - loss: 1.4072 - val_loss: 1.3595\n",
      "Epoch 10/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4098\n",
      "Epoch 10: val_loss improved from 1.35735 to 1.35706, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 727us/sample - loss: 1.4098 - val_loss: 1.3571\n",
      "Epoch 11/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4127\n",
      "Epoch 11: val_loss improved from 1.35706 to 1.35654, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 23s 701us/sample - loss: 1.4127 - val_loss: 1.3565\n",
      "Epoch 12/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 12: val_loss did not improve from 1.35654\n",
      "32683/32683 [==============================] - 23s 712us/sample - loss: 1.4082 - val_loss: 1.3584\n",
      "Epoch 13/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 13: val_loss did not improve from 1.35654\n",
      "32683/32683 [==============================] - 23s 715us/sample - loss: 1.4080 - val_loss: 1.3569\n",
      "Epoch 14/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 14: val_loss improved from 1.35654 to 1.35242, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 21s 656us/sample - loss: 1.4063 - val_loss: 1.3524\n",
      "Epoch 15/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4057\n",
      "Epoch 15: val_loss did not improve from 1.35242\n",
      "32683/32683 [==============================] - 21s 640us/sample - loss: 1.4057 - val_loss: 1.3562\n",
      "Epoch 16/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4033\n",
      "Epoch 16: val_loss did not improve from 1.35242\n",
      "32683/32683 [==============================] - 23s 714us/sample - loss: 1.4033 - val_loss: 1.3549\n",
      "Epoch 17/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4003\n",
      "Epoch 17: val_loss did not improve from 1.35242\n",
      "32683/32683 [==============================] - 23s 711us/sample - loss: 1.4003 - val_loss: 1.3552\n",
      "Epoch 18/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.4024\n",
      "Epoch 18: val_loss improved from 1.35242 to 1.35074, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 726us/sample - loss: 1.4024 - val_loss: 1.3507\n",
      "Epoch 19/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 19: val_loss improved from 1.35074 to 1.34867, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p2_47.h5\n",
      "32683/32683 [==============================] - 24s 745us/sample - loss: 1.3995 - val_loss: 1.3487\n",
      "Epoch 20/20\n",
      "32683/32683 [==============================] - ETA: 0s - loss: 1.3997\n",
      "Epoch 20: val_loss did not improve from 1.34867\n",
      "32683/32683 [==============================] - 20s 624us/sample - loss: 1.3997 - val_loss: 1.3561\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "\n",
    "test_person_id = [2]\n",
    "ra_all = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "idx = 30\n",
    "for ra in ra_all:\n",
    "    flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "    ## Data Normalization before training ans testing\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalers = []\n",
    "    X_train_normalized = []\n",
    "    X_val_normalized = []\n",
    "    X_test_normalized = []\n",
    "    train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "    np.random.shuffle(train_idx)\n",
    "    val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "    test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "    \n",
    "    for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "        scaler = StandardScaler()\n",
    "        if len(feature.shape)==2:\n",
    "            X_train_i = feature[train_idx,:]\n",
    "            X_val_i = feature[val_idx,:]\n",
    "            X_test_i = feature[test_idx,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i)\n",
    "            scalers.append(scaler)\n",
    "        else:\n",
    "            X_train_i = feature[train_idx,:,:]\n",
    "            X_val_i = feature[val_idx,:,:]\n",
    "            X_test_i = feature[test_idx,:,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "            scalers.append(scaler)\n",
    "        X_train_normalized.append(X_train_normalized_i)\n",
    "        X_val_normalized.append(X_val_normalized_i)\n",
    "        X_test_normalized.append(X_test_normalized_i)\n",
    "    y_train = gts[train_idx,:]\n",
    "    y_val = gts[val_idx,:]\n",
    "    y_test = gts[test_idx,:]\n",
    "    X_train_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "    for feature in X_train_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_train_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_train_normalized_new.append(feature)\n",
    "    X_train_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_val_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "    for feature in X_val_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_val_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_val_normalized_new.append(feature)\n",
    "    X_val_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_test_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "    for feature in X_test_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_test_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_test_normalized_new.append(feature)\n",
    "    X_test_normalized_new.append(combined_feature)\n",
    "    \n",
    "    \n",
    "    num_epochs = 50\n",
    "    \n",
    "    \n",
    "    # Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    \n",
    "    \n",
    "    rates = [0.4, 0.5, 0.6]\n",
    "    \n",
    "    for r in rates:\n",
    "        model = individual_model(X_train_normalized)\n",
    "        model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=20, frequency=1)\n",
    "        model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import tensorflow as tf\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        from tensorflow.keras.models import Model\n",
    "        layers = model.layers\n",
    "        second_last_layer_output = layers[-4].output\n",
    "        feature_extractor_model = Model(inputs=model.input, outputs=second_last_layer_output)\n",
    "        train_features = feature_extractor_model.predict(X_train_normalized_new)\n",
    "        test_features = feature_extractor_model.predict(X_test_normalized_new)\n",
    "        \n",
    "        p_train = people_nums[train_idx,:]\n",
    "        p_val = people_nums[val_idx,:]\n",
    "        p_test = people_nums[test_idx,:]\n",
    "        ## Calculate the distance between test person and training person\n",
    "        def euclidean_distance(a, b):\n",
    "            return np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "        \n",
    "        distance_dict = {}\n",
    "        for ii in range(len(person_nums)):\n",
    "            if person_nums[ii] == test_person_id[0]:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                ind = np.where(p_train ==person_nums[ii])[0]\n",
    "                tmp_train_features = train_features[ind, :]\n",
    "                distances = np.array([euclidean_distance(train_sample, test_features) for train_sample in tmp_train_features])\n",
    "                print(distances.shape)\n",
    "                average_distances = np.mean(distances, axis=1)\n",
    "        \n",
    "                # Step 4: Find the overall average distance\n",
    "                overall_average_distance = np.mean(average_distances)\n",
    "                distance_dict[person_nums[ii]] = overall_average_distance\n",
    "        \n",
    "        \n",
    "        def normalize_to_weights(distance_dict):\n",
    "            distances = np.array(list(distance_dict.values()))\n",
    "            # Handle the case where a distance is zero to avoid division by zero\n",
    "            distances = np.clip(distances, a_min=1e-10, a_max=None)\n",
    "            weights = 1 / distances\n",
    "            normalized_weights = weights\n",
    "            # normalized_weights = weights / sum(weights)\n",
    "            # print(sum(weights))\n",
    "            # print(sum(normalized_weights))\n",
    "            # Assign the normalized weights back to the dictionary\n",
    "            normalized_weight_dict = dict(zip(distance_dict.keys(), normalized_weights))\n",
    "            return normalized_weight_dict\n",
    "        def scale_dict_values(my_dict):\n",
    "            scaled_dict = my_dict.copy()\n",
    "            min_val = min(scaled_dict.values())\n",
    "            max_val = max(scaled_dict.values())\n",
    "            \n",
    "            for key in scaled_dict:\n",
    "                scaled_dict[key] = 1 + 9 * (scaled_dict[key] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            return scaled_dict\n",
    "        weights_dict = normalize_to_weights(distance_dict)\n",
    "        weights_dict = scale_dict_values(weights_dict)\n",
    "        print(weights_dict)\n",
    "        \n",
    "        w_train = np.zeros_like(p_train)\n",
    "        for i in range(len(w_train)):\n",
    "            if p_train[i] == test_person_id[0]:\n",
    "                w_train[i] = 50\n",
    "            else:\n",
    "                w_train[i] = weights_dict[int(p_train[i])]\n",
    "        \n",
    "        w_train = np.squeeze(w_train)\n",
    "        \n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,sample_weight= w_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_2_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        idx += 1\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0508e9a1-9544-41f8-af41-e3d3b02a8d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35497\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "ra = 0.1\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71b59e4-6581-4ea8-994d-a02a6654ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:02:52.491217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.502564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.502798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.506027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.506220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.506388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.582997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.583204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.583372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:52.583515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-12-04 18:02:52.583802: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:02:54.466775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:54.467063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:54.467243: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:54.467468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:54.467647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:02:54.467786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-12-04 18:02:54.467848: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-12-04 18:02:54.515527: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-12-04 18:02:54.767082: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_33/lstm_cell_33/kernel/Assign' id:5638 op device:{requested: '', assigned: ''} def:{{{node lstm_33/lstm_cell_33/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_33/lstm_cell_33/kernel, lstm_33/lstm_cell_33/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:02:55.719387: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_17/lstm_cell_17/recurrent_kernel/v/Assign' id:7871 op device:{requested: '', assigned: ''} def:{{{node lstm_17/lstm_cell_17/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_17/lstm_cell_17/recurrent_kernel/v, lstm_17/lstm_cell_17/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:02:56.478365: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3/BiasAdd' id:6369 op device:{requested: '', assigned: ''} def:{{{node dense_3/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3/MatMul, dense_3/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:02:57.045785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-04 18:02:57.094664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.0865947081449818\n",
      "[0.74780105 1.31723215]\n",
      "1.0325166005641222\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_30.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df9b379-2abd-4715-aacd-b28770946484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:03:10.489936: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_4/bias/Assign' id:15514 op device:{requested: '', assigned: ''} def:{{{node dense_4/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_4/bias, dense_4/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:03:11.680242: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_65/lstm_cell_65/kernel/m/Assign' id:16619 op device:{requested: '', assigned: ''} def:{{{node lstm_65/lstm_cell_65/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_65/lstm_cell_65/kernel/m, lstm_65/lstm_cell_65/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:03:12.695562: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_7/BiasAdd' id:15600 op device:{requested: '', assigned: ''} def:{{{node dense_7/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_7/MatMul, dense_7/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.1035816439209467\n",
      "[0.75050656 1.32431437]\n",
      "1.0374104650691152\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_31.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8587f4-15ed-4a01-a6ef-f3d45ecb4d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:03:25.152710: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_102/lstm_cell_102/kernel/Assign' id:23300 op device:{requested: '', assigned: ''} def:{{{node lstm_102/lstm_cell_102/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_102/lstm_cell_102/kernel, lstm_102/lstm_cell_102/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:03:26.644950: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_110/lstm_cell_110/bias/v/Assign' id:26623 op device:{requested: '', assigned: ''} def:{{{node lstm_110/lstm_cell_110/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_110/lstm_cell_110/bias/v, lstm_110/lstm_cell_110/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:03:27.974867: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_11/BiasAdd' id:24831 op device:{requested: '', assigned: ''} def:{{{node dense_11/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_11/MatMul, dense_11/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.0790005066887813\n",
      "[0.75193371 1.28590043]\n",
      "1.018917066976428\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_32.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f606bb-7f25-47b8-86e9-8e8cb694c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35663\n"
     ]
    }
   ],
   "source": [
    "ra = 0.2\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9e993a-bd44-47b9-9f32-21bc44315216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:04:14.467440: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_113/lstm_cell_113/recurrent_kernel/Assign' id:28389 op device:{requested: '', assigned: ''} def:{{{node lstm_113/lstm_cell_113/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_113/lstm_cell_113/recurrent_kernel, lstm_113/lstm_cell_113/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:04:16.327483: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_146/lstm_cell_146/kernel/m/Assign' id:35186 op device:{requested: '', assigned: ''} def:{{{node lstm_146/lstm_cell_146/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_146/lstm_cell_146/kernel/m, lstm_146/lstm_cell_146/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:04:18.028973: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_15/BiasAdd' id:34062 op device:{requested: '', assigned: ''} def:{{{node dense_15/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_15/MatMul, dense_15/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.93481456262292\n",
      "[0.74974022 0.92920852]\n",
      "0.8394743721736105\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_33.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493bb259-adb6-4151-842e-f01758768849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:04:53.394220: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_184/lstm_cell_184/bias/Assign' id:43071 op device:{requested: '', assigned: ''} def:{{{node lstm_184/lstm_cell_184/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_184/lstm_cell_184/bias, lstm_184/lstm_cell_184/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:04:55.650138: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_153/lstm_cell_153/kernel/v/Assign' id:44610 op device:{requested: '', assigned: ''} def:{{{node lstm_153/lstm_cell_153/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_153/lstm_cell_153/kernel/v, lstm_153/lstm_cell_153/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:04:57.757993: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_19/BiasAdd' id:43293 op device:{requested: '', assigned: ''} def:{{{node dense_19/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_19/MatMul, dense_19/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9232833359184465\n",
      "[0.75996254 0.92437163]\n",
      "0.8421670862457209\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_34.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a80894-dad3-4b10-83e5-6eec239dd0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:05:09.681629: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_21/kernel/Assign' id:52472 op device:{requested: '', assigned: ''} def:{{{node dense_21/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_21/kernel, dense_21/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:05:12.290009: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_211/lstm_cell_211/kernel/m/Assign' id:53513 op device:{requested: '', assigned: ''} def:{{{node lstm_211/lstm_cell_211/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_211/lstm_cell_211/kernel/m, lstm_211/lstm_cell_211/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:05:14.758159: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_23/BiasAdd' id:52524 op device:{requested: '', assigned: ''} def:{{{node dense_23/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_23/MatMul, dense_23/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9351695056097034\n",
      "[0.76606113 0.91902519]\n",
      "0.8425431601833879\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_35.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc1e891-3b39-43b5-a1e7-0fa0548a28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35826\n"
     ]
    }
   ],
   "source": [
    "ra = 0.3\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92ffcd8-c9e9-4dcd-8017-1fdeaa952e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:05:37.066227: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_222/lstm_cell_222/bias/Assign' id:55771 op device:{requested: '', assigned: ''} def:{{{node lstm_222/lstm_cell_222/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_222/lstm_cell_222/bias, lstm_222/lstm_cell_222/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:05:40.059185: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_233/lstm_cell_233/kernel/v/Assign' id:63162 op device:{requested: '', assigned: ''} def:{{{node lstm_233/lstm_cell_233/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_233/lstm_cell_233/kernel/v, lstm_233/lstm_cell_233/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:05:42.902543: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_27/BiasAdd' id:61755 op device:{requested: '', assigned: ''} def:{{{node dense_27/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_27/MatMul, dense_27/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8948128486694173\n",
      "[0.6772107  1.01631259]\n",
      "0.8467616438865662\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_36.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c69267-87a0-4b1b-8376-7b41fd79aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:05:54.273491: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_259/lstm_cell_259/bias/Assign' id:65002 op device:{requested: '', assigned: ''} def:{{{node lstm_259/lstm_cell_259/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_259/lstm_cell_259/bias, lstm_259/lstm_cell_259/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:05:57.671570: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_265/lstm_cell_265/kernel/v/Assign' id:72318 op device:{requested: '', assigned: ''} def:{{{node lstm_265/lstm_cell_265/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_265/lstm_cell_265/kernel/v, lstm_265/lstm_cell_265/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:06:00.931870: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_31/BiasAdd' id:70986 op device:{requested: '', assigned: ''} def:{{{node dense_31/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_31/MatMul, dense_31/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.9131851087732518\n",
      "[0.68598142 1.00282523]\n",
      "0.844403321146965\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_37.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e315a1e1-8203-4a59-8ad1-ef0f45d95ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:06:12.726009: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_315/lstm_cell_315/recurrent_kernel/Assign' id:77264 op device:{requested: '', assigned: ''} def:{{{node lstm_315/lstm_cell_315/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_315/lstm_cell_315/recurrent_kernel, lstm_315/lstm_cell_315/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:06:16.511791: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_328/lstm_cell_328/kernel/m/Assign' id:81296 op device:{requested: '', assigned: ''} def:{{{node lstm_328/lstm_cell_328/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_328/lstm_cell_328/kernel/m, lstm_328/lstm_cell_328/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:06:20.167226: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_35/BiasAdd' id:80217 op device:{requested: '', assigned: ''} def:{{{node dense_35/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_35/MatMul, dense_35/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8981542209868736\n",
      "[0.69769372 1.00701135]\n",
      "0.8523525303602218\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_38.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c201d5a-f22f-4d5b-9c48-601155988317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35997\n"
     ]
    }
   ],
   "source": [
    "ra = 0.4\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154998fc-eabc-4564-8639-7d044f9a4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:07:41.521024: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_367/lstm_cell_367/recurrent_kernel/Assign' id:88897 op device:{requested: '', assigned: ''} def:{{{node lstm_367/lstm_cell_367/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_367/lstm_cell_367/recurrent_kernel, lstm_367/lstm_cell_367/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:07:45.703146: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_36/bias/v/Assign' id:91252 op device:{requested: '', assigned: ''} def:{{{node dense_36/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_36/bias/v, dense_36/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:07:49.760134: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_39/BiasAdd' id:89448 op device:{requested: '', assigned: ''} def:{{{node dense_39/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_39/MatMul, dense_39/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8683481273423153\n",
      "[0.70279614 0.96728958]\n",
      "0.8350428606188575\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_39.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e001ca-7c2e-4d36-8bda-b68d9bba4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:08:01.273924: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_42/bias/Assign' id:98653 op device:{requested: '', assigned: ''} def:{{{node dense_42/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_42/bias, dense_42/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:08:05.885857: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_397/lstm_cell_397/bias/m/Assign' id:99693 op device:{requested: '', assigned: ''} def:{{{node lstm_397/lstm_cell_397/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_397/lstm_cell_397/bias/m, lstm_397/lstm_cell_397/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:08:10.361360: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_43/BiasAdd' id:98679 op device:{requested: '', assigned: ''} def:{{{node dense_43/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_43/MatMul, dense_43/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8427907328800376\n",
      "[0.6869143  0.92248536]\n",
      "0.8046998312306959\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_40.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3161609d-c036-40c3-bf09-b7c0aeba7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:08:22.222494: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_441/lstm_cell_441/kernel/Assign' id:107339 op device:{requested: '', assigned: ''} def:{{{node lstm_441/lstm_cell_441/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_441/lstm_cell_441/kernel, lstm_441/lstm_cell_441/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:08:27.292585: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_426/lstm_cell_426/recurrent_kernel/v/Assign' id:109442 op device:{requested: '', assigned: ''} def:{{{node lstm_426/lstm_cell_426/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_426/lstm_cell_426/recurrent_kernel/v, lstm_426/lstm_cell_426/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:08:32.240613: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_47/BiasAdd' id:107910 op device:{requested: '', assigned: ''} def:{{{node dense_47/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_47/MatMul, dense_47/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.855536894197483\n",
      "[0.68514277 0.95294498]\n",
      "0.8190438775129096\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_41.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9adab8c7-01f5-445f-aadb-5f182a66495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36167\n"
     ]
    }
   ],
   "source": [
    "ra = 0.5\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d029010e-d630-4e6e-b2d1-9cb6bd767875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:08:50.566582: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_463/lstm_cell_463/recurrent_kernel/Assign' id:114188 op device:{requested: '', assigned: ''} def:{{{node lstm_463/lstm_cell_463/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_463/lstm_cell_463/recurrent_kernel, lstm_463/lstm_cell_463/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:08:56.076111: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_478/lstm_cell_478/kernel/v/Assign' id:118893 op device:{requested: '', assigned: ''} def:{{{node lstm_478/lstm_cell_478/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_478/lstm_cell_478/kernel/v, lstm_478/lstm_cell_478/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:09:01.435136: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_51/BiasAdd' id:117141 op device:{requested: '', assigned: ''} def:{{{node dense_51/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_51/MatMul, dense_51/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8274425944264272\n",
      "[0.65208757 0.94432876]\n",
      "0.7982081628181565\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_42.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6485e267-b493-43a4-a54c-11c58825da58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:09:13.098749: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_493/lstm_cell_493/recurrent_kernel/Assign' id:122299 op device:{requested: '', assigned: ''} def:{{{node lstm_493/lstm_cell_493/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_493/lstm_cell_493/recurrent_kernel, lstm_493/lstm_cell_493/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:09:18.890761: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_55/bias/v/Assign' id:128210 op device:{requested: '', assigned: ''} def:{{{node dense_55/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_55/bias/v, dense_55/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:09:24.584778: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_55/BiasAdd' id:126372 op device:{requested: '', assigned: ''} def:{{{node dense_55/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_55/MatMul, dense_55/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8223609301111967\n",
      "[0.66895257 0.92135502]\n",
      "0.795153794154315\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_43.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb84078-92a2-4ec7-a487-421725425719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:09:36.764170: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_529/lstm_cell_529/bias/Assign' id:131379 op device:{requested: '', assigned: ''} def:{{{node lstm_529/lstm_cell_529/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_529/lstm_cell_529/bias, lstm_529/lstm_cell_529/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:09:42.983926: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_57/bias/m/Assign' id:136177 op device:{requested: '', assigned: ''} def:{{{node conv2d_57/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_57/bias/m, conv2d_57/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:09:49.064861: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_59/BiasAdd' id:135603 op device:{requested: '', assigned: ''} def:{{{node dense_59/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_59/MatMul, dense_59/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8337548766776526\n",
      "[0.65852559 0.95457182]\n",
      "0.8065487028847278\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_44.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "429bb79d-1af2-4135-9f5c-36ade88a98fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36328\n"
     ]
    }
   ],
   "source": [
    "ra = 0.6\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bbc4c8b-2c6a-48e6-86d4-a56f99ac57e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:10:21.934258: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_62/kernel/Assign' id:138597 op device:{requested: '', assigned: ''} def:{{{node conv2d_62/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_62/kernel, conv2d_62/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:10:28.566786: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_568/lstm_cell_568/kernel/m/Assign' id:145628 op device:{requested: '', assigned: ''} def:{{{node lstm_568/lstm_cell_568/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_568/lstm_cell_568/kernel/m, lstm_568/lstm_cell_568/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:10:34.966249: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_63/BiasAdd' id:144834 op device:{requested: '', assigned: ''} def:{{{node dense_63/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_63/MatMul, dense_63/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8287728557260748\n",
      "[0.61851506 0.97061304]\n",
      "0.7945640505405894\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_45.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14b0c6bb-f727-469c-977d-c27fd92446ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:10:48.545397: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_627/lstm_cell_627/kernel/Assign' id:153654 op device:{requested: '', assigned: ''} def:{{{node lstm_627/lstm_cell_627/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_627/lstm_cell_627/kernel, lstm_627/lstm_cell_627/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:10:55.545911: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_606/lstm_cell_606/kernel/m/Assign' id:154874 op device:{requested: '', assigned: ''} def:{{{node lstm_606/lstm_cell_606/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_606/lstm_cell_606/kernel/m, lstm_606/lstm_cell_606/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:11:02.446844: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_67/BiasAdd' id:154065 op device:{requested: '', assigned: ''} def:{{{node dense_67/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_67/MatMul, dense_67/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8778266753519803\n",
      "[0.67801124 1.01868455]\n",
      "0.8483478981151915\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_46.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c82b1034-628e-4fc5-b816-ff0ea71cb83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:11:15.855244: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_650/lstm_cell_650/bias/Assign' id:160672 op device:{requested: '', assigned: ''} def:{{{node lstm_650/lstm_cell_650/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_650/lstm_cell_650/bias, lstm_650/lstm_cell_650/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:11:23.321595: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_655/lstm_cell_655/kernel/v/Assign' id:164928 op device:{requested: '', assigned: ''} def:{{{node lstm_655/lstm_cell_655/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_655/lstm_cell_655/kernel/v, lstm_655/lstm_cell_655/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:11:30.651827: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_71/BiasAdd' id:163296 op device:{requested: '', assigned: ''} def:{{{node dense_71/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_71/MatMul, dense_71/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "0.8526589003395716\n",
      "[0.66511258 0.99107279]\n",
      "0.8280926859169676\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_few_shot_p2_47.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc5b6b53-6b52-4245-b428-7d866b854826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35332\n"
     ]
    }
   ],
   "source": [
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "test_person_id = [2]\n",
    "flag_tr_val_te = split_data_unknown(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, rand_seed = 42)\n",
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]\n",
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ddc8c6-4ff6-49c6-a4c6-994f0545354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:12:36.592121: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_1_1/bias/Assign' id:172480 op device:{requested: '', assigned: ''} def:{{{node dense_1_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_1_1/bias, dense_1_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:12:44.477686: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_6_1/lstm_cell_672/recurrent_kernel/v/Assign' id:173864 op device:{requested: '', assigned: ''} def:{{{node lstm_6_1/lstm_cell_672/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_6_1/lstm_cell_672/recurrent_kernel/v, lstm_6_1/lstm_cell_672/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-04 18:12:52.211878: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_3_1/BiasAdd' id:172527 op device:{requested: '', assigned: ''} def:{{{node dense_3_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_3_1/MatMul, dense_3_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.1979000295544184\n",
      "[0.82767452 1.40138737]\n",
      "1.114530944488418\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_p2_20.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed6536f3-a586-4ae3-8186-ccc943000654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:13:12.562142: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_45_1/lstm_cell_711/bias/Assign' id:177054 op device:{requested: '', assigned: ''} def:{{{node lstm_45_1/lstm_cell_711/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_45_1/lstm_cell_711/bias, lstm_45_1/lstm_cell_711/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:13:20.819970: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_60_1/lstm_cell_726/bias/m/Assign' id:182712 op device:{requested: '', assigned: ''} def:{{{node lstm_60_1/lstm_cell_726/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_60_1/lstm_cell_726/bias/m, lstm_60_1/lstm_cell_726/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:13:28.989369: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_7_1/BiasAdd' id:181758 op device:{requested: '', assigned: ''} def:{{{node dense_7_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_7_1/MatMul, dense_7_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.2259714898411709\n",
      "[0.82736458 1.39599526]\n",
      "1.1116799200084848\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_p2_21.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c87a8d19-3f83-4aa5-8421-06d2c1fab9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:13:50.674820: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_80_1/lstm_cell_746/bias/Assign' id:185965 op device:{requested: '', assigned: ''} def:{{{node lstm_80_1/lstm_cell_746/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_80_1/lstm_cell_746/bias, lstm_80_1/lstm_cell_746/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:14:00.060300: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_100_1/lstm_cell_766/recurrent_kernel/v/Assign' id:192626 op device:{requested: '', assigned: ''} def:{{{node lstm_100_1/lstm_cell_766/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_100_1/lstm_cell_766/recurrent_kernel/v, lstm_100_1/lstm_cell_766/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 18:14:08.653966: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_11_1/BiasAdd' id:190989 op device:{requested: '', assigned: ''} def:{{{node dense_11_1/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_11_1/MatMul, dense_11_1/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:\n",
      "1.1592747076604808\n",
      "[0.82875315 1.37660028]\n",
      "1.1026767106123374\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on test data\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./checkpoints/unknown_person_p2_22.h5\")\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "trace_wlk_num = label_unique_tuples(people_nums_all, walk_nums_all, trace_nums_all)\n",
    "trace_wlk_num = np.array(trace_wlk_num )\n",
    "\n",
    "y_pred = model.predict(X_test_normalized_new)\n",
    "print('Test MAE:')\n",
    "err = np.mean(np.abs(y_pred - y_test))\n",
    "print(err)\n",
    "## Evaluation: trace median vote\n",
    "trace_num_test = trace_wlk_num[test_idx]\n",
    "u = np.unique(trace_num_test)\n",
    "pred_trace = np.empty((0, 2))\n",
    "gt_trace = np.empty((0, 2))\n",
    "for i in u:\n",
    "  trace_idx = np.where(trace_num_test == i)[0]\n",
    "  y_pred_trace = y_pred[trace_idx,:]\n",
    "  pred = np.mean(y_pred_trace, axis = 0)\n",
    "  pred_trace = np.vstack((pred_trace, pred))\n",
    "  gt_t = y_test[trace_idx[0],:]\n",
    "  gt_trace = np.vstack((gt_trace, gt_t))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace), axis = 0))\n",
    "print(np.mean(np.abs(pred_trace-gt_trace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b237b-bcde-4961-8f6e-0b455a402d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
