{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f8da1-2837-4bf7-b3f4-dfcaa7ab42f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T04:12:46.517039Z",
     "iopub.status.busy": "2023-11-24T04:12:46.516896Z",
     "iopub.status.idle": "2023-11-24T04:12:46.605170Z",
     "shell.execute_reply": "2023-11-24T04:12:46.604580Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe25376-b856-4296-ba02-5e3771ff9451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T04:12:46.607721Z",
     "iopub.status.busy": "2023-11-24T04:12:46.607532Z",
     "iopub.status.idle": "2023-11-24T21:17:27.844285Z",
     "shell.execute_reply": "2023-11-24T21:17:27.843610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:12:46.792193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35057\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:14:10.042922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.054234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.054455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.057817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.057996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.058158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.130869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.131076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.131242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:10.131383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-11-23 23:14:10.131638: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:14:11.074917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:11.075203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:11.075401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:11.075616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:11.075791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:14:11.075928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-11-23 23:14:11.075960: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-23 23:14:11.099901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-23 23:14:11.317708: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_11/lstm_cell_11/bias/Assign' id:1860 op device:{requested: '', assigned: ''} def:{{{node lstm_11/lstm_cell_11/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_11/lstm_cell_11/bias, lstm_11/lstm_cell_11/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 23:14:11.452118: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 23:14:11.485429: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31543, 95)\n",
      "Train on 31543 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:14:16.019205: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_20/lstm_cell_20/recurrent_kernel/m/Assign' id:16699 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_20/lstm_cell_20/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_20/lstm_cell_20/recurrent_kernel/m, training/Adam/lstm_20/lstm_cell_20/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:14:19.980394: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-23 23:14:22.323134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-23 23:14:22.336166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 2.8456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-23 23:14:44.572469: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6477 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.83815, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 30s 944us/sample - loss: 2.8456 - val_loss: 1.8382\n",
      "Epoch 2/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.7470\n",
      "Epoch 2: val_loss improved from 1.83815 to 1.59166, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 696us/sample - loss: 1.7470 - val_loss: 1.5917\n",
      "Epoch 3/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.6084\n",
      "Epoch 3: val_loss improved from 1.59166 to 1.51471, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 21s 656us/sample - loss: 1.6084 - val_loss: 1.5147\n",
      "Epoch 4/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5520\n",
      "Epoch 4: val_loss improved from 1.51471 to 1.47992, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 693us/sample - loss: 1.5520 - val_loss: 1.4799\n",
      "Epoch 5/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5289\n",
      "Epoch 5: val_loss improved from 1.47992 to 1.46043, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 683us/sample - loss: 1.5289 - val_loss: 1.4604\n",
      "Epoch 6/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5119\n",
      "Epoch 6: val_loss improved from 1.46043 to 1.45124, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 627us/sample - loss: 1.5119 - val_loss: 1.4512\n",
      "Epoch 7/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5020\n",
      "Epoch 7: val_loss improved from 1.45124 to 1.44394, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.5020 - val_loss: 1.4439\n",
      "Epoch 8/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4962\n",
      "Epoch 8: val_loss improved from 1.44394 to 1.44028, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 1.4962 - val_loss: 1.4403\n",
      "Epoch 9/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4887\n",
      "Epoch 9: val_loss improved from 1.44028 to 1.43712, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 694us/sample - loss: 1.4887 - val_loss: 1.4371\n",
      "Epoch 10/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4839\n",
      "Epoch 10: val_loss improved from 1.43712 to 1.43700, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 689us/sample - loss: 1.4839 - val_loss: 1.4370\n",
      "Epoch 11/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 11: val_loss improved from 1.43700 to 1.42689, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 693us/sample - loss: 1.4827 - val_loss: 1.4269\n",
      "Epoch 12/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4749\n",
      "Epoch 12: val_loss did not improve from 1.42689\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 1.4749 - val_loss: 1.4289\n",
      "Epoch 13/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4702\n",
      "Epoch 13: val_loss did not improve from 1.42689\n",
      "31543/31543 [==============================] - 22s 686us/sample - loss: 1.4702 - val_loss: 1.4301\n",
      "Epoch 14/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4973\n",
      "Epoch 14: val_loss improved from 1.42689 to 1.42503, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 647us/sample - loss: 1.4973 - val_loss: 1.4250\n",
      "Epoch 15/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4777\n",
      "Epoch 15: val_loss did not improve from 1.42503\n",
      "31543/31543 [==============================] - 20s 620us/sample - loss: 1.4777 - val_loss: 1.4281\n",
      "Epoch 16/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4607\n",
      "Epoch 16: val_loss improved from 1.42503 to 1.41832, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 21s 657us/sample - loss: 1.4607 - val_loss: 1.4183\n",
      "Epoch 17/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4634\n",
      "Epoch 17: val_loss did not improve from 1.41832\n",
      "31543/31543 [==============================] - 20s 640us/sample - loss: 1.4634 - val_loss: 1.4254\n",
      "Epoch 18/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4662\n",
      "Epoch 18: val_loss improved from 1.41832 to 1.41397, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 622us/sample - loss: 1.4662 - val_loss: 1.4140\n",
      "Epoch 19/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4613\n",
      "Epoch 19: val_loss did not improve from 1.41397\n",
      "31543/31543 [==============================] - 20s 618us/sample - loss: 1.4613 - val_loss: 1.4179\n",
      "Epoch 20/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4642\n",
      "Epoch 20: val_loss did not improve from 1.41397\n",
      "31543/31543 [==============================] - 20s 620us/sample - loss: 1.4642 - val_loss: 1.4288\n",
      "Epoch 21/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 21: val_loss improved from 1.41397 to 1.40974, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 707us/sample - loss: 1.4525 - val_loss: 1.4097\n",
      "Epoch 22/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4831\n",
      "Epoch 22: val_loss did not improve from 1.40974\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 1.4831 - val_loss: 1.4138\n",
      "Epoch 23/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4833\n",
      "Epoch 23: val_loss did not improve from 1.40974\n",
      "31543/31543 [==============================] - 22s 686us/sample - loss: 1.4833 - val_loss: 1.4195\n",
      "Epoch 24/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4556\n",
      "Epoch 24: val_loss did not improve from 1.40974\n",
      "31543/31543 [==============================] - 19s 613us/sample - loss: 1.4556 - val_loss: 1.4111\n",
      "Epoch 25/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 25: val_loss improved from 1.40974 to 1.40436, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 623us/sample - loss: 1.4432 - val_loss: 1.4044\n",
      "Epoch 26/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 26: val_loss improved from 1.40436 to 1.40120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 621us/sample - loss: 1.4420 - val_loss: 1.4012\n",
      "Epoch 27/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4352\n",
      "Epoch 27: val_loss did not improve from 1.40120\n",
      "31543/31543 [==============================] - 21s 668us/sample - loss: 1.4352 - val_loss: 1.4066\n",
      "Epoch 28/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4343\n",
      "Epoch 28: val_loss improved from 1.40120 to 1.39810, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 1.4343 - val_loss: 1.3981\n",
      "Epoch 29/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4302\n",
      "Epoch 29: val_loss did not improve from 1.39810\n",
      "31543/31543 [==============================] - 22s 686us/sample - loss: 1.4302 - val_loss: 1.4010\n",
      "Epoch 30/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4303\n",
      "Epoch 30: val_loss did not improve from 1.39810\n",
      "31543/31543 [==============================] - 21s 671us/sample - loss: 1.4303 - val_loss: 1.4015\n",
      "Epoch 31/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4264\n",
      "Epoch 31: val_loss did not improve from 1.39810\n",
      "31543/31543 [==============================] - 19s 611us/sample - loss: 1.4264 - val_loss: 1.3985\n",
      "Epoch 32/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4234\n",
      "Epoch 32: val_loss improved from 1.39810 to 1.38913, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 21s 666us/sample - loss: 1.4234 - val_loss: 1.3891\n",
      "Epoch 33/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4253\n",
      "Epoch 33: val_loss did not improve from 1.38913\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4253 - val_loss: 1.3957\n",
      "Epoch 34/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4203\n",
      "Epoch 34: val_loss did not improve from 1.38913\n",
      "31543/31543 [==============================] - 20s 632us/sample - loss: 1.4203 - val_loss: 1.3922\n",
      "Epoch 35/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 35: val_loss did not improve from 1.38913\n",
      "31543/31543 [==============================] - 20s 619us/sample - loss: 1.4191 - val_loss: 1.3958\n",
      "Epoch 36/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4197\n",
      "Epoch 36: val_loss did not improve from 1.38913\n",
      "31543/31543 [==============================] - 20s 631us/sample - loss: 1.4197 - val_loss: 1.3946\n",
      "Epoch 37/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4167\n",
      "Epoch 37: val_loss improved from 1.38913 to 1.38909, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4167 - val_loss: 1.3891\n",
      "Epoch 38/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 38: val_loss did not improve from 1.38909\n",
      "31543/31543 [==============================] - 19s 608us/sample - loss: 1.4123 - val_loss: 1.3909\n",
      "Epoch 39/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4133\n",
      "Epoch 39: val_loss improved from 1.38909 to 1.38754, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 21s 650us/sample - loss: 1.4133 - val_loss: 1.3875\n",
      "Epoch 40/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 40: val_loss did not improve from 1.38754\n",
      "31543/31543 [==============================] - 19s 606us/sample - loss: 1.4126 - val_loss: 1.3879\n",
      "Epoch 41/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4086\n",
      "Epoch 41: val_loss did not improve from 1.38754\n",
      "31543/31543 [==============================] - 19s 612us/sample - loss: 1.4086 - val_loss: 1.3972\n",
      "Epoch 42/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4089\n",
      "Epoch 42: val_loss improved from 1.38754 to 1.38652, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 19s 611us/sample - loss: 1.4089 - val_loss: 1.3865\n",
      "Epoch 43/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 43: val_loss did not improve from 1.38652\n",
      "31543/31543 [==============================] - 19s 603us/sample - loss: 1.4082 - val_loss: 1.3878\n",
      "Epoch 44/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4072\n",
      "Epoch 44: val_loss improved from 1.38652 to 1.38521, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 19s 610us/sample - loss: 1.4072 - val_loss: 1.3852\n",
      "Epoch 45/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4029\n",
      "Epoch 45: val_loss did not improve from 1.38521\n",
      "31543/31543 [==============================] - 19s 597us/sample - loss: 1.4029 - val_loss: 1.3888\n",
      "Epoch 46/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4013\n",
      "Epoch 46: val_loss improved from 1.38521 to 1.38180, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 622us/sample - loss: 1.4013 - val_loss: 1.3818\n",
      "Epoch 47/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4009\n",
      "Epoch 47: val_loss improved from 1.38180 to 1.38067, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 629us/sample - loss: 1.4009 - val_loss: 1.3807\n",
      "Epoch 48/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 48: val_loss did not improve from 1.38067\n",
      "31543/31543 [==============================] - 20s 627us/sample - loss: 1.4011 - val_loss: 1.3912\n",
      "Epoch 49/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4012\n",
      "Epoch 49: val_loss improved from 1.38067 to 1.38031, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 629us/sample - loss: 1.4012 - val_loss: 1.3803\n",
      "Epoch 50/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 50: val_loss improved from 1.38031 to 1.37992, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_30.h5\n",
      "31543/31543 [==============================] - 20s 635us/sample - loss: 1.3984 - val_loss: 1.3799\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/ops/init_ops.py:94: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:31:35.863799: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_29_1/lstm_cell_66/kernel/Assign' id:23282 op device:{requested: '', assigned: ''} def:{{{node lstm_29_1/lstm_cell_66/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_29_1/lstm_cell_66/kernel, lstm_29_1/lstm_cell_66/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 23:31:37.838092: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_14_1/lstm_cell_51/bias/m/Assign' id:25472 op device:{requested: '', assigned: ''} def:{{{node lstm_14_1/lstm_cell_51/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_14_1/lstm_cell_51/bias/m, lstm_14_1/lstm_cell_51/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-23 23:31:39.411142: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_4_1/cond/Merge' id:24591 op device:{requested: '', assigned: ''} def:{{{node dropout_4_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_4_1/cond/Identity, dropout_4_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1944)\n",
      "(1514, 1944)\n",
      "(1644, 1944)\n",
      "(1764, 1944)\n",
      "(1836, 1944)\n",
      "(1699, 1944)\n",
      "(1369, 1944)\n",
      "(1766, 1944)\n",
      "(1631, 1944)\n",
      "(1692, 1944)\n",
      "(1550, 1944)\n",
      "(1920, 1944)\n",
      "(1739, 1944)\n",
      "(1788, 1944)\n",
      "(1812, 1944)\n",
      "(1788, 1944)\n",
      "(1776, 1944)\n",
      "(946, 1944)\n",
      "(1608, 1944)\n",
      "{1: 4.622800994560576, 2: 1.7828899655461234, 4: 4.526228916857533, 5: 9.215116876080431, 6: 10.0, 8: 5.012085625358194, 9: 1.4754130325584307, 10: 6.197867411231607, 11: 3.3924667214519486, 12: 4.697843275672263, 13: 5.341006783408661, 17: 4.2802015567874605, 19: 5.093618177791599, 21: 5.617144789659331, 22: 2.2472379412163095, 25: 3.9311500257592242, 26: 3.2420411895992998, 27: 1.0, 28: 4.775502729073519}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2920137/1660627543.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31543 samples, validate on 3514 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:35:31.076561: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3049\n",
      "Epoch 1: val_loss improved from inf to 1.39994, saving model to ./checkpoints/unknown_person_few_shot_p29_30.h5\n",
      "31543/31543 [==============================] - 25s 791us/sample - loss: 7.3049 - val_loss: 1.3999\n",
      "Epoch 2/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.2528\n",
      "Epoch 2: val_loss improved from 1.39994 to 1.39536, saving model to ./checkpoints/unknown_person_few_shot_p29_30.h5\n",
      "31543/31543 [==============================] - 19s 596us/sample - loss: 7.2528 - val_loss: 1.3954\n",
      "Epoch 3/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.2029\n",
      "Epoch 3: val_loss did not improve from 1.39536\n",
      "31543/31543 [==============================] - 19s 597us/sample - loss: 7.2029 - val_loss: 1.4008\n",
      "Epoch 4/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.1643\n",
      "Epoch 4: val_loss improved from 1.39536 to 1.39280, saving model to ./checkpoints/unknown_person_few_shot_p29_30.h5\n",
      "31543/31543 [==============================] - 19s 604us/sample - loss: 7.1643 - val_loss: 1.3928\n",
      "Epoch 5/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.1363\n",
      "Epoch 5: val_loss did not improve from 1.39280\n",
      "31543/31543 [==============================] - 20s 622us/sample - loss: 7.1363 - val_loss: 1.3942\n",
      "Epoch 6/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.1195\n",
      "Epoch 6: val_loss improved from 1.39280 to 1.38643, saving model to ./checkpoints/unknown_person_few_shot_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 693us/sample - loss: 7.1195 - val_loss: 1.3864\n",
      "Epoch 7/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0939\n",
      "Epoch 7: val_loss did not improve from 1.38643\n",
      "31543/31543 [==============================] - 22s 687us/sample - loss: 7.0939 - val_loss: 1.3957\n",
      "Epoch 8/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0729\n",
      "Epoch 8: val_loss did not improve from 1.38643\n",
      "31543/31543 [==============================] - 20s 633us/sample - loss: 7.0729 - val_loss: 1.3919\n",
      "Epoch 9/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0934\n",
      "Epoch 9: val_loss improved from 1.38643 to 1.37861, saving model to ./checkpoints/unknown_person_few_shot_p29_30.h5\n",
      "31543/31543 [==============================] - 19s 607us/sample - loss: 7.0934 - val_loss: 1.3786\n",
      "Epoch 10/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0502\n",
      "Epoch 10: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 19s 598us/sample - loss: 7.0502 - val_loss: 1.3805\n",
      "Epoch 11/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0466\n",
      "Epoch 11: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 19s 610us/sample - loss: 7.0466 - val_loss: 1.3840\n",
      "Epoch 12/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0272\n",
      "Epoch 12: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 7.0272 - val_loss: 1.3866\n",
      "Epoch 13/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0275\n",
      "Epoch 13: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 20s 627us/sample - loss: 7.0275 - val_loss: 1.3905\n",
      "Epoch 14/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.0060\n",
      "Epoch 14: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 20s 631us/sample - loss: 7.0060 - val_loss: 1.3820\n",
      "Epoch 15/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 6.9820\n",
      "Epoch 15: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 20s 648us/sample - loss: 6.9820 - val_loss: 1.3820\n",
      "Epoch 16/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 6.9975\n",
      "Epoch 16: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 6.9975 - val_loss: 1.3808\n",
      "Epoch 17/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 6.9594\n",
      "Epoch 17: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 6.9594 - val_loss: 1.3815\n",
      "Epoch 18/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 6.9699\n",
      "Epoch 18: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 21s 679us/sample - loss: 6.9699 - val_loss: 1.3806\n",
      "Epoch 19/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 6.9392\n",
      "Epoch 19: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 19s 611us/sample - loss: 6.9392 - val_loss: 1.3881\n",
      "Epoch 20/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 6.9604\n",
      "Epoch 20: val_loss did not improve from 1.37861\n",
      "31543/31543 [==============================] - 19s 595us/sample - loss: 6.9604 - val_loss: 1.3813\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:42:19.739781: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_27_2/lstm_cell_101/kernel/Assign' id:42360 op device:{requested: '', assigned: ''} def:{{{node lstm_27_2/lstm_cell_101/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_27_2/lstm_cell_101/kernel, lstm_27_2/lstm_cell_101/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 23:42:22.224850: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_5/bias/m/Assign' id:44613 op device:{requested: '', assigned: ''} def:{{{node conv2d_5/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_5/bias/m, conv2d_5/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31543 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:42:27.514261: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:42:40.417233: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_6/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:43:01.178904: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_5/mul' id:44579 op device:{requested: '', assigned: ''} def:{{{node loss_5/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul/x, loss_5/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38012, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_30.h5\n",
      "31543/31543 [==============================] - 27s 860us/sample - loss: 1.3984 - val_loss: 1.3801\n",
      "Epoch 2/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 2: val_loss did not improve from 1.38012\n",
      "31543/31543 [==============================] - 19s 615us/sample - loss: 1.3948 - val_loss: 1.3863\n",
      "Epoch 3/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3960\n",
      "Epoch 3: val_loss did not improve from 1.38012\n",
      "31543/31543 [==============================] - 19s 610us/sample - loss: 1.3960 - val_loss: 1.3831\n",
      "Epoch 4/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 4: val_loss did not improve from 1.38012\n",
      "31543/31543 [==============================] - 19s 613us/sample - loss: 1.3939 - val_loss: 1.3836\n",
      "Epoch 5/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 5: val_loss did not improve from 1.38012\n",
      "31543/31543 [==============================] - 21s 668us/sample - loss: 1.3902 - val_loss: 1.3815\n",
      "Epoch 6/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3899\n",
      "Epoch 6: val_loss improved from 1.38012 to 1.37380, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_30.h5\n",
      "31543/31543 [==============================] - 19s 613us/sample - loss: 1.3899 - val_loss: 1.3738\n",
      "Epoch 7/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3877\n",
      "Epoch 7: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 1.3877 - val_loss: 1.3771\n",
      "Epoch 8/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3833\n",
      "Epoch 8: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 686us/sample - loss: 1.3833 - val_loss: 1.3755\n",
      "Epoch 9/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3860\n",
      "Epoch 9: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 21s 663us/sample - loss: 1.3860 - val_loss: 1.3834\n",
      "Epoch 10/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3879\n",
      "Epoch 10: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 20s 643us/sample - loss: 1.3879 - val_loss: 1.3860\n",
      "Epoch 11/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3839\n",
      "Epoch 11: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 21s 681us/sample - loss: 1.3839 - val_loss: 1.3802\n",
      "Epoch 12/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3826\n",
      "Epoch 12: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 693us/sample - loss: 1.3826 - val_loss: 1.3785\n",
      "Epoch 13/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3810\n",
      "Epoch 13: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 699us/sample - loss: 1.3810 - val_loss: 1.3759\n",
      "Epoch 14/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3812\n",
      "Epoch 14: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 693us/sample - loss: 1.3812 - val_loss: 1.3766\n",
      "Epoch 15/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3787\n",
      "Epoch 15: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 690us/sample - loss: 1.3787 - val_loss: 1.3743\n",
      "Epoch 16/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3770\n",
      "Epoch 16: val_loss did not improve from 1.37380\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.3770 - val_loss: 1.3740\n",
      "Epoch 17/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3774\n",
      "Epoch 17: val_loss improved from 1.37380 to 1.37312, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_30.h5\n",
      "31543/31543 [==============================] - 22s 684us/sample - loss: 1.3774 - val_loss: 1.3731\n",
      "Epoch 18/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3788\n",
      "Epoch 18: val_loss did not improve from 1.37312\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 1.3788 - val_loss: 1.3762\n",
      "Epoch 19/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3751\n",
      "Epoch 19: val_loss improved from 1.37312 to 1.36581, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_30.h5\n",
      "31543/31543 [==============================] - 21s 682us/sample - loss: 1.3751 - val_loss: 1.3658\n",
      "Epoch 20/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3755\n",
      "Epoch 20: val_loss did not improve from 1.36581\n",
      "31543/31543 [==============================] - 19s 602us/sample - loss: 1.3755 - val_loss: 1.3666\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:49:46.200022: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_53/lstm_cell_127/recurrent_kernel/Assign' id:59720 op device:{requested: '', assigned: ''} def:{{{node lstm_53/lstm_cell_127/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_53/lstm_cell_127/recurrent_kernel, lstm_53/lstm_cell_127/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 23:49:47.572587: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_1' id:60678 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-23 23:49:48.627547: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_1/stack_2' id:60679 op device:{requested: '', assigned: ''} def:{{{node strided_slice_1/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31543, 95)\n",
      "Train on 31543 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:49:55.049489: W tensorflow/c/c_api.cc:304] Operation '{name:'training_6/Adam/lstm_47/lstm_cell_121/kernel/v/Assign' id:74229 op device:{requested: '', assigned: ''} def:{{{node training_6/Adam/lstm_47/lstm_cell_121/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_6/Adam/lstm_47/lstm_cell_121/kernel/v, training_6/Adam/lstm_47/lstm_cell_121/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:50:11.762950: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 3.4618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:50:33.133109: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_7/mul' id:63519 op device:{requested: '', assigned: ''} def:{{{node loss_7/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_7/mul/x, loss_7/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.00187, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 38s 1ms/sample - loss: 3.4618 - val_loss: 2.0019\n",
      "Epoch 2/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.8295\n",
      "Epoch 2: val_loss improved from 2.00187 to 1.59619, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 1.8295 - val_loss: 1.5962\n",
      "Epoch 3/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.6172\n",
      "Epoch 3: val_loss improved from 1.59619 to 1.52162, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 672us/sample - loss: 1.6172 - val_loss: 1.5216\n",
      "Epoch 4/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5598\n",
      "Epoch 4: val_loss improved from 1.52162 to 1.48916, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 635us/sample - loss: 1.5598 - val_loss: 1.4892\n",
      "Epoch 5/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5352\n",
      "Epoch 5: val_loss improved from 1.48916 to 1.47730, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 19s 603us/sample - loss: 1.5352 - val_loss: 1.4773\n",
      "Epoch 6/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5169\n",
      "Epoch 6: val_loss improved from 1.47730 to 1.46758, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 19s 606us/sample - loss: 1.5169 - val_loss: 1.4676\n",
      "Epoch 7/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5060\n",
      "Epoch 7: val_loss improved from 1.46758 to 1.45433, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 684us/sample - loss: 1.5060 - val_loss: 1.4543\n",
      "Epoch 8/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5033\n",
      "Epoch 8: val_loss improved from 1.45433 to 1.44601, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.5033 - val_loss: 1.4460\n",
      "Epoch 9/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4932\n",
      "Epoch 9: val_loss did not improve from 1.44601\n",
      "31543/31543 [==============================] - 20s 634us/sample - loss: 1.4932 - val_loss: 1.4464\n",
      "Epoch 10/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5326\n",
      "Epoch 10: val_loss improved from 1.44601 to 1.44264, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 650us/sample - loss: 1.5326 - val_loss: 1.4426\n",
      "Epoch 11/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5060\n",
      "Epoch 11: val_loss improved from 1.44264 to 1.43303, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 678us/sample - loss: 1.5060 - val_loss: 1.4330\n",
      "Epoch 12/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5138\n",
      "Epoch 12: val_loss improved from 1.43303 to 1.43064, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 658us/sample - loss: 1.5138 - val_loss: 1.4306\n",
      "Epoch 13/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4885\n",
      "Epoch 13: val_loss improved from 1.43064 to 1.42703, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 699us/sample - loss: 1.4885 - val_loss: 1.4270\n",
      "Epoch 14/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5164\n",
      "Epoch 14: val_loss did not improve from 1.42703\n",
      "31543/31543 [==============================] - 19s 618us/sample - loss: 1.5164 - val_loss: 1.4289\n",
      "Epoch 15/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5421\n",
      "Epoch 15: val_loss did not improve from 1.42703\n",
      "31543/31543 [==============================] - 19s 613us/sample - loss: 1.5421 - val_loss: 1.4290\n",
      "Epoch 16/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5026\n",
      "Epoch 16: val_loss improved from 1.42703 to 1.42638, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 676us/sample - loss: 1.5026 - val_loss: 1.4264\n",
      "Epoch 17/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4934\n",
      "Epoch 17: val_loss improved from 1.42638 to 1.42213, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 635us/sample - loss: 1.4934 - val_loss: 1.4221\n",
      "Epoch 18/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 18: val_loss improved from 1.42213 to 1.42166, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 690us/sample - loss: 1.4836 - val_loss: 1.4217\n",
      "Epoch 19/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4870\n",
      "Epoch 19: val_loss improved from 1.42166 to 1.41938, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 689us/sample - loss: 1.4870 - val_loss: 1.4194\n",
      "Epoch 20/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5186\n",
      "Epoch 20: val_loss did not improve from 1.41938\n",
      "31543/31543 [==============================] - 22s 694us/sample - loss: 1.5186 - val_loss: 1.4210\n",
      "Epoch 21/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5180\n",
      "Epoch 21: val_loss did not improve from 1.41938\n",
      "31543/31543 [==============================] - 22s 695us/sample - loss: 1.5180 - val_loss: 1.4265\n",
      "Epoch 22/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5118\n",
      "Epoch 22: val_loss did not improve from 1.41938\n",
      "31543/31543 [==============================] - 22s 694us/sample - loss: 1.5118 - val_loss: 1.4235\n",
      "Epoch 23/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4802\n",
      "Epoch 23: val_loss improved from 1.41938 to 1.41688, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 694us/sample - loss: 1.4802 - val_loss: 1.4169\n",
      "Epoch 24/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4724\n",
      "Epoch 24: val_loss did not improve from 1.41688\n",
      "31543/31543 [==============================] - 22s 696us/sample - loss: 1.4724 - val_loss: 1.4245\n",
      "Epoch 25/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 25: val_loss did not improve from 1.41688\n",
      "31543/31543 [==============================] - 21s 660us/sample - loss: 1.4689 - val_loss: 1.4196\n",
      "Epoch 26/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4639\n",
      "Epoch 26: val_loss improved from 1.41688 to 1.41681, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.4639 - val_loss: 1.4168\n",
      "Epoch 27/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4587\n",
      "Epoch 27: val_loss improved from 1.41681 to 1.41195, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 675us/sample - loss: 1.4587 - val_loss: 1.4120\n",
      "Epoch 28/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4562\n",
      "Epoch 28: val_loss did not improve from 1.41195\n",
      "31543/31543 [==============================] - 20s 633us/sample - loss: 1.4562 - val_loss: 1.4135\n",
      "Epoch 29/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4524\n",
      "Epoch 29: val_loss did not improve from 1.41195\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4524 - val_loss: 1.4137\n",
      "Epoch 30/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4472\n",
      "Epoch 30: val_loss improved from 1.41195 to 1.40775, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 654us/sample - loss: 1.4472 - val_loss: 1.4078\n",
      "Epoch 31/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4435\n",
      "Epoch 31: val_loss improved from 1.40775 to 1.40436, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 699us/sample - loss: 1.4435 - val_loss: 1.4044\n",
      "Epoch 32/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4434\n",
      "Epoch 32: val_loss did not improve from 1.40436\n",
      "31543/31543 [==============================] - 22s 689us/sample - loss: 1.4434 - val_loss: 1.4055\n",
      "Epoch 33/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4436\n",
      "Epoch 33: val_loss improved from 1.40436 to 1.40166, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.4436 - val_loss: 1.4017\n",
      "Epoch 34/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4401\n",
      "Epoch 34: val_loss improved from 1.40166 to 1.40134, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.4401 - val_loss: 1.4013\n",
      "Epoch 35/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4358\n",
      "Epoch 35: val_loss improved from 1.40134 to 1.40095, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 657us/sample - loss: 1.4358 - val_loss: 1.4009\n",
      "Epoch 36/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4313\n",
      "Epoch 36: val_loss did not improve from 1.40095\n",
      "31543/31543 [==============================] - 19s 611us/sample - loss: 1.4313 - val_loss: 1.4035\n",
      "Epoch 37/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4340\n",
      "Epoch 37: val_loss improved from 1.40095 to 1.40051, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 19s 618us/sample - loss: 1.4340 - val_loss: 1.4005\n",
      "Epoch 38/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 38: val_loss did not improve from 1.40051\n",
      "31543/31543 [==============================] - 19s 617us/sample - loss: 1.4305 - val_loss: 1.4011\n",
      "Epoch 39/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4303\n",
      "Epoch 39: val_loss improved from 1.40051 to 1.39728, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 651us/sample - loss: 1.4303 - val_loss: 1.3973\n",
      "Epoch 40/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 40: val_loss improved from 1.39728 to 1.39550, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 673us/sample - loss: 1.4283 - val_loss: 1.3955\n",
      "Epoch 41/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4279\n",
      "Epoch 41: val_loss did not improve from 1.39550\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4279 - val_loss: 1.3965\n",
      "Epoch 42/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4222\n",
      "Epoch 42: val_loss improved from 1.39550 to 1.39177, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 690us/sample - loss: 1.4222 - val_loss: 1.3918\n",
      "Epoch 43/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4223\n",
      "Epoch 43: val_loss did not improve from 1.39177\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 1.4223 - val_loss: 1.3945\n",
      "Epoch 44/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4240\n",
      "Epoch 44: val_loss did not improve from 1.39177\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4240 - val_loss: 1.3988\n",
      "Epoch 45/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4225\n",
      "Epoch 45: val_loss did not improve from 1.39177\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 1.4225 - val_loss: 1.3925\n",
      "Epoch 46/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 46: val_loss improved from 1.39177 to 1.38929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4204 - val_loss: 1.3893\n",
      "Epoch 47/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4179\n",
      "Epoch 47: val_loss did not improve from 1.38929\n",
      "31543/31543 [==============================] - 22s 690us/sample - loss: 1.4179 - val_loss: 1.3939\n",
      "Epoch 48/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4153\n",
      "Epoch 48: val_loss did not improve from 1.38929\n",
      "31543/31543 [==============================] - 22s 689us/sample - loss: 1.4153 - val_loss: 1.3942\n",
      "Epoch 49/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4157\n",
      "Epoch 49: val_loss improved from 1.38929 to 1.38690, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 1.4157 - val_loss: 1.3869\n",
      "Epoch 50/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 50: val_loss did not improve from 1.38690\n",
      "31543/31543 [==============================] - 22s 693us/sample - loss: 1.4141 - val_loss: 1.3880\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:08:07.835187: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_51_1/lstm_cell_162/bias/Assign' id:77951 op device:{requested: '', assigned: ''} def:{{{node lstm_51_1/lstm_cell_162/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_51_1/lstm_cell_162/bias, lstm_51_1/lstm_cell_162/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:08:12.018663: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_5_2/bias/m/Assign' id:82269 op device:{requested: '', assigned: ''} def:{{{node conv2d_5_2/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_5_2/bias/m, conv2d_5_2/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:08:15.977974: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_9_1/cond/Merge' id:81633 op device:{requested: '', assigned: ''} def:{{{node dropout_9_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_9_1/cond/Identity, dropout_9_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1944)\n",
      "(1514, 1944)\n",
      "(1644, 1944)\n",
      "(1764, 1944)\n",
      "(1836, 1944)\n",
      "(1699, 1944)\n",
      "(1369, 1944)\n",
      "(1766, 1944)\n",
      "(1631, 1944)\n",
      "(1692, 1944)\n",
      "(1550, 1944)\n",
      "(1920, 1944)\n",
      "(1739, 1944)\n",
      "(1788, 1944)\n",
      "(1812, 1944)\n",
      "(1788, 1944)\n",
      "(1776, 1944)\n",
      "(946, 1944)\n",
      "(1608, 1944)\n",
      "{1: 5.606446328197446, 2: 1.507365042131422, 4: 4.593582818982564, 5: 9.333053549625465, 6: 10.0, 8: 5.506910003449647, 9: 1.6984003019512373, 10: 6.445329264017767, 11: 3.482005999378207, 12: 5.099566308688957, 13: 5.830625398270913, 17: 4.737318062973648, 19: 5.061415379490605, 21: 6.173366948552239, 22: 2.2612838486071962, 25: 4.120679485913874, 26: 3.3612237113803602, 27: 1.0, 28: 4.98786407452673}\n",
      "Train on 31543 samples, validate on 3514 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:12:22.642407: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 7.7430\n",
      "Epoch 1: val_loss improved from inf to 1.40555, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 30s 945us/sample - loss: 7.7430 - val_loss: 1.4056\n",
      "Epoch 2/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.6168\n",
      "Epoch 2: val_loss improved from 1.40555 to 1.40147, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 19s 605us/sample - loss: 7.6168 - val_loss: 1.4015\n",
      "Epoch 3/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.6252\n",
      "Epoch 3: val_loss improved from 1.40147 to 1.39075, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 19s 602us/sample - loss: 7.6252 - val_loss: 1.3908\n",
      "Epoch 4/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5609\n",
      "Epoch 4: val_loss did not improve from 1.39075\n",
      "31543/31543 [==============================] - 20s 647us/sample - loss: 7.5609 - val_loss: 1.4048\n",
      "Epoch 5/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5210\n",
      "Epoch 5: val_loss did not improve from 1.39075\n",
      "31543/31543 [==============================] - 22s 691us/sample - loss: 7.5210 - val_loss: 1.3910\n",
      "Epoch 6/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4979\n",
      "Epoch 6: val_loss improved from 1.39075 to 1.39006, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 649us/sample - loss: 7.4979 - val_loss: 1.3901\n",
      "Epoch 7/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5290\n",
      "Epoch 7: val_loss did not improve from 1.39006\n",
      "31543/31543 [==============================] - 20s 621us/sample - loss: 7.5290 - val_loss: 1.4136\n",
      "Epoch 8/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4552\n",
      "Epoch 8: val_loss improved from 1.39006 to 1.38767, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 623us/sample - loss: 7.4552 - val_loss: 1.3877\n",
      "Epoch 9/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4339\n",
      "Epoch 9: val_loss did not improve from 1.38767\n",
      "31543/31543 [==============================] - 20s 623us/sample - loss: 7.4339 - val_loss: 1.3883\n",
      "Epoch 10/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4244\n",
      "Epoch 10: val_loss improved from 1.38767 to 1.38490, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 642us/sample - loss: 7.4244 - val_loss: 1.3849\n",
      "Epoch 11/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3874\n",
      "Epoch 11: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 20s 619us/sample - loss: 7.3874 - val_loss: 1.3891\n",
      "Epoch 12/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4127\n",
      "Epoch 12: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 19s 616us/sample - loss: 7.4127 - val_loss: 1.3933\n",
      "Epoch 13/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3975\n",
      "Epoch 13: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 19s 617us/sample - loss: 7.3975 - val_loss: 1.3861\n",
      "Epoch 14/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3639\n",
      "Epoch 14: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 20s 619us/sample - loss: 7.3639 - val_loss: 1.3865\n",
      "Epoch 15/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3737\n",
      "Epoch 15: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 20s 624us/sample - loss: 7.3737 - val_loss: 1.3873\n",
      "Epoch 16/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3579\n",
      "Epoch 16: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 20s 624us/sample - loss: 7.3579 - val_loss: 1.3860\n",
      "Epoch 17/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3509\n",
      "Epoch 17: val_loss improved from 1.38490 to 1.38279, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 626us/sample - loss: 7.3509 - val_loss: 1.3828\n",
      "Epoch 18/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3435\n",
      "Epoch 18: val_loss improved from 1.38279 to 1.38145, saving model to ./checkpoints/unknown_person_few_shot_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 629us/sample - loss: 7.3435 - val_loss: 1.3814\n",
      "Epoch 19/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3382\n",
      "Epoch 19: val_loss did not improve from 1.38145\n",
      "31543/31543 [==============================] - 20s 635us/sample - loss: 7.3382 - val_loss: 1.3926\n",
      "Epoch 20/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.3116\n",
      "Epoch 20: val_loss did not improve from 1.38145\n",
      "31543/31543 [==============================] - 20s 635us/sample - loss: 7.3116 - val_loss: 1.3831\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:19:12.059049: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_71_2/lstm_cell_219/kernel/Assign' id:100522 op device:{requested: '', assigned: ''} def:{{{node lstm_71_2/lstm_cell_219/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_71_2/lstm_cell_219/kernel, lstm_71_2/lstm_cell_219/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:19:17.038567: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_46_2/lstm_cell_194/bias/m/Assign' id:101837 op device:{requested: '', assigned: ''} def:{{{node lstm_46_2/lstm_cell_194/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_46_2/lstm_cell_194/bias/m, lstm_46_2/lstm_cell_194/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31543 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:19:24.498120: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:19:51.021571: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_5_3/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:20:14.381745: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_11/mul' id:101621 op device:{requested: '', assigned: ''} def:{{{node loss_11/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_11/mul/x, loss_11/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39304, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 34s 1ms/sample - loss: 1.4154 - val_loss: 1.3930\n",
      "Epoch 2/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 2: val_loss improved from 1.39304 to 1.39014, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 704us/sample - loss: 1.4126 - val_loss: 1.3901\n",
      "Epoch 3/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4110\n",
      "Epoch 3: val_loss improved from 1.39014 to 1.38644, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 706us/sample - loss: 1.4110 - val_loss: 1.3864\n",
      "Epoch 4/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 4: val_loss improved from 1.38644 to 1.38490, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 704us/sample - loss: 1.4093 - val_loss: 1.3849\n",
      "Epoch 5/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4092\n",
      "Epoch 5: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 22s 702us/sample - loss: 1.4092 - val_loss: 1.3866\n",
      "Epoch 6/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 6: val_loss did not improve from 1.38490\n",
      "31543/31543 [==============================] - 22s 700us/sample - loss: 1.4069 - val_loss: 1.3885\n",
      "Epoch 7/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4059\n",
      "Epoch 7: val_loss improved from 1.38490 to 1.38435, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 706us/sample - loss: 1.4059 - val_loss: 1.3844\n",
      "Epoch 8/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4056\n",
      "Epoch 8: val_loss did not improve from 1.38435\n",
      "31543/31543 [==============================] - 20s 619us/sample - loss: 1.4056 - val_loss: 1.3881\n",
      "Epoch 9/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4044\n",
      "Epoch 9: val_loss improved from 1.38435 to 1.38168, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 19s 603us/sample - loss: 1.4044 - val_loss: 1.3817\n",
      "Epoch 10/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4003\n",
      "Epoch 10: val_loss did not improve from 1.38168\n",
      "31543/31543 [==============================] - 19s 602us/sample - loss: 1.4003 - val_loss: 1.3866\n",
      "Epoch 11/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 11: val_loss did not improve from 1.38168\n",
      "31543/31543 [==============================] - 19s 610us/sample - loss: 1.4010 - val_loss: 1.3882\n",
      "Epoch 12/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 12: val_loss did not improve from 1.38168\n",
      "31543/31543 [==============================] - 21s 675us/sample - loss: 1.3995 - val_loss: 1.3825\n",
      "Epoch 13/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3961\n",
      "Epoch 13: val_loss improved from 1.38168 to 1.38130, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 21s 675us/sample - loss: 1.3961 - val_loss: 1.3813\n",
      "Epoch 14/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3979\n",
      "Epoch 14: val_loss improved from 1.38130 to 1.37906, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 22s 706us/sample - loss: 1.3979 - val_loss: 1.3791\n",
      "Epoch 15/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3960\n",
      "Epoch 15: val_loss did not improve from 1.37906\n",
      "31543/31543 [==============================] - 22s 698us/sample - loss: 1.3960 - val_loss: 1.3805\n",
      "Epoch 16/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 16: val_loss did not improve from 1.37906\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 1.3918 - val_loss: 1.3805\n",
      "Epoch 17/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3924\n",
      "Epoch 17: val_loss did not improve from 1.37906\n",
      "31543/31543 [==============================] - 22s 698us/sample - loss: 1.3924 - val_loss: 1.3796\n",
      "Epoch 18/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3913\n",
      "Epoch 18: val_loss did not improve from 1.37906\n",
      "31543/31543 [==============================] - 20s 630us/sample - loss: 1.3913 - val_loss: 1.3807\n",
      "Epoch 19/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3875\n",
      "Epoch 19: val_loss improved from 1.37906 to 1.37716, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_31.h5\n",
      "31543/31543 [==============================] - 20s 630us/sample - loss: 1.3875 - val_loss: 1.3772\n",
      "Epoch 20/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.3910\n",
      "Epoch 20: val_loss did not improve from 1.37716\n",
      "31543/31543 [==============================] - 19s 598us/sample - loss: 1.3910 - val_loss: 1.3813\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:27:06.469931: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_86/lstm_cell_234/recurrent_kernel/Assign' id:116102 op device:{requested: '', assigned: ''} def:{{{node lstm_86/lstm_cell_234/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_86/lstm_cell_234/recurrent_kernel, lstm_86/lstm_cell_234/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:27:09.366562: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_1' id:117720 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:27:11.634805: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_2/stack_2' id:117721 op device:{requested: '', assigned: ''} def:{{{node strided_slice_2/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31543, 95)\n",
      "Train on 31543 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:27:20.909806: W tensorflow/c/c_api.cc:304] Operation '{name:'training_12/Adam/dense_11/kernel/m/Assign' id:131069 op device:{requested: '', assigned: ''} def:{{{node training_12/Adam/dense_11/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_12/Adam/dense_11/kernel/m, training_12/Adam/dense_11/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:27:52.559761: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 3.1000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:28:14.822957: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_13/mul' id:120561 op device:{requested: '', assigned: ''} def:{{{node loss_13/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_13/mul/x, loss_13/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.90731, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 52s 2ms/sample - loss: 3.1000 - val_loss: 1.9073\n",
      "Epoch 2/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.7650\n",
      "Epoch 2: val_loss improved from 1.90731 to 1.56578, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 665us/sample - loss: 1.7650 - val_loss: 1.5658\n",
      "Epoch 3/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5869\n",
      "Epoch 3: val_loss improved from 1.56578 to 1.51291, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 655us/sample - loss: 1.5869 - val_loss: 1.5129\n",
      "Epoch 4/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5467\n",
      "Epoch 4: val_loss improved from 1.51291 to 1.48967, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 704us/sample - loss: 1.5467 - val_loss: 1.4897\n",
      "Epoch 5/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5282\n",
      "Epoch 5: val_loss improved from 1.48967 to 1.47747, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 705us/sample - loss: 1.5282 - val_loss: 1.4775\n",
      "Epoch 6/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5149\n",
      "Epoch 6: val_loss improved from 1.47747 to 1.46610, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 644us/sample - loss: 1.5149 - val_loss: 1.4661\n",
      "Epoch 7/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5014\n",
      "Epoch 7: val_loss improved from 1.46610 to 1.45578, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 623us/sample - loss: 1.5014 - val_loss: 1.4558\n",
      "Epoch 8/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4989\n",
      "Epoch 8: val_loss improved from 1.45578 to 1.44637, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 19s 617us/sample - loss: 1.4989 - val_loss: 1.4464\n",
      "Epoch 9/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4959\n",
      "Epoch 9: val_loss improved from 1.44637 to 1.43658, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 19s 617us/sample - loss: 1.4959 - val_loss: 1.4366\n",
      "Epoch 10/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4862\n",
      "Epoch 10: val_loss improved from 1.43658 to 1.43245, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 619us/sample - loss: 1.4862 - val_loss: 1.4325\n",
      "Epoch 11/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4839\n",
      "Epoch 11: val_loss did not improve from 1.43245\n",
      "31543/31543 [==============================] - 20s 635us/sample - loss: 1.4839 - val_loss: 1.4395\n",
      "Epoch 12/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5340\n",
      "Epoch 12: val_loss improved from 1.43245 to 1.43070, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 624us/sample - loss: 1.5340 - val_loss: 1.4307\n",
      "Epoch 13/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4884\n",
      "Epoch 13: val_loss improved from 1.43070 to 1.42844, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 630us/sample - loss: 1.4884 - val_loss: 1.4284\n",
      "Epoch 14/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4792\n",
      "Epoch 14: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 20s 638us/sample - loss: 1.4792 - val_loss: 1.4304\n",
      "Epoch 15/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5314\n",
      "Epoch 15: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 20s 622us/sample - loss: 1.5314 - val_loss: 1.4286\n",
      "Epoch 16/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5523\n",
      "Epoch 16: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 19s 614us/sample - loss: 1.5523 - val_loss: 1.4301\n",
      "Epoch 17/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5636\n",
      "Epoch 17: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 21s 664us/sample - loss: 1.5636 - val_loss: 1.4453\n",
      "Epoch 18/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5275\n",
      "Epoch 18: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 20s 628us/sample - loss: 1.5275 - val_loss: 1.4482\n",
      "Epoch 19/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5389\n",
      "Epoch 19: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.5389 - val_loss: 1.4447\n",
      "Epoch 20/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5062\n",
      "Epoch 20: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 22s 701us/sample - loss: 1.5062 - val_loss: 1.4415\n",
      "Epoch 21/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5105\n",
      "Epoch 21: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 21s 679us/sample - loss: 1.5105 - val_loss: 1.4387\n",
      "Epoch 22/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5166\n",
      "Epoch 22: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 21s 668us/sample - loss: 1.5166 - val_loss: 1.4531\n",
      "Epoch 23/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.5166\n",
      "Epoch 23: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 22s 704us/sample - loss: 1.5166 - val_loss: 1.4420\n",
      "Epoch 24/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4913\n",
      "Epoch 24: val_loss did not improve from 1.42844\n",
      "31543/31543 [==============================] - 22s 700us/sample - loss: 1.4913 - val_loss: 1.4340\n",
      "Epoch 25/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4859\n",
      "Epoch 25: val_loss improved from 1.42844 to 1.42796, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 701us/sample - loss: 1.4859 - val_loss: 1.4280\n",
      "Epoch 26/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4850\n",
      "Epoch 26: val_loss improved from 1.42796 to 1.42401, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 630us/sample - loss: 1.4850 - val_loss: 1.4240\n",
      "Epoch 27/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 27: val_loss did not improve from 1.42401\n",
      "31543/31543 [==============================] - 20s 621us/sample - loss: 1.4781 - val_loss: 1.4258\n",
      "Epoch 28/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4737\n",
      "Epoch 28: val_loss improved from 1.42401 to 1.42050, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 625us/sample - loss: 1.4737 - val_loss: 1.4205\n",
      "Epoch 29/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4741\n",
      "Epoch 29: val_loss improved from 1.42050 to 1.41897, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 650us/sample - loss: 1.4741 - val_loss: 1.4190\n",
      "Epoch 30/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4682\n",
      "Epoch 30: val_loss improved from 1.41897 to 1.41711, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 662us/sample - loss: 1.4682 - val_loss: 1.4171\n",
      "Epoch 31/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4653\n",
      "Epoch 31: val_loss did not improve from 1.41711\n",
      "31543/31543 [==============================] - 22s 695us/sample - loss: 1.4653 - val_loss: 1.4242\n",
      "Epoch 32/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4633\n",
      "Epoch 32: val_loss did not improve from 1.41711\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.4633 - val_loss: 1.4185\n",
      "Epoch 33/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4678\n",
      "Epoch 33: val_loss improved from 1.41711 to 1.41482, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 700us/sample - loss: 1.4678 - val_loss: 1.4148\n",
      "Epoch 34/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4654\n",
      "Epoch 34: val_loss did not improve from 1.41482\n",
      "31543/31543 [==============================] - 22s 697us/sample - loss: 1.4654 - val_loss: 1.4171\n",
      "Epoch 35/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4614\n",
      "Epoch 35: val_loss did not improve from 1.41482\n",
      "31543/31543 [==============================] - 22s 702us/sample - loss: 1.4614 - val_loss: 1.4162\n",
      "Epoch 36/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4552\n",
      "Epoch 36: val_loss improved from 1.41482 to 1.41363, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 19s 613us/sample - loss: 1.4552 - val_loss: 1.4136\n",
      "Epoch 37/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4543\n",
      "Epoch 37: val_loss improved from 1.41363 to 1.41317, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 688us/sample - loss: 1.4543 - val_loss: 1.4132\n",
      "Epoch 38/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4534\n",
      "Epoch 38: val_loss did not improve from 1.41317\n",
      "31543/31543 [==============================] - 22s 701us/sample - loss: 1.4534 - val_loss: 1.4152\n",
      "Epoch 39/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4534\n",
      "Epoch 39: val_loss did not improve from 1.41317\n",
      "31543/31543 [==============================] - 22s 698us/sample - loss: 1.4534 - val_loss: 1.4166\n",
      "Epoch 40/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4512\n",
      "Epoch 40: val_loss improved from 1.41317 to 1.40922, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 707us/sample - loss: 1.4512 - val_loss: 1.4092\n",
      "Epoch 41/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4477\n",
      "Epoch 41: val_loss improved from 1.40922 to 1.40517, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 703us/sample - loss: 1.4477 - val_loss: 1.4052\n",
      "Epoch 42/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4471\n",
      "Epoch 42: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 21s 671us/sample - loss: 1.4471 - val_loss: 1.4072\n",
      "Epoch 43/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4448\n",
      "Epoch 43: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 19s 615us/sample - loss: 1.4448 - val_loss: 1.4093\n",
      "Epoch 44/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4453\n",
      "Epoch 44: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 22s 692us/sample - loss: 1.4453 - val_loss: 1.4103\n",
      "Epoch 45/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4422\n",
      "Epoch 45: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 22s 698us/sample - loss: 1.4422 - val_loss: 1.4110\n",
      "Epoch 46/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4392\n",
      "Epoch 46: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 21s 680us/sample - loss: 1.4392 - val_loss: 1.4071\n",
      "Epoch 47/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4398\n",
      "Epoch 47: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 21s 678us/sample - loss: 1.4398 - val_loss: 1.4096\n",
      "Epoch 48/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4391\n",
      "Epoch 48: val_loss did not improve from 1.40517\n",
      "31543/31543 [==============================] - 22s 687us/sample - loss: 1.4391 - val_loss: 1.4097\n",
      "Epoch 49/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4353\n",
      "Epoch 49: val_loss improved from 1.40517 to 1.40489, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 623us/sample - loss: 1.4353 - val_loss: 1.4049\n",
      "Epoch 50/50\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4363\n",
      "Epoch 50: val_loss did not improve from 1.40489\n",
      "31543/31543 [==============================] - 19s 602us/sample - loss: 1.4363 - val_loss: 1.4056\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:45:52.671272: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_105_1/lstm_cell_290/bias/Assign' id:137715 op device:{requested: '', assigned: ''} def:{{{node lstm_105_1/lstm_cell_290/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_105_1/lstm_cell_290/bias, lstm_105_1/lstm_cell_290/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:45:59.639444: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_101_1/lstm_cell_286/kernel/v/Assign' id:140384 op device:{requested: '', assigned: ''} def:{{{node lstm_101_1/lstm_cell_286/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_101_1/lstm_cell_286/kernel/v, lstm_101_1/lstm_cell_286/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:46:06.423105: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_14_1/cond/Merge' id:138675 op device:{requested: '', assigned: ''} def:{{{node dropout_14_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_14_1/cond/Identity, dropout_14_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1944)\n",
      "(1514, 1944)\n",
      "(1644, 1944)\n",
      "(1764, 1944)\n",
      "(1836, 1944)\n",
      "(1699, 1944)\n",
      "(1369, 1944)\n",
      "(1766, 1944)\n",
      "(1631, 1944)\n",
      "(1692, 1944)\n",
      "(1550, 1944)\n",
      "(1920, 1944)\n",
      "(1739, 1944)\n",
      "(1788, 1944)\n",
      "(1812, 1944)\n",
      "(1788, 1944)\n",
      "(1776, 1944)\n",
      "(946, 1944)\n",
      "(1608, 1944)\n",
      "{1: 5.435601291603098, 2: 1.4356272125368448, 4: 4.44002636529261, 5: 9.326034562655657, 6: 10.0, 8: 5.093375138333147, 9: 1.3591038551305463, 10: 6.396816168737873, 11: 3.4381732830290885, 12: 4.925390030703081, 13: 5.699536173985539, 17: 4.46009075500803, 19: 5.235022461282589, 21: 6.032372072256983, 22: 3.098208598978821, 25: 4.234270754203952, 26: 4.0328714469805815, 27: 1.0, 28: 5.599452274799986}\n",
      "Train on 31543 samples, validate on 3514 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:50:08.343437: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 7.8381\n",
      "Epoch 1: val_loss improved from inf to 1.42719, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 35s 1ms/sample - loss: 7.8381 - val_loss: 1.4272\n",
      "Epoch 2/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.7424\n",
      "Epoch 2: val_loss improved from 1.42719 to 1.40077, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 19s 607us/sample - loss: 7.7424 - val_loss: 1.4008\n",
      "Epoch 3/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.7431\n",
      "Epoch 3: val_loss did not improve from 1.40077\n",
      "31543/31543 [==============================] - 22s 698us/sample - loss: 7.7431 - val_loss: 1.4218\n",
      "Epoch 4/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.6551\n",
      "Epoch 4: val_loss improved from 1.40077 to 1.39762, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 673us/sample - loss: 7.6551 - val_loss: 1.3976\n",
      "Epoch 5/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.6579\n",
      "Epoch 5: val_loss did not improve from 1.39762\n",
      "31543/31543 [==============================] - 20s 627us/sample - loss: 7.6579 - val_loss: 1.4029\n",
      "Epoch 6/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.6316\n",
      "Epoch 6: val_loss did not improve from 1.39762\n",
      "31543/31543 [==============================] - 20s 619us/sample - loss: 7.6316 - val_loss: 1.4057\n",
      "Epoch 7/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.6097\n",
      "Epoch 7: val_loss improved from 1.39762 to 1.39380, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 646us/sample - loss: 7.6097 - val_loss: 1.3938\n",
      "Epoch 8/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5696\n",
      "Epoch 8: val_loss did not improve from 1.39380\n",
      "31543/31543 [==============================] - 22s 695us/sample - loss: 7.5696 - val_loss: 1.3975\n",
      "Epoch 9/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5634\n",
      "Epoch 9: val_loss did not improve from 1.39380\n",
      "31543/31543 [==============================] - 22s 695us/sample - loss: 7.5634 - val_loss: 1.3942\n",
      "Epoch 10/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5710\n",
      "Epoch 10: val_loss improved from 1.39380 to 1.39151, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 705us/sample - loss: 7.5710 - val_loss: 1.3915\n",
      "Epoch 11/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5614\n",
      "Epoch 11: val_loss did not improve from 1.39151\n",
      "31543/31543 [==============================] - 22s 703us/sample - loss: 7.5614 - val_loss: 1.3977\n",
      "Epoch 12/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5401\n",
      "Epoch 12: val_loss improved from 1.39151 to 1.39121, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 711us/sample - loss: 7.5401 - val_loss: 1.3912\n",
      "Epoch 13/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5183\n",
      "Epoch 13: val_loss did not improve from 1.39121\n",
      "31543/31543 [==============================] - 22s 695us/sample - loss: 7.5183 - val_loss: 1.3950\n",
      "Epoch 14/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5260\n",
      "Epoch 14: val_loss did not improve from 1.39121\n",
      "31543/31543 [==============================] - 20s 638us/sample - loss: 7.5260 - val_loss: 1.3920\n",
      "Epoch 15/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5105\n",
      "Epoch 15: val_loss improved from 1.39121 to 1.38633, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 663us/sample - loss: 7.5105 - val_loss: 1.3863\n",
      "Epoch 16/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5002\n",
      "Epoch 16: val_loss improved from 1.38633 to 1.38577, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 701us/sample - loss: 7.5002 - val_loss: 1.3858\n",
      "Epoch 17/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4900\n",
      "Epoch 17: val_loss improved from 1.38577 to 1.38258, saving model to ./checkpoints/unknown_person_few_shot_p29_32.h5\n",
      "31543/31543 [==============================] - 19s 597us/sample - loss: 7.4900 - val_loss: 1.3826\n",
      "Epoch 18/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5044\n",
      "Epoch 18: val_loss did not improve from 1.38258\n",
      "31543/31543 [==============================] - 31s 996us/sample - loss: 7.5044 - val_loss: 1.3975\n",
      "Epoch 19/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.5041\n",
      "Epoch 19: val_loss did not improve from 1.38258\n",
      "31543/31543 [==============================] - 32s 1ms/sample - loss: 7.5041 - val_loss: 1.3891\n",
      "Epoch 20/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 7.4705\n",
      "Epoch 20: val_loss did not improve from 1.38258\n",
      "31543/31543 [==============================] - 22s 707us/sample - loss: 7.4705 - val_loss: 1.3852\n",
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_100 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:57:49.478632: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_109_2/lstm_cell_331/kernel/Assign' id:157724 op device:{requested: '', assigned: ''} def:{{{node lstm_109_2/lstm_cell_331/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_109_2/lstm_cell_331/kernel, lstm_109_2/lstm_cell_331/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 00:57:58.586908: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_75_2/lstm_cell_297/bias/m/Assign' id:158759 op device:{requested: '', assigned: ''} def:{{{node lstm_75_2/lstm_cell_297/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_75_2/lstm_cell_297/bias/m, lstm_75_2/lstm_cell_297/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31543 samples, validate on 3514 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:58:09.751485: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:58:54.262805: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_10_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:59:18.440003: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_17/mul' id:158663 op device:{requested: '', assigned: ''} def:{{{node loss_17/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_17/mul/x, loss_17/dense_11_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40030, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 41s 1ms/sample - loss: 1.4368 - val_loss: 1.4003\n",
      "Epoch 2/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 2: val_loss improved from 1.40030 to 1.39669, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 709us/sample - loss: 1.4311 - val_loss: 1.3967\n",
      "Epoch 3/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4271\n",
      "Epoch 3: val_loss did not improve from 1.39669\n",
      "31543/31543 [==============================] - 22s 712us/sample - loss: 1.4271 - val_loss: 1.4003\n",
      "Epoch 4/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 4: val_loss did not improve from 1.39669\n",
      "31543/31543 [==============================] - 22s 709us/sample - loss: 1.4275 - val_loss: 1.3971\n",
      "Epoch 5/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 5: val_loss improved from 1.39669 to 1.39440, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 683us/sample - loss: 1.4262 - val_loss: 1.3944\n",
      "Epoch 6/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4254\n",
      "Epoch 6: val_loss improved from 1.39440 to 1.39396, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 22s 702us/sample - loss: 1.4254 - val_loss: 1.3940\n",
      "Epoch 7/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4222\n",
      "Epoch 7: val_loss did not improve from 1.39396\n",
      "31543/31543 [==============================] - 22s 711us/sample - loss: 1.4222 - val_loss: 1.3991\n",
      "Epoch 8/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4202\n",
      "Epoch 8: val_loss did not improve from 1.39396\n",
      "31543/31543 [==============================] - 22s 694us/sample - loss: 1.4202 - val_loss: 1.3964\n",
      "Epoch 9/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4189\n",
      "Epoch 9: val_loss did not improve from 1.39396\n",
      "31543/31543 [==============================] - 19s 615us/sample - loss: 1.4189 - val_loss: 1.3957\n",
      "Epoch 10/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4182\n",
      "Epoch 10: val_loss improved from 1.39396 to 1.39105, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 19s 618us/sample - loss: 1.4182 - val_loss: 1.3910\n",
      "Epoch 11/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4182\n",
      "Epoch 11: val_loss did not improve from 1.39105\n",
      "31543/31543 [==============================] - 21s 676us/sample - loss: 1.4182 - val_loss: 1.3965\n",
      "Epoch 12/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 12: val_loss improved from 1.39105 to 1.39068, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 667us/sample - loss: 1.4148 - val_loss: 1.3907\n",
      "Epoch 13/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4106\n",
      "Epoch 13: val_loss improved from 1.39068 to 1.39034, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 672us/sample - loss: 1.4106 - val_loss: 1.3903\n",
      "Epoch 14/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4111\n",
      "Epoch 14: val_loss improved from 1.39034 to 1.38813, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 626us/sample - loss: 1.4111 - val_loss: 1.3881\n",
      "Epoch 15/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 15: val_loss did not improve from 1.38813\n",
      "31543/31543 [==============================] - 22s 687us/sample - loss: 1.4097 - val_loss: 1.3885\n",
      "Epoch 16/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4090\n",
      "Epoch 16: val_loss improved from 1.38813 to 1.38729, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 659us/sample - loss: 1.4090 - val_loss: 1.3873\n",
      "Epoch 17/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4091\n",
      "Epoch 17: val_loss did not improve from 1.38729\n",
      "31543/31543 [==============================] - 19s 616us/sample - loss: 1.4091 - val_loss: 1.3896\n",
      "Epoch 18/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 18: val_loss did not improve from 1.38729\n",
      "31543/31543 [==============================] - 19s 615us/sample - loss: 1.4080 - val_loss: 1.3904\n",
      "Epoch 19/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 19: val_loss improved from 1.38729 to 1.38513, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 20s 622us/sample - loss: 1.4066 - val_loss: 1.3851\n",
      "Epoch 20/20\n",
      "31543/31543 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 20: val_loss improved from 1.38513 to 1.38062, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_32.h5\n",
      "31543/31543 [==============================] - 21s 672us/sample - loss: 1.4042 - val_loss: 1.3806\n",
      "35273\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:06:22.651986: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_132/lstm_cell_354/kernel/Assign' id:174609 op device:{requested: '', assigned: ''} def:{{{node lstm_132/lstm_cell_354/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_132/lstm_cell_354/kernel, lstm_132/lstm_cell_354/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 01:06:27.064876: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_1' id:174762 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 01:06:30.555914: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_3/stack_2' id:174763 op device:{requested: '', assigned: ''} def:{{{node strided_slice_3/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31735, 95)\n",
      "Train on 31735 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:06:41.851098: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_134/lstm_cell_356/bias/Assign' id:175197 op device:{requested: '', assigned: ''} def:{{{node lstm_134/lstm_cell_356/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_134/lstm_cell_356/bias, lstm_134/lstm_cell_356/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:07:27.928587: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 3.4870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-24 01:07:52.044112: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_19/mul' id:177603 op device:{requested: '', assigned: ''} def:{{{node loss_19/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_19/mul/x, loss_19/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.09827, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 66s 2ms/sample - loss: 3.4870 - val_loss: 2.0983\n",
      "Epoch 2/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.8791\n",
      "Epoch 2: val_loss improved from 2.09827 to 1.60921, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 700us/sample - loss: 1.8791 - val_loss: 1.6092\n",
      "Epoch 3/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.6180\n",
      "Epoch 3: val_loss improved from 1.60921 to 1.53603, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 632us/sample - loss: 1.6180 - val_loss: 1.5360\n",
      "Epoch 4/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5610\n",
      "Epoch 4: val_loss improved from 1.53603 to 1.49620, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 613us/sample - loss: 1.5610 - val_loss: 1.4962\n",
      "Epoch 5/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5323\n",
      "Epoch 5: val_loss improved from 1.49620 to 1.47314, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 609us/sample - loss: 1.5323 - val_loss: 1.4731\n",
      "Epoch 6/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5188\n",
      "Epoch 6: val_loss improved from 1.47314 to 1.45997, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 609us/sample - loss: 1.5188 - val_loss: 1.4600\n",
      "Epoch 7/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5050\n",
      "Epoch 7: val_loss improved from 1.45997 to 1.45745, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 638us/sample - loss: 1.5050 - val_loss: 1.4575\n",
      "Epoch 8/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5083\n",
      "Epoch 8: val_loss did not improve from 1.45745\n",
      "31735/31735 [==============================] - 21s 662us/sample - loss: 1.5083 - val_loss: 1.4605\n",
      "Epoch 9/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5010\n",
      "Epoch 9: val_loss improved from 1.45745 to 1.44310, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 700us/sample - loss: 1.5010 - val_loss: 1.4431\n",
      "Epoch 10/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4920\n",
      "Epoch 10: val_loss improved from 1.44310 to 1.44006, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 700us/sample - loss: 1.4920 - val_loss: 1.4401\n",
      "Epoch 11/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4981\n",
      "Epoch 11: val_loss did not improve from 1.44006\n",
      "31735/31735 [==============================] - 22s 693us/sample - loss: 1.4981 - val_loss: 1.4419\n",
      "Epoch 12/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4839\n",
      "Epoch 12: val_loss did not improve from 1.44006\n",
      "31735/31735 [==============================] - 22s 696us/sample - loss: 1.4839 - val_loss: 1.4410\n",
      "Epoch 13/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5270\n",
      "Epoch 13: val_loss improved from 1.44006 to 1.43841, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 699us/sample - loss: 1.5270 - val_loss: 1.4384\n",
      "Epoch 14/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4967\n",
      "Epoch 14: val_loss improved from 1.43841 to 1.43721, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 702us/sample - loss: 1.4967 - val_loss: 1.4372\n",
      "Epoch 15/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4790\n",
      "Epoch 15: val_loss improved from 1.43721 to 1.43236, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 701us/sample - loss: 1.4790 - val_loss: 1.4324\n",
      "Epoch 16/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4786\n",
      "Epoch 16: val_loss improved from 1.43236 to 1.42996, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 700us/sample - loss: 1.4786 - val_loss: 1.4300\n",
      "Epoch 17/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4728\n",
      "Epoch 17: val_loss did not improve from 1.42996\n",
      "31735/31735 [==============================] - 21s 669us/sample - loss: 1.4728 - val_loss: 1.4313\n",
      "Epoch 18/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4700\n",
      "Epoch 18: val_loss improved from 1.42996 to 1.42490, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 612us/sample - loss: 1.4700 - val_loss: 1.4249\n",
      "Epoch 19/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5074\n",
      "Epoch 19: val_loss did not improve from 1.42490\n",
      "31735/31735 [==============================] - 19s 606us/sample - loss: 1.5074 - val_loss: 1.4272\n",
      "Epoch 20/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4783\n",
      "Epoch 20: val_loss did not improve from 1.42490\n",
      "31735/31735 [==============================] - 21s 649us/sample - loss: 1.4783 - val_loss: 1.4267\n",
      "Epoch 21/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4669\n",
      "Epoch 21: val_loss improved from 1.42490 to 1.42345, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 21s 668us/sample - loss: 1.4669 - val_loss: 1.4235\n",
      "Epoch 22/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4705\n",
      "Epoch 22: val_loss did not improve from 1.42345\n",
      "31735/31735 [==============================] - 19s 614us/sample - loss: 1.4705 - val_loss: 1.4253\n",
      "Epoch 23/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4624\n",
      "Epoch 23: val_loss did not improve from 1.42345\n",
      "31735/31735 [==============================] - 19s 608us/sample - loss: 1.4624 - val_loss: 1.4257\n",
      "Epoch 24/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4534\n",
      "Epoch 24: val_loss improved from 1.42345 to 1.41789, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 615us/sample - loss: 1.4534 - val_loss: 1.4179\n",
      "Epoch 25/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4505\n",
      "Epoch 25: val_loss improved from 1.41789 to 1.41651, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 611us/sample - loss: 1.4505 - val_loss: 1.4165\n",
      "Epoch 26/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 26: val_loss improved from 1.41651 to 1.41576, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 609us/sample - loss: 1.4483 - val_loss: 1.4158\n",
      "Epoch 27/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4429\n",
      "Epoch 27: val_loss did not improve from 1.41576\n",
      "31735/31735 [==============================] - 22s 699us/sample - loss: 1.4429 - val_loss: 1.4175\n",
      "Epoch 28/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4390\n",
      "Epoch 28: val_loss improved from 1.41576 to 1.41281, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 700us/sample - loss: 1.4390 - val_loss: 1.4128\n",
      "Epoch 29/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4382\n",
      "Epoch 29: val_loss improved from 1.41281 to 1.41041, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 694us/sample - loss: 1.4382 - val_loss: 1.4104\n",
      "Epoch 30/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4355\n",
      "Epoch 30: val_loss improved from 1.41041 to 1.40870, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 619us/sample - loss: 1.4355 - val_loss: 1.4087\n",
      "Epoch 31/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 31: val_loss improved from 1.40870 to 1.40704, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 21s 648us/sample - loss: 1.4311 - val_loss: 1.4070\n",
      "Epoch 32/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4290\n",
      "Epoch 32: val_loss did not improve from 1.40704\n",
      "31735/31735 [==============================] - 20s 627us/sample - loss: 1.4290 - val_loss: 1.4095\n",
      "Epoch 33/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4270\n",
      "Epoch 33: val_loss improved from 1.40704 to 1.40205, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 612us/sample - loss: 1.4270 - val_loss: 1.4021\n",
      "Epoch 34/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 34: val_loss improved from 1.40205 to 1.40192, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 609us/sample - loss: 1.4242 - val_loss: 1.4019\n",
      "Epoch 35/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4236\n",
      "Epoch 35: val_loss improved from 1.40192 to 1.40137, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 634us/sample - loss: 1.4236 - val_loss: 1.4014\n",
      "Epoch 36/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4197\n",
      "Epoch 36: val_loss improved from 1.40137 to 1.39934, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 23s 712us/sample - loss: 1.4197 - val_loss: 1.3993\n",
      "Epoch 37/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4193\n",
      "Epoch 37: val_loss improved from 1.39934 to 1.39239, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 21s 655us/sample - loss: 1.4193 - val_loss: 1.3924\n",
      "Epoch 38/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 38: val_loss did not improve from 1.39239\n",
      "31735/31735 [==============================] - 20s 631us/sample - loss: 1.4166 - val_loss: 1.3943\n",
      "Epoch 39/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4162\n",
      "Epoch 39: val_loss did not improve from 1.39239\n",
      "31735/31735 [==============================] - 21s 671us/sample - loss: 1.4162 - val_loss: 1.3970\n",
      "Epoch 40/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4123\n",
      "Epoch 40: val_loss did not improve from 1.39239\n",
      "31735/31735 [==============================] - 20s 621us/sample - loss: 1.4123 - val_loss: 1.3956\n",
      "Epoch 41/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4142\n",
      "Epoch 41: val_loss did not improve from 1.39239\n",
      "31735/31735 [==============================] - 21s 656us/sample - loss: 1.4142 - val_loss: 1.3944\n",
      "Epoch 42/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4105\n",
      "Epoch 42: val_loss did not improve from 1.39239\n",
      "31735/31735 [==============================] - 22s 684us/sample - loss: 1.4105 - val_loss: 1.3942\n",
      "Epoch 43/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 43: val_loss did not improve from 1.39239\n",
      "31735/31735 [==============================] - 20s 627us/sample - loss: 1.4093 - val_loss: 1.3932\n",
      "Epoch 44/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 44: val_loss improved from 1.39239 to 1.39223, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 21s 677us/sample - loss: 1.4078 - val_loss: 1.3922\n",
      "Epoch 45/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 45: val_loss did not improve from 1.39223\n",
      "31735/31735 [==============================] - 19s 608us/sample - loss: 1.4065 - val_loss: 1.3924\n",
      "Epoch 46/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4054\n",
      "Epoch 46: val_loss improved from 1.39223 to 1.38704, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 629us/sample - loss: 1.4054 - val_loss: 1.3870\n",
      "Epoch 47/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4021\n",
      "Epoch 47: val_loss improved from 1.38704 to 1.37929, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 702us/sample - loss: 1.4021 - val_loss: 1.3793\n",
      "Epoch 48/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4004\n",
      "Epoch 48: val_loss did not improve from 1.37929\n",
      "31735/31735 [==============================] - 22s 695us/sample - loss: 1.4004 - val_loss: 1.3851\n",
      "Epoch 49/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4016\n",
      "Epoch 49: val_loss did not improve from 1.37929\n",
      "31735/31735 [==============================] - 20s 616us/sample - loss: 1.4016 - val_loss: 1.3870\n",
      "Epoch 50/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4007\n",
      "Epoch 50: val_loss did not improve from 1.37929\n",
      "31735/31735 [==============================] - 19s 607us/sample - loss: 1.4007 - val_loss: 1.3889\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:25:32.038719: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_144_1/lstm_cell_403/recurrent_kernel/Assign' id:195068 op device:{requested: '', assigned: ''} def:{{{node lstm_144_1/lstm_cell_403/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_144_1/lstm_cell_403/recurrent_kernel, lstm_144_1/lstm_cell_403/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 01:25:41.966903: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_137_1/lstm_cell_396/kernel/m/Assign' id:196768 op device:{requested: '', assigned: ''} def:{{{node lstm_137_1/lstm_cell_396/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_137_1/lstm_cell_396/kernel/m, lstm_137_1/lstm_cell_396/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-24 01:25:51.697245: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_19_1/cond/Merge' id:195717 op device:{requested: '', assigned: ''} def:{{{node dropout_19_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_19_1/cond/Identity, dropout_19_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1728)\n",
      "(1514, 1728)\n",
      "(1644, 1728)\n",
      "(1764, 1728)\n",
      "(1836, 1728)\n",
      "(1699, 1728)\n",
      "(1369, 1728)\n",
      "(1778, 1728)\n",
      "(1631, 1728)\n",
      "(1704, 1728)\n",
      "(1550, 1728)\n",
      "(1920, 1728)\n",
      "(1739, 1728)\n",
      "(1788, 1728)\n",
      "(1812, 1728)\n",
      "(1788, 1728)\n",
      "(1776, 1728)\n",
      "(946, 1728)\n",
      "(1572, 1728)\n",
      "{1: 5.44006868399484, 2: 1.7918926876232395, 4: 5.278394707568207, 5: 10.0, 6: 9.909291746850204, 8: 5.516603561977533, 9: 1.494976315928404, 10: 7.461961644946231, 11: 3.8230458566010683, 12: 5.655223619246645, 13: 6.12221038354929, 17: 5.305065544465311, 19: 5.811189155936456, 21: 6.767419084570351, 22: 3.7995358912937744, 25: 4.862264951829969, 26: 4.606279283710503, 27: 1.0, 28: 6.144961020784547}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2920137/1660627543.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31735 samples, validate on 3538 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:30:55.206907: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 8.7071\n",
      "Epoch 1: val_loss improved from inf to 1.41862, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 42s 1ms/sample - loss: 8.7071 - val_loss: 1.4186\n",
      "Epoch 2/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.6716\n",
      "Epoch 2: val_loss improved from 1.41862 to 1.41028, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 697us/sample - loss: 8.6716 - val_loss: 1.4103\n",
      "Epoch 3/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.5668\n",
      "Epoch 3: val_loss improved from 1.41028 to 1.41009, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 21s 658us/sample - loss: 8.5668 - val_loss: 1.4101\n",
      "Epoch 4/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.5728\n",
      "Epoch 4: val_loss did not improve from 1.41009\n",
      "31735/31735 [==============================] - 20s 616us/sample - loss: 8.5728 - val_loss: 1.4171\n",
      "Epoch 5/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.4958\n",
      "Epoch 5: val_loss improved from 1.41009 to 1.39209, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 21s 658us/sample - loss: 8.4958 - val_loss: 1.3921\n",
      "Epoch 6/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.4800\n",
      "Epoch 6: val_loss did not improve from 1.39209\n",
      "31735/31735 [==============================] - 22s 682us/sample - loss: 8.4800 - val_loss: 1.3960\n",
      "Epoch 7/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.4080\n",
      "Epoch 7: val_loss improved from 1.39209 to 1.38957, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 637us/sample - loss: 8.4080 - val_loss: 1.3896\n",
      "Epoch 8/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.4095\n",
      "Epoch 8: val_loss did not improve from 1.38957\n",
      "31735/31735 [==============================] - 19s 611us/sample - loss: 8.4095 - val_loss: 1.3938\n",
      "Epoch 9/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3947\n",
      "Epoch 9: val_loss did not improve from 1.38957\n",
      "31735/31735 [==============================] - 21s 664us/sample - loss: 8.3947 - val_loss: 1.3915\n",
      "Epoch 10/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3923\n",
      "Epoch 10: val_loss improved from 1.38957 to 1.38407, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 691us/sample - loss: 8.3923 - val_loss: 1.3841\n",
      "Epoch 11/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3742\n",
      "Epoch 11: val_loss did not improve from 1.38407\n",
      "31735/31735 [==============================] - 21s 664us/sample - loss: 8.3742 - val_loss: 1.3958\n",
      "Epoch 12/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3903\n",
      "Epoch 12: val_loss did not improve from 1.38407\n",
      "31735/31735 [==============================] - 21s 659us/sample - loss: 8.3903 - val_loss: 1.3875\n",
      "Epoch 13/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3605\n",
      "Epoch 13: val_loss improved from 1.38407 to 1.38211, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 623us/sample - loss: 8.3605 - val_loss: 1.3821\n",
      "Epoch 14/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3498\n",
      "Epoch 14: val_loss did not improve from 1.38211\n",
      "31735/31735 [==============================] - 19s 606us/sample - loss: 8.3498 - val_loss: 1.3838\n",
      "Epoch 15/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3316\n",
      "Epoch 15: val_loss improved from 1.38211 to 1.38098, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 602us/sample - loss: 8.3316 - val_loss: 1.3810\n",
      "Epoch 16/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.3090\n",
      "Epoch 16: val_loss did not improve from 1.38098\n",
      "31735/31735 [==============================] - 19s 598us/sample - loss: 8.3090 - val_loss: 1.3840\n",
      "Epoch 17/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.2883\n",
      "Epoch 17: val_loss did not improve from 1.38098\n",
      "31735/31735 [==============================] - 19s 597us/sample - loss: 8.2883 - val_loss: 1.3952\n",
      "Epoch 18/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.2713\n",
      "Epoch 18: val_loss did not improve from 1.38098\n",
      "31735/31735 [==============================] - 19s 598us/sample - loss: 8.2713 - val_loss: 1.3849\n",
      "Epoch 19/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.2854\n",
      "Epoch 19: val_loss improved from 1.38098 to 1.37967, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 602us/sample - loss: 8.2854 - val_loss: 1.3797\n",
      "Epoch 20/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 8.2634\n",
      "Epoch 20: val_loss improved from 1.37967 to 1.37921, saving model to ./checkpoints/unknown_person_few_shot_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 601us/sample - loss: 8.2634 - val_loss: 1.3792\n",
      "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_116 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_128 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:38:04.898895: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_124_2/lstm_cell_420/recurrent_kernel/Assign' id:211264 op device:{requested: '', assigned: ''} def:{{{node lstm_124_2/lstm_cell_420/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_124_2/lstm_cell_420/recurrent_kernel, lstm_124_2/lstm_cell_420/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 01:38:15.496250: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_124_2/lstm_cell_420/kernel/m/Assign' id:215971 op device:{requested: '', assigned: ''} def:{{{node lstm_124_2/lstm_cell_420/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_124_2/lstm_cell_420/kernel/m, lstm_124_2/lstm_cell_420/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31735 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:38:28.528983: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:39:25.049604: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_15_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:39:45.560583: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_23/mul' id:215705 op device:{requested: '', assigned: ''} def:{{{node loss_23/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_23/mul/x, loss_23/dense_15_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38888, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 41s 1ms/sample - loss: 1.4010 - val_loss: 1.3889\n",
      "Epoch 2/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4006\n",
      "Epoch 2: val_loss did not improve from 1.38888\n",
      "31735/31735 [==============================] - 21s 661us/sample - loss: 1.4006 - val_loss: 1.3941\n",
      "Epoch 3/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4003\n",
      "Epoch 3: val_loss improved from 1.38888 to 1.38331, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 683us/sample - loss: 1.4003 - val_loss: 1.3833\n",
      "Epoch 4/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 4: val_loss did not improve from 1.38331\n",
      "31735/31735 [==============================] - 21s 676us/sample - loss: 1.3965 - val_loss: 1.3908\n",
      "Epoch 5/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3933\n",
      "Epoch 5: val_loss did not improve from 1.38331\n",
      "31735/31735 [==============================] - 22s 692us/sample - loss: 1.3933 - val_loss: 1.3840\n",
      "Epoch 6/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3911\n",
      "Epoch 6: val_loss did not improve from 1.38331\n",
      "31735/31735 [==============================] - 22s 695us/sample - loss: 1.3911 - val_loss: 1.3875\n",
      "Epoch 7/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3930\n",
      "Epoch 7: val_loss improved from 1.38331 to 1.38044, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 20s 633us/sample - loss: 1.3930 - val_loss: 1.3804\n",
      "Epoch 8/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3913\n",
      "Epoch 8: val_loss did not improve from 1.38044\n",
      "31735/31735 [==============================] - 19s 595us/sample - loss: 1.3913 - val_loss: 1.3863\n",
      "Epoch 9/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3903\n",
      "Epoch 9: val_loss improved from 1.38044 to 1.38027, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 687us/sample - loss: 1.3903 - val_loss: 1.3803\n",
      "Epoch 10/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3876\n",
      "Epoch 10: val_loss improved from 1.38027 to 1.37760, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 697us/sample - loss: 1.3876 - val_loss: 1.3776\n",
      "Epoch 11/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3873\n",
      "Epoch 11: val_loss improved from 1.37760 to 1.37647, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 698us/sample - loss: 1.3873 - val_loss: 1.3765\n",
      "Epoch 12/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3829\n",
      "Epoch 12: val_loss did not improve from 1.37647\n",
      "31735/31735 [==============================] - 22s 693us/sample - loss: 1.3829 - val_loss: 1.3792\n",
      "Epoch 13/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3832\n",
      "Epoch 13: val_loss did not improve from 1.37647\n",
      "31735/31735 [==============================] - 20s 641us/sample - loss: 1.3832 - val_loss: 1.3794\n",
      "Epoch 14/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3821\n",
      "Epoch 14: val_loss improved from 1.37647 to 1.37559, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 599us/sample - loss: 1.3821 - val_loss: 1.3756\n",
      "Epoch 15/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3817\n",
      "Epoch 15: val_loss did not improve from 1.37559\n",
      "31735/31735 [==============================] - 19s 610us/sample - loss: 1.3817 - val_loss: 1.3785\n",
      "Epoch 16/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3804\n",
      "Epoch 16: val_loss did not improve from 1.37559\n",
      "31735/31735 [==============================] - 20s 642us/sample - loss: 1.3804 - val_loss: 1.3797\n",
      "Epoch 17/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3782\n",
      "Epoch 17: val_loss did not improve from 1.37559\n",
      "31735/31735 [==============================] - 22s 690us/sample - loss: 1.3782 - val_loss: 1.3760\n",
      "Epoch 18/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3785\n",
      "Epoch 18: val_loss improved from 1.37559 to 1.37162, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 22s 696us/sample - loss: 1.3785 - val_loss: 1.3716\n",
      "Epoch 19/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3774\n",
      "Epoch 19: val_loss did not improve from 1.37162\n",
      "31735/31735 [==============================] - 20s 629us/sample - loss: 1.3774 - val_loss: 1.3800\n",
      "Epoch 20/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3770\n",
      "Epoch 20: val_loss improved from 1.37162 to 1.37105, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_33.h5\n",
      "31735/31735 [==============================] - 19s 604us/sample - loss: 1.3770 - val_loss: 1.3710\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:46:47.757878: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_154/lstm_cell_450/kernel/Assign' id:229176 op device:{requested: '', assigned: ''} def:{{{node lstm_154/lstm_cell_450/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_154/lstm_cell_450/kernel, lstm_154/lstm_cell_450/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 01:46:54.103587: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_1' id:231804 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 01:46:59.211918: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_4/stack_2' id:231805 op device:{requested: '', assigned: ''} def:{{{node strided_slice_4/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31735, 95)\n",
      "Train on 31735 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:47:14.482408: W tensorflow/c/c_api.cc:304] Operation '{name:'training_24/Adam/lstm_165/lstm_cell_461/bias/m/Assign' id:244827 op device:{requested: '', assigned: ''} def:{{{node training_24/Adam/lstm_165/lstm_cell_461/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_24/Adam/lstm_165/lstm_cell_461/bias/m, training_24/Adam/lstm_165/lstm_cell_461/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:48:19.091352: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 3.2189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 01:48:41.605677: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_25/mul' id:234645 op device:{requested: '', assigned: ''} def:{{{node loss_25/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_25/mul/x, loss_25/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.92525, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 81s 3ms/sample - loss: 3.2189 - val_loss: 1.9252\n",
      "Epoch 2/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.7914\n",
      "Epoch 2: val_loss improved from 1.92525 to 1.59450, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 19s 603us/sample - loss: 1.7914 - val_loss: 1.5945\n",
      "Epoch 3/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.6002\n",
      "Epoch 3: val_loss improved from 1.59450 to 1.52444, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 22s 679us/sample - loss: 1.6002 - val_loss: 1.5244\n",
      "Epoch 4/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5529\n",
      "Epoch 4: val_loss improved from 1.52444 to 1.49256, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 33s 1ms/sample - loss: 1.5529 - val_loss: 1.4926\n",
      "Epoch 5/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5296\n",
      "Epoch 5: val_loss improved from 1.49256 to 1.47388, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 996us/sample - loss: 1.5296 - val_loss: 1.4739\n",
      "Epoch 6/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5118\n",
      "Epoch 6: val_loss improved from 1.47388 to 1.46343, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 33s 1ms/sample - loss: 1.5118 - val_loss: 1.4634\n",
      "Epoch 7/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5007\n",
      "Epoch 7: val_loss improved from 1.46343 to 1.45075, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.5007 - val_loss: 1.4508\n",
      "Epoch 8/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4998\n",
      "Epoch 8: val_loss improved from 1.45075 to 1.44853, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4998 - val_loss: 1.4485\n",
      "Epoch 9/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4906\n",
      "Epoch 9: val_loss improved from 1.44853 to 1.43844, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4906 - val_loss: 1.4384\n",
      "Epoch 10/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4928\n",
      "Epoch 10: val_loss improved from 1.43844 to 1.43403, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4928 - val_loss: 1.4340\n",
      "Epoch 11/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4904\n",
      "Epoch 11: val_loss did not improve from 1.43403\n",
      "31735/31735 [==============================] - 32s 998us/sample - loss: 1.4904 - val_loss: 1.4344\n",
      "Epoch 12/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 12: val_loss did not improve from 1.43403\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4987 - val_loss: 1.4404\n",
      "Epoch 13/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4775\n",
      "Epoch 13: val_loss improved from 1.43403 to 1.42955, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4775 - val_loss: 1.4296\n",
      "Epoch 14/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4764\n",
      "Epoch 14: val_loss improved from 1.42955 to 1.42823, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4764 - val_loss: 1.4282\n",
      "Epoch 15/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4721\n",
      "Epoch 15: val_loss did not improve from 1.42823\n",
      "31735/31735 [==============================] - 31s 977us/sample - loss: 1.4721 - val_loss: 1.4342\n",
      "Epoch 16/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4769\n",
      "Epoch 16: val_loss did not improve from 1.42823\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4769 - val_loss: 1.4368\n",
      "Epoch 17/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4688\n",
      "Epoch 17: val_loss improved from 1.42823 to 1.42279, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 33s 1ms/sample - loss: 1.4688 - val_loss: 1.4228\n",
      "Epoch 18/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4819\n",
      "Epoch 18: val_loss did not improve from 1.42279\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4819 - val_loss: 1.4373\n",
      "Epoch 19/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4780\n",
      "Epoch 19: val_loss did not improve from 1.42279\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4780 - val_loss: 1.4261\n",
      "Epoch 20/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4958\n",
      "Epoch 20: val_loss did not improve from 1.42279\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4958 - val_loss: 1.4240\n",
      "Epoch 21/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5780\n",
      "Epoch 21: val_loss did not improve from 1.42279\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.5780 - val_loss: 1.4431\n",
      "Epoch 22/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5272\n",
      "Epoch 22: val_loss improved from 1.42279 to 1.41820, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.5272 - val_loss: 1.4182\n",
      "Epoch 23/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 23: val_loss did not improve from 1.41820\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4829 - val_loss: 1.4246\n",
      "Epoch 24/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4652\n",
      "Epoch 24: val_loss did not improve from 1.41820\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4652 - val_loss: 1.4241\n",
      "Epoch 25/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4583\n",
      "Epoch 25: val_loss did not improve from 1.41820\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4583 - val_loss: 1.4237\n",
      "Epoch 26/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4540\n",
      "Epoch 26: val_loss did not improve from 1.41820\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4540 - val_loss: 1.4195\n",
      "Epoch 27/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4592\n",
      "Epoch 27: val_loss improved from 1.41820 to 1.41438, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 31s 965us/sample - loss: 1.4592 - val_loss: 1.4144\n",
      "Epoch 28/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4664\n",
      "Epoch 28: val_loss did not improve from 1.41438\n",
      "31735/31735 [==============================] - 31s 976us/sample - loss: 1.4664 - val_loss: 1.4169\n",
      "Epoch 29/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4501\n",
      "Epoch 29: val_loss improved from 1.41438 to 1.41074, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 994us/sample - loss: 1.4501 - val_loss: 1.4107\n",
      "Epoch 30/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4438\n",
      "Epoch 30: val_loss did not improve from 1.41074\n",
      "31735/31735 [==============================] - 31s 983us/sample - loss: 1.4438 - val_loss: 1.4147\n",
      "Epoch 31/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 31: val_loss did not improve from 1.41074\n",
      "31735/31735 [==============================] - 32s 993us/sample - loss: 1.4412 - val_loss: 1.4122\n",
      "Epoch 32/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4380\n",
      "Epoch 32: val_loss did not improve from 1.41074\n",
      "31735/31735 [==============================] - 33s 1ms/sample - loss: 1.4380 - val_loss: 1.4109\n",
      "Epoch 33/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4374\n",
      "Epoch 33: val_loss improved from 1.41074 to 1.40042, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 998us/sample - loss: 1.4374 - val_loss: 1.4004\n",
      "Epoch 34/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4343\n",
      "Epoch 34: val_loss did not improve from 1.40042\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4343 - val_loss: 1.4064\n",
      "Epoch 35/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 35: val_loss did not improve from 1.40042\n",
      "31735/31735 [==============================] - 31s 989us/sample - loss: 1.4312 - val_loss: 1.4110\n",
      "Epoch 36/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4303\n",
      "Epoch 36: val_loss did not improve from 1.40042\n",
      "31735/31735 [==============================] - 31s 992us/sample - loss: 1.4303 - val_loss: 1.4027\n",
      "Epoch 37/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4287\n",
      "Epoch 37: val_loss did not improve from 1.40042\n",
      "31735/31735 [==============================] - 31s 992us/sample - loss: 1.4287 - val_loss: 1.4016\n",
      "Epoch 38/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4256\n",
      "Epoch 38: val_loss did not improve from 1.40042\n",
      "31735/31735 [==============================] - 32s 998us/sample - loss: 1.4256 - val_loss: 1.4020\n",
      "Epoch 39/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 39: val_loss improved from 1.40042 to 1.39718, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 996us/sample - loss: 1.4242 - val_loss: 1.3972\n",
      "Epoch 40/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 40: val_loss improved from 1.39718 to 1.39297, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4207 - val_loss: 1.3930\n",
      "Epoch 41/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 41: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 30s 954us/sample - loss: 1.4210 - val_loss: 1.3946\n",
      "Epoch 42/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4189\n",
      "Epoch 42: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 31s 973us/sample - loss: 1.4189 - val_loss: 1.3935\n",
      "Epoch 43/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 43: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 31s 982us/sample - loss: 1.4174 - val_loss: 1.3946\n",
      "Epoch 44/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4170\n",
      "Epoch 44: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 31s 991us/sample - loss: 1.4170 - val_loss: 1.3934\n",
      "Epoch 45/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 45: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 32s 995us/sample - loss: 1.4148 - val_loss: 1.3945\n",
      "Epoch 46/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4135\n",
      "Epoch 46: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 31s 985us/sample - loss: 1.4135 - val_loss: 1.3934\n",
      "Epoch 47/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4143\n",
      "Epoch 47: val_loss did not improve from 1.39297\n",
      "31735/31735 [==============================] - 31s 988us/sample - loss: 1.4143 - val_loss: 1.3957\n",
      "Epoch 48/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 48: val_loss improved from 1.39297 to 1.38671, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_34.h5\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4096 - val_loss: 1.3867\n",
      "Epoch 49/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 49: val_loss did not improve from 1.38671\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4096 - val_loss: 1.3923\n",
      "Epoch 50/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 50: val_loss did not improve from 1.38671\n",
      "31735/31735 [==============================] - 32s 1ms/sample - loss: 1.4070 - val_loss: 1.4022\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:15:24.691213: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_173_1/lstm_cell_506/kernel/Assign' id:250810 op device:{requested: '', assigned: ''} def:{{{node lstm_173_1/lstm_cell_506/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_173_1/lstm_cell_506/kernel, lstm_173_1/lstm_cell_506/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:15:44.223920: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_156_1/lstm_cell_489/bias/v/Assign' id:254193 op device:{requested: '', assigned: ''} def:{{{node lstm_156_1/lstm_cell_489/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_156_1/lstm_cell_489/bias/v, lstm_156_1/lstm_cell_489/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:16:00.427375: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_24_1/cond/Merge' id:252759 op device:{requested: '', assigned: ''} def:{{{node dropout_24_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_24_1/cond/Identity, dropout_24_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1728)\n",
      "(1514, 1728)\n",
      "(1644, 1728)\n",
      "(1764, 1728)\n",
      "(1836, 1728)\n",
      "(1699, 1728)\n",
      "(1369, 1728)\n",
      "(1778, 1728)\n",
      "(1631, 1728)\n",
      "(1704, 1728)\n",
      "(1550, 1728)\n",
      "(1920, 1728)\n",
      "(1739, 1728)\n",
      "(1788, 1728)\n",
      "(1812, 1728)\n",
      "(1788, 1728)\n",
      "(1776, 1728)\n",
      "(946, 1728)\n",
      "(1572, 1728)\n",
      "{1: 4.55162623166086, 2: 1.0, 4: 4.0905001679139374, 5: 8.716621754854277, 6: 10.0, 8: 4.552024050235106, 9: 1.2359675427479777, 10: 5.589319487665738, 11: 3.0650325558980915, 12: 4.1191236994755585, 13: 5.342165480667796, 17: 3.943988438465067, 19: 4.6216830528748325, 21: 5.317386234938281, 22: 1.9801366706250874, 25: 3.639011016555829, 26: 3.2729791166810505, 27: 1.035891967999862, 28: 4.412378087204203}\n",
      "Train on 31735 samples, validate on 3538 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:21:18.426770: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 7.2214\n",
      "Epoch 1: val_loss improved from inf to 1.42114, saving model to ./checkpoints/unknown_person_few_shot_p29_34.h5\n",
      "31735/31735 [==============================] - 48s 1ms/sample - loss: 7.2214 - val_loss: 1.4211\n",
      "Epoch 2/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1016\n",
      "Epoch 2: val_loss improved from 1.42114 to 1.40033, saving model to ./checkpoints/unknown_person_few_shot_p29_34.h5\n",
      "31735/31735 [==============================] - 22s 699us/sample - loss: 7.1016 - val_loss: 1.4003\n",
      "Epoch 3/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0480\n",
      "Epoch 3: val_loss did not improve from 1.40033\n",
      "31735/31735 [==============================] - 22s 692us/sample - loss: 7.0480 - val_loss: 1.4060\n",
      "Epoch 4/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0154\n",
      "Epoch 4: val_loss did not improve from 1.40033\n",
      "31735/31735 [==============================] - 22s 687us/sample - loss: 7.0154 - val_loss: 1.4109\n",
      "Epoch 5/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9968\n",
      "Epoch 5: val_loss did not improve from 1.40033\n",
      "31735/31735 [==============================] - 20s 617us/sample - loss: 6.9968 - val_loss: 1.4085\n",
      "Epoch 6/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9494\n",
      "Epoch 6: val_loss did not improve from 1.40033\n",
      "31735/31735 [==============================] - 21s 667us/sample - loss: 6.9494 - val_loss: 1.4020\n",
      "Epoch 7/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9238\n",
      "Epoch 7: val_loss improved from 1.40033 to 1.38762, saving model to ./checkpoints/unknown_person_few_shot_p29_34.h5\n",
      "31735/31735 [==============================] - 21s 661us/sample - loss: 6.9238 - val_loss: 1.3876\n",
      "Epoch 8/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9193\n",
      "Epoch 8: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 20s 618us/sample - loss: 6.9193 - val_loss: 1.3998\n",
      "Epoch 9/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9228\n",
      "Epoch 9: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 22s 692us/sample - loss: 6.9228 - val_loss: 1.3995\n",
      "Epoch 10/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9166\n",
      "Epoch 10: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 22s 691us/sample - loss: 6.9166 - val_loss: 1.4018\n",
      "Epoch 11/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9033\n",
      "Epoch 11: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 22s 692us/sample - loss: 6.9033 - val_loss: 1.4409\n",
      "Epoch 12/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8697\n",
      "Epoch 12: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 20s 645us/sample - loss: 6.8697 - val_loss: 1.4045\n",
      "Epoch 13/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.9010\n",
      "Epoch 13: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 19s 614us/sample - loss: 6.9010 - val_loss: 1.3904\n",
      "Epoch 14/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8747\n",
      "Epoch 14: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 19s 607us/sample - loss: 6.8747 - val_loss: 1.3898\n",
      "Epoch 15/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8624\n",
      "Epoch 15: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 19s 608us/sample - loss: 6.8624 - val_loss: 1.4035\n",
      "Epoch 16/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8153\n",
      "Epoch 16: val_loss did not improve from 1.38762\n",
      "31735/31735 [==============================] - 19s 609us/sample - loss: 6.8153 - val_loss: 1.3979\n",
      "Epoch 17/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8032\n",
      "Epoch 17: val_loss improved from 1.38762 to 1.38497, saving model to ./checkpoints/unknown_person_few_shot_p29_34.h5\n",
      "31735/31735 [==============================] - 19s 610us/sample - loss: 6.8032 - val_loss: 1.3850\n",
      "Epoch 18/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8149\n",
      "Epoch 18: val_loss improved from 1.38497 to 1.38477, saving model to ./checkpoints/unknown_person_few_shot_p29_34.h5\n",
      "31735/31735 [==============================] - 19s 605us/sample - loss: 6.8149 - val_loss: 1.3848\n",
      "Epoch 19/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8109\n",
      "Epoch 19: val_loss did not improve from 1.38477\n",
      "31735/31735 [==============================] - 19s 602us/sample - loss: 6.8109 - val_loss: 1.3849\n",
      "Epoch 20/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 6.8204\n",
      "Epoch 20: val_loss did not improve from 1.38477\n",
      "31735/31735 [==============================] - 19s 600us/sample - loss: 6.8204 - val_loss: 1.3902\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_152 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_153 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_154 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_155 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_156 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_157 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_158 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_159 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:28:39.562393: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_173_2/lstm_cell_543/kernel/Assign' id:270208 op device:{requested: '', assigned: ''} def:{{{node lstm_173_2/lstm_cell_543/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_173_2/lstm_cell_543/kernel, lstm_173_2/lstm_cell_543/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:28:53.458646: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_16_2/kernel/m/Assign' id:273375 op device:{requested: '', assigned: ''} def:{{{node dense_16_2/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_16_2/kernel/m, dense_16_2/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31735 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:29:09.986127: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:30:23.607122: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_20_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:30:45.347867: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_29/mul' id:272747 op device:{requested: '', assigned: ''} def:{{{node loss_29/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_29/mul/x, loss_29/dense_19_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38522, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 48s 2ms/sample - loss: 1.4083 - val_loss: 1.3852\n",
      "Epoch 2/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4090\n",
      "Epoch 2: val_loss did not improve from 1.38522\n",
      "31735/31735 [==============================] - 20s 624us/sample - loss: 1.4090 - val_loss: 1.3860\n",
      "Epoch 3/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 3: val_loss did not improve from 1.38522\n",
      "31735/31735 [==============================] - 21s 664us/sample - loss: 1.4050 - val_loss: 1.3864\n",
      "Epoch 4/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4045\n",
      "Epoch 4: val_loss did not improve from 1.38522\n",
      "31735/31735 [==============================] - 22s 680us/sample - loss: 1.4045 - val_loss: 1.3891\n",
      "Epoch 5/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4030\n",
      "Epoch 5: val_loss did not improve from 1.38522\n",
      "31735/31735 [==============================] - 20s 624us/sample - loss: 1.4030 - val_loss: 1.3944\n",
      "Epoch 6/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4035\n",
      "Epoch 6: val_loss did not improve from 1.38522\n",
      "31735/31735 [==============================] - 20s 633us/sample - loss: 1.4035 - val_loss: 1.3867\n",
      "Epoch 7/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4009\n",
      "Epoch 7: val_loss did not improve from 1.38522\n",
      "31735/31735 [==============================] - 20s 630us/sample - loss: 1.4009 - val_loss: 1.3923\n",
      "Epoch 8/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 8: val_loss improved from 1.38522 to 1.38444, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 22s 699us/sample - loss: 1.4001 - val_loss: 1.3844\n",
      "Epoch 9/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 9: val_loss did not improve from 1.38444\n",
      "31735/31735 [==============================] - 21s 652us/sample - loss: 1.3996 - val_loss: 1.3870\n",
      "Epoch 10/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3972\n",
      "Epoch 10: val_loss improved from 1.38444 to 1.38369, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 21s 659us/sample - loss: 1.3972 - val_loss: 1.3837\n",
      "Epoch 11/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 11: val_loss did not improve from 1.38369\n",
      "31735/31735 [==============================] - 20s 616us/sample - loss: 1.3949 - val_loss: 1.3880\n",
      "Epoch 12/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3918\n",
      "Epoch 12: val_loss did not improve from 1.38369\n",
      "31735/31735 [==============================] - 21s 670us/sample - loss: 1.3918 - val_loss: 1.3857\n",
      "Epoch 13/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3931\n",
      "Epoch 13: val_loss improved from 1.38369 to 1.37695, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 20s 628us/sample - loss: 1.3931 - val_loss: 1.3769\n",
      "Epoch 14/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3928\n",
      "Epoch 14: val_loss did not improve from 1.37695\n",
      "31735/31735 [==============================] - 20s 615us/sample - loss: 1.3928 - val_loss: 1.3798\n",
      "Epoch 15/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 15: val_loss did not improve from 1.37695\n",
      "31735/31735 [==============================] - 19s 613us/sample - loss: 1.3882 - val_loss: 1.3829\n",
      "Epoch 16/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 16: val_loss improved from 1.37695 to 1.37612, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 19s 613us/sample - loss: 1.3902 - val_loss: 1.3761\n",
      "Epoch 17/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3887\n",
      "Epoch 17: val_loss improved from 1.37612 to 1.37549, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 19s 612us/sample - loss: 1.3887 - val_loss: 1.3755\n",
      "Epoch 18/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3860\n",
      "Epoch 18: val_loss did not improve from 1.37549\n",
      "31735/31735 [==============================] - 19s 607us/sample - loss: 1.3860 - val_loss: 1.3880\n",
      "Epoch 19/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3848\n",
      "Epoch 19: val_loss improved from 1.37549 to 1.37285, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_34.h5\n",
      "31735/31735 [==============================] - 20s 615us/sample - loss: 1.3848 - val_loss: 1.3728\n",
      "Epoch 20/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3866\n",
      "Epoch 20: val_loss did not improve from 1.37285\n",
      "31735/31735 [==============================] - 19s 606us/sample - loss: 1.3866 - val_loss: 1.3729\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:37:39.398120: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_186/lstm_cell_556/bias/Assign' id:285422 op device:{requested: '', assigned: ''} def:{{{node lstm_186/lstm_cell_556/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_186/lstm_cell_556/bias, lstm_186/lstm_cell_556/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:37:47.029447: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_1' id:288846 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:37:53.121592: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_5/stack_2' id:288847 op device:{requested: '', assigned: ''} def:{{{node strided_slice_5/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31735, 95)\n",
      "Train on 31735 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:38:10.602089: W tensorflow/c/c_api.cc:304] Operation '{name:'training_30/Adam/lstm_213/lstm_cell_583/bias/m/Assign' id:302034 op device:{requested: '', assigned: ''} def:{{{node training_30/Adam/lstm_213/lstm_cell_583/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_30/Adam/lstm_213/lstm_cell_583/bias/m, training_30/Adam/lstm_213/lstm_cell_583/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:39:27.886581: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 3.2527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:39:48.150284: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_31/mul' id:291687 op device:{requested: '', assigned: ''} def:{{{node loss_31/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_31/mul/x, loss_31/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.83880, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 89s 3ms/sample - loss: 3.2527 - val_loss: 1.8388\n",
      "Epoch 2/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.7826\n",
      "Epoch 2: val_loss improved from 1.83880 to 1.58098, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 606us/sample - loss: 1.7826 - val_loss: 1.5810\n",
      "Epoch 3/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5994\n",
      "Epoch 3: val_loss improved from 1.58098 to 1.52431, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 685us/sample - loss: 1.5994 - val_loss: 1.5243\n",
      "Epoch 4/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5548\n",
      "Epoch 4: val_loss improved from 1.52431 to 1.48565, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 589us/sample - loss: 1.5548 - val_loss: 1.4857\n",
      "Epoch 5/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5246\n",
      "Epoch 5: val_loss improved from 1.48565 to 1.46567, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 588us/sample - loss: 1.5246 - val_loss: 1.4657\n",
      "Epoch 6/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5069\n",
      "Epoch 6: val_loss improved from 1.46567 to 1.44980, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 588us/sample - loss: 1.5069 - val_loss: 1.4498\n",
      "Epoch 7/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4943\n",
      "Epoch 7: val_loss improved from 1.44980 to 1.44462, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 593us/sample - loss: 1.4943 - val_loss: 1.4446\n",
      "Epoch 8/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4975\n",
      "Epoch 8: val_loss improved from 1.44462 to 1.44167, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 595us/sample - loss: 1.4975 - val_loss: 1.4417\n",
      "Epoch 9/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4959\n",
      "Epoch 9: val_loss improved from 1.44167 to 1.43887, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 596us/sample - loss: 1.4959 - val_loss: 1.4389\n",
      "Epoch 10/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5301\n",
      "Epoch 10: val_loss did not improve from 1.43887\n",
      "31735/31735 [==============================] - 19s 595us/sample - loss: 1.5301 - val_loss: 1.4562\n",
      "Epoch 11/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 11: val_loss did not improve from 1.43887\n",
      "31735/31735 [==============================] - 19s 601us/sample - loss: 1.4865 - val_loss: 1.4395\n",
      "Epoch 12/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4811\n",
      "Epoch 12: val_loss did not improve from 1.43887\n",
      "31735/31735 [==============================] - 19s 592us/sample - loss: 1.4811 - val_loss: 1.4454\n",
      "Epoch 13/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4766\n",
      "Epoch 13: val_loss did not improve from 1.43887\n",
      "31735/31735 [==============================] - 19s 589us/sample - loss: 1.4766 - val_loss: 1.4395\n",
      "Epoch 14/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4906\n",
      "Epoch 14: val_loss did not improve from 1.43887\n",
      "31735/31735 [==============================] - 19s 592us/sample - loss: 1.4906 - val_loss: 1.4414\n",
      "Epoch 15/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4999\n",
      "Epoch 15: val_loss improved from 1.43887 to 1.42892, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 20s 628us/sample - loss: 1.4999 - val_loss: 1.4289\n",
      "Epoch 16/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4851\n",
      "Epoch 16: val_loss did not improve from 1.42892\n",
      "31735/31735 [==============================] - 21s 675us/sample - loss: 1.4851 - val_loss: 1.4349\n",
      "Epoch 17/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5112\n",
      "Epoch 17: val_loss did not improve from 1.42892\n",
      "31735/31735 [==============================] - 19s 594us/sample - loss: 1.5112 - val_loss: 1.4320\n",
      "Epoch 18/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5284\n",
      "Epoch 18: val_loss improved from 1.42892 to 1.42742, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 602us/sample - loss: 1.5284 - val_loss: 1.4274\n",
      "Epoch 19/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5185\n",
      "Epoch 19: val_loss improved from 1.42742 to 1.42192, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 598us/sample - loss: 1.5185 - val_loss: 1.4219\n",
      "Epoch 20/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5101\n",
      "Epoch 20: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 586us/sample - loss: 1.5101 - val_loss: 1.4347\n",
      "Epoch 21/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5319\n",
      "Epoch 21: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 584us/sample - loss: 1.5319 - val_loss: 1.4337\n",
      "Epoch 22/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5318\n",
      "Epoch 22: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 585us/sample - loss: 1.5318 - val_loss: 1.4404\n",
      "Epoch 23/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.5030\n",
      "Epoch 23: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 586us/sample - loss: 1.5030 - val_loss: 1.4410\n",
      "Epoch 24/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 24: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 583us/sample - loss: 1.4854 - val_loss: 1.4383\n",
      "Epoch 25/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4803\n",
      "Epoch 25: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 585us/sample - loss: 1.4803 - val_loss: 1.4295\n",
      "Epoch 26/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4774\n",
      "Epoch 26: val_loss did not improve from 1.42192\n",
      "31735/31735 [==============================] - 19s 587us/sample - loss: 1.4774 - val_loss: 1.4321\n",
      "Epoch 27/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4721\n",
      "Epoch 27: val_loss improved from 1.42192 to 1.42100, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 595us/sample - loss: 1.4721 - val_loss: 1.4210\n",
      "Epoch 28/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4663\n",
      "Epoch 28: val_loss did not improve from 1.42100\n",
      "31735/31735 [==============================] - 19s 584us/sample - loss: 1.4663 - val_loss: 1.4243\n",
      "Epoch 29/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4667\n",
      "Epoch 29: val_loss improved from 1.42100 to 1.41876, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 594us/sample - loss: 1.4667 - val_loss: 1.4188\n",
      "Epoch 30/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4611\n",
      "Epoch 30: val_loss did not improve from 1.41876\n",
      "31735/31735 [==============================] - 18s 580us/sample - loss: 1.4611 - val_loss: 1.4262\n",
      "Epoch 31/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4586\n",
      "Epoch 31: val_loss did not improve from 1.41876\n",
      "31735/31735 [==============================] - 22s 680us/sample - loss: 1.4586 - val_loss: 1.4258\n",
      "Epoch 32/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4542\n",
      "Epoch 32: val_loss improved from 1.41876 to 1.41671, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 671us/sample - loss: 1.4542 - val_loss: 1.4167\n",
      "Epoch 33/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4518\n",
      "Epoch 33: val_loss did not improve from 1.41671\n",
      "31735/31735 [==============================] - 19s 610us/sample - loss: 1.4518 - val_loss: 1.4212\n",
      "Epoch 34/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4478\n",
      "Epoch 34: val_loss did not improve from 1.41671\n",
      "31735/31735 [==============================] - 20s 644us/sample - loss: 1.4478 - val_loss: 1.4189\n",
      "Epoch 35/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4473\n",
      "Epoch 35: val_loss improved from 1.41671 to 1.41008, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 695us/sample - loss: 1.4473 - val_loss: 1.4101\n",
      "Epoch 36/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4433\n",
      "Epoch 36: val_loss did not improve from 1.41008\n",
      "31735/31735 [==============================] - 20s 624us/sample - loss: 1.4433 - val_loss: 1.4135\n",
      "Epoch 37/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4394\n",
      "Epoch 37: val_loss did not improve from 1.41008\n",
      "31735/31735 [==============================] - 19s 610us/sample - loss: 1.4394 - val_loss: 1.4109\n",
      "Epoch 38/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4400\n",
      "Epoch 38: val_loss improved from 1.41008 to 1.40395, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 652us/sample - loss: 1.4400 - val_loss: 1.4040\n",
      "Epoch 39/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4394\n",
      "Epoch 39: val_loss did not improve from 1.40395\n",
      "31735/31735 [==============================] - 22s 680us/sample - loss: 1.4394 - val_loss: 1.4135\n",
      "Epoch 40/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4382\n",
      "Epoch 40: val_loss did not improve from 1.40395\n",
      "31735/31735 [==============================] - 21s 674us/sample - loss: 1.4382 - val_loss: 1.4066\n",
      "Epoch 41/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 41: val_loss did not improve from 1.40395\n",
      "31735/31735 [==============================] - 21s 665us/sample - loss: 1.4354 - val_loss: 1.4113\n",
      "Epoch 42/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 42: val_loss improved from 1.40395 to 1.39680, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 692us/sample - loss: 1.4330 - val_loss: 1.3968\n",
      "Epoch 43/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4322\n",
      "Epoch 43: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 20s 626us/sample - loss: 1.4322 - val_loss: 1.4032\n",
      "Epoch 44/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 44: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 19s 600us/sample - loss: 1.4311 - val_loss: 1.4007\n",
      "Epoch 45/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4282\n",
      "Epoch 45: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 20s 620us/sample - loss: 1.4282 - val_loss: 1.4077\n",
      "Epoch 46/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 46: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 22s 687us/sample - loss: 1.4262 - val_loss: 1.4002\n",
      "Epoch 47/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 47: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 22s 681us/sample - loss: 1.4242 - val_loss: 1.3972\n",
      "Epoch 48/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 48: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 22s 686us/sample - loss: 1.4262 - val_loss: 1.3999\n",
      "Epoch 49/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 49: val_loss did not improve from 1.39680\n",
      "31735/31735 [==============================] - 20s 632us/sample - loss: 1.4249 - val_loss: 1.4057\n",
      "Epoch 50/50\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 50: val_loss improved from 1.39680 to 1.39575, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_35.h5\n",
      "31735/31735 [==============================] - 19s 598us/sample - loss: 1.4210 - val_loss: 1.3957\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 02:57:07.295550: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_211_1/lstm_cell_618/bias/Assign' id:308041 op device:{requested: '', assigned: ''} def:{{{node lstm_211_1/lstm_cell_618/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_211_1/lstm_cell_618/bias, lstm_211_1/lstm_cell_618/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:57:22.968181: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_193_1/lstm_cell_600/kernel/m/Assign' id:310582 op device:{requested: '', assigned: ''} def:{{{node lstm_193_1/lstm_cell_600/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_193_1/lstm_cell_600/kernel/m, lstm_193_1/lstm_cell_600/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 02:57:38.472266: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_29_1/cond/Merge' id:309801 op device:{requested: '', assigned: ''} def:{{{node dropout_29_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_29_1/cond/Identity, dropout_29_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1728)\n",
      "(1514, 1728)\n",
      "(1644, 1728)\n",
      "(1764, 1728)\n",
      "(1836, 1728)\n",
      "(1699, 1728)\n",
      "(1369, 1728)\n",
      "(1778, 1728)\n",
      "(1631, 1728)\n",
      "(1704, 1728)\n",
      "(1550, 1728)\n",
      "(1920, 1728)\n",
      "(1739, 1728)\n",
      "(1788, 1728)\n",
      "(1812, 1728)\n",
      "(1788, 1728)\n",
      "(1776, 1728)\n",
      "(946, 1728)\n",
      "(1572, 1728)\n",
      "{1: 5.100647931226211, 2: 1.4854154804146025, 4: 4.089773364538213, 5: 8.937309106315402, 6: 10.0, 8: 4.61506137946625, 9: 1.4192162493629654, 10: 5.743863278728779, 11: 3.0689357748438093, 12: 4.1855130663958855, 13: 5.608919188932939, 17: 3.8495676772468297, 19: 4.539680243626636, 21: 5.152091989760585, 22: 2.7895816474756336, 25: 3.620233089788786, 26: 3.433668490511159, 27: 1.0, 28: 4.652998333160189}\n",
      "Train on 31735 samples, validate on 3538 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:02:53.375349: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 7.4512\n",
      "Epoch 1: val_loss improved from inf to 1.41306, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 54s 2ms/sample - loss: 7.4512 - val_loss: 1.4131\n",
      "Epoch 2/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.3482\n",
      "Epoch 2: val_loss improved from 1.41306 to 1.41012, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 671us/sample - loss: 7.3482 - val_loss: 1.4101\n",
      "Epoch 3/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.2613\n",
      "Epoch 3: val_loss improved from 1.41012 to 1.40908, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 650us/sample - loss: 7.2613 - val_loss: 1.4091\n",
      "Epoch 4/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.2472\n",
      "Epoch 4: val_loss did not improve from 1.40908\n",
      "31735/31735 [==============================] - 22s 703us/sample - loss: 7.2472 - val_loss: 1.4273\n",
      "Epoch 5/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.2277\n",
      "Epoch 5: val_loss improved from 1.40908 to 1.40086, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 658us/sample - loss: 7.2277 - val_loss: 1.4009\n",
      "Epoch 6/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.2092\n",
      "Epoch 6: val_loss did not improve from 1.40086\n",
      "31735/31735 [==============================] - 22s 683us/sample - loss: 7.2092 - val_loss: 1.4067\n",
      "Epoch 7/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1903\n",
      "Epoch 7: val_loss did not improve from 1.40086\n",
      "31735/31735 [==============================] - 22s 689us/sample - loss: 7.1903 - val_loss: 1.4037\n",
      "Epoch 8/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1551\n",
      "Epoch 8: val_loss improved from 1.40086 to 1.39948, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 706us/sample - loss: 7.1551 - val_loss: 1.3995\n",
      "Epoch 9/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1087\n",
      "Epoch 9: val_loss improved from 1.39948 to 1.39912, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 20s 636us/sample - loss: 7.1087 - val_loss: 1.3991\n",
      "Epoch 10/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1278\n",
      "Epoch 10: val_loss improved from 1.39912 to 1.39335, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 662us/sample - loss: 7.1278 - val_loss: 1.3934\n",
      "Epoch 11/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1158\n",
      "Epoch 11: val_loss did not improve from 1.39335\n",
      "31735/31735 [==============================] - 22s 708us/sample - loss: 7.1158 - val_loss: 1.3935\n",
      "Epoch 12/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1248\n",
      "Epoch 12: val_loss improved from 1.39335 to 1.39064, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 708us/sample - loss: 7.1248 - val_loss: 1.3906\n",
      "Epoch 13/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.1087\n",
      "Epoch 13: val_loss did not improve from 1.39064\n",
      "31735/31735 [==============================] - 23s 712us/sample - loss: 7.1087 - val_loss: 1.3931\n",
      "Epoch 14/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0754\n",
      "Epoch 14: val_loss did not improve from 1.39064\n",
      "31735/31735 [==============================] - 20s 643us/sample - loss: 7.0754 - val_loss: 1.3968\n",
      "Epoch 15/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0944\n",
      "Epoch 15: val_loss did not improve from 1.39064\n",
      "31735/31735 [==============================] - 20s 627us/sample - loss: 7.0944 - val_loss: 1.3918\n",
      "Epoch 16/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0592\n",
      "Epoch 16: val_loss improved from 1.39064 to 1.38309, saving model to ./checkpoints/unknown_person_few_shot_p29_35.h5\n",
      "31735/31735 [==============================] - 20s 639us/sample - loss: 7.0592 - val_loss: 1.3831\n",
      "Epoch 17/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0448\n",
      "Epoch 17: val_loss did not improve from 1.38309\n",
      "31735/31735 [==============================] - 20s 645us/sample - loss: 7.0448 - val_loss: 1.3954\n",
      "Epoch 18/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0455\n",
      "Epoch 18: val_loss did not improve from 1.38309\n",
      "31735/31735 [==============================] - 21s 673us/sample - loss: 7.0455 - val_loss: 1.3987\n",
      "Epoch 19/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0169\n",
      "Epoch 19: val_loss did not improve from 1.38309\n",
      "31735/31735 [==============================] - 21s 666us/sample - loss: 7.0169 - val_loss: 1.3886\n",
      "Epoch 20/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 7.0138\n",
      "Epoch 20: val_loss did not improve from 1.38309\n",
      "31735/31735 [==============================] - 22s 681us/sample - loss: 7.0138 - val_loss: 1.3851\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_208 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_209 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_210 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_211 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_212 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_213 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_214 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_215 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_216 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_217 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_218 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_219 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_220 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_221 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:10:39.151034: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_23_2/bias/Assign' id:329256 op device:{requested: '', assigned: ''} def:{{{node dense_23_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_23_2/bias, dense_23_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 03:10:55.633021: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_212_2/lstm_cell_656/recurrent_kernel/v/Assign' id:330913 op device:{requested: '', assigned: ''} def:{{{node lstm_212_2/lstm_cell_656/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_212_2/lstm_cell_656/recurrent_kernel/v, lstm_212_2/lstm_cell_656/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31735 samples, validate on 3538 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:11:14.339331: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:12:39.266204: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_25_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:13:03.020658: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_35/mul' id:329789 op device:{requested: '', assigned: ''} def:{{{node loss_35/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_35/mul/x, loss_35/dense_23_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40335, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 54s 2ms/sample - loss: 1.4215 - val_loss: 1.4033\n",
      "Epoch 2/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4168\n",
      "Epoch 2: val_loss improved from 1.40335 to 1.39742, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 20s 617us/sample - loss: 1.4168 - val_loss: 1.3974\n",
      "Epoch 3/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4189\n",
      "Epoch 3: val_loss improved from 1.39742 to 1.39095, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 20s 617us/sample - loss: 1.4189 - val_loss: 1.3909\n",
      "Epoch 4/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4153\n",
      "Epoch 4: val_loss did not improve from 1.39095\n",
      "31735/31735 [==============================] - 21s 660us/sample - loss: 1.4153 - val_loss: 1.3983\n",
      "Epoch 5/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4165\n",
      "Epoch 5: val_loss improved from 1.39095 to 1.38887, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 682us/sample - loss: 1.4165 - val_loss: 1.3889\n",
      "Epoch 6/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 6: val_loss improved from 1.38887 to 1.38664, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 21s 650us/sample - loss: 1.4117 - val_loss: 1.3866\n",
      "Epoch 7/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4091\n",
      "Epoch 7: val_loss improved from 1.38664 to 1.38360, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 22s 680us/sample - loss: 1.4091 - val_loss: 1.3836\n",
      "Epoch 8/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4088\n",
      "Epoch 8: val_loss did not improve from 1.38360\n",
      "31735/31735 [==============================] - 20s 629us/sample - loss: 1.4088 - val_loss: 1.3886\n",
      "Epoch 9/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 9: val_loss did not improve from 1.38360\n",
      "31735/31735 [==============================] - 21s 652us/sample - loss: 1.4063 - val_loss: 1.3961\n",
      "Epoch 10/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4062\n",
      "Epoch 10: val_loss did not improve from 1.38360\n",
      "31735/31735 [==============================] - 22s 695us/sample - loss: 1.4062 - val_loss: 1.3938\n",
      "Epoch 11/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 11: val_loss did not improve from 1.38360\n",
      "31735/31735 [==============================] - 22s 692us/sample - loss: 1.4042 - val_loss: 1.3872\n",
      "Epoch 12/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4025\n",
      "Epoch 12: val_loss did not improve from 1.38360\n",
      "31735/31735 [==============================] - 20s 638us/sample - loss: 1.4025 - val_loss: 1.3891\n",
      "Epoch 13/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4009\n",
      "Epoch 13: val_loss improved from 1.38360 to 1.38126, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_35.h5\n",
      "31735/31735 [==============================] - 20s 617us/sample - loss: 1.4009 - val_loss: 1.3813\n",
      "Epoch 14/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.4005\n",
      "Epoch 14: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 21s 667us/sample - loss: 1.4005 - val_loss: 1.3841\n",
      "Epoch 15/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 15: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 22s 693us/sample - loss: 1.3991 - val_loss: 1.3854\n",
      "Epoch 16/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3964\n",
      "Epoch 16: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 22s 679us/sample - loss: 1.3964 - val_loss: 1.3964\n",
      "Epoch 17/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3979\n",
      "Epoch 17: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 22s 693us/sample - loss: 1.3979 - val_loss: 1.3830\n",
      "Epoch 18/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3950\n",
      "Epoch 18: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 22s 690us/sample - loss: 1.3950 - val_loss: 1.3837\n",
      "Epoch 19/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3957\n",
      "Epoch 19: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 21s 668us/sample - loss: 1.3957 - val_loss: 1.3844\n",
      "Epoch 20/20\n",
      "31735/31735 [==============================] - ETA: 0s - loss: 1.3956\n",
      "Epoch 20: val_loss did not improve from 1.38126\n",
      "31735/31735 [==============================] - 20s 626us/sample - loss: 1.3956 - val_loss: 1.3837\n",
      "35489\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:20:22.740589: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_231/lstm_cell_675/bias/Assign' id:343784 op device:{requested: '', assigned: ''} def:{{{node lstm_231/lstm_cell_675/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_231/lstm_cell_675/bias, lstm_231/lstm_cell_675/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 03:20:31.677968: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_1' id:345888 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 03:20:38.884325: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_6/stack_2' id:345889 op device:{requested: '', assigned: ''} def:{{{node strided_slice_6/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31927, 95)\n",
      "Train on 31927 samples, validate on 3562 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:20:57.738475: W tensorflow/c/c_api.cc:304] Operation '{name:'training_36/Adam/lstm_255/lstm_cell_699/bias/v/Assign' id:359794 op device:{requested: '', assigned: ''} def:{{{node training_36/Adam/lstm_255/lstm_cell_699/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_36/Adam/lstm_255/lstm_cell_699/bias/v, training_36/Adam/lstm_255/lstm_cell_699/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:22:27.605091: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 3.0270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-24 03:22:49.612469: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_37/mul' id:348729 op device:{requested: '', assigned: ''} def:{{{node loss_37/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_37/mul/x, loss_37/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.81718, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 101s 3ms/sample - loss: 3.0270 - val_loss: 1.8172\n",
      "Epoch 2/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.7250\n",
      "Epoch 2: val_loss improved from 1.81718 to 1.56421, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.7250 - val_loss: 1.5642\n",
      "Epoch 3/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5894\n",
      "Epoch 3: val_loss improved from 1.56421 to 1.51464, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 622us/sample - loss: 1.5894 - val_loss: 1.5146\n",
      "Epoch 4/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5467\n",
      "Epoch 4: val_loss improved from 1.51464 to 1.48757, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 622us/sample - loss: 1.5467 - val_loss: 1.4876\n",
      "Epoch 5/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5272\n",
      "Epoch 5: val_loss improved from 1.48757 to 1.47773, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 621us/sample - loss: 1.5272 - val_loss: 1.4777\n",
      "Epoch 6/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5126\n",
      "Epoch 6: val_loss improved from 1.47773 to 1.46223, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 633us/sample - loss: 1.5126 - val_loss: 1.4622\n",
      "Epoch 7/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 7: val_loss improved from 1.46223 to 1.45418, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 622us/sample - loss: 1.5028 - val_loss: 1.4542\n",
      "Epoch 8/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4914\n",
      "Epoch 8: val_loss improved from 1.45418 to 1.44065, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 635us/sample - loss: 1.4914 - val_loss: 1.4407\n",
      "Epoch 9/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4843\n",
      "Epoch 9: val_loss did not improve from 1.44065\n",
      "31927/31927 [==============================] - 20s 623us/sample - loss: 1.4843 - val_loss: 1.4465\n",
      "Epoch 10/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4806\n",
      "Epoch 10: val_loss improved from 1.44065 to 1.43869, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 625us/sample - loss: 1.4806 - val_loss: 1.4387\n",
      "Epoch 11/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 11: val_loss improved from 1.43869 to 1.43096, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 626us/sample - loss: 1.4794 - val_loss: 1.4310\n",
      "Epoch 12/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4746\n",
      "Epoch 12: val_loss improved from 1.43096 to 1.42271, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 623us/sample - loss: 1.4746 - val_loss: 1.4227\n",
      "Epoch 13/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4697\n",
      "Epoch 13: val_loss did not improve from 1.42271\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.4697 - val_loss: 1.4299\n",
      "Epoch 14/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4857\n",
      "Epoch 14: val_loss did not improve from 1.42271\n",
      "31927/31927 [==============================] - 20s 615us/sample - loss: 1.4857 - val_loss: 1.4262\n",
      "Epoch 15/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4721\n",
      "Epoch 15: val_loss did not improve from 1.42271\n",
      "31927/31927 [==============================] - 20s 615us/sample - loss: 1.4721 - val_loss: 1.4255\n",
      "Epoch 16/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4738\n",
      "Epoch 16: val_loss improved from 1.42271 to 1.41894, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.4738 - val_loss: 1.4189\n",
      "Epoch 17/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4680\n",
      "Epoch 17: val_loss did not improve from 1.41894\n",
      "31927/31927 [==============================] - 23s 719us/sample - loss: 1.4680 - val_loss: 1.4261\n",
      "Epoch 18/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4600\n",
      "Epoch 18: val_loss did not improve from 1.41894\n",
      "31927/31927 [==============================] - 23s 714us/sample - loss: 1.4600 - val_loss: 1.4232\n",
      "Epoch 19/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4630\n",
      "Epoch 19: val_loss did not improve from 1.41894\n",
      "31927/31927 [==============================] - 23s 714us/sample - loss: 1.4630 - val_loss: 1.4199\n",
      "Epoch 20/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4547\n",
      "Epoch 20: val_loss improved from 1.41894 to 1.41622, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 723us/sample - loss: 1.4547 - val_loss: 1.4162\n",
      "Epoch 21/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4503\n",
      "Epoch 21: val_loss improved from 1.41622 to 1.41181, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 721us/sample - loss: 1.4503 - val_loss: 1.4118\n",
      "Epoch 22/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4597\n",
      "Epoch 22: val_loss did not improve from 1.41181\n",
      "31927/31927 [==============================] - 23s 713us/sample - loss: 1.4597 - val_loss: 1.4130\n",
      "Epoch 23/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4458\n",
      "Epoch 23: val_loss did not improve from 1.41181\n",
      "31927/31927 [==============================] - 23s 707us/sample - loss: 1.4458 - val_loss: 1.4129\n",
      "Epoch 24/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4413\n",
      "Epoch 24: val_loss improved from 1.41181 to 1.40923, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 715us/sample - loss: 1.4413 - val_loss: 1.4092\n",
      "Epoch 25/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 25: val_loss did not improve from 1.40923\n",
      "31927/31927 [==============================] - 23s 721us/sample - loss: 1.4412 - val_loss: 1.4097\n",
      "Epoch 26/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4377\n",
      "Epoch 26: val_loss improved from 1.40923 to 1.40198, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 721us/sample - loss: 1.4377 - val_loss: 1.4020\n",
      "Epoch 27/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4320\n",
      "Epoch 27: val_loss did not improve from 1.40198\n",
      "31927/31927 [==============================] - 22s 681us/sample - loss: 1.4320 - val_loss: 1.4182\n",
      "Epoch 28/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4299\n",
      "Epoch 28: val_loss did not improve from 1.40198\n",
      "31927/31927 [==============================] - 23s 712us/sample - loss: 1.4299 - val_loss: 1.4048\n",
      "Epoch 29/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4279\n",
      "Epoch 29: val_loss improved from 1.40198 to 1.40059, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 22s 700us/sample - loss: 1.4279 - val_loss: 1.4006\n",
      "Epoch 30/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 30: val_loss did not improve from 1.40059\n",
      "31927/31927 [==============================] - 20s 642us/sample - loss: 1.4255 - val_loss: 1.4013\n",
      "Epoch 31/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4238\n",
      "Epoch 31: val_loss improved from 1.40059 to 1.39974, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 720us/sample - loss: 1.4238 - val_loss: 1.3997\n",
      "Epoch 32/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 32: val_loss did not improve from 1.39974\n",
      "31927/31927 [==============================] - 23s 721us/sample - loss: 1.4211 - val_loss: 1.4090\n",
      "Epoch 33/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4182\n",
      "Epoch 33: val_loss did not improve from 1.39974\n",
      "31927/31927 [==============================] - 22s 698us/sample - loss: 1.4182 - val_loss: 1.4025\n",
      "Epoch 34/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4160\n",
      "Epoch 34: val_loss improved from 1.39974 to 1.39836, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 21s 644us/sample - loss: 1.4160 - val_loss: 1.3984\n",
      "Epoch 35/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 35: val_loss did not improve from 1.39836\n",
      "31927/31927 [==============================] - 23s 708us/sample - loss: 1.4145 - val_loss: 1.4001\n",
      "Epoch 36/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4134\n",
      "Epoch 36: val_loss improved from 1.39836 to 1.39818, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 715us/sample - loss: 1.4134 - val_loss: 1.3982\n",
      "Epoch 37/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4136\n",
      "Epoch 37: val_loss did not improve from 1.39818\n",
      "31927/31927 [==============================] - 23s 708us/sample - loss: 1.4136 - val_loss: 1.4037\n",
      "Epoch 38/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4104\n",
      "Epoch 38: val_loss did not improve from 1.39818\n",
      "31927/31927 [==============================] - 23s 712us/sample - loss: 1.4104 - val_loss: 1.4002\n",
      "Epoch 39/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4080\n",
      "Epoch 39: val_loss improved from 1.39818 to 1.39058, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 21s 670us/sample - loss: 1.4080 - val_loss: 1.3906\n",
      "Epoch 40/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4075\n",
      "Epoch 40: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 21s 662us/sample - loss: 1.4075 - val_loss: 1.4027\n",
      "Epoch 41/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 41: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 23s 717us/sample - loss: 1.4058 - val_loss: 1.3939\n",
      "Epoch 42/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 42: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 23s 712us/sample - loss: 1.4051 - val_loss: 1.3911\n",
      "Epoch 43/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4061\n",
      "Epoch 43: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 22s 692us/sample - loss: 1.4061 - val_loss: 1.3992\n",
      "Epoch 44/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4054\n",
      "Epoch 44: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 21s 655us/sample - loss: 1.4054 - val_loss: 1.3909\n",
      "Epoch 45/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4023\n",
      "Epoch 45: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 20s 633us/sample - loss: 1.4023 - val_loss: 1.3944\n",
      "Epoch 46/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3988\n",
      "Epoch 46: val_loss did not improve from 1.39058\n",
      "31927/31927 [==============================] - 20s 635us/sample - loss: 1.3988 - val_loss: 1.3906\n",
      "Epoch 47/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 47: val_loss improved from 1.39058 to 1.38546, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 21s 645us/sample - loss: 1.3975 - val_loss: 1.3855\n",
      "Epoch 48/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3985\n",
      "Epoch 48: val_loss improved from 1.38546 to 1.38366, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_36.h5\n",
      "31927/31927 [==============================] - 21s 645us/sample - loss: 1.3985 - val_loss: 1.3837\n",
      "Epoch 49/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3948\n",
      "Epoch 49: val_loss did not improve from 1.38366\n",
      "31927/31927 [==============================] - 20s 642us/sample - loss: 1.3948 - val_loss: 1.3890\n",
      "Epoch 50/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 50: val_loss did not improve from 1.38366\n",
      "31927/31927 [==============================] - 20s 641us/sample - loss: 1.3953 - val_loss: 1.3954\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:41:45.629580: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_250_1/lstm_cell_731/kernel/Assign' id:365374 op device:{requested: '', assigned: ''} def:{{{node lstm_250_1/lstm_cell_731/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_250_1/lstm_cell_731/kernel, lstm_250_1/lstm_cell_731/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 03:42:04.234034: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_234_1/lstm_cell_715/kernel/v/Assign' id:368327 op device:{requested: '', assigned: ''} def:{{{node lstm_234_1/lstm_cell_715/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_234_1/lstm_cell_715/kernel/v, lstm_234_1/lstm_cell_715/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-24 03:42:24.029738: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_34_1/cond/Merge' id:366843 op device:{requested: '', assigned: ''} def:{{{node dropout_34_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_34_1/cond/Identity, dropout_34_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1512)\n",
      "(1514, 1512)\n",
      "(1644, 1512)\n",
      "(1764, 1512)\n",
      "(1836, 1512)\n",
      "(1699, 1512)\n",
      "(1369, 1512)\n",
      "(1778, 1512)\n",
      "(1631, 1512)\n",
      "(1692, 1512)\n",
      "(1550, 1512)\n",
      "(1920, 1512)\n",
      "(1739, 1512)\n",
      "(1788, 1512)\n",
      "(1812, 1512)\n",
      "(1788, 1512)\n",
      "(1788, 1512)\n",
      "(934, 1512)\n",
      "(1584, 1512)\n",
      "{1: 4.059966953003214, 2: 1.8508067202334835, 4: 4.345351955935531, 5: 8.982971560478104, 6: 10.0, 8: 4.53175652894977, 9: 1.5564740295182804, 10: 5.766047632027088, 11: 3.1109876860756613, 12: 4.342711854531791, 13: 5.474500360075416, 17: 4.282871588457624, 19: 4.646990146647459, 21: 5.471236308609359, 22: 2.4484716159177498, 25: 3.738248545302094, 26: 3.345958743419224, 27: 1.0, 28: 4.51263357736563}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2920137/1660627543.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31927 samples, validate on 3562 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:47:48.450684: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 7.8202\n",
      "Epoch 1: val_loss improved from inf to 1.43110, saving model to ./checkpoints/unknown_person_few_shot_p29_36.h5\n",
      "31927/31927 [==============================] - 57s 2ms/sample - loss: 7.8202 - val_loss: 1.4311\n",
      "Epoch 2/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5748\n",
      "Epoch 2: val_loss improved from 1.43110 to 1.41164, saving model to ./checkpoints/unknown_person_few_shot_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 720us/sample - loss: 7.5748 - val_loss: 1.4116\n",
      "Epoch 3/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4962\n",
      "Epoch 3: val_loss improved from 1.41164 to 1.39991, saving model to ./checkpoints/unknown_person_few_shot_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 723us/sample - loss: 7.4962 - val_loss: 1.3999\n",
      "Epoch 4/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4888\n",
      "Epoch 4: val_loss did not improve from 1.39991\n",
      "31927/31927 [==============================] - 23s 711us/sample - loss: 7.4888 - val_loss: 1.4045\n",
      "Epoch 5/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4544\n",
      "Epoch 5: val_loss improved from 1.39991 to 1.38660, saving model to ./checkpoints/unknown_person_few_shot_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 724us/sample - loss: 7.4544 - val_loss: 1.3866\n",
      "Epoch 6/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4461\n",
      "Epoch 6: val_loss did not improve from 1.38660\n",
      "31927/31927 [==============================] - 22s 692us/sample - loss: 7.4461 - val_loss: 1.3905\n",
      "Epoch 7/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3779\n",
      "Epoch 7: val_loss improved from 1.38660 to 1.37811, saving model to ./checkpoints/unknown_person_few_shot_p29_36.h5\n",
      "31927/31927 [==============================] - 22s 694us/sample - loss: 7.3779 - val_loss: 1.3781\n",
      "Epoch 8/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3658\n",
      "Epoch 8: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 20s 638us/sample - loss: 7.3658 - val_loss: 1.3953\n",
      "Epoch 9/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3596\n",
      "Epoch 9: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 20s 631us/sample - loss: 7.3596 - val_loss: 1.3827\n",
      "Epoch 10/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3543\n",
      "Epoch 10: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 20s 639us/sample - loss: 7.3543 - val_loss: 1.3943\n",
      "Epoch 11/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3158\n",
      "Epoch 11: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 21s 671us/sample - loss: 7.3158 - val_loss: 1.3929\n",
      "Epoch 12/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3197\n",
      "Epoch 12: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 23s 717us/sample - loss: 7.3197 - val_loss: 1.3826\n",
      "Epoch 13/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3096\n",
      "Epoch 13: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 23s 736us/sample - loss: 7.3096 - val_loss: 1.4077\n",
      "Epoch 14/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.2905\n",
      "Epoch 14: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 23s 724us/sample - loss: 7.2905 - val_loss: 1.3940\n",
      "Epoch 15/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.3080\n",
      "Epoch 15: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 22s 696us/sample - loss: 7.3080 - val_loss: 1.3836\n",
      "Epoch 16/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.2745\n",
      "Epoch 16: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 23s 723us/sample - loss: 7.2745 - val_loss: 1.3982\n",
      "Epoch 17/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.2608\n",
      "Epoch 17: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 22s 689us/sample - loss: 7.2608 - val_loss: 1.3904\n",
      "Epoch 18/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.2244\n",
      "Epoch 18: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 21s 661us/sample - loss: 7.2244 - val_loss: 1.3871\n",
      "Epoch 19/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.2571\n",
      "Epoch 19: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 23s 728us/sample - loss: 7.2571 - val_loss: 1.3860\n",
      "Epoch 20/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.2415\n",
      "Epoch 20: val_loss did not improve from 1.37811\n",
      "31927/31927 [==============================] - 23s 720us/sample - loss: 7.2415 - val_loss: 1.3911\n",
      "WARNING:tensorflow:Layer lstm_222 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_223 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_224 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_225 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_226 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_227 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_228 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_229 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_230 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_231 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_232 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_233 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_234 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_235 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_236 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_237 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_238 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_239 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_240 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_241 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_242 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_243 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_244 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_245 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_246 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_247 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_248 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_249 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_250 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_251 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_252 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_253 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_254 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_255 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_256 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_257 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_258 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:55:55.646543: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_258_2/lstm_cell_776/bias/Assign' id:386081 op device:{requested: '', assigned: ''} def:{{{node lstm_258_2/lstm_cell_776/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_258_2/lstm_cell_776/bias, lstm_258_2/lstm_cell_776/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 03:56:15.039785: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_27_2/kernel/m/Assign' id:386892 op device:{requested: '', assigned: ''} def:{{{node conv2d_27_2/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_27_2/kernel/m, conv2d_27_2/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31927 samples, validate on 3562 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:56:36.981940: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:58:17.692523: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_30_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 03:58:43.060389: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_41/mul' id:386831 op device:{requested: '', assigned: ''} def:{{{node loss_41/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_41/mul/x, loss_41/dense_27_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38191, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_36.h5\n",
      "31927/31927 [==============================] - 61s 2ms/sample - loss: 1.3997 - val_loss: 1.3819\n",
      "Epoch 2/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3941\n",
      "Epoch 2: val_loss did not improve from 1.38191\n",
      "31927/31927 [==============================] - 23s 723us/sample - loss: 1.3941 - val_loss: 1.3891\n",
      "Epoch 3/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3904\n",
      "Epoch 3: val_loss did not improve from 1.38191\n",
      "31927/31927 [==============================] - 23s 720us/sample - loss: 1.3904 - val_loss: 1.3956\n",
      "Epoch 4/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 4: val_loss did not improve from 1.38191\n",
      "31927/31927 [==============================] - 23s 720us/sample - loss: 1.3939 - val_loss: 1.3846\n",
      "Epoch 5/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3885\n",
      "Epoch 5: val_loss improved from 1.38191 to 1.37865, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 728us/sample - loss: 1.3885 - val_loss: 1.3786\n",
      "Epoch 6/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3881\n",
      "Epoch 6: val_loss did not improve from 1.37865\n",
      "31927/31927 [==============================] - 23s 715us/sample - loss: 1.3881 - val_loss: 1.3849\n",
      "Epoch 7/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3871\n",
      "Epoch 7: val_loss did not improve from 1.37865\n",
      "31927/31927 [==============================] - 23s 714us/sample - loss: 1.3871 - val_loss: 1.3828\n",
      "Epoch 8/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 8: val_loss did not improve from 1.37865\n",
      "31927/31927 [==============================] - 23s 713us/sample - loss: 1.3896 - val_loss: 1.3834\n",
      "Epoch 9/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3845\n",
      "Epoch 9: val_loss did not improve from 1.37865\n",
      "31927/31927 [==============================] - 23s 711us/sample - loss: 1.3845 - val_loss: 1.3840\n",
      "Epoch 10/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3847\n",
      "Epoch 10: val_loss did not improve from 1.37865\n",
      "31927/31927 [==============================] - 23s 712us/sample - loss: 1.3847 - val_loss: 1.3789\n",
      "Epoch 11/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3836\n",
      "Epoch 11: val_loss improved from 1.37865 to 1.37443, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_36.h5\n",
      "31927/31927 [==============================] - 23s 721us/sample - loss: 1.3836 - val_loss: 1.3744\n",
      "Epoch 12/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3819\n",
      "Epoch 12: val_loss did not improve from 1.37443\n",
      "31927/31927 [==============================] - 20s 631us/sample - loss: 1.3819 - val_loss: 1.3803\n",
      "Epoch 13/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3806\n",
      "Epoch 13: val_loss did not improve from 1.37443\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.3806 - val_loss: 1.3800\n",
      "Epoch 14/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3799\n",
      "Epoch 14: val_loss did not improve from 1.37443\n",
      "31927/31927 [==============================] - 20s 626us/sample - loss: 1.3799 - val_loss: 1.3789\n",
      "Epoch 15/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3766\n",
      "Epoch 15: val_loss did not improve from 1.37443\n",
      "31927/31927 [==============================] - 20s 631us/sample - loss: 1.3766 - val_loss: 1.3806\n",
      "Epoch 16/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3754\n",
      "Epoch 16: val_loss did not improve from 1.37443\n",
      "31927/31927 [==============================] - 20s 634us/sample - loss: 1.3754 - val_loss: 1.3758\n",
      "Epoch 17/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3751\n",
      "Epoch 17: val_loss improved from 1.37443 to 1.37438, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_36.h5\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.3751 - val_loss: 1.3744\n",
      "Epoch 18/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3735\n",
      "Epoch 18: val_loss did not improve from 1.37438\n",
      "31927/31927 [==============================] - 20s 627us/sample - loss: 1.3735 - val_loss: 1.3769\n",
      "Epoch 19/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3726\n",
      "Epoch 19: val_loss did not improve from 1.37438\n",
      "31927/31927 [==============================] - 22s 680us/sample - loss: 1.3726 - val_loss: 1.3817\n",
      "Epoch 20/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3741\n",
      "Epoch 20: val_loss did not improve from 1.37438\n",
      "31927/31927 [==============================] - 22s 675us/sample - loss: 1.3741 - val_loss: 1.3791\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:06:19.244869: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_263/lstm_cell_781/bias/Assign' id:400001 op device:{requested: '', assigned: ''} def:{{{node lstm_263/lstm_cell_781/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_263/lstm_cell_781/bias, lstm_263/lstm_cell_781/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:06:29.851345: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_1' id:402930 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:06:38.396529: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_7/stack_2' id:402931 op device:{requested: '', assigned: ''} def:{{{node strided_slice_7/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31927, 95)\n",
      "Train on 31927 samples, validate on 3562 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:06:59.754917: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_28/kernel/Assign' id:403012 op device:{requested: '', assigned: ''} def:{{{node conv2d_28/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_28/kernel, conv2d_28/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:08:44.815693: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 3.3739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:09:06.495611: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_43/mul' id:405771 op device:{requested: '', assigned: ''} def:{{{node loss_43/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_43/mul/x, loss_43/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.01649, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 114s 4ms/sample - loss: 3.3739 - val_loss: 2.0165\n",
      "Epoch 2/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.8224\n",
      "Epoch 2: val_loss improved from 2.01649 to 1.57843, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.8224 - val_loss: 1.5784\n",
      "Epoch 3/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5993\n",
      "Epoch 3: val_loss improved from 1.57843 to 1.50750, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 620us/sample - loss: 1.5993 - val_loss: 1.5075\n",
      "Epoch 4/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5466\n",
      "Epoch 4: val_loss improved from 1.50750 to 1.47597, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 623us/sample - loss: 1.5466 - val_loss: 1.4760\n",
      "Epoch 5/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5240\n",
      "Epoch 5: val_loss improved from 1.47597 to 1.45993, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 22s 689us/sample - loss: 1.5240 - val_loss: 1.4599\n",
      "Epoch 6/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5120\n",
      "Epoch 6: val_loss improved from 1.45993 to 1.45047, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 716us/sample - loss: 1.5120 - val_loss: 1.4505\n",
      "Epoch 7/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4997\n",
      "Epoch 7: val_loss improved from 1.45047 to 1.44711, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 715us/sample - loss: 1.4997 - val_loss: 1.4471\n",
      "Epoch 8/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4992\n",
      "Epoch 8: val_loss improved from 1.44711 to 1.44384, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.4992 - val_loss: 1.4438\n",
      "Epoch 9/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4938\n",
      "Epoch 9: val_loss improved from 1.44384 to 1.44034, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 22s 694us/sample - loss: 1.4938 - val_loss: 1.4403\n",
      "Epoch 10/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4899\n",
      "Epoch 10: val_loss did not improve from 1.44034\n",
      "31927/31927 [==============================] - 21s 656us/sample - loss: 1.4899 - val_loss: 1.4430\n",
      "Epoch 11/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4838\n",
      "Epoch 11: val_loss improved from 1.44034 to 1.43246, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 720us/sample - loss: 1.4838 - val_loss: 1.4325\n",
      "Epoch 12/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4814\n",
      "Epoch 12: val_loss improved from 1.43246 to 1.43185, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 718us/sample - loss: 1.4814 - val_loss: 1.4318\n",
      "Epoch 13/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5108\n",
      "Epoch 13: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 23s 706us/sample - loss: 1.5108 - val_loss: 1.4366\n",
      "Epoch 14/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5016\n",
      "Epoch 14: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 21s 653us/sample - loss: 1.5016 - val_loss: 1.4369\n",
      "Epoch 15/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5849\n",
      "Epoch 15: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 23s 712us/sample - loss: 1.5849 - val_loss: 1.4408\n",
      "Epoch 16/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5586\n",
      "Epoch 16: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 23s 712us/sample - loss: 1.5586 - val_loss: 1.4551\n",
      "Epoch 17/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5064\n",
      "Epoch 17: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 21s 659us/sample - loss: 1.5064 - val_loss: 1.4338\n",
      "Epoch 18/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5431\n",
      "Epoch 18: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 21s 650us/sample - loss: 1.5431 - val_loss: 1.4615\n",
      "Epoch 19/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4894\n",
      "Epoch 19: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 23s 710us/sample - loss: 1.4894 - val_loss: 1.4402\n",
      "Epoch 20/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5162\n",
      "Epoch 20: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 23s 707us/sample - loss: 1.5162 - val_loss: 1.4358\n",
      "Epoch 21/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5178\n",
      "Epoch 21: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 21s 650us/sample - loss: 1.5178 - val_loss: 1.4433\n",
      "Epoch 22/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4913\n",
      "Epoch 22: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 20s 630us/sample - loss: 1.4913 - val_loss: 1.4325\n",
      "Epoch 23/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4847\n",
      "Epoch 23: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 23s 710us/sample - loss: 1.4847 - val_loss: 1.4332\n",
      "Epoch 24/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4881\n",
      "Epoch 24: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 21s 659us/sample - loss: 1.4881 - val_loss: 1.4325\n",
      "Epoch 25/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4701\n",
      "Epoch 25: val_loss did not improve from 1.43185\n",
      "31927/31927 [==============================] - 20s 633us/sample - loss: 1.4701 - val_loss: 1.4353\n",
      "Epoch 26/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4634\n",
      "Epoch 26: val_loss improved from 1.43185 to 1.42185, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 21s 666us/sample - loss: 1.4634 - val_loss: 1.4218\n",
      "Epoch 27/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 27: val_loss did not improve from 1.42185\n",
      "31927/31927 [==============================] - 22s 700us/sample - loss: 1.4623 - val_loss: 1.4270\n",
      "Epoch 28/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4584\n",
      "Epoch 28: val_loss improved from 1.42185 to 1.41741, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.4584 - val_loss: 1.4174\n",
      "Epoch 29/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4602\n",
      "Epoch 29: val_loss did not improve from 1.41741\n",
      "31927/31927 [==============================] - 20s 621us/sample - loss: 1.4602 - val_loss: 1.4191\n",
      "Epoch 30/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4563\n",
      "Epoch 30: val_loss did not improve from 1.41741\n",
      "31927/31927 [==============================] - 20s 617us/sample - loss: 1.4563 - val_loss: 1.4218\n",
      "Epoch 31/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 31: val_loss did not improve from 1.41741\n",
      "31927/31927 [==============================] - 20s 622us/sample - loss: 1.4525 - val_loss: 1.4198\n",
      "Epoch 32/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4500\n",
      "Epoch 32: val_loss improved from 1.41741 to 1.41694, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.4500 - val_loss: 1.4169\n",
      "Epoch 33/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4506\n",
      "Epoch 33: val_loss improved from 1.41694 to 1.41375, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 21s 665us/sample - loss: 1.4506 - val_loss: 1.4137\n",
      "Epoch 34/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4482\n",
      "Epoch 34: val_loss improved from 1.41375 to 1.41035, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 709us/sample - loss: 1.4482 - val_loss: 1.4103\n",
      "Epoch 35/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4456\n",
      "Epoch 35: val_loss did not improve from 1.41035\n",
      "31927/31927 [==============================] - 23s 716us/sample - loss: 1.4456 - val_loss: 1.4141\n",
      "Epoch 36/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4424\n",
      "Epoch 36: val_loss did not improve from 1.41035\n",
      "31927/31927 [==============================] - 20s 635us/sample - loss: 1.4424 - val_loss: 1.4171\n",
      "Epoch 37/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4404\n",
      "Epoch 37: val_loss did not improve from 1.41035\n",
      "31927/31927 [==============================] - 21s 649us/sample - loss: 1.4404 - val_loss: 1.4105\n",
      "Epoch 38/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4402\n",
      "Epoch 38: val_loss improved from 1.41035 to 1.40639, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 718us/sample - loss: 1.4402 - val_loss: 1.4064\n",
      "Epoch 39/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 39: val_loss did not improve from 1.40639\n",
      "31927/31927 [==============================] - 23s 713us/sample - loss: 1.4383 - val_loss: 1.4126\n",
      "Epoch 40/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4361\n",
      "Epoch 40: val_loss did not improve from 1.40639\n",
      "31927/31927 [==============================] - 23s 715us/sample - loss: 1.4361 - val_loss: 1.4077\n",
      "Epoch 41/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4331\n",
      "Epoch 41: val_loss improved from 1.40639 to 1.40517, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 719us/sample - loss: 1.4331 - val_loss: 1.4052\n",
      "Epoch 42/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4330\n",
      "Epoch 42: val_loss improved from 1.40517 to 1.40456, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 724us/sample - loss: 1.4330 - val_loss: 1.4046\n",
      "Epoch 43/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4323\n",
      "Epoch 43: val_loss did not improve from 1.40456\n",
      "31927/31927 [==============================] - 23s 714us/sample - loss: 1.4323 - val_loss: 1.4130\n",
      "Epoch 44/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4294\n",
      "Epoch 44: val_loss improved from 1.40456 to 1.40331, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 716us/sample - loss: 1.4294 - val_loss: 1.4033\n",
      "Epoch 45/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4268\n",
      "Epoch 45: val_loss improved from 1.40331 to 1.40306, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 723us/sample - loss: 1.4268 - val_loss: 1.4031\n",
      "Epoch 46/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4260\n",
      "Epoch 46: val_loss improved from 1.40306 to 1.39882, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 717us/sample - loss: 1.4260 - val_loss: 1.3988\n",
      "Epoch 47/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 47: val_loss did not improve from 1.39882\n",
      "31927/31927 [==============================] - 22s 674us/sample - loss: 1.4237 - val_loss: 1.3992\n",
      "Epoch 48/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 48: val_loss improved from 1.39882 to 1.39561, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 722us/sample - loss: 1.4206 - val_loss: 1.3956\n",
      "Epoch 49/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 49: val_loss improved from 1.39561 to 1.39342, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_37.h5\n",
      "31927/31927 [==============================] - 23s 711us/sample - loss: 1.4207 - val_loss: 1.3934\n",
      "Epoch 50/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 50: val_loss did not improve from 1.39342\n",
      "31927/31927 [==============================] - 23s 713us/sample - loss: 1.4206 - val_loss: 1.4017\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:28:32.031087: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_264_1/lstm_cell_819/recurrent_kernel/Assign' id:418754 op device:{requested: '', assigned: ''} def:{{{node lstm_264_1/lstm_cell_819/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_264_1/lstm_cell_819/recurrent_kernel, lstm_264_1/lstm_cell_819/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:28:53.252226: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_272_1/lstm_cell_827/bias/v/Assign' id:425394 op device:{requested: '', assigned: ''} def:{{{node lstm_272_1/lstm_cell_827/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_272_1/lstm_cell_827/bias/v, lstm_272_1/lstm_cell_827/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:29:14.450016: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_39_1/cond/Merge' id:423885 op device:{requested: '', assigned: ''} def:{{{node dropout_39_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_39_1/cond/Identity, dropout_39_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1512)\n",
      "(1514, 1512)\n",
      "(1644, 1512)\n",
      "(1764, 1512)\n",
      "(1836, 1512)\n",
      "(1699, 1512)\n",
      "(1369, 1512)\n",
      "(1778, 1512)\n",
      "(1631, 1512)\n",
      "(1692, 1512)\n",
      "(1550, 1512)\n",
      "(1920, 1512)\n",
      "(1739, 1512)\n",
      "(1788, 1512)\n",
      "(1812, 1512)\n",
      "(1788, 1512)\n",
      "(1788, 1512)\n",
      "(934, 1512)\n",
      "(1584, 1512)\n",
      "{1: 4.894264165914148, 2: 1.0, 4: 4.180124913476226, 5: 9.30465463400797, 6: 10.0, 8: 4.913912523986809, 9: 1.5834305331527176, 10: 6.164344207575251, 11: 3.677982914890536, 12: 4.278784212742984, 13: 4.989641755412942, 17: 4.061908539445446, 19: 4.711901065520632, 21: 5.468971905524935, 22: 2.532293590398659, 25: 3.6463779398338243, 26: 3.454820664878356, 27: 1.361350214815065, 28: 4.500360228211597}\n",
      "Train on 31927 samples, validate on 3562 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:35:03.000864: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 7.9054\n",
      "Epoch 1: val_loss improved from inf to 1.40979, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 62s 2ms/sample - loss: 7.9054 - val_loss: 1.4098\n",
      "Epoch 2/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.7744\n",
      "Epoch 2: val_loss did not improve from 1.40979\n",
      "31927/31927 [==============================] - 22s 686us/sample - loss: 7.7744 - val_loss: 1.4107\n",
      "Epoch 3/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.7262\n",
      "Epoch 3: val_loss improved from 1.40979 to 1.39895, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 22s 699us/sample - loss: 7.7262 - val_loss: 1.3990\n",
      "Epoch 4/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.7402\n",
      "Epoch 4: val_loss did not improve from 1.39895\n",
      "31927/31927 [==============================] - 20s 619us/sample - loss: 7.7402 - val_loss: 1.4250\n",
      "Epoch 5/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.6384\n",
      "Epoch 5: val_loss did not improve from 1.39895\n",
      "31927/31927 [==============================] - 21s 650us/sample - loss: 7.6384 - val_loss: 1.4002\n",
      "Epoch 6/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.6092\n",
      "Epoch 6: val_loss did not improve from 1.39895\n",
      "31927/31927 [==============================] - 23s 726us/sample - loss: 7.6092 - val_loss: 1.4229\n",
      "Epoch 7/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5934\n",
      "Epoch 7: val_loss improved from 1.39895 to 1.39133, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 24s 737us/sample - loss: 7.5934 - val_loss: 1.3913\n",
      "Epoch 8/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.6320\n",
      "Epoch 8: val_loss did not improve from 1.39133\n",
      "31927/31927 [==============================] - 23s 727us/sample - loss: 7.6320 - val_loss: 1.4022\n",
      "Epoch 9/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5988\n",
      "Epoch 9: val_loss did not improve from 1.39133\n",
      "31927/31927 [==============================] - 23s 729us/sample - loss: 7.5988 - val_loss: 1.3918\n",
      "Epoch 10/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5833\n",
      "Epoch 10: val_loss did not improve from 1.39133\n",
      "31927/31927 [==============================] - 21s 658us/sample - loss: 7.5833 - val_loss: 1.3951\n",
      "Epoch 11/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5706\n",
      "Epoch 11: val_loss improved from 1.39133 to 1.38689, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 22s 689us/sample - loss: 7.5706 - val_loss: 1.3869\n",
      "Epoch 12/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5883\n",
      "Epoch 12: val_loss did not improve from 1.38689\n",
      "31927/31927 [==============================] - 20s 619us/sample - loss: 7.5883 - val_loss: 1.3973\n",
      "Epoch 13/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5680\n",
      "Epoch 13: val_loss did not improve from 1.38689\n",
      "31927/31927 [==============================] - 20s 620us/sample - loss: 7.5680 - val_loss: 1.3925\n",
      "Epoch 14/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5102\n",
      "Epoch 14: val_loss did not improve from 1.38689\n",
      "31927/31927 [==============================] - 21s 667us/sample - loss: 7.5102 - val_loss: 1.4029\n",
      "Epoch 15/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5409\n",
      "Epoch 15: val_loss did not improve from 1.38689\n",
      "31927/31927 [==============================] - 20s 642us/sample - loss: 7.5409 - val_loss: 1.4108\n",
      "Epoch 16/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5128\n",
      "Epoch 16: val_loss improved from 1.38689 to 1.38657, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 630us/sample - loss: 7.5128 - val_loss: 1.3866\n",
      "Epoch 17/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.5172\n",
      "Epoch 17: val_loss improved from 1.38657 to 1.38621, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 627us/sample - loss: 7.5172 - val_loss: 1.3862\n",
      "Epoch 18/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4980\n",
      "Epoch 18: val_loss did not improve from 1.38621\n",
      "31927/31927 [==============================] - 20s 616us/sample - loss: 7.4980 - val_loss: 1.4020\n",
      "Epoch 19/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4787\n",
      "Epoch 19: val_loss did not improve from 1.38621\n",
      "31927/31927 [==============================] - 20s 623us/sample - loss: 7.4787 - val_loss: 1.3917\n",
      "Epoch 20/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 7.4551\n",
      "Epoch 20: val_loss improved from 1.38621 to 1.38375, saving model to ./checkpoints/unknown_person_few_shot_p29_37.h5\n",
      "31927/31927 [==============================] - 22s 680us/sample - loss: 7.4551 - val_loss: 1.3837\n",
      "WARNING:tensorflow:Layer lstm_259 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_260 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_261 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_262 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_263 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_264 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_265 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_266 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_267 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_268 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_269 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_270 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_271 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_272 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_273 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_274 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_275 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_276 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_277 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_278 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_279 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_280 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_281 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_282 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_283 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_284 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_285 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_286 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_287 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_288 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_289 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_290 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_291 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_292 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_293 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_294 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_295 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:42:58.382852: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_276_2/lstm_cell_868/kernel/Assign' id:440052 op device:{requested: '', assigned: ''} def:{{{node lstm_276_2/lstm_cell_868/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_276_2/lstm_cell_868/kernel, lstm_276_2/lstm_cell_868/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:43:20.538246: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_279_2/lstm_cell_871/kernel/m/Assign' id:444244 op device:{requested: '', assigned: ''} def:{{{node lstm_279_2/lstm_cell_871/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_279_2/lstm_cell_871/kernel/m, lstm_279_2/lstm_cell_871/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31927 samples, validate on 3562 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:43:45.155259: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:45:39.550719: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_35_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:46:01.391943: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_47/mul' id:443873 op device:{requested: '', assigned: ''} def:{{{node loss_47/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_47/mul/x, loss_47/dense_31_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40299, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 61s 2ms/sample - loss: 1.4224 - val_loss: 1.4030\n",
      "Epoch 2/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4162\n",
      "Epoch 2: val_loss improved from 1.40299 to 1.38982, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 641us/sample - loss: 1.4162 - val_loss: 1.3898\n",
      "Epoch 3/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4194\n",
      "Epoch 3: val_loss did not improve from 1.38982\n",
      "31927/31927 [==============================] - 20s 625us/sample - loss: 1.4194 - val_loss: 1.3974\n",
      "Epoch 4/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 4: val_loss did not improve from 1.38982\n",
      "31927/31927 [==============================] - 20s 628us/sample - loss: 1.4141 - val_loss: 1.3930\n",
      "Epoch 5/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4129\n",
      "Epoch 5: val_loss did not improve from 1.38982\n",
      "31927/31927 [==============================] - 20s 628us/sample - loss: 1.4129 - val_loss: 1.4073\n",
      "Epoch 6/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4132\n",
      "Epoch 6: val_loss improved from 1.38982 to 1.38959, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 22s 686us/sample - loss: 1.4132 - val_loss: 1.3896\n",
      "Epoch 7/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 7: val_loss did not improve from 1.38959\n",
      "31927/31927 [==============================] - 22s 694us/sample - loss: 1.4126 - val_loss: 1.3999\n",
      "Epoch 8/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 8: val_loss did not improve from 1.38959\n",
      "31927/31927 [==============================] - 21s 643us/sample - loss: 1.4087 - val_loss: 1.4004\n",
      "Epoch 9/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4044\n",
      "Epoch 9: val_loss did not improve from 1.38959\n",
      "31927/31927 [==============================] - 20s 621us/sample - loss: 1.4044 - val_loss: 1.3945\n",
      "Epoch 10/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4038\n",
      "Epoch 10: val_loss did not improve from 1.38959\n",
      "31927/31927 [==============================] - 20s 621us/sample - loss: 1.4038 - val_loss: 1.3990\n",
      "Epoch 11/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 11: val_loss improved from 1.38959 to 1.38487, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 626us/sample - loss: 1.4049 - val_loss: 1.3849\n",
      "Epoch 12/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 12: val_loss did not improve from 1.38487\n",
      "31927/31927 [==============================] - 20s 619us/sample - loss: 1.4051 - val_loss: 1.3852\n",
      "Epoch 13/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4019\n",
      "Epoch 13: val_loss did not improve from 1.38487\n",
      "31927/31927 [==============================] - 20s 620us/sample - loss: 1.4019 - val_loss: 1.3903\n",
      "Epoch 14/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4023\n",
      "Epoch 14: val_loss improved from 1.38487 to 1.38293, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 630us/sample - loss: 1.4023 - val_loss: 1.3829\n",
      "Epoch 15/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 15: val_loss improved from 1.38293 to 1.38177, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 627us/sample - loss: 1.3984 - val_loss: 1.3818\n",
      "Epoch 16/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4013\n",
      "Epoch 16: val_loss did not improve from 1.38177\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.4013 - val_loss: 1.3886\n",
      "Epoch 17/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3970\n",
      "Epoch 17: val_loss did not improve from 1.38177\n",
      "31927/31927 [==============================] - 20s 620us/sample - loss: 1.3970 - val_loss: 1.3824\n",
      "Epoch 18/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3937\n",
      "Epoch 18: val_loss did not improve from 1.38177\n",
      "31927/31927 [==============================] - 20s 622us/sample - loss: 1.3937 - val_loss: 1.3886\n",
      "Epoch 19/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3932\n",
      "Epoch 19: val_loss improved from 1.38177 to 1.38034, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_37.h5\n",
      "31927/31927 [==============================] - 20s 625us/sample - loss: 1.3932 - val_loss: 1.3803\n",
      "Epoch 20/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3940\n",
      "Epoch 20: val_loss did not improve from 1.38034\n",
      "31927/31927 [==============================] - 20s 620us/sample - loss: 1.3940 - val_loss: 1.3887\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:53:13.243518: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_306/lstm_cell_898/recurrent_kernel/Assign' id:458024 op device:{requested: '', assigned: ''} def:{{{node lstm_306/lstm_cell_898/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_306/lstm_cell_898/recurrent_kernel, lstm_306/lstm_cell_898/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:53:25.722760: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_1' id:459972 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 04:53:35.795473: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_8/stack_2' id:459973 op device:{requested: '', assigned: ''} def:{{{node strided_slice_8/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(31927, 95)\n",
      "Train on 31927 samples, validate on 3562 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:54:00.155712: W tensorflow/c/c_api.cc:304] Operation '{name:'training_48/Adam/lstm_322/lstm_cell_914/bias/v/Assign' id:473773 op device:{requested: '', assigned: ''} def:{{{node training_48/Adam/lstm_322/lstm_cell_914/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_48/Adam/lstm_322/lstm_cell_914/bias/v, training_48/Adam/lstm_322/lstm_cell_914/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:56:00.372924: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 3.0199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 04:56:21.727678: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_49/mul' id:462813 op device:{requested: '', assigned: ''} def:{{{node loss_49/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_49/mul/x, loss_49/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.82210, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 131s 4ms/sample - loss: 3.0199 - val_loss: 1.8221\n",
      "Epoch 2/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.7542\n",
      "Epoch 2: val_loss improved from 1.82210 to 1.57029, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 630us/sample - loss: 1.7542 - val_loss: 1.5703\n",
      "Epoch 3/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5955\n",
      "Epoch 3: val_loss improved from 1.57029 to 1.50321, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 627us/sample - loss: 1.5955 - val_loss: 1.5032\n",
      "Epoch 4/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5474\n",
      "Epoch 4: val_loss improved from 1.50321 to 1.47911, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 622us/sample - loss: 1.5474 - val_loss: 1.4791\n",
      "Epoch 5/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5253\n",
      "Epoch 5: val_loss improved from 1.47911 to 1.47066, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 621us/sample - loss: 1.5253 - val_loss: 1.4707\n",
      "Epoch 6/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5096\n",
      "Epoch 6: val_loss improved from 1.47066 to 1.45501, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 23s 708us/sample - loss: 1.5096 - val_loss: 1.4550\n",
      "Epoch 7/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5022\n",
      "Epoch 7: val_loss improved from 1.45501 to 1.44833, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 23s 717us/sample - loss: 1.5022 - val_loss: 1.4483\n",
      "Epoch 8/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4963\n",
      "Epoch 8: val_loss improved from 1.44833 to 1.44341, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 23s 718us/sample - loss: 1.4963 - val_loss: 1.4434\n",
      "Epoch 9/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4907\n",
      "Epoch 9: val_loss improved from 1.44341 to 1.43999, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 21s 669us/sample - loss: 1.4907 - val_loss: 1.4400\n",
      "Epoch 10/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5018\n",
      "Epoch 10: val_loss improved from 1.43999 to 1.43894, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 22s 690us/sample - loss: 1.5018 - val_loss: 1.4389\n",
      "Epoch 11/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4940\n",
      "Epoch 11: val_loss did not improve from 1.43894\n",
      "31927/31927 [==============================] - 20s 627us/sample - loss: 1.4940 - val_loss: 1.4483\n",
      "Epoch 12/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4876\n",
      "Epoch 12: val_loss improved from 1.43894 to 1.43698, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 23s 714us/sample - loss: 1.4876 - val_loss: 1.4370\n",
      "Epoch 13/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5777\n",
      "Epoch 13: val_loss did not improve from 1.43698\n",
      "31927/31927 [==============================] - 23s 710us/sample - loss: 1.5777 - val_loss: 1.4482\n",
      "Epoch 14/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5268\n",
      "Epoch 14: val_loss did not improve from 1.43698\n",
      "31927/31927 [==============================] - 21s 670us/sample - loss: 1.5268 - val_loss: 1.4411\n",
      "Epoch 15/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4876\n",
      "Epoch 15: val_loss improved from 1.43698 to 1.43156, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 620us/sample - loss: 1.4876 - val_loss: 1.4316\n",
      "Epoch 16/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5015\n",
      "Epoch 16: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 20s 615us/sample - loss: 1.5015 - val_loss: 1.4320\n",
      "Epoch 17/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.6288\n",
      "Epoch 17: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 21s 672us/sample - loss: 1.6288 - val_loss: 1.4318\n",
      "Epoch 18/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.6518\n",
      "Epoch 18: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 21s 646us/sample - loss: 1.6518 - val_loss: 1.4647\n",
      "Epoch 19/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5254\n",
      "Epoch 19: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 19s 611us/sample - loss: 1.5254 - val_loss: 1.4506\n",
      "Epoch 20/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4928\n",
      "Epoch 20: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 20s 614us/sample - loss: 1.4928 - val_loss: 1.4349\n",
      "Epoch 21/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5613\n",
      "Epoch 21: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 20s 616us/sample - loss: 1.5613 - val_loss: 1.4520\n",
      "Epoch 22/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5479\n",
      "Epoch 22: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 20s 612us/sample - loss: 1.5479 - val_loss: 1.4395\n",
      "Epoch 23/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.5197\n",
      "Epoch 23: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 20s 612us/sample - loss: 1.5197 - val_loss: 1.4424\n",
      "Epoch 24/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4962\n",
      "Epoch 24: val_loss did not improve from 1.43156\n",
      "31927/31927 [==============================] - 19s 609us/sample - loss: 1.4962 - val_loss: 1.4385\n",
      "Epoch 25/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4848\n",
      "Epoch 25: val_loss improved from 1.43156 to 1.42687, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 634us/sample - loss: 1.4848 - val_loss: 1.4269\n",
      "Epoch 26/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4867\n",
      "Epoch 26: val_loss did not improve from 1.42687\n",
      "31927/31927 [==============================] - 20s 613us/sample - loss: 1.4867 - val_loss: 1.4307\n",
      "Epoch 27/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4744\n",
      "Epoch 27: val_loss improved from 1.42687 to 1.42611, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 617us/sample - loss: 1.4744 - val_loss: 1.4261\n",
      "Epoch 28/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4666\n",
      "Epoch 28: val_loss improved from 1.42611 to 1.42208, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 623us/sample - loss: 1.4666 - val_loss: 1.4221\n",
      "Epoch 29/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4652\n",
      "Epoch 29: val_loss did not improve from 1.42208\n",
      "31927/31927 [==============================] - 20s 613us/sample - loss: 1.4652 - val_loss: 1.4229\n",
      "Epoch 30/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4604\n",
      "Epoch 30: val_loss did not improve from 1.42208\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.4604 - val_loss: 1.4224\n",
      "Epoch 31/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4586\n",
      "Epoch 31: val_loss improved from 1.42208 to 1.41550, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.4586 - val_loss: 1.4155\n",
      "Epoch 32/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4571\n",
      "Epoch 32: val_loss did not improve from 1.41550\n",
      "31927/31927 [==============================] - 20s 618us/sample - loss: 1.4571 - val_loss: 1.4196\n",
      "Epoch 33/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4527\n",
      "Epoch 33: val_loss did not improve from 1.41550\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.4527 - val_loss: 1.4229\n",
      "Epoch 34/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4530\n",
      "Epoch 34: val_loss improved from 1.41550 to 1.41296, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 639us/sample - loss: 1.4530 - val_loss: 1.4130\n",
      "Epoch 35/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4492\n",
      "Epoch 35: val_loss improved from 1.41296 to 1.41121, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 630us/sample - loss: 1.4492 - val_loss: 1.4112\n",
      "Epoch 36/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4509\n",
      "Epoch 36: val_loss did not improve from 1.41121\n",
      "31927/31927 [==============================] - 20s 623us/sample - loss: 1.4509 - val_loss: 1.4163\n",
      "Epoch 37/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4445\n",
      "Epoch 37: val_loss did not improve from 1.41121\n",
      "31927/31927 [==============================] - 20s 626us/sample - loss: 1.4445 - val_loss: 1.4164\n",
      "Epoch 38/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4411\n",
      "Epoch 38: val_loss improved from 1.41121 to 1.40983, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.4411 - val_loss: 1.4098\n",
      "Epoch 39/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4392\n",
      "Epoch 39: val_loss improved from 1.40983 to 1.40908, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 21s 670us/sample - loss: 1.4392 - val_loss: 1.4091\n",
      "Epoch 40/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4358\n",
      "Epoch 40: val_loss improved from 1.40908 to 1.40692, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 23s 725us/sample - loss: 1.4358 - val_loss: 1.4069\n",
      "Epoch 41/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4332\n",
      "Epoch 41: val_loss improved from 1.40692 to 1.40279, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 21s 644us/sample - loss: 1.4332 - val_loss: 1.4028\n",
      "Epoch 42/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4349\n",
      "Epoch 42: val_loss improved from 1.40279 to 1.40162, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 638us/sample - loss: 1.4349 - val_loss: 1.4016\n",
      "Epoch 43/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4324\n",
      "Epoch 43: val_loss did not improve from 1.40162\n",
      "31927/31927 [==============================] - 20s 624us/sample - loss: 1.4324 - val_loss: 1.4043\n",
      "Epoch 44/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 44: val_loss improved from 1.40162 to 1.40006, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 632us/sample - loss: 1.4308 - val_loss: 1.4001\n",
      "Epoch 45/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 45: val_loss improved from 1.40006 to 1.39786, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 627us/sample - loss: 1.4283 - val_loss: 1.3979\n",
      "Epoch 46/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4247\n",
      "Epoch 46: val_loss improved from 1.39786 to 1.39762, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 628us/sample - loss: 1.4247 - val_loss: 1.3976\n",
      "Epoch 47/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4226\n",
      "Epoch 47: val_loss improved from 1.39762 to 1.39640, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 625us/sample - loss: 1.4226 - val_loss: 1.3964\n",
      "Epoch 48/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4231\n",
      "Epoch 48: val_loss improved from 1.39640 to 1.39575, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 21s 660us/sample - loss: 1.4231 - val_loss: 1.3957\n",
      "Epoch 49/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 49: val_loss did not improve from 1.39575\n",
      "31927/31927 [==============================] - 20s 621us/sample - loss: 1.4249 - val_loss: 1.3965\n",
      "Epoch 50/50\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4241\n",
      "Epoch 50: val_loss improved from 1.39575 to 1.38904, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_38.h5\n",
      "31927/31927 [==============================] - 20s 631us/sample - loss: 1.4241 - val_loss: 1.3890\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:15:04.814298: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_300_1/lstm_cell_929/bias/Assign' id:475645 op device:{requested: '', assigned: ''} def:{{{node lstm_300_1/lstm_cell_929/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_300_1/lstm_cell_929/bias, lstm_300_1/lstm_cell_929/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 05:15:30.066436: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_309_1/lstm_cell_938/bias/v/Assign' id:482436 op device:{requested: '', assigned: ''} def:{{{node lstm_309_1/lstm_cell_938/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_309_1/lstm_cell_938/bias/v, lstm_309_1/lstm_cell_938/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 05:15:55.523702: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_44_1/cond/Merge' id:480927 op device:{requested: '', assigned: ''} def:{{{node dropout_44_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_44_1/cond/Identity, dropout_44_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1512)\n",
      "(1514, 1512)\n",
      "(1644, 1512)\n",
      "(1764, 1512)\n",
      "(1836, 1512)\n",
      "(1699, 1512)\n",
      "(1369, 1512)\n",
      "(1778, 1512)\n",
      "(1631, 1512)\n",
      "(1692, 1512)\n",
      "(1550, 1512)\n",
      "(1920, 1512)\n",
      "(1739, 1512)\n",
      "(1788, 1512)\n",
      "(1812, 1512)\n",
      "(1788, 1512)\n",
      "(1788, 1512)\n",
      "(934, 1512)\n",
      "(1584, 1512)\n",
      "{1: 5.41816446162557, 2: 1.0, 4: 4.789687305892031, 5: 9.68997132352829, 6: 10.0, 8: 5.05452879169649, 9: 1.140346071140237, 10: 6.858202554479955, 11: 3.5027188469586, 12: 5.017088369012318, 13: 5.943685605754219, 17: 4.691470008744874, 19: 5.292892996622617, 21: 6.333237694222431, 22: 3.1577885083503627, 25: 4.349199760088273, 26: 4.163545168876794, 27: 1.0127670582274308, 28: 5.410536733812444}\n",
      "Train on 31927 samples, validate on 3562 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:21:59.389573: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 8.4957\n",
      "Epoch 1: val_loss improved from inf to 1.41908, saving model to ./checkpoints/unknown_person_few_shot_p29_38.h5\n",
      "31927/31927 [==============================] - 96s 3ms/sample - loss: 8.4957 - val_loss: 1.4191\n",
      "Epoch 2/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.4279\n",
      "Epoch 2: val_loss improved from 1.41908 to 1.39707, saving model to ./checkpoints/unknown_person_few_shot_p29_38.h5\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 8.4279 - val_loss: 1.3971\n",
      "Epoch 3/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.4386\n",
      "Epoch 3: val_loss did not improve from 1.39707\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 8.4386 - val_loss: 1.3987\n",
      "Epoch 4/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.3115\n",
      "Epoch 4: val_loss did not improve from 1.39707\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.3115 - val_loss: 1.4028\n",
      "Epoch 5/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.3104\n",
      "Epoch 5: val_loss did not improve from 1.39707\n",
      "31927/31927 [==============================] - 36s 1ms/sample - loss: 8.3104 - val_loss: 1.4077\n",
      "Epoch 6/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.2392\n",
      "Epoch 6: val_loss did not improve from 1.39707\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 8.2392 - val_loss: 1.4011\n",
      "Epoch 7/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.2262\n",
      "Epoch 7: val_loss improved from 1.39707 to 1.39573, saving model to ./checkpoints/unknown_person_few_shot_p29_38.h5\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 8.2262 - val_loss: 1.3957\n",
      "Epoch 8/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.2266\n",
      "Epoch 8: val_loss improved from 1.39573 to 1.39223, saving model to ./checkpoints/unknown_person_few_shot_p29_38.h5\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 8.2266 - val_loss: 1.3922\n",
      "Epoch 9/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1879\n",
      "Epoch 9: val_loss did not improve from 1.39223\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 8.1879 - val_loss: 1.3949\n",
      "Epoch 10/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1835\n",
      "Epoch 10: val_loss did not improve from 1.39223\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.1835 - val_loss: 1.3945\n",
      "Epoch 11/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1684\n",
      "Epoch 11: val_loss improved from 1.39223 to 1.38801, saving model to ./checkpoints/unknown_person_few_shot_p29_38.h5\n",
      "31927/31927 [==============================] - 32s 1ms/sample - loss: 8.1684 - val_loss: 1.3880\n",
      "Epoch 12/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1490\n",
      "Epoch 12: val_loss did not improve from 1.38801\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 8.1490 - val_loss: 1.3921\n",
      "Epoch 13/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1302\n",
      "Epoch 13: val_loss did not improve from 1.38801\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.1302 - val_loss: 1.3937\n",
      "Epoch 14/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1182\n",
      "Epoch 14: val_loss did not improve from 1.38801\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 8.1182 - val_loss: 1.3926\n",
      "Epoch 15/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1071\n",
      "Epoch 15: val_loss did not improve from 1.38801\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.1071 - val_loss: 1.3902\n",
      "Epoch 16/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1101\n",
      "Epoch 16: val_loss did not improve from 1.38801\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 8.1101 - val_loss: 1.4121\n",
      "Epoch 17/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1355\n",
      "Epoch 17: val_loss improved from 1.38801 to 1.38493, saving model to ./checkpoints/unknown_person_few_shot_p29_38.h5\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.1355 - val_loss: 1.3849\n",
      "Epoch 18/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1112\n",
      "Epoch 18: val_loss did not improve from 1.38493\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.1112 - val_loss: 1.3986\n",
      "Epoch 19/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.0927\n",
      "Epoch 19: val_loss did not improve from 1.38493\n",
      "31927/31927 [==============================] - 32s 1ms/sample - loss: 8.0927 - val_loss: 1.3854\n",
      "Epoch 20/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 8.1076\n",
      "Epoch 20: val_loss did not improve from 1.38493\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 8.1076 - val_loss: 1.3850\n",
      "WARNING:tensorflow:Layer lstm_296 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_297 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_298 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_299 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_300 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_301 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_302 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_303 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_304 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_305 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_306 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_307 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_308 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_309 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_310 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_311 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_312 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_313 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_314 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_315 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_316 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_317 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_318 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_319 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_320 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_321 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_322 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_323 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_324 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_325 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_326 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_327 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_328 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_329 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_330 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_331 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_332 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:34:33.206244: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_306_2/lstm_cell_972/recurrent_kernel/Assign' id:495994 op device:{requested: '', assigned: ''} def:{{{node lstm_306_2/lstm_cell_972/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_306_2/lstm_cell_972/recurrent_kernel, lstm_306_2/lstm_cell_972/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 05:35:07.755620: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_318_2/lstm_cell_984/recurrent_kernel/m/Assign' id:501321 op device:{requested: '', assigned: ''} def:{{{node lstm_318_2/lstm_cell_984/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_318_2/lstm_cell_984/recurrent_kernel/m, lstm_318_2/lstm_cell_984/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31927 samples, validate on 3562 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:35:44.788537: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:38:50.786597: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_40_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:39:30.332002: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_53/mul' id:500915 op device:{requested: '', assigned: ''} def:{{{node loss_53/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_53/mul/x, loss_53/dense_35_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.39892, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_38.h5\n",
      "31927/31927 [==============================] - 105s 3ms/sample - loss: 1.4206 - val_loss: 1.3989\n",
      "Epoch 2/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 2: val_loss improved from 1.39892 to 1.39205, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_38.h5\n",
      "31927/31927 [==============================] - 39s 1ms/sample - loss: 1.4166 - val_loss: 1.3920\n",
      "Epoch 3/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4217\n",
      "Epoch 3: val_loss did not improve from 1.39205\n",
      "31927/31927 [==============================] - 36s 1ms/sample - loss: 1.4217 - val_loss: 1.3945\n",
      "Epoch 4/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4173\n",
      "Epoch 4: val_loss did not improve from 1.39205\n",
      "31927/31927 [==============================] - 36s 1ms/sample - loss: 1.4173 - val_loss: 1.4015\n",
      "Epoch 5/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4174\n",
      "Epoch 5: val_loss did not improve from 1.39205\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 1.4174 - val_loss: 1.3930\n",
      "Epoch 6/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 6: val_loss improved from 1.39205 to 1.39024, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_38.h5\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 1.4141 - val_loss: 1.3902\n",
      "Epoch 7/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4122\n",
      "Epoch 7: val_loss did not improve from 1.39024\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 1.4122 - val_loss: 1.3918\n",
      "Epoch 8/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4102\n",
      "Epoch 8: val_loss did not improve from 1.39024\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 1.4102 - val_loss: 1.3909\n",
      "Epoch 9/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 9: val_loss did not improve from 1.39024\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 1.4082 - val_loss: 1.3908\n",
      "Epoch 10/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 10: val_loss did not improve from 1.39024\n",
      "31927/31927 [==============================] - 31s 976us/sample - loss: 1.4066 - val_loss: 1.3928\n",
      "Epoch 11/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 11: val_loss did not improve from 1.39024\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 1.4049 - val_loss: 1.3912\n",
      "Epoch 12/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 12: val_loss improved from 1.39024 to 1.38803, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_38.h5\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 1.4042 - val_loss: 1.3880\n",
      "Epoch 13/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4065\n",
      "Epoch 13: val_loss did not improve from 1.38803\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 1.4065 - val_loss: 1.3901\n",
      "Epoch 14/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4077\n",
      "Epoch 14: val_loss improved from 1.38803 to 1.38476, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_38.h5\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 1.4077 - val_loss: 1.3848\n",
      "Epoch 15/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 15: val_loss did not improve from 1.38476\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 1.4058 - val_loss: 1.3873\n",
      "Epoch 16/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4042\n",
      "Epoch 16: val_loss did not improve from 1.38476\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 1.4042 - val_loss: 1.3869\n",
      "Epoch 17/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4001\n",
      "Epoch 17: val_loss did not improve from 1.38476\n",
      "31927/31927 [==============================] - 34s 1ms/sample - loss: 1.4001 - val_loss: 1.3881\n",
      "Epoch 18/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3990\n",
      "Epoch 18: val_loss improved from 1.38476 to 1.38226, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_38.h5\n",
      "31927/31927 [==============================] - 35s 1ms/sample - loss: 1.3990 - val_loss: 1.3823\n",
      "Epoch 19/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.4004\n",
      "Epoch 19: val_loss did not improve from 1.38226\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 1.4004 - val_loss: 1.3884\n",
      "Epoch 20/20\n",
      "31927/31927 [==============================] - ETA: 0s - loss: 1.3981\n",
      "Epoch 20: val_loss did not improve from 1.38226\n",
      "31927/31927 [==============================] - 33s 1ms/sample - loss: 1.3981 - val_loss: 1.3835\n",
      "35705\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:52:02.202118: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_345/lstm_cell_1011/kernel/Assign' id:515376 op device:{requested: '', assigned: ''} def:{{{node lstm_345/lstm_cell_1011/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_345/lstm_cell_1011/kernel, lstm_345/lstm_cell_1011/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 05:52:19.447453: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_1' id:517014 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 05:52:32.683095: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_9/stack_2' id:517015 op device:{requested: '', assigned: ''} def:{{{node strided_slice_9/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32119, 95)\n",
      "Train on 32119 samples, validate on 3586 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:53:13.350260: W tensorflow/c/c_api.cc:304] Operation '{name:'training_54/Adam/lstm_356/lstm_cell_1022/recurrent_kernel/m/Assign' id:530122 op device:{requested: '', assigned: ''} def:{{{node training_54/Adam/lstm_356/lstm_cell_1022/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_54/Adam/lstm_356/lstm_cell_1022/recurrent_kernel/m, training_54/Adam/lstm_356/lstm_cell_1022/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 05:56:26.700155: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 3.4278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-24 05:57:03.977632: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_55/mul' id:519855 op device:{requested: '', assigned: ''} def:{{{node loss_55/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_55/mul/x, loss_55/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.99620, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 223s 7ms/sample - loss: 3.4278 - val_loss: 1.9962\n",
      "Epoch 2/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.8283\n",
      "Epoch 2: val_loss improved from 1.99620 to 1.59379, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.8283 - val_loss: 1.5938\n",
      "Epoch 3/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.6169\n",
      "Epoch 3: val_loss improved from 1.59379 to 1.51793, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.6169 - val_loss: 1.5179\n",
      "Epoch 4/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5522\n",
      "Epoch 4: val_loss improved from 1.51793 to 1.49482, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.5522 - val_loss: 1.4948\n",
      "Epoch 5/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5213\n",
      "Epoch 5: val_loss improved from 1.49482 to 1.47735, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 1.5213 - val_loss: 1.4773\n",
      "Epoch 6/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5083\n",
      "Epoch 6: val_loss improved from 1.47735 to 1.47200, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.5083 - val_loss: 1.4720\n",
      "Epoch 7/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4997\n",
      "Epoch 7: val_loss improved from 1.47200 to 1.46254, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4997 - val_loss: 1.4625\n",
      "Epoch 8/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4992\n",
      "Epoch 8: val_loss improved from 1.46254 to 1.44797, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4992 - val_loss: 1.4480\n",
      "Epoch 9/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4909\n",
      "Epoch 9: val_loss did not improve from 1.44797\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4909 - val_loss: 1.4568\n",
      "Epoch 10/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4872\n",
      "Epoch 10: val_loss did not improve from 1.44797\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4872 - val_loss: 1.4484\n",
      "Epoch 11/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4781\n",
      "Epoch 11: val_loss improved from 1.44797 to 1.44069, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4781 - val_loss: 1.4407\n",
      "Epoch 12/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 12: val_loss did not improve from 1.44069\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4772 - val_loss: 1.4413\n",
      "Epoch 13/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4765\n",
      "Epoch 13: val_loss did not improve from 1.44069\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.4765 - val_loss: 1.4483\n",
      "Epoch 14/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 14: val_loss improved from 1.44069 to 1.43448, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4731 - val_loss: 1.4345\n",
      "Epoch 15/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4964\n",
      "Epoch 15: val_loss did not improve from 1.43448\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4964 - val_loss: 1.4425\n",
      "Epoch 16/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5056\n",
      "Epoch 16: val_loss did not improve from 1.43448\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.5056 - val_loss: 1.4389\n",
      "Epoch 17/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4731\n",
      "Epoch 17: val_loss did not improve from 1.43448\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4731 - val_loss: 1.4377\n",
      "Epoch 18/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4705\n",
      "Epoch 18: val_loss did not improve from 1.43448\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4705 - val_loss: 1.4354\n",
      "Epoch 19/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5442\n",
      "Epoch 19: val_loss did not improve from 1.43448\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.5442 - val_loss: 1.4417\n",
      "Epoch 20/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4850\n",
      "Epoch 20: val_loss improved from 1.43448 to 1.42523, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4850 - val_loss: 1.4252\n",
      "Epoch 21/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5154\n",
      "Epoch 21: val_loss did not improve from 1.42523\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.5154 - val_loss: 1.4257\n",
      "Epoch 22/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4840\n",
      "Epoch 22: val_loss did not improve from 1.42523\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4840 - val_loss: 1.4319\n",
      "Epoch 23/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 23: val_loss did not improve from 1.42523\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4794 - val_loss: 1.4386\n",
      "Epoch 24/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4607\n",
      "Epoch 24: val_loss did not improve from 1.42523\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4607 - val_loss: 1.4303\n",
      "Epoch 25/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4541\n",
      "Epoch 25: val_loss did not improve from 1.42523\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4541 - val_loss: 1.4344\n",
      "Epoch 26/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4495\n",
      "Epoch 26: val_loss improved from 1.42523 to 1.42234, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4495 - val_loss: 1.4223\n",
      "Epoch 27/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4451\n",
      "Epoch 27: val_loss did not improve from 1.42234\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4451 - val_loss: 1.4247\n",
      "Epoch 28/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 28: val_loss did not improve from 1.42234\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4420 - val_loss: 1.4236\n",
      "Epoch 29/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4402\n",
      "Epoch 29: val_loss improved from 1.42234 to 1.42120, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4402 - val_loss: 1.4212\n",
      "Epoch 30/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 30: val_loss did not improve from 1.42120\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4383 - val_loss: 1.4223\n",
      "Epoch 31/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4351\n",
      "Epoch 31: val_loss improved from 1.42120 to 1.41294, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4351 - val_loss: 1.4129\n",
      "Epoch 32/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4319\n",
      "Epoch 32: val_loss did not improve from 1.41294\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4319 - val_loss: 1.4133\n",
      "Epoch 33/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4315\n",
      "Epoch 33: val_loss improved from 1.41294 to 1.41162, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4315 - val_loss: 1.4116\n",
      "Epoch 34/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4278\n",
      "Epoch 34: val_loss improved from 1.41162 to 1.41150, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.4278 - val_loss: 1.4115\n",
      "Epoch 35/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4258\n",
      "Epoch 35: val_loss did not improve from 1.41150\n",
      "32119/32119 [==============================] - 32s 988us/sample - loss: 1.4258 - val_loss: 1.4166\n",
      "Epoch 36/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4242\n",
      "Epoch 36: val_loss did not improve from 1.41150\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4242 - val_loss: 1.4140\n",
      "Epoch 37/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4216\n",
      "Epoch 37: val_loss did not improve from 1.41150\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4216 - val_loss: 1.4163\n",
      "Epoch 38/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4196\n",
      "Epoch 38: val_loss improved from 1.41150 to 1.40632, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4196 - val_loss: 1.4063\n",
      "Epoch 39/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4204\n",
      "Epoch 39: val_loss improved from 1.40632 to 1.40237, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4204 - val_loss: 1.4024\n",
      "Epoch 40/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4167\n",
      "Epoch 40: val_loss did not improve from 1.40237\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4167 - val_loss: 1.4052\n",
      "Epoch 41/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4156\n",
      "Epoch 41: val_loss did not improve from 1.40237\n",
      "32119/32119 [==============================] - 32s 1000us/sample - loss: 1.4156 - val_loss: 1.4077\n",
      "Epoch 42/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 42: val_loss did not improve from 1.40237\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4124 - val_loss: 1.4109\n",
      "Epoch 43/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4102\n",
      "Epoch 43: val_loss improved from 1.40237 to 1.39703, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4102 - val_loss: 1.3970\n",
      "Epoch 44/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 44: val_loss did not improve from 1.39703\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4070 - val_loss: 1.4086\n",
      "Epoch 45/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 45: val_loss improved from 1.39703 to 1.39664, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4078 - val_loss: 1.3966\n",
      "Epoch 46/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 46: val_loss did not improve from 1.39664\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4067 - val_loss: 1.4035\n",
      "Epoch 47/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4071\n",
      "Epoch 47: val_loss did not improve from 1.39664\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4071 - val_loss: 1.4046\n",
      "Epoch 48/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4030\n",
      "Epoch 48: val_loss did not improve from 1.39664\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4030 - val_loss: 1.4013\n",
      "Epoch 49/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4002\n",
      "Epoch 49: val_loss did not improve from 1.39664\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.4002 - val_loss: 1.4027\n",
      "Epoch 50/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4000\n",
      "Epoch 50: val_loss improved from 1.39664 to 1.39500, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4000 - val_loss: 1.3950\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 06:28:21.810085: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_348_1/lstm_cell_1051/bias/Assign' id:534447 op device:{requested: '', assigned: ''} def:{{{node lstm_348_1/lstm_cell_1051/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_348_1/lstm_cell_1051/bias, lstm_348_1/lstm_cell_1051/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 06:29:04.029410: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_335_1/lstm_cell_1038/kernel/m/Assign' id:538660 op device:{requested: '', assigned: ''} def:{{{node lstm_335_1/lstm_cell_1038/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_335_1/lstm_cell_1038/kernel/m, lstm_335_1/lstm_cell_1038/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-24 06:29:41.973230: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_49_1/cond/Merge' id:537969 op device:{requested: '', assigned: ''} def:{{{node dropout_49_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_49_1/cond/Identity, dropout_49_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1296)\n",
      "(1514, 1296)\n",
      "(1644, 1296)\n",
      "(1764, 1296)\n",
      "(1836, 1296)\n",
      "(1699, 1296)\n",
      "(1369, 1296)\n",
      "(1766, 1296)\n",
      "(1631, 1296)\n",
      "(1692, 1296)\n",
      "(1550, 1296)\n",
      "(1920, 1296)\n",
      "(1739, 1296)\n",
      "(1788, 1296)\n",
      "(1812, 1296)\n",
      "(1788, 1296)\n",
      "(1788, 1296)\n",
      "(946, 1296)\n",
      "(1560, 1296)\n",
      "{1: 3.859009831744579, 2: 1.4855902278417517, 4: 4.514894651418677, 5: 7.910204635528131, 6: 10.0, 8: 4.459213620085897, 9: 1.1678125147259866, 10: 5.879735780716123, 11: 3.174308815300657, 12: 4.518818233623222, 13: 4.6302892203074535, 17: 4.152219384818773, 19: 5.154640176070655, 21: 5.254632425212589, 22: 1.1887108623511984, 25: 3.8431324178737363, 26: 3.273332335936094, 27: 1.0, 28: 4.259653230215163}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2920137/1660627543.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32119 samples, validate on 3586 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 06:38:59.673557: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 7.8102\n",
      "Epoch 1: val_loss improved from inf to 1.41592, saving model to ./checkpoints/unknown_person_few_shot_p29_39.h5\n",
      "32119/32119 [==============================] - 112s 3ms/sample - loss: 7.8102 - val_loss: 1.4159\n",
      "Epoch 2/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7418\n",
      "Epoch 2: val_loss did not improve from 1.41592\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.7418 - val_loss: 1.4236\n",
      "Epoch 3/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.5852\n",
      "Epoch 3: val_loss did not improve from 1.41592\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.5852 - val_loss: 1.4215\n",
      "Epoch 4/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.5797\n",
      "Epoch 4: val_loss improved from 1.41592 to 1.41006, saving model to ./checkpoints/unknown_person_few_shot_p29_39.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.5797 - val_loss: 1.4101\n",
      "Epoch 5/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.4872\n",
      "Epoch 5: val_loss did not improve from 1.41006\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.4872 - val_loss: 1.4125\n",
      "Epoch 6/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.5023\n",
      "Epoch 6: val_loss improved from 1.41006 to 1.40461, saving model to ./checkpoints/unknown_person_few_shot_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.5023 - val_loss: 1.4046\n",
      "Epoch 7/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.4765\n",
      "Epoch 7: val_loss improved from 1.40461 to 1.39882, saving model to ./checkpoints/unknown_person_few_shot_p29_39.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 7.4765 - val_loss: 1.3988\n",
      "Epoch 8/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.4533\n",
      "Epoch 8: val_loss improved from 1.39882 to 1.39490, saving model to ./checkpoints/unknown_person_few_shot_p29_39.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 7.4533 - val_loss: 1.3949\n",
      "Epoch 9/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.4720\n",
      "Epoch 9: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.4720 - val_loss: 1.4254\n",
      "Epoch 10/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.4311\n",
      "Epoch 10: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 7.4311 - val_loss: 1.4119\n",
      "Epoch 11/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3850\n",
      "Epoch 11: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 7.3850 - val_loss: 1.4073\n",
      "Epoch 12/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3867\n",
      "Epoch 12: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 30s 937us/sample - loss: 7.3867 - val_loss: 1.4008\n",
      "Epoch 13/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3424\n",
      "Epoch 13: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.3424 - val_loss: 1.4057\n",
      "Epoch 14/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3721\n",
      "Epoch 14: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.3721 - val_loss: 1.4223\n",
      "Epoch 15/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3932\n",
      "Epoch 15: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.3932 - val_loss: 1.4054\n",
      "Epoch 16/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3904\n",
      "Epoch 16: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 7.3904 - val_loss: 1.4025\n",
      "Epoch 17/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3624\n",
      "Epoch 17: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 7.3624 - val_loss: 1.3951\n",
      "Epoch 18/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.2978\n",
      "Epoch 18: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.2978 - val_loss: 1.4048\n",
      "Epoch 19/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3207\n",
      "Epoch 19: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 7.3207 - val_loss: 1.3976\n",
      "Epoch 20/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.3281\n",
      "Epoch 20: val_loss did not improve from 1.39490\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.3281 - val_loss: 1.3993\n",
      "WARNING:tensorflow:Layer lstm_333 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_334 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_335 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_336 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_337 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_338 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_339 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_340 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_341 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_342 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_343 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_344 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_345 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_346 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_347 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_348 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_349 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_350 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_351 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_352 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_353 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_354 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_355 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_356 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_357 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_358 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_359 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_360 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_361 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_362 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_363 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_364 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_365 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_366 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_367 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_368 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_369 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 06:51:57.153559: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_351_2/lstm_cell_1091/bias/Assign' id:554325 op device:{requested: '', assigned: ''} def:{{{node lstm_351_2/lstm_cell_1091/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_351_2/lstm_cell_1091/bias, lstm_351_2/lstm_cell_1091/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 06:52:37.862172: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_362_2/lstm_cell_1102/kernel/v/Assign' id:559106 op device:{requested: '', assigned: ''} def:{{{node lstm_362_2/lstm_cell_1102/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_362_2/lstm_cell_1102/kernel/v, lstm_362_2/lstm_cell_1102/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32119 samples, validate on 3586 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 06:53:23.649944: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 06:56:38.527916: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_45_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 06:57:22.757310: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_59/mul' id:557957 op device:{requested: '', assigned: ''} def:{{{node loss_59/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_59/mul/x, loss_59/dense_39_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40589, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_39.h5\n",
      "32119/32119 [==============================] - 114s 4ms/sample - loss: 1.3996 - val_loss: 1.4059\n",
      "Epoch 2/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 2: val_loss improved from 1.40589 to 1.38935, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_39.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.3953 - val_loss: 1.3894\n",
      "Epoch 3/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3991\n",
      "Epoch 3: val_loss did not improve from 1.38935\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3991 - val_loss: 1.3946\n",
      "Epoch 4/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3951\n",
      "Epoch 4: val_loss did not improve from 1.38935\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3951 - val_loss: 1.3999\n",
      "Epoch 5/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3936\n",
      "Epoch 5: val_loss did not improve from 1.38935\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.3936 - val_loss: 1.3966\n",
      "Epoch 6/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3915\n",
      "Epoch 6: val_loss did not improve from 1.38935\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3915 - val_loss: 1.3931\n",
      "Epoch 7/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 7: val_loss did not improve from 1.38935\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.3907 - val_loss: 1.3899\n",
      "Epoch 8/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3891\n",
      "Epoch 8: val_loss did not improve from 1.38935\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3891 - val_loss: 1.3914\n",
      "Epoch 9/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3875\n",
      "Epoch 9: val_loss improved from 1.38935 to 1.38797, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_39.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3875 - val_loss: 1.3880\n",
      "Epoch 10/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3872\n",
      "Epoch 10: val_loss did not improve from 1.38797\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.3872 - val_loss: 1.3965\n",
      "Epoch 11/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3858\n",
      "Epoch 11: val_loss improved from 1.38797 to 1.38507, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_39.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3858 - val_loss: 1.3851\n",
      "Epoch 12/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3821\n",
      "Epoch 12: val_loss did not improve from 1.38507\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3821 - val_loss: 1.3911\n",
      "Epoch 13/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3859\n",
      "Epoch 13: val_loss did not improve from 1.38507\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.3859 - val_loss: 1.4014\n",
      "Epoch 14/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3825\n",
      "Epoch 14: val_loss did not improve from 1.38507\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.3825 - val_loss: 1.3914\n",
      "Epoch 15/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3843\n",
      "Epoch 15: val_loss improved from 1.38507 to 1.38306, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_39.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3843 - val_loss: 1.3831\n",
      "Epoch 16/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3800\n",
      "Epoch 16: val_loss did not improve from 1.38306\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.3800 - val_loss: 1.3858\n",
      "Epoch 17/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3801\n",
      "Epoch 17: val_loss did not improve from 1.38306\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3801 - val_loss: 1.3901\n",
      "Epoch 18/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3778\n",
      "Epoch 18: val_loss did not improve from 1.38306\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.3778 - val_loss: 1.3845\n",
      "Epoch 19/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3764\n",
      "Epoch 19: val_loss did not improve from 1.38306\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3764 - val_loss: 1.3879\n",
      "Epoch 20/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3755\n",
      "Epoch 20: val_loss improved from 1.38306 to 1.37606, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_39.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3755 - val_loss: 1.3761\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 07:09:28.358683: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_373/lstm_cell_1113/bias/Assign' id:570962 op device:{requested: '', assigned: ''} def:{{{node lstm_373/lstm_cell_1113/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_373/lstm_cell_1113/bias, lstm_373/lstm_cell_1113/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 07:09:53.553669: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_1' id:574056 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 07:10:13.377633: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_10/stack_2' id:574057 op device:{requested: '', assigned: ''} def:{{{node strided_slice_10/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32119, 95)\n",
      "Train on 32119 samples, validate on 3586 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 07:10:59.991759: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_405/lstm_cell_1145/bias/Assign' id:576471 op device:{requested: '', assigned: ''} def:{{{node lstm_405/lstm_cell_1145/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_405/lstm_cell_1145/bias, lstm_405/lstm_cell_1145/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 07:14:45.858413: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 3.4655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 07:15:27.785477: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_61/mul' id:576897 op device:{requested: '', assigned: ''} def:{{{node loss_61/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_61/mul/x, loss_61/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.02479, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 234s 7ms/sample - loss: 3.4655 - val_loss: 2.0248\n",
      "Epoch 2/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.8509\n",
      "Epoch 2: val_loss improved from 2.02479 to 1.59097, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.8509 - val_loss: 1.5910\n",
      "Epoch 3/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.6056\n",
      "Epoch 3: val_loss improved from 1.59097 to 1.51551, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.6056 - val_loss: 1.5155\n",
      "Epoch 4/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5532\n",
      "Epoch 4: val_loss improved from 1.51551 to 1.48947, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.5532 - val_loss: 1.4895\n",
      "Epoch 5/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5252\n",
      "Epoch 5: val_loss improved from 1.48947 to 1.47873, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.5252 - val_loss: 1.4787\n",
      "Epoch 6/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5127\n",
      "Epoch 6: val_loss improved from 1.47873 to 1.46867, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.5127 - val_loss: 1.4687\n",
      "Epoch 7/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5011\n",
      "Epoch 7: val_loss improved from 1.46867 to 1.45213, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5011 - val_loss: 1.4521\n",
      "Epoch 8/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5006\n",
      "Epoch 8: val_loss did not improve from 1.45213\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.5006 - val_loss: 1.4538\n",
      "Epoch 9/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5103\n",
      "Epoch 9: val_loss improved from 1.45213 to 1.44987, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.5103 - val_loss: 1.4499\n",
      "Epoch 10/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5001\n",
      "Epoch 10: val_loss improved from 1.44987 to 1.44628, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.5001 - val_loss: 1.4463\n",
      "Epoch 11/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4897\n",
      "Epoch 11: val_loss improved from 1.44628 to 1.44545, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4897 - val_loss: 1.4454\n",
      "Epoch 12/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4905\n",
      "Epoch 12: val_loss did not improve from 1.44545\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4905 - val_loss: 1.4507\n",
      "Epoch 13/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4807\n",
      "Epoch 13: val_loss improved from 1.44545 to 1.43202, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4807 - val_loss: 1.4320\n",
      "Epoch 14/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4764\n",
      "Epoch 14: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4764 - val_loss: 1.4322\n",
      "Epoch 15/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4703\n",
      "Epoch 15: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4703 - val_loss: 1.4416\n",
      "Epoch 16/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5509\n",
      "Epoch 16: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.5509 - val_loss: 1.4375\n",
      "Epoch 17/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4989\n",
      "Epoch 17: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4989 - val_loss: 1.4367\n",
      "Epoch 18/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5135\n",
      "Epoch 18: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5135 - val_loss: 1.4579\n",
      "Epoch 19/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4923\n",
      "Epoch 19: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4923 - val_loss: 1.4338\n",
      "Epoch 20/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4886\n",
      "Epoch 20: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 1.4886 - val_loss: 1.4368\n",
      "Epoch 21/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4980\n",
      "Epoch 21: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4980 - val_loss: 1.4550\n",
      "Epoch 22/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5318\n",
      "Epoch 22: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 40s 1ms/sample - loss: 1.5318 - val_loss: 1.4654\n",
      "Epoch 23/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5148\n",
      "Epoch 23: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5148 - val_loss: 1.4501\n",
      "Epoch 24/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4823\n",
      "Epoch 24: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4823 - val_loss: 1.4487\n",
      "Epoch 25/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4702\n",
      "Epoch 25: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4702 - val_loss: 1.4343\n",
      "Epoch 26/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4647\n",
      "Epoch 26: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4647 - val_loss: 1.4342\n",
      "Epoch 27/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4641\n",
      "Epoch 27: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4641 - val_loss: 1.4396\n",
      "Epoch 28/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4587\n",
      "Epoch 28: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4587 - val_loss: 1.4418\n",
      "Epoch 29/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4572\n",
      "Epoch 29: val_loss did not improve from 1.43202\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4572 - val_loss: 1.4402\n",
      "Epoch 30/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4519\n",
      "Epoch 30: val_loss improved from 1.43202 to 1.43179, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4519 - val_loss: 1.4318\n",
      "Epoch 31/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4492\n",
      "Epoch 31: val_loss did not improve from 1.43179\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4492 - val_loss: 1.4370\n",
      "Epoch 32/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 32: val_loss did not improve from 1.43179\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4483 - val_loss: 1.4391\n",
      "Epoch 33/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4447\n",
      "Epoch 33: val_loss improved from 1.43179 to 1.42725, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4447 - val_loss: 1.4273\n",
      "Epoch 34/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 34: val_loss did not improve from 1.42725\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4420 - val_loss: 1.4327\n",
      "Epoch 35/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4407\n",
      "Epoch 35: val_loss did not improve from 1.42725\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4407 - val_loss: 1.4284\n",
      "Epoch 36/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4396\n",
      "Epoch 36: val_loss did not improve from 1.42725\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4396 - val_loss: 1.4273\n",
      "Epoch 37/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4341\n",
      "Epoch 37: val_loss did not improve from 1.42725\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4341 - val_loss: 1.4288\n",
      "Epoch 38/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4315\n",
      "Epoch 38: val_loss improved from 1.42725 to 1.42496, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4315 - val_loss: 1.4250\n",
      "Epoch 39/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4326\n",
      "Epoch 39: val_loss did not improve from 1.42496\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4326 - val_loss: 1.4357\n",
      "Epoch 40/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4299\n",
      "Epoch 40: val_loss improved from 1.42496 to 1.42034, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4299 - val_loss: 1.4203\n",
      "Epoch 41/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4308\n",
      "Epoch 41: val_loss improved from 1.42034 to 1.41482, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4308 - val_loss: 1.4148\n",
      "Epoch 42/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4254\n",
      "Epoch 42: val_loss did not improve from 1.41482\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4254 - val_loss: 1.4296\n",
      "Epoch 43/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4268\n",
      "Epoch 43: val_loss did not improve from 1.41482\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4268 - val_loss: 1.4218\n",
      "Epoch 44/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 44: val_loss improved from 1.41482 to 1.40807, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4220 - val_loss: 1.4081\n",
      "Epoch 45/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4223\n",
      "Epoch 45: val_loss did not improve from 1.40807\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4223 - val_loss: 1.4116\n",
      "Epoch 46/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4230\n",
      "Epoch 46: val_loss did not improve from 1.40807\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4230 - val_loss: 1.4177\n",
      "Epoch 47/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4186\n",
      "Epoch 47: val_loss improved from 1.40807 to 1.40756, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4186 - val_loss: 1.4076\n",
      "Epoch 48/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4194\n",
      "Epoch 48: val_loss did not improve from 1.40756\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4194 - val_loss: 1.4146\n",
      "Epoch 49/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4169\n",
      "Epoch 49: val_loss did not improve from 1.40756\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4169 - val_loss: 1.4114\n",
      "Epoch 50/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4151\n",
      "Epoch 50: val_loss did not improve from 1.40756\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 1.4151 - val_loss: 1.4145\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 07:48:02.639371: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_42_1/kernel/Assign' id:595042 op device:{requested: '', assigned: ''} def:{{{node dense_42_1/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_42_1/kernel, dense_42_1/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 07:48:49.180030: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_376_1/lstm_cell_1153/bias/m/Assign' id:595772 op device:{requested: '', assigned: ''} def:{{{node lstm_376_1/lstm_cell_1153/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_376_1/lstm_cell_1153/bias/m, lstm_376_1/lstm_cell_1153/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 07:49:34.839620: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_54_1/cond/Merge' id:595011 op device:{requested: '', assigned: ''} def:{{{node dropout_54_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_54_1/cond/Identity, dropout_54_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1296)\n",
      "(1514, 1296)\n",
      "(1644, 1296)\n",
      "(1764, 1296)\n",
      "(1836, 1296)\n",
      "(1699, 1296)\n",
      "(1369, 1296)\n",
      "(1766, 1296)\n",
      "(1631, 1296)\n",
      "(1692, 1296)\n",
      "(1550, 1296)\n",
      "(1920, 1296)\n",
      "(1739, 1296)\n",
      "(1788, 1296)\n",
      "(1812, 1296)\n",
      "(1788, 1296)\n",
      "(1788, 1296)\n",
      "(946, 1296)\n",
      "(1560, 1296)\n",
      "{1: 5.097300090684121, 2: 1.159430415775822, 4: 4.526326290735751, 5: 8.91076857393309, 6: 10.0, 8: 4.604242059465711, 9: 1.190233112091815, 10: 6.435565811235186, 11: 3.3162159568120417, 12: 4.9317282842734445, 13: 5.640465827026894, 17: 4.443070182323311, 19: 5.369174443531405, 21: 5.6123428748663144, 22: 2.6761911392440974, 25: 4.411617496456322, 26: 4.195691180378187, 27: 1.0, 28: 5.474613174067178}\n",
      "Train on 32119 samples, validate on 3586 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 07:59:49.901396: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 8.5786\n",
      "Epoch 1: val_loss improved from inf to 1.42131, saving model to ./checkpoints/unknown_person_few_shot_p29_40.h5\n",
      "32119/32119 [==============================] - 117s 4ms/sample - loss: 8.5786 - val_loss: 1.4213\n",
      "Epoch 2/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.5257\n",
      "Epoch 2: val_loss did not improve from 1.42131\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 8.5257 - val_loss: 1.4403\n",
      "Epoch 3/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.3298\n",
      "Epoch 3: val_loss improved from 1.42131 to 1.41883, saving model to ./checkpoints/unknown_person_few_shot_p29_40.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 8.3298 - val_loss: 1.4188\n",
      "Epoch 4/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.3282\n",
      "Epoch 4: val_loss did not improve from 1.41883\n",
      "32119/32119 [==============================] - 30s 949us/sample - loss: 8.3282 - val_loss: 1.4418\n",
      "Epoch 5/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.2531\n",
      "Epoch 5: val_loss improved from 1.41883 to 1.40815, saving model to ./checkpoints/unknown_person_few_shot_p29_40.h5\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 8.2531 - val_loss: 1.4081\n",
      "Epoch 6/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.2727\n",
      "Epoch 6: val_loss did not improve from 1.40815\n",
      "32119/32119 [==============================] - 31s 968us/sample - loss: 8.2727 - val_loss: 1.4137\n",
      "Epoch 7/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.2457\n",
      "Epoch 7: val_loss did not improve from 1.40815\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 8.2457 - val_loss: 1.4140\n",
      "Epoch 8/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.2145\n",
      "Epoch 8: val_loss did not improve from 1.40815\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 8.2145 - val_loss: 1.4089\n",
      "Epoch 9/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1765\n",
      "Epoch 9: val_loss improved from 1.40815 to 1.40418, saving model to ./checkpoints/unknown_person_few_shot_p29_40.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 8.1765 - val_loss: 1.4042\n",
      "Epoch 10/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1543\n",
      "Epoch 10: val_loss did not improve from 1.40418\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 8.1543 - val_loss: 1.4139\n",
      "Epoch 11/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1400\n",
      "Epoch 11: val_loss did not improve from 1.40418\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 8.1400 - val_loss: 1.4153\n",
      "Epoch 12/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1355\n",
      "Epoch 12: val_loss improved from 1.40418 to 1.39863, saving model to ./checkpoints/unknown_person_few_shot_p29_40.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 8.1355 - val_loss: 1.3986\n",
      "Epoch 13/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1621\n",
      "Epoch 13: val_loss did not improve from 1.39863\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 8.1621 - val_loss: 1.4178\n",
      "Epoch 14/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1242\n",
      "Epoch 14: val_loss did not improve from 1.39863\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 8.1242 - val_loss: 1.4055\n",
      "Epoch 15/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1053\n",
      "Epoch 15: val_loss did not improve from 1.39863\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 8.1053 - val_loss: 1.4101\n",
      "Epoch 16/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1118\n",
      "Epoch 16: val_loss improved from 1.39863 to 1.39503, saving model to ./checkpoints/unknown_person_few_shot_p29_40.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 8.1118 - val_loss: 1.3950\n",
      "Epoch 17/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1288\n",
      "Epoch 17: val_loss did not improve from 1.39503\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 8.1288 - val_loss: 1.4029\n",
      "Epoch 18/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.0948\n",
      "Epoch 18: val_loss did not improve from 1.39503\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 8.0948 - val_loss: 1.4091\n",
      "Epoch 19/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.1071\n",
      "Epoch 19: val_loss did not improve from 1.39503\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 8.1071 - val_loss: 1.4053\n",
      "Epoch 20/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 8.0540\n",
      "Epoch 20: val_loss did not improve from 1.39503\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 8.0540 - val_loss: 1.4142\n",
      "WARNING:tensorflow:Layer lstm_370 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_371 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_372 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_373 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_374 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_375 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_376 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_377 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_378 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_379 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_380 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_381 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_382 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_383 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_384 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_385 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_386 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_387 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_388 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_389 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_390 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_391 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_392 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_393 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:12:45.952522: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_391_2/lstm_cell_1205/kernel/Assign' id:611818 op device:{requested: '', assigned: ''} def:{{{node lstm_391_2/lstm_cell_1205/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_391_2/lstm_cell_1205/kernel, lstm_391_2/lstm_cell_1205/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 08:13:32.584995: W tensorflow/c/c_api.cc:304] Operation '{name:'decay_21/Assign' id:615018 op device:{requested: '', assigned: ''} def:{{{node decay_21/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](decay_21, decay_21/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32119 samples, validate on 3586 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:14:21.610676: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:18:06.952048: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_50_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:18:44.480978: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_65/mul' id:614999 op device:{requested: '', assigned: ''} def:{{{node loss_65/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_65/mul/x, loss_65/dense_43_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41791, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_40.h5\n",
      "32119/32119 [==============================] - 118s 4ms/sample - loss: 1.4169 - val_loss: 1.4179\n",
      "Epoch 2/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4144\n",
      "Epoch 2: val_loss improved from 1.41791 to 1.41277, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_40.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 1.4144 - val_loss: 1.4128\n",
      "Epoch 3/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4109\n",
      "Epoch 3: val_loss did not improve from 1.41277\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4109 - val_loss: 1.4169\n",
      "Epoch 4/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 4: val_loss improved from 1.41277 to 1.39925, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_40.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4178 - val_loss: 1.3993\n",
      "Epoch 5/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4097\n",
      "Epoch 5: val_loss did not improve from 1.39925\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4097 - val_loss: 1.4037\n",
      "Epoch 6/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 6: val_loss did not improve from 1.39925\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4100 - val_loss: 1.4044\n",
      "Epoch 7/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 7: val_loss did not improve from 1.39925\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4069 - val_loss: 1.4024\n",
      "Epoch 8/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4064\n",
      "Epoch 8: val_loss did not improve from 1.39925\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4064 - val_loss: 1.4060\n",
      "Epoch 9/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4033\n",
      "Epoch 9: val_loss improved from 1.39925 to 1.39597, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_40.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4033 - val_loss: 1.3960\n",
      "Epoch 10/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4014\n",
      "Epoch 10: val_loss did not improve from 1.39597\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4014 - val_loss: 1.4065\n",
      "Epoch 11/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3995\n",
      "Epoch 11: val_loss did not improve from 1.39597\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3995 - val_loss: 1.3979\n",
      "Epoch 12/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4004\n",
      "Epoch 12: val_loss did not improve from 1.39597\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4004 - val_loss: 1.4043\n",
      "Epoch 13/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4019\n",
      "Epoch 13: val_loss did not improve from 1.39597\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4019 - val_loss: 1.3990\n",
      "Epoch 14/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3977\n",
      "Epoch 14: val_loss did not improve from 1.39597\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.3977 - val_loss: 1.4025\n",
      "Epoch 15/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 15: val_loss improved from 1.39597 to 1.38672, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_40.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.3975 - val_loss: 1.3867\n",
      "Epoch 16/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3970\n",
      "Epoch 16: val_loss did not improve from 1.38672\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.3970 - val_loss: 1.4055\n",
      "Epoch 17/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 17: val_loss did not improve from 1.38672\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.3949 - val_loss: 1.3953\n",
      "Epoch 18/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3934\n",
      "Epoch 18: val_loss did not improve from 1.38672\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.3934 - val_loss: 1.3912\n",
      "Epoch 19/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3934\n",
      "Epoch 19: val_loss did not improve from 1.38672\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.3934 - val_loss: 1.3926\n",
      "Epoch 20/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3892\n",
      "Epoch 20: val_loss did not improve from 1.38672\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.3892 - val_loss: 1.3937\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:31:11.207239: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_422/lstm_cell_1236/bias/Assign' id:629984 op device:{requested: '', assigned: ''} def:{{{node lstm_422/lstm_cell_1236/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_422/lstm_cell_1236/bias, lstm_422/lstm_cell_1236/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 08:31:37.596124: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_1' id:631098 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 08:31:58.869818: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_11/stack_2' id:631099 op device:{requested: '', assigned: ''} def:{{{node strided_slice_11/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32119, 95)\n",
      "Train on 32119 samples, validate on 3586 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:32:51.382224: W tensorflow/c/c_api.cc:304] Operation '{name:'training_66/Adam/lstm_428/lstm_cell_1242/kernel/m/Assign' id:644171 op device:{requested: '', assigned: ''} def:{{{node training_66/Adam/lstm_428/lstm_cell_1242/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_66/Adam/lstm_428/lstm_cell_1242/kernel/m, training_66/Adam/lstm_428/lstm_cell_1242/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:36:52.489070: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 2.8689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:37:32.167742: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_67/mul' id:633939 op device:{requested: '', assigned: ''} def:{{{node loss_67/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_67/mul/x, loss_67/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.82586, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 271s 8ms/sample - loss: 2.8689 - val_loss: 1.8259\n",
      "Epoch 2/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.7288\n",
      "Epoch 2: val_loss improved from 1.82586 to 1.58656, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.7288 - val_loss: 1.5866\n",
      "Epoch 3/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5903\n",
      "Epoch 3: val_loss improved from 1.58656 to 1.52843, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.5903 - val_loss: 1.5284\n",
      "Epoch 4/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5449\n",
      "Epoch 4: val_loss improved from 1.52843 to 1.48992, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5449 - val_loss: 1.4899\n",
      "Epoch 5/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5213\n",
      "Epoch 5: val_loss improved from 1.48992 to 1.47462, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.5213 - val_loss: 1.4746\n",
      "Epoch 6/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5050\n",
      "Epoch 6: val_loss improved from 1.47462 to 1.46508, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.5050 - val_loss: 1.4651\n",
      "Epoch 7/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4919\n",
      "Epoch 7: val_loss improved from 1.46508 to 1.45612, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4919 - val_loss: 1.4561\n",
      "Epoch 8/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4987\n",
      "Epoch 8: val_loss improved from 1.45612 to 1.45535, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4987 - val_loss: 1.4553\n",
      "Epoch 9/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4847\n",
      "Epoch 9: val_loss improved from 1.45535 to 1.44947, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4847 - val_loss: 1.4495\n",
      "Epoch 10/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5035\n",
      "Epoch 10: val_loss did not improve from 1.44947\n",
      "32119/32119 [==============================] - 39s 1ms/sample - loss: 1.5035 - val_loss: 1.4546\n",
      "Epoch 11/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5184\n",
      "Epoch 11: val_loss improved from 1.44947 to 1.44206, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 1.5184 - val_loss: 1.4421\n",
      "Epoch 12/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5018\n",
      "Epoch 12: val_loss did not improve from 1.44206\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5018 - val_loss: 1.4435\n",
      "Epoch 13/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4850\n",
      "Epoch 13: val_loss did not improve from 1.44206\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4850 - val_loss: 1.4428\n",
      "Epoch 14/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4824\n",
      "Epoch 14: val_loss improved from 1.44206 to 1.43902, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4824 - val_loss: 1.4390\n",
      "Epoch 15/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4862\n",
      "Epoch 15: val_loss did not improve from 1.43902\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4862 - val_loss: 1.4396\n",
      "Epoch 16/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4767\n",
      "Epoch 16: val_loss improved from 1.43902 to 1.43828, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.4767 - val_loss: 1.4383\n",
      "Epoch 17/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4950\n",
      "Epoch 17: val_loss improved from 1.43828 to 1.43573, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 1.4950 - val_loss: 1.4357\n",
      "Epoch 18/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5051\n",
      "Epoch 18: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5051 - val_loss: 1.4431\n",
      "Epoch 19/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5064\n",
      "Epoch 19: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 41s 1ms/sample - loss: 1.5064 - val_loss: 1.4433\n",
      "Epoch 20/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5174\n",
      "Epoch 20: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 1.5174 - val_loss: 1.4438\n",
      "Epoch 21/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5185\n",
      "Epoch 21: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.5185 - val_loss: 1.4439\n",
      "Epoch 22/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5118\n",
      "Epoch 22: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5118 - val_loss: 1.4431\n",
      "Epoch 23/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5857\n",
      "Epoch 23: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.5857 - val_loss: 1.4744\n",
      "Epoch 24/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.5235\n",
      "Epoch 24: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.5235 - val_loss: 1.4580\n",
      "Epoch 25/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4903\n",
      "Epoch 25: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4903 - val_loss: 1.4466\n",
      "Epoch 26/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4808\n",
      "Epoch 26: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4808 - val_loss: 1.4427\n",
      "Epoch 27/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4714\n",
      "Epoch 27: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4714 - val_loss: 1.4363\n",
      "Epoch 28/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4647\n",
      "Epoch 28: val_loss did not improve from 1.43573\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4647 - val_loss: 1.4440\n",
      "Epoch 29/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4606\n",
      "Epoch 29: val_loss improved from 1.43573 to 1.43513, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4606 - val_loss: 1.4351\n",
      "Epoch 30/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4570\n",
      "Epoch 30: val_loss improved from 1.43513 to 1.43347, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4570 - val_loss: 1.4335\n",
      "Epoch 31/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4533\n",
      "Epoch 31: val_loss did not improve from 1.43347\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4533 - val_loss: 1.4337\n",
      "Epoch 32/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4506\n",
      "Epoch 32: val_loss improved from 1.43347 to 1.43127, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4506 - val_loss: 1.4313\n",
      "Epoch 33/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 33: val_loss improved from 1.43127 to 1.42342, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4483 - val_loss: 1.4234\n",
      "Epoch 34/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4463\n",
      "Epoch 34: val_loss did not improve from 1.42342\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4463 - val_loss: 1.4246\n",
      "Epoch 35/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 35: val_loss did not improve from 1.42342\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4432 - val_loss: 1.4267\n",
      "Epoch 36/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4398\n",
      "Epoch 36: val_loss did not improve from 1.42342\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4398 - val_loss: 1.4252\n",
      "Epoch 37/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4386\n",
      "Epoch 37: val_loss improved from 1.42342 to 1.42068, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4386 - val_loss: 1.4207\n",
      "Epoch 38/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4340\n",
      "Epoch 38: val_loss improved from 1.42068 to 1.41406, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 1.4340 - val_loss: 1.4141\n",
      "Epoch 39/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4346\n",
      "Epoch 39: val_loss did not improve from 1.41406\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4346 - val_loss: 1.4201\n",
      "Epoch 40/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 40: val_loss did not improve from 1.41406\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4311 - val_loss: 1.4177\n",
      "Epoch 41/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4314\n",
      "Epoch 41: val_loss did not improve from 1.41406\n",
      "32119/32119 [==============================] - 31s 956us/sample - loss: 1.4314 - val_loss: 1.4178\n",
      "Epoch 42/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4261\n",
      "Epoch 42: val_loss improved from 1.41406 to 1.40886, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4261 - val_loss: 1.4089\n",
      "Epoch 43/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4275\n",
      "Epoch 43: val_loss did not improve from 1.40886\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4275 - val_loss: 1.4124\n",
      "Epoch 44/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4244\n",
      "Epoch 44: val_loss did not improve from 1.40886\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4244 - val_loss: 1.4128\n",
      "Epoch 45/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4246\n",
      "Epoch 45: val_loss improved from 1.40886 to 1.40563, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4246 - val_loss: 1.4056\n",
      "Epoch 46/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4197\n",
      "Epoch 46: val_loss improved from 1.40563 to 1.40265, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_41.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4197 - val_loss: 1.4026\n",
      "Epoch 47/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4194\n",
      "Epoch 47: val_loss did not improve from 1.40265\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4194 - val_loss: 1.4083\n",
      "Epoch 48/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4199\n",
      "Epoch 48: val_loss did not improve from 1.40265\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4199 - val_loss: 1.4125\n",
      "Epoch 49/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 49: val_loss did not improve from 1.40265\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.4166 - val_loss: 1.4191\n",
      "Epoch 50/50\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4165\n",
      "Epoch 50: val_loss did not improve from 1.40265\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.4165 - val_loss: 1.4045\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:10:46.170331: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_420_1/lstm_cell_1271/kernel/Assign' id:648182 op device:{requested: '', assigned: ''} def:{{{node lstm_420_1/lstm_cell_1271/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_420_1/lstm_cell_1271/kernel, lstm_420_1/lstm_cell_1271/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 09:11:35.845245: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_415_1/lstm_cell_1266/recurrent_kernel/v/Assign' id:653482 op device:{requested: '', assigned: ''} def:{{{node lstm_415_1/lstm_cell_1266/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_415_1/lstm_cell_1266/recurrent_kernel/v, lstm_415_1/lstm_cell_1266/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 09:12:25.280418: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_59_1/cond/Merge' id:652053 op device:{requested: '', assigned: ''} def:{{{node dropout_59_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_59_1/cond/Identity, dropout_59_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1296)\n",
      "(1514, 1296)\n",
      "(1644, 1296)\n",
      "(1764, 1296)\n",
      "(1836, 1296)\n",
      "(1699, 1296)\n",
      "(1369, 1296)\n",
      "(1766, 1296)\n",
      "(1631, 1296)\n",
      "(1692, 1296)\n",
      "(1550, 1296)\n",
      "(1920, 1296)\n",
      "(1739, 1296)\n",
      "(1788, 1296)\n",
      "(1812, 1296)\n",
      "(1788, 1296)\n",
      "(1788, 1296)\n",
      "(946, 1296)\n",
      "(1560, 1296)\n",
      "{1: 4.953600883986915, 2: 1.2656085892084257, 4: 4.040565506897341, 5: 8.959978641926899, 6: 10.0, 8: 4.734411804784987, 9: 1.392871743102427, 10: 5.893791790305252, 11: 3.063539340476793, 12: 4.184682442347571, 13: 5.278796086948864, 17: 3.785712895214735, 19: 4.503546237354565, 21: 5.349116430235393, 22: 2.7391988312387774, 25: 3.42503585171342, 26: 3.318278858195929, 27: 1.0, 28: 4.482076924289153}\n",
      "Train on 32119 samples, validate on 3586 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:22:54.631926: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 8.0617\n",
      "Epoch 1: val_loss improved from inf to 1.43177, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 127s 4ms/sample - loss: 8.0617 - val_loss: 1.4318\n",
      "Epoch 2/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.9427\n",
      "Epoch 2: val_loss improved from 1.43177 to 1.43156, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 7.9427 - val_loss: 1.4316\n",
      "Epoch 3/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.9544\n",
      "Epoch 3: val_loss did not improve from 1.43156\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 7.9544 - val_loss: 1.4334\n",
      "Epoch 4/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7746\n",
      "Epoch 4: val_loss improved from 1.43156 to 1.42752, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 38s 1ms/sample - loss: 7.7746 - val_loss: 1.4275\n",
      "Epoch 5/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7773\n",
      "Epoch 5: val_loss improved from 1.42752 to 1.41275, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 7.7773 - val_loss: 1.4127\n",
      "Epoch 6/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7468\n",
      "Epoch 6: val_loss did not improve from 1.41275\n",
      "32119/32119 [==============================] - 37s 1ms/sample - loss: 7.7468 - val_loss: 1.4134\n",
      "Epoch 7/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7166\n",
      "Epoch 7: val_loss did not improve from 1.41275\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.7166 - val_loss: 1.4297\n",
      "Epoch 8/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7001\n",
      "Epoch 8: val_loss improved from 1.41275 to 1.40652, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 36s 1ms/sample - loss: 7.7001 - val_loss: 1.4065\n",
      "Epoch 9/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7228\n",
      "Epoch 9: val_loss did not improve from 1.40652\n",
      "32119/32119 [==============================] - 31s 978us/sample - loss: 7.7228 - val_loss: 1.4079\n",
      "Epoch 10/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.7213\n",
      "Epoch 10: val_loss did not improve from 1.40652\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 7.7213 - val_loss: 1.4075\n",
      "Epoch 11/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6634\n",
      "Epoch 11: val_loss did not improve from 1.40652\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.6634 - val_loss: 1.4124\n",
      "Epoch 12/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6361\n",
      "Epoch 12: val_loss did not improve from 1.40652\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 7.6361 - val_loss: 1.4149\n",
      "Epoch 13/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6520\n",
      "Epoch 13: val_loss did not improve from 1.40652\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.6520 - val_loss: 1.4205\n",
      "Epoch 14/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6252\n",
      "Epoch 14: val_loss improved from 1.40652 to 1.40313, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.6252 - val_loss: 1.4031\n",
      "Epoch 15/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6378\n",
      "Epoch 15: val_loss did not improve from 1.40313\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.6378 - val_loss: 1.4127\n",
      "Epoch 16/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6342\n",
      "Epoch 16: val_loss did not improve from 1.40313\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.6342 - val_loss: 1.4065\n",
      "Epoch 17/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6178\n",
      "Epoch 17: val_loss did not improve from 1.40313\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.6178 - val_loss: 1.4057\n",
      "Epoch 18/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6301\n",
      "Epoch 18: val_loss improved from 1.40313 to 1.40205, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.6301 - val_loss: 1.4020\n",
      "Epoch 19/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.5765\n",
      "Epoch 19: val_loss improved from 1.40205 to 1.39876, saving model to ./checkpoints/unknown_person_few_shot_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 7.5765 - val_loss: 1.3988\n",
      "Epoch 20/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 7.6323\n",
      "Epoch 20: val_loss did not improve from 1.39876\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 7.6323 - val_loss: 1.3998\n",
      "WARNING:tensorflow:Layer lstm_407 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_408 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_409 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_410 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_411 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_412 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_413 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_414 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_415 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_416 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_417 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_418 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_419 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_420 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_421 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_422 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_423 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_424 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_425 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_426 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_427 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_428 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_429 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_430 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_431 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_432 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_433 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_434 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_435 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_436 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_437 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_438 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_439 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_440 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_441 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_442 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_443 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:36:25.358964: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_413_2/lstm_cell_1301/kernel/Assign' id:666460 op device:{requested: '', assigned: ''} def:{{{node lstm_413_2/lstm_cell_1301/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_413_2/lstm_cell_1301/kernel, lstm_413_2/lstm_cell_1301/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 09:37:17.060571: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_442_2/lstm_cell_1330/kernel/m/Assign' id:672637 op device:{requested: '', assigned: ''} def:{{{node lstm_442_2/lstm_cell_1330/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_442_2/lstm_cell_1330/kernel/m, lstm_442_2/lstm_cell_1330/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32119 samples, validate on 3586 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:38:13.308718: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:42:25.080622: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_55_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:43:01.902040: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_71/mul' id:672041 op device:{requested: '', assigned: ''} def:{{{node loss_71/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_71/mul/x, loss_71/dense_47_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41271, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_41.h5\n",
      "32119/32119 [==============================] - 126s 4ms/sample - loss: 1.4211 - val_loss: 1.4127\n",
      "Epoch 2/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4150\n",
      "Epoch 2: val_loss improved from 1.41271 to 1.40345, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_41.h5\n",
      "32119/32119 [==============================] - 35s 1ms/sample - loss: 1.4150 - val_loss: 1.4034\n",
      "Epoch 3/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4176\n",
      "Epoch 3: val_loss did not improve from 1.40345\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4176 - val_loss: 1.4091\n",
      "Epoch 4/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4112\n",
      "Epoch 4: val_loss did not improve from 1.40345\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4112 - val_loss: 1.4082\n",
      "Epoch 5/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 5: val_loss improved from 1.40345 to 1.39988, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4124 - val_loss: 1.3999\n",
      "Epoch 6/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 6: val_loss did not improve from 1.39988\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4096 - val_loss: 1.4042\n",
      "Epoch 7/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4069\n",
      "Epoch 7: val_loss did not improve from 1.39988\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4069 - val_loss: 1.4052\n",
      "Epoch 8/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4083\n",
      "Epoch 8: val_loss did not improve from 1.39988\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4083 - val_loss: 1.4014\n",
      "Epoch 9/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4058\n",
      "Epoch 9: val_loss improved from 1.39988 to 1.39660, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_41.h5\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4058 - val_loss: 1.3966\n",
      "Epoch 10/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4022\n",
      "Epoch 10: val_loss did not improve from 1.39660\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4022 - val_loss: 1.4012\n",
      "Epoch 11/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4024\n",
      "Epoch 11: val_loss did not improve from 1.39660\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.4024 - val_loss: 1.3990\n",
      "Epoch 12/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4029\n",
      "Epoch 12: val_loss did not improve from 1.39660\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4029 - val_loss: 1.4003\n",
      "Epoch 13/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4012\n",
      "Epoch 13: val_loss did not improve from 1.39660\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4012 - val_loss: 1.4031\n",
      "Epoch 14/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 14: val_loss did not improve from 1.39660\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4008 - val_loss: 1.4016\n",
      "Epoch 15/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 15: val_loss improved from 1.39660 to 1.39453, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.4008 - val_loss: 1.3945\n",
      "Epoch 16/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3971\n",
      "Epoch 16: val_loss did not improve from 1.39453\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.3971 - val_loss: 1.3975\n",
      "Epoch 17/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 17: val_loss did not improve from 1.39453\n",
      "32119/32119 [==============================] - 32s 1ms/sample - loss: 1.3980 - val_loss: 1.4055\n",
      "Epoch 18/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3942\n",
      "Epoch 18: val_loss improved from 1.39453 to 1.39153, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_41.h5\n",
      "32119/32119 [==============================] - 34s 1ms/sample - loss: 1.3942 - val_loss: 1.3915\n",
      "Epoch 19/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 19: val_loss did not improve from 1.39153\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3949 - val_loss: 1.3977\n",
      "Epoch 20/20\n",
      "32119/32119 [==============================] - ETA: 0s - loss: 1.3935\n",
      "Epoch 20: val_loss did not improve from 1.39153\n",
      "32119/32119 [==============================] - 33s 1ms/sample - loss: 1.3935 - val_loss: 1.3938\n",
      "35921\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:55:57.734684: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_457/lstm_cell_1345/bias/Assign' id:686696 op device:{requested: '', assigned: ''} def:{{{node lstm_457/lstm_cell_1345/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_457/lstm_cell_1345/bias, lstm_457/lstm_cell_1345/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 09:56:25.940043: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_1' id:688140 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 09:56:48.376494: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_12/stack_2' id:688141 op device:{requested: '', assigned: ''} def:{{{node strided_slice_12/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32323, 95)\n",
      "Train on 32323 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 09:57:41.874927: W tensorflow/c/c_api.cc:304] Operation '{name:'training_72/Adam/lstm_448/lstm_cell_1336/recurrent_kernel/v/Assign' id:701606 op device:{requested: '', assigned: ''} def:{{{node training_72/Adam/lstm_448/lstm_cell_1336/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_72/Adam/lstm_448/lstm_cell_1336/recurrent_kernel/v, training_72/Adam/lstm_448/lstm_cell_1336/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 10:01:59.167517: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 2.8682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-24 10:02:35.614350: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_73/mul' id:690981 op device:{requested: '', assigned: ''} def:{{{node loss_73/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_73/mul/x, loss_73/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.81802, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 278s 9ms/sample - loss: 2.8682 - val_loss: 1.8180\n",
      "Epoch 2/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.7222\n",
      "Epoch 2: val_loss improved from 1.81802 to 1.59257, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.7222 - val_loss: 1.5926\n",
      "Epoch 3/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5884\n",
      "Epoch 3: val_loss improved from 1.59257 to 1.53365, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.5884 - val_loss: 1.5336\n",
      "Epoch 4/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5480\n",
      "Epoch 4: val_loss improved from 1.53365 to 1.50909, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.5480 - val_loss: 1.5091\n",
      "Epoch 5/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5255\n",
      "Epoch 5: val_loss improved from 1.50909 to 1.49357, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.5255 - val_loss: 1.4936\n",
      "Epoch 6/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5068\n",
      "Epoch 6: val_loss improved from 1.49357 to 1.49323, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.5068 - val_loss: 1.4932\n",
      "Epoch 7/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4954\n",
      "Epoch 7: val_loss improved from 1.49323 to 1.47638, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4954 - val_loss: 1.4764\n",
      "Epoch 8/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4930\n",
      "Epoch 8: val_loss improved from 1.47638 to 1.46833, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4930 - val_loss: 1.4683\n",
      "Epoch 9/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4882\n",
      "Epoch 9: val_loss improved from 1.46833 to 1.46212, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.4882 - val_loss: 1.4621\n",
      "Epoch 10/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4865\n",
      "Epoch 10: val_loss did not improve from 1.46212\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.4865 - val_loss: 1.4678\n",
      "Epoch 11/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4713\n",
      "Epoch 11: val_loss improved from 1.46212 to 1.45475, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4713 - val_loss: 1.4547\n",
      "Epoch 12/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4641\n",
      "Epoch 12: val_loss improved from 1.45475 to 1.45374, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4641 - val_loss: 1.4537\n",
      "Epoch 13/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4656\n",
      "Epoch 13: val_loss did not improve from 1.45374\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4656 - val_loss: 1.4553\n",
      "Epoch 14/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4628\n",
      "Epoch 14: val_loss improved from 1.45374 to 1.44671, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4628 - val_loss: 1.4467\n",
      "Epoch 15/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4678\n",
      "Epoch 15: val_loss improved from 1.44671 to 1.44164, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4678 - val_loss: 1.4416\n",
      "Epoch 16/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4955\n",
      "Epoch 16: val_loss improved from 1.44164 to 1.44054, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4955 - val_loss: 1.4405\n",
      "Epoch 17/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4550\n",
      "Epoch 17: val_loss improved from 1.44054 to 1.43825, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4550 - val_loss: 1.4383\n",
      "Epoch 18/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4720\n",
      "Epoch 18: val_loss did not improve from 1.43825\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4720 - val_loss: 1.4392\n",
      "Epoch 19/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5238\n",
      "Epoch 19: val_loss did not improve from 1.43825\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.5238 - val_loss: 1.4456\n",
      "Epoch 20/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4766\n",
      "Epoch 20: val_loss did not improve from 1.43825\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4766 - val_loss: 1.4390\n",
      "Epoch 21/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4710\n",
      "Epoch 21: val_loss did not improve from 1.43825\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4710 - val_loss: 1.4439\n",
      "Epoch 22/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 22: val_loss did not improve from 1.43825\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4827 - val_loss: 1.4418\n",
      "Epoch 23/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4541\n",
      "Epoch 23: val_loss improved from 1.43825 to 1.43543, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4541 - val_loss: 1.4354\n",
      "Epoch 24/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4374\n",
      "Epoch 24: val_loss improved from 1.43543 to 1.42878, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4374 - val_loss: 1.4288\n",
      "Epoch 25/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4336\n",
      "Epoch 25: val_loss improved from 1.42878 to 1.42777, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.4336 - val_loss: 1.4278\n",
      "Epoch 26/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4304\n",
      "Epoch 26: val_loss improved from 1.42777 to 1.42512, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4304 - val_loss: 1.4251\n",
      "Epoch 27/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4296\n",
      "Epoch 27: val_loss improved from 1.42512 to 1.42490, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4296 - val_loss: 1.4249\n",
      "Epoch 28/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 28: val_loss improved from 1.42490 to 1.42356, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4249 - val_loss: 1.4236\n",
      "Epoch 29/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4258\n",
      "Epoch 29: val_loss did not improve from 1.42356\n",
      "32323/32323 [==============================] - 32s 993us/sample - loss: 1.4258 - val_loss: 1.4314\n",
      "Epoch 30/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4207\n",
      "Epoch 30: val_loss improved from 1.42356 to 1.42062, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4207 - val_loss: 1.4206\n",
      "Epoch 31/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 31: val_loss improved from 1.42062 to 1.41984, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4191 - val_loss: 1.4198\n",
      "Epoch 32/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4166\n",
      "Epoch 32: val_loss improved from 1.41984 to 1.41662, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4166 - val_loss: 1.4166\n",
      "Epoch 33/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4152\n",
      "Epoch 33: val_loss improved from 1.41662 to 1.41459, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4152 - val_loss: 1.4146\n",
      "Epoch 34/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4109\n",
      "Epoch 34: val_loss improved from 1.41459 to 1.41458, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4109 - val_loss: 1.4146\n",
      "Epoch 35/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4119\n",
      "Epoch 35: val_loss did not improve from 1.41458\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4119 - val_loss: 1.4172\n",
      "Epoch 36/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4100\n",
      "Epoch 36: val_loss improved from 1.41458 to 1.41163, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4100 - val_loss: 1.4116\n",
      "Epoch 37/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4060\n",
      "Epoch 37: val_loss did not improve from 1.41163\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.4060 - val_loss: 1.4155\n",
      "Epoch 38/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4047\n",
      "Epoch 38: val_loss did not improve from 1.41163\n",
      "32323/32323 [==============================] - 32s 1ms/sample - loss: 1.4047 - val_loss: 1.4163\n",
      "Epoch 39/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4061\n",
      "Epoch 39: val_loss improved from 1.41163 to 1.41010, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4061 - val_loss: 1.4101\n",
      "Epoch 40/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4043\n",
      "Epoch 40: val_loss improved from 1.41010 to 1.40653, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4043 - val_loss: 1.4065\n",
      "Epoch 41/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 41: val_loss improved from 1.40653 to 1.40617, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4026 - val_loss: 1.4062\n",
      "Epoch 42/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4020\n",
      "Epoch 42: val_loss did not improve from 1.40617\n",
      "32323/32323 [==============================] - 32s 1ms/sample - loss: 1.4020 - val_loss: 1.4086\n",
      "Epoch 43/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4014\n",
      "Epoch 43: val_loss improved from 1.40617 to 1.40519, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.4014 - val_loss: 1.4052\n",
      "Epoch 44/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3987\n",
      "Epoch 44: val_loss did not improve from 1.40519\n",
      "32323/32323 [==============================] - 32s 994us/sample - loss: 1.3987 - val_loss: 1.4103\n",
      "Epoch 45/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3954\n",
      "Epoch 45: val_loss did not improve from 1.40519\n",
      "32323/32323 [==============================] - 32s 1ms/sample - loss: 1.3954 - val_loss: 1.4098\n",
      "Epoch 46/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3947\n",
      "Epoch 46: val_loss improved from 1.40519 to 1.40470, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3947 - val_loss: 1.4047\n",
      "Epoch 47/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3934\n",
      "Epoch 47: val_loss improved from 1.40470 to 1.40278, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3934 - val_loss: 1.4028\n",
      "Epoch 48/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3931\n",
      "Epoch 48: val_loss improved from 1.40278 to 1.40077, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3931 - val_loss: 1.4008\n",
      "Epoch 49/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 49: val_loss did not improve from 1.40077\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3917 - val_loss: 1.4060\n",
      "Epoch 50/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3908\n",
      "Epoch 50: val_loss did not improve from 1.40077\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3908 - val_loss: 1.4042\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 10:34:19.913187: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_446_1/lstm_cell_1371/recurrent_kernel/Assign' id:703484 op device:{requested: '', assigned: ''} def:{{{node lstm_446_1/lstm_cell_1371/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_446_1/lstm_cell_1371/recurrent_kernel, lstm_446_1/lstm_cell_1371/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 10:35:13.045651: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_447_1/lstm_cell_1372/recurrent_kernel/v/Assign' id:710449 op device:{requested: '', assigned: ''} def:{{{node lstm_447_1/lstm_cell_1372/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_447_1/lstm_cell_1372/recurrent_kernel/v, lstm_447_1/lstm_cell_1372/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-24 10:36:08.011602: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_64_1/cond/Merge' id:709095 op device:{requested: '', assigned: ''} def:{{{node dropout_64_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_64_1/cond/Identity, dropout_64_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1080)\n",
      "(1514, 1080)\n",
      "(1644, 1080)\n",
      "(1764, 1080)\n",
      "(1836, 1080)\n",
      "(1699, 1080)\n",
      "(1369, 1080)\n",
      "(1766, 1080)\n",
      "(1631, 1080)\n",
      "(1692, 1080)\n",
      "(1550, 1080)\n",
      "(1920, 1080)\n",
      "(1739, 1080)\n",
      "(1788, 1080)\n",
      "(1812, 1080)\n",
      "(1788, 1080)\n",
      "(1788, 1080)\n",
      "(946, 1080)\n",
      "(1632, 1080)\n",
      "{1: 4.16775967909941, 2: 1.4529462768346346, 4: 4.119935421629922, 5: 7.947517595204461, 6: 10.0, 8: 4.67381676811619, 9: 1.5049400402488322, 10: 5.776933995234195, 11: 3.400109195564345, 12: 4.155578990795005, 13: 4.457539128073284, 17: 3.8796898004138747, 19: 4.681774526404375, 21: 5.1440311618831664, 22: 1.0, 25: 3.5636815606952092, 26: 3.0291615833977414, 27: 1.402816285006089, 28: 4.232089546298771}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2920137/1660627543.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32323 samples, validate on 3598 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 10:46:47.646972: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 7.7916\n",
      "Epoch 1: val_loss improved from inf to 1.42801, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 127s 4ms/sample - loss: 7.7916 - val_loss: 1.4280\n",
      "Epoch 2/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.6689\n",
      "Epoch 2: val_loss improved from 1.42801 to 1.42502, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.6689 - val_loss: 1.4250\n",
      "Epoch 3/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.5798\n",
      "Epoch 3: val_loss improved from 1.42502 to 1.41344, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.5798 - val_loss: 1.4134\n",
      "Epoch 4/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.5491\n",
      "Epoch 4: val_loss did not improve from 1.41344\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 7.5491 - val_loss: 1.4353\n",
      "Epoch 5/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.5246\n",
      "Epoch 5: val_loss improved from 1.41344 to 1.40846, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.5246 - val_loss: 1.4085\n",
      "Epoch 6/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4851\n",
      "Epoch 6: val_loss did not improve from 1.40846\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 7.4851 - val_loss: 1.4367\n",
      "Epoch 7/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4763\n",
      "Epoch 7: val_loss improved from 1.40846 to 1.40813, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.4763 - val_loss: 1.4081\n",
      "Epoch 8/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.5197\n",
      "Epoch 8: val_loss did not improve from 1.40813\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.5197 - val_loss: 1.4106\n",
      "Epoch 9/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4616\n",
      "Epoch 9: val_loss did not improve from 1.40813\n",
      "32323/32323 [==============================] - 32s 1ms/sample - loss: 7.4616 - val_loss: 1.4124\n",
      "Epoch 10/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4450\n",
      "Epoch 10: val_loss improved from 1.40813 to 1.40438, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 7.4450 - val_loss: 1.4044\n",
      "Epoch 11/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4332\n",
      "Epoch 11: val_loss did not improve from 1.40438\n",
      "32323/32323 [==============================] - 32s 997us/sample - loss: 7.4332 - val_loss: 1.4061\n",
      "Epoch 12/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3734\n",
      "Epoch 12: val_loss did not improve from 1.40438\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.3734 - val_loss: 1.4141\n",
      "Epoch 13/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3890\n",
      "Epoch 13: val_loss did not improve from 1.40438\n",
      "32323/32323 [==============================] - 32s 1ms/sample - loss: 7.3890 - val_loss: 1.4071\n",
      "Epoch 14/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3602\n",
      "Epoch 14: val_loss improved from 1.40438 to 1.40135, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.3602 - val_loss: 1.4014\n",
      "Epoch 15/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3562\n",
      "Epoch 15: val_loss did not improve from 1.40135\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.3562 - val_loss: 1.4040\n",
      "Epoch 16/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3124\n",
      "Epoch 16: val_loss did not improve from 1.40135\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 7.3124 - val_loss: 1.4038\n",
      "Epoch 17/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3471\n",
      "Epoch 17: val_loss did not improve from 1.40135\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 7.3471 - val_loss: 1.4017\n",
      "Epoch 18/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3259\n",
      "Epoch 18: val_loss improved from 1.40135 to 1.40007, saving model to ./checkpoints/unknown_person_few_shot_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 7.3259 - val_loss: 1.4001\n",
      "Epoch 19/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3173\n",
      "Epoch 19: val_loss did not improve from 1.40007\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 7.3173 - val_loss: 1.4078\n",
      "Epoch 20/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3001\n",
      "Epoch 20: val_loss did not improve from 1.40007\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 7.3001 - val_loss: 1.4007\n",
      "WARNING:tensorflow:Layer lstm_444 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_445 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_446 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_447 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_448 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_449 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_450 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_451 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_452 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_453 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_454 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_455 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_456 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_457 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_458 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_459 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_460 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_461 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_462 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_463 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_464 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_465 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_466 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_467 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_468 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_469 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_470 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_471 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_472 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_473 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_474 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_475 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_476 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_477 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_478 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_479 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_480 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 10:59:53.685178: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_472_2/lstm_cell_1434/bias/Assign' id:727053 op device:{requested: '', assigned: ''} def:{{{node lstm_472_2/lstm_cell_1434/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_472_2/lstm_cell_1434/bias, lstm_472_2/lstm_cell_1434/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 11:00:48.655238: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_480_2/lstm_cell_1442/recurrent_kernel/v/Assign' id:730342 op device:{requested: '', assigned: ''} def:{{{node lstm_480_2/lstm_cell_1442/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_480_2/lstm_cell_1442/recurrent_kernel/v, lstm_480_2/lstm_cell_1442/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32323 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:01:47.506170: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:06:18.923042: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_60_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:06:55.714364: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_77/mul' id:729083 op device:{requested: '', assigned: ''} def:{{{node loss_77/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_77/mul/x, loss_77/dense_51_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40122, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 130s 4ms/sample - loss: 1.3929 - val_loss: 1.4012\n",
      "Epoch 2/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3913\n",
      "Epoch 2: val_loss did not improve from 1.40122\n",
      "32323/32323 [==============================] - 32s 997us/sample - loss: 1.3913 - val_loss: 1.4036\n",
      "Epoch 3/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3885\n",
      "Epoch 3: val_loss improved from 1.40122 to 1.39898, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3885 - val_loss: 1.3990\n",
      "Epoch 4/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3850\n",
      "Epoch 4: val_loss did not improve from 1.39898\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3850 - val_loss: 1.3996\n",
      "Epoch 5/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3850\n",
      "Epoch 5: val_loss improved from 1.39898 to 1.39878, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3850 - val_loss: 1.3988\n",
      "Epoch 6/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3845\n",
      "Epoch 6: val_loss improved from 1.39878 to 1.39544, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3845 - val_loss: 1.3954\n",
      "Epoch 7/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3854\n",
      "Epoch 7: val_loss improved from 1.39544 to 1.39516, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.3854 - val_loss: 1.3952\n",
      "Epoch 8/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3798\n",
      "Epoch 8: val_loss improved from 1.39516 to 1.39438, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3798 - val_loss: 1.3944\n",
      "Epoch 9/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3824\n",
      "Epoch 9: val_loss improved from 1.39438 to 1.39229, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3824 - val_loss: 1.3923\n",
      "Epoch 10/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3805\n",
      "Epoch 10: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3805 - val_loss: 1.3937\n",
      "Epoch 11/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 11: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3796 - val_loss: 1.3985\n",
      "Epoch 12/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3776\n",
      "Epoch 12: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3776 - val_loss: 1.3945\n",
      "Epoch 13/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3766\n",
      "Epoch 13: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3766 - val_loss: 1.3965\n",
      "Epoch 14/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3746\n",
      "Epoch 14: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.3746 - val_loss: 1.3946\n",
      "Epoch 15/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3769\n",
      "Epoch 15: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3769 - val_loss: 1.3977\n",
      "Epoch 16/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3756\n",
      "Epoch 16: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3756 - val_loss: 1.3971\n",
      "Epoch 17/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3714\n",
      "Epoch 17: val_loss did not improve from 1.39229\n",
      "32323/32323 [==============================] - 35s 1ms/sample - loss: 1.3714 - val_loss: 1.3937\n",
      "Epoch 18/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3705\n",
      "Epoch 18: val_loss improved from 1.39229 to 1.39080, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_42.h5\n",
      "32323/32323 [==============================] - 34s 1ms/sample - loss: 1.3705 - val_loss: 1.3908\n",
      "Epoch 19/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3687\n",
      "Epoch 19: val_loss did not improve from 1.39080\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3687 - val_loss: 1.3918\n",
      "Epoch 20/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3686\n",
      "Epoch 20: val_loss did not improve from 1.39080\n",
      "32323/32323 [==============================] - 33s 1ms/sample - loss: 1.3686 - val_loss: 1.3918\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:19:32.701814: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_491/lstm_cell_1453/recurrent_kernel/Assign' id:743234 op device:{requested: '', assigned: ''} def:{{{node lstm_491/lstm_cell_1453/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_491/lstm_cell_1453/recurrent_kernel, lstm_491/lstm_cell_1453/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 11:20:03.771134: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_1' id:745182 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 11:20:29.296284: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_13/stack_2' id:745183 op device:{requested: '', assigned: ''} def:{{{node strided_slice_13/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32323, 95)\n",
      "Train on 32323 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:21:27.928095: W tensorflow/c/c_api.cc:304] Operation '{name:'training_78/Adam/lstm_497/lstm_cell_1459/kernel/v/Assign' id:758823 op device:{requested: '', assigned: ''} def:{{{node training_78/Adam/lstm_497/lstm_cell_1459/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_78/Adam/lstm_497/lstm_cell_1459/kernel/v, training_78/Adam/lstm_497/lstm_cell_1459/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:25:13.516897: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 2.8032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:25:38.550291: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_79/mul' id:748023 op device:{requested: '', assigned: ''} def:{{{node loss_79/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_79/mul/x, loss_79/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.84615, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 203s 6ms/sample - loss: 2.8032 - val_loss: 1.8462\n",
      "Epoch 2/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.7384\n",
      "Epoch 2: val_loss improved from 1.84615 to 1.59252, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 653us/sample - loss: 1.7384 - val_loss: 1.5925\n",
      "Epoch 3/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5840\n",
      "Epoch 3: val_loss improved from 1.59252 to 1.52978, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 634us/sample - loss: 1.5840 - val_loss: 1.5298\n",
      "Epoch 4/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5389\n",
      "Epoch 4: val_loss improved from 1.52978 to 1.49872, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 664us/sample - loss: 1.5389 - val_loss: 1.4987\n",
      "Epoch 5/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5126\n",
      "Epoch 5: val_loss improved from 1.49872 to 1.48071, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 644us/sample - loss: 1.5126 - val_loss: 1.4807\n",
      "Epoch 6/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4992\n",
      "Epoch 6: val_loss improved from 1.48071 to 1.47162, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 702us/sample - loss: 1.4992 - val_loss: 1.4716\n",
      "Epoch 7/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4877\n",
      "Epoch 7: val_loss improved from 1.47162 to 1.46420, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 724us/sample - loss: 1.4877 - val_loss: 1.4642\n",
      "Epoch 8/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4876\n",
      "Epoch 8: val_loss improved from 1.46420 to 1.45438, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 706us/sample - loss: 1.4876 - val_loss: 1.4544\n",
      "Epoch 9/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4825\n",
      "Epoch 9: val_loss improved from 1.45438 to 1.45106, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 22s 678us/sample - loss: 1.4825 - val_loss: 1.4511\n",
      "Epoch 10/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4896\n",
      "Epoch 10: val_loss did not improve from 1.45106\n",
      "32323/32323 [==============================] - 23s 699us/sample - loss: 1.4896 - val_loss: 1.4515\n",
      "Epoch 11/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4702\n",
      "Epoch 11: val_loss improved from 1.45106 to 1.44669, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 24s 740us/sample - loss: 1.4702 - val_loss: 1.4467\n",
      "Epoch 12/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4764\n",
      "Epoch 12: val_loss improved from 1.44669 to 1.44386, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 721us/sample - loss: 1.4764 - val_loss: 1.4439\n",
      "Epoch 13/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4899\n",
      "Epoch 13: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 713us/sample - loss: 1.4899 - val_loss: 1.4567\n",
      "Epoch 14/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4726\n",
      "Epoch 14: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 21s 643us/sample - loss: 1.4726 - val_loss: 1.4489\n",
      "Epoch 15/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4745\n",
      "Epoch 15: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 21s 640us/sample - loss: 1.4745 - val_loss: 1.4516\n",
      "Epoch 16/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4809\n",
      "Epoch 16: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 21s 653us/sample - loss: 1.4809 - val_loss: 1.4584\n",
      "Epoch 17/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4958\n",
      "Epoch 17: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 710us/sample - loss: 1.4958 - val_loss: 1.4538\n",
      "Epoch 18/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4786\n",
      "Epoch 18: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 711us/sample - loss: 1.4786 - val_loss: 1.4479\n",
      "Epoch 19/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4827\n",
      "Epoch 19: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 711us/sample - loss: 1.4827 - val_loss: 1.4511\n",
      "Epoch 20/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5089\n",
      "Epoch 20: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 711us/sample - loss: 1.5089 - val_loss: 1.4486\n",
      "Epoch 21/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4883\n",
      "Epoch 21: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 714us/sample - loss: 1.4883 - val_loss: 1.4460\n",
      "Epoch 22/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5392\n",
      "Epoch 22: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 711us/sample - loss: 1.5392 - val_loss: 1.4551\n",
      "Epoch 23/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5117\n",
      "Epoch 23: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 710us/sample - loss: 1.5117 - val_loss: 1.4517\n",
      "Epoch 24/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4846\n",
      "Epoch 24: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 29s 893us/sample - loss: 1.4846 - val_loss: 1.4449\n",
      "Epoch 25/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4621\n",
      "Epoch 25: val_loss did not improve from 1.44386\n",
      "32323/32323 [==============================] - 23s 718us/sample - loss: 1.4621 - val_loss: 1.4461\n",
      "Epoch 26/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4551\n",
      "Epoch 26: val_loss improved from 1.44386 to 1.44008, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 725us/sample - loss: 1.4551 - val_loss: 1.4401\n",
      "Epoch 27/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4488\n",
      "Epoch 27: val_loss did not improve from 1.44008\n",
      "32323/32323 [==============================] - 21s 638us/sample - loss: 1.4488 - val_loss: 1.4409\n",
      "Epoch 28/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4455\n",
      "Epoch 28: val_loss improved from 1.44008 to 1.43754, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 648us/sample - loss: 1.4455 - val_loss: 1.4375\n",
      "Epoch 29/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 29: val_loss improved from 1.43754 to 1.43700, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 696us/sample - loss: 1.4412 - val_loss: 1.4370\n",
      "Epoch 30/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4397\n",
      "Epoch 30: val_loss improved from 1.43700 to 1.43297, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 1.4397 - val_loss: 1.4330\n",
      "Epoch 31/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4352\n",
      "Epoch 31: val_loss improved from 1.43297 to 1.42996, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 648us/sample - loss: 1.4352 - val_loss: 1.4300\n",
      "Epoch 32/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4334\n",
      "Epoch 32: val_loss did not improve from 1.42996\n",
      "32323/32323 [==============================] - 22s 691us/sample - loss: 1.4334 - val_loss: 1.4323\n",
      "Epoch 33/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4293\n",
      "Epoch 33: val_loss improved from 1.42996 to 1.42670, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 723us/sample - loss: 1.4293 - val_loss: 1.4267\n",
      "Epoch 34/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4288\n",
      "Epoch 34: val_loss improved from 1.42670 to 1.42628, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 718us/sample - loss: 1.4288 - val_loss: 1.4263\n",
      "Epoch 35/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4273\n",
      "Epoch 35: val_loss improved from 1.42628 to 1.42352, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 650us/sample - loss: 1.4273 - val_loss: 1.4235\n",
      "Epoch 36/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4259\n",
      "Epoch 36: val_loss improved from 1.42352 to 1.42300, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 658us/sample - loss: 1.4259 - val_loss: 1.4230\n",
      "Epoch 37/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4261\n",
      "Epoch 37: val_loss did not improve from 1.42300\n",
      "32323/32323 [==============================] - 23s 710us/sample - loss: 1.4261 - val_loss: 1.4253\n",
      "Epoch 38/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4201\n",
      "Epoch 38: val_loss did not improve from 1.42300\n",
      "32323/32323 [==============================] - 23s 710us/sample - loss: 1.4201 - val_loss: 1.4249\n",
      "Epoch 39/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4206\n",
      "Epoch 39: val_loss improved from 1.42300 to 1.41993, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 719us/sample - loss: 1.4206 - val_loss: 1.4199\n",
      "Epoch 40/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4180\n",
      "Epoch 40: val_loss improved from 1.41993 to 1.41743, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 661us/sample - loss: 1.4180 - val_loss: 1.4174\n",
      "Epoch 41/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 41: val_loss did not improve from 1.41743\n",
      "32323/32323 [==============================] - 22s 668us/sample - loss: 1.4178 - val_loss: 1.4189\n",
      "Epoch 42/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 42: val_loss did not improve from 1.41743\n",
      "32323/32323 [==============================] - 21s 637us/sample - loss: 1.4145 - val_loss: 1.4186\n",
      "Epoch 43/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4163\n",
      "Epoch 43: val_loss did not improve from 1.41743\n",
      "32323/32323 [==============================] - 21s 664us/sample - loss: 1.4163 - val_loss: 1.4175\n",
      "Epoch 44/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4127\n",
      "Epoch 44: val_loss improved from 1.41743 to 1.41533, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 721us/sample - loss: 1.4127 - val_loss: 1.4153\n",
      "Epoch 45/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 45: val_loss improved from 1.41533 to 1.41415, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 22s 679us/sample - loss: 1.4096 - val_loss: 1.4142\n",
      "Epoch 46/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4090\n",
      "Epoch 46: val_loss improved from 1.41415 to 1.40947, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 22s 679us/sample - loss: 1.4090 - val_loss: 1.4095\n",
      "Epoch 47/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4082\n",
      "Epoch 47: val_loss did not improve from 1.40947\n",
      "32323/32323 [==============================] - 23s 724us/sample - loss: 1.4082 - val_loss: 1.4112\n",
      "Epoch 48/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4090\n",
      "Epoch 48: val_loss did not improve from 1.40947\n",
      "32323/32323 [==============================] - 24s 731us/sample - loss: 1.4090 - val_loss: 1.4120\n",
      "Epoch 49/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 49: val_loss did not improve from 1.40947\n",
      "32323/32323 [==============================] - 23s 707us/sample - loss: 1.4066 - val_loss: 1.4101\n",
      "Epoch 50/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4037\n",
      "Epoch 50: val_loss improved from 1.40947 to 1.40488, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_43.h5\n",
      "32323/32323 [==============================] - 24s 745us/sample - loss: 1.4037 - val_loss: 1.4049\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:47:09.934876: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_53_1/bias/Assign' id:766152 op device:{requested: '', assigned: ''} def:{{{node dense_53_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_53_1/bias, dense_53_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 11:47:49.786760: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_54_1/bias/v/Assign' id:767426 op device:{requested: '', assigned: ''} def:{{{node conv2d_54_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_54_1/bias/v, conv2d_54_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 11:48:29.643984: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_69_1/cond/Merge' id:766137 op device:{requested: '', assigned: ''} def:{{{node dropout_69_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_69_1/cond/Identity, dropout_69_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1080)\n",
      "(1514, 1080)\n",
      "(1644, 1080)\n",
      "(1764, 1080)\n",
      "(1836, 1080)\n",
      "(1699, 1080)\n",
      "(1369, 1080)\n",
      "(1766, 1080)\n",
      "(1631, 1080)\n",
      "(1692, 1080)\n",
      "(1550, 1080)\n",
      "(1920, 1080)\n",
      "(1739, 1080)\n",
      "(1788, 1080)\n",
      "(1812, 1080)\n",
      "(1788, 1080)\n",
      "(1788, 1080)\n",
      "(946, 1080)\n",
      "(1632, 1080)\n",
      "{1: 4.48888227541346, 2: 1.5738317577566239, 4: 4.492091487222812, 5: 9.180401864634348, 6: 10.0, 8: 4.748680314502757, 9: 1.232409884920956, 10: 6.420274812761692, 11: 3.2872620348871497, 12: 4.53113031457133, 13: 5.473369713543559, 17: 4.382235229739793, 19: 4.934873846432358, 21: 5.704753884997758, 22: 3.0804209279010797, 25: 3.952447709733649, 26: 3.8177126548547555, 27: 1.0, 28: 5.142122276455768}\n",
      "Train on 32323 samples, validate on 3598 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 11:56:00.983148: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 8.4730\n",
      "Epoch 1: val_loss improved from inf to 1.42624, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 92s 3ms/sample - loss: 8.4730 - val_loss: 1.4262\n",
      "Epoch 2/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.3103\n",
      "Epoch 2: val_loss did not improve from 1.42624\n",
      "32323/32323 [==============================] - 20s 630us/sample - loss: 8.3103 - val_loss: 1.4289\n",
      "Epoch 3/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.3169\n",
      "Epoch 3: val_loss improved from 1.42624 to 1.41471, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 640us/sample - loss: 8.3169 - val_loss: 1.4147\n",
      "Epoch 4/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.2258\n",
      "Epoch 4: val_loss did not improve from 1.41471\n",
      "32323/32323 [==============================] - 20s 626us/sample - loss: 8.2258 - val_loss: 1.4163\n",
      "Epoch 5/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1990\n",
      "Epoch 5: val_loss did not improve from 1.41471\n",
      "32323/32323 [==============================] - 20s 633us/sample - loss: 8.1990 - val_loss: 1.4150\n",
      "Epoch 6/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.2120\n",
      "Epoch 6: val_loss improved from 1.41471 to 1.40853, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 22s 677us/sample - loss: 8.2120 - val_loss: 1.4085\n",
      "Epoch 7/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1521\n",
      "Epoch 7: val_loss improved from 1.40853 to 1.40659, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 699us/sample - loss: 8.1521 - val_loss: 1.4066\n",
      "Epoch 8/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1680\n",
      "Epoch 8: val_loss improved from 1.40659 to 1.40613, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 706us/sample - loss: 8.1680 - val_loss: 1.4061\n",
      "Epoch 9/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1613\n",
      "Epoch 9: val_loss did not improve from 1.40613\n",
      "32323/32323 [==============================] - 20s 630us/sample - loss: 8.1613 - val_loss: 1.4130\n",
      "Epoch 10/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1315\n",
      "Epoch 10: val_loss did not improve from 1.40613\n",
      "32323/32323 [==============================] - 21s 655us/sample - loss: 8.1315 - val_loss: 1.4107\n",
      "Epoch 11/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1067\n",
      "Epoch 11: val_loss improved from 1.40613 to 1.39878, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 23s 720us/sample - loss: 8.1067 - val_loss: 1.3988\n",
      "Epoch 12/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0938\n",
      "Epoch 12: val_loss did not improve from 1.39878\n",
      "32323/32323 [==============================] - 20s 629us/sample - loss: 8.0938 - val_loss: 1.4154\n",
      "Epoch 13/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0944\n",
      "Epoch 13: val_loss did not improve from 1.39878\n",
      "32323/32323 [==============================] - 20s 626us/sample - loss: 8.0944 - val_loss: 1.4094\n",
      "Epoch 14/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0779\n",
      "Epoch 14: val_loss did not improve from 1.39878\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 8.0779 - val_loss: 1.4150\n",
      "Epoch 15/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.1206\n",
      "Epoch 15: val_loss did not improve from 1.39878\n",
      "32323/32323 [==============================] - 20s 617us/sample - loss: 8.1206 - val_loss: 1.4164\n",
      "Epoch 16/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0712\n",
      "Epoch 16: val_loss improved from 1.39878 to 1.39796, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 627us/sample - loss: 8.0712 - val_loss: 1.3980\n",
      "Epoch 17/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0530\n",
      "Epoch 17: val_loss did not improve from 1.39796\n",
      "32323/32323 [==============================] - 20s 615us/sample - loss: 8.0530 - val_loss: 1.4052\n",
      "Epoch 18/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0389\n",
      "Epoch 18: val_loss did not improve from 1.39796\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 8.0389 - val_loss: 1.4106\n",
      "Epoch 19/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0351\n",
      "Epoch 19: val_loss did not improve from 1.39796\n",
      "32323/32323 [==============================] - 20s 626us/sample - loss: 8.0351 - val_loss: 1.4153\n",
      "Epoch 20/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 8.0745\n",
      "Epoch 20: val_loss improved from 1.39796 to 1.39609, saving model to ./checkpoints/unknown_person_few_shot_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 631us/sample - loss: 8.0745 - val_loss: 1.3961\n",
      "WARNING:tensorflow:Layer lstm_481 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_482 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_483 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_484 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_485 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_486 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_487 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_488 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_489 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_490 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_491 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_492 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_493 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_494 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_495 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_496 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_497 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_498 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_499 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_500 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_501 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_502 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_503 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_504 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_505 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_506 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_507 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_508 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_509 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_510 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_511 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_512 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_513 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_514 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_515 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_516 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_517 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:04:24.168990: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_494_2/lstm_cell_1530/recurrent_kernel/Assign' id:781684 op device:{requested: '', assigned: ''} def:{{{node lstm_494_2/lstm_cell_1530/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_494_2/lstm_cell_1530/recurrent_kernel, lstm_494_2/lstm_cell_1530/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 12:05:04.663589: W tensorflow/c/c_api.cc:304] Operation '{name:'conv2d_53_2/kernel/m/Assign' id:786166 op device:{requested: '', assigned: ''} def:{{{node conv2d_53_2/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv2d_53_2/kernel/m, conv2d_53_2/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32323 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:05:47.645427: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:09:13.814817: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_65_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:09:36.555223: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_83/mul' id:786125 op device:{requested: '', assigned: ''} def:{{{node loss_83/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_83/mul/x, loss_83/dense_55_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40917, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 93s 3ms/sample - loss: 1.3994 - val_loss: 1.4092\n",
      "Epoch 2/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4006\n",
      "Epoch 2: val_loss improved from 1.40917 to 1.40544, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 637us/sample - loss: 1.4006 - val_loss: 1.4054\n",
      "Epoch 3/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4008\n",
      "Epoch 3: val_loss did not improve from 1.40544\n",
      "32323/32323 [==============================] - 20s 630us/sample - loss: 1.4008 - val_loss: 1.4064\n",
      "Epoch 4/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3988\n",
      "Epoch 4: val_loss improved from 1.40544 to 1.40194, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 635us/sample - loss: 1.3988 - val_loss: 1.4019\n",
      "Epoch 5/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3962\n",
      "Epoch 5: val_loss did not improve from 1.40194\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.3962 - val_loss: 1.4033\n",
      "Epoch 6/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3975\n",
      "Epoch 6: val_loss did not improve from 1.40194\n",
      "32323/32323 [==============================] - 20s 616us/sample - loss: 1.3975 - val_loss: 1.4033\n",
      "Epoch 7/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3949\n",
      "Epoch 7: val_loss did not improve from 1.40194\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 1.3949 - val_loss: 1.4050\n",
      "Epoch 8/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3932\n",
      "Epoch 8: val_loss improved from 1.40194 to 1.39819, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 21s 653us/sample - loss: 1.3932 - val_loss: 1.3982\n",
      "Epoch 9/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3904\n",
      "Epoch 9: val_loss did not improve from 1.39819\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.3904 - val_loss: 1.4017\n",
      "Epoch 10/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3869\n",
      "Epoch 10: val_loss improved from 1.39819 to 1.39380, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 630us/sample - loss: 1.3869 - val_loss: 1.3938\n",
      "Epoch 11/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3899\n",
      "Epoch 11: val_loss did not improve from 1.39380\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 1.3899 - val_loss: 1.4010\n",
      "Epoch 12/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3894\n",
      "Epoch 12: val_loss did not improve from 1.39380\n",
      "32323/32323 [==============================] - 20s 618us/sample - loss: 1.3894 - val_loss: 1.4014\n",
      "Epoch 13/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3875\n",
      "Epoch 13: val_loss did not improve from 1.39380\n",
      "32323/32323 [==============================] - 20s 629us/sample - loss: 1.3875 - val_loss: 1.3960\n",
      "Epoch 14/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3863\n",
      "Epoch 14: val_loss did not improve from 1.39380\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.3863 - val_loss: 1.3996\n",
      "Epoch 15/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3833\n",
      "Epoch 15: val_loss improved from 1.39380 to 1.39376, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 624us/sample - loss: 1.3833 - val_loss: 1.3938\n",
      "Epoch 16/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3844\n",
      "Epoch 16: val_loss did not improve from 1.39376\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 1.3844 - val_loss: 1.3977\n",
      "Epoch 17/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3831\n",
      "Epoch 17: val_loss did not improve from 1.39376\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.3831 - val_loss: 1.3962\n",
      "Epoch 18/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3835\n",
      "Epoch 18: val_loss did not improve from 1.39376\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 1.3835 - val_loss: 1.3939\n",
      "Epoch 19/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3829\n",
      "Epoch 19: val_loss improved from 1.39376 to 1.39281, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_43.h5\n",
      "32323/32323 [==============================] - 20s 626us/sample - loss: 1.3829 - val_loss: 1.3928\n",
      "Epoch 20/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3809\n",
      "Epoch 20: val_loss did not improve from 1.39281\n",
      "32323/32323 [==============================] - 20s 618us/sample - loss: 1.3809 - val_loss: 1.3993\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:17:26.571330: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_519/lstm_cell_1555/kernel/Assign' id:798771 op device:{requested: '', assigned: ''} def:{{{node lstm_519/lstm_cell_1555/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_519/lstm_cell_1555/kernel, lstm_519/lstm_cell_1555/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 12:17:49.153391: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_1' id:802224 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 12:18:07.378361: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_14/stack_2' id:802225 op device:{requested: '', assigned: ''} def:{{{node strided_slice_14/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32323, 95)\n",
      "Train on 32323 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:18:48.395531: W tensorflow/c/c_api.cc:304] Operation '{name:'training_84/Adam/lstm_521/lstm_cell_1557/recurrent_kernel/v/Assign' id:815675 op device:{requested: '', assigned: ''} def:{{{node training_84/Adam/lstm_521/lstm_cell_1557/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_84/Adam/lstm_521/lstm_cell_1557/recurrent_kernel/v, training_84/Adam/lstm_521/lstm_cell_1557/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:22:24.248601: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 3.3742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:22:46.493198: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_85/mul' id:805065 op device:{requested: '', assigned: ''} def:{{{node loss_85/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_85/mul/x, loss_85/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.93865, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 215s 7ms/sample - loss: 3.3742 - val_loss: 1.9386\n",
      "Epoch 2/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.8013\n",
      "Epoch 2: val_loss improved from 1.93865 to 1.60469, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 1.8013 - val_loss: 1.6047\n",
      "Epoch 3/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.6155\n",
      "Epoch 3: val_loss improved from 1.60469 to 1.54109, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 1.6155 - val_loss: 1.5411\n",
      "Epoch 4/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5570\n",
      "Epoch 4: val_loss improved from 1.54109 to 1.50936, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 1.5570 - val_loss: 1.5094\n",
      "Epoch 5/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5235\n",
      "Epoch 5: val_loss improved from 1.50936 to 1.49358, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.5235 - val_loss: 1.4936\n",
      "Epoch 6/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5042\n",
      "Epoch 6: val_loss improved from 1.49358 to 1.47924, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 21s 657us/sample - loss: 1.5042 - val_loss: 1.4792\n",
      "Epoch 7/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4966\n",
      "Epoch 7: val_loss improved from 1.47924 to 1.47205, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 630us/sample - loss: 1.4966 - val_loss: 1.4720\n",
      "Epoch 8/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4954\n",
      "Epoch 8: val_loss did not improve from 1.47205\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 1.4954 - val_loss: 1.4758\n",
      "Epoch 9/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4858\n",
      "Epoch 9: val_loss improved from 1.47205 to 1.46399, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 623us/sample - loss: 1.4858 - val_loss: 1.4640\n",
      "Epoch 10/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4892\n",
      "Epoch 10: val_loss improved from 1.46399 to 1.46186, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 630us/sample - loss: 1.4892 - val_loss: 1.4619\n",
      "Epoch 11/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4758\n",
      "Epoch 11: val_loss improved from 1.46186 to 1.45262, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 625us/sample - loss: 1.4758 - val_loss: 1.4526\n",
      "Epoch 12/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4773\n",
      "Epoch 12: val_loss did not improve from 1.45262\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.4773 - val_loss: 1.4531\n",
      "Epoch 13/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4809\n",
      "Epoch 13: val_loss improved from 1.45262 to 1.45229, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.4809 - val_loss: 1.4523\n",
      "Epoch 14/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4820\n",
      "Epoch 14: val_loss did not improve from 1.45229\n",
      "32323/32323 [==============================] - 20s 618us/sample - loss: 1.4820 - val_loss: 1.4571\n",
      "Epoch 15/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5231\n",
      "Epoch 15: val_loss did not improve from 1.45229\n",
      "32323/32323 [==============================] - 20s 615us/sample - loss: 1.5231 - val_loss: 1.4581\n",
      "Epoch 16/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5021\n",
      "Epoch 16: val_loss improved from 1.45229 to 1.44793, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.5021 - val_loss: 1.4479\n",
      "Epoch 17/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4866\n",
      "Epoch 17: val_loss improved from 1.44793 to 1.44756, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4866 - val_loss: 1.4476\n",
      "Epoch 18/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5127\n",
      "Epoch 18: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.5127 - val_loss: 1.4500\n",
      "Epoch 19/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4854\n",
      "Epoch 19: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.4854 - val_loss: 1.4525\n",
      "Epoch 20/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5073\n",
      "Epoch 20: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.5073 - val_loss: 1.4479\n",
      "Epoch 21/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5159\n",
      "Epoch 21: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 610us/sample - loss: 1.5159 - val_loss: 1.4554\n",
      "Epoch 22/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5352\n",
      "Epoch 22: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 611us/sample - loss: 1.5352 - val_loss: 1.4548\n",
      "Epoch 23/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.5273\n",
      "Epoch 23: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.5273 - val_loss: 1.4670\n",
      "Epoch 24/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4848\n",
      "Epoch 24: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.4848 - val_loss: 1.4496\n",
      "Epoch 25/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4706\n",
      "Epoch 25: val_loss did not improve from 1.44756\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.4706 - val_loss: 1.4478\n",
      "Epoch 26/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4643\n",
      "Epoch 26: val_loss improved from 1.44756 to 1.44338, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 618us/sample - loss: 1.4643 - val_loss: 1.4434\n",
      "Epoch 27/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4573\n",
      "Epoch 27: val_loss improved from 1.44338 to 1.44030, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.4573 - val_loss: 1.4403\n",
      "Epoch 28/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 28: val_loss improved from 1.44030 to 1.43883, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 618us/sample - loss: 1.4525 - val_loss: 1.4388\n",
      "Epoch 29/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4503\n",
      "Epoch 29: val_loss did not improve from 1.43883\n",
      "32323/32323 [==============================] - 20s 611us/sample - loss: 1.4503 - val_loss: 1.4409\n",
      "Epoch 30/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4478\n",
      "Epoch 30: val_loss improved from 1.43883 to 1.43444, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4478 - val_loss: 1.4344\n",
      "Epoch 31/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4458\n",
      "Epoch 31: val_loss improved from 1.43444 to 1.43128, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4458 - val_loss: 1.4313\n",
      "Epoch 32/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4420\n",
      "Epoch 32: val_loss improved from 1.43128 to 1.43035, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4420 - val_loss: 1.4303\n",
      "Epoch 33/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4427\n",
      "Epoch 33: val_loss did not improve from 1.43035\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.4427 - val_loss: 1.4322\n",
      "Epoch 34/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4383\n",
      "Epoch 34: val_loss improved from 1.43035 to 1.42990, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4383 - val_loss: 1.4299\n",
      "Epoch 35/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4312\n",
      "Epoch 35: val_loss improved from 1.42990 to 1.42745, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4312 - val_loss: 1.4275\n",
      "Epoch 36/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4300\n",
      "Epoch 36: val_loss did not improve from 1.42745\n",
      "32323/32323 [==============================] - 20s 611us/sample - loss: 1.4300 - val_loss: 1.4293\n",
      "Epoch 37/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 37: val_loss improved from 1.42745 to 1.42356, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4269 - val_loss: 1.4236\n",
      "Epoch 38/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 38: val_loss did not improve from 1.42356\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.4280 - val_loss: 1.4278\n",
      "Epoch 39/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4258\n",
      "Epoch 39: val_loss did not improve from 1.42356\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.4258 - val_loss: 1.4282\n",
      "Epoch 40/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4255\n",
      "Epoch 40: val_loss did not improve from 1.42356\n",
      "32323/32323 [==============================] - 20s 610us/sample - loss: 1.4255 - val_loss: 1.4238\n",
      "Epoch 41/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4221\n",
      "Epoch 41: val_loss did not improve from 1.42356\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.4221 - val_loss: 1.4254\n",
      "Epoch 42/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4226\n",
      "Epoch 42: val_loss improved from 1.42356 to 1.42337, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 1.4226 - val_loss: 1.4234\n",
      "Epoch 43/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 43: val_loss improved from 1.42337 to 1.42205, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 623us/sample - loss: 1.4211 - val_loss: 1.4221\n",
      "Epoch 44/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 44: val_loss improved from 1.42205 to 1.42074, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 614us/sample - loss: 1.4191 - val_loss: 1.4207\n",
      "Epoch 45/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4192\n",
      "Epoch 45: val_loss did not improve from 1.42074\n",
      "32323/32323 [==============================] - 20s 609us/sample - loss: 1.4192 - val_loss: 1.4214\n",
      "Epoch 46/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4151\n",
      "Epoch 46: val_loss improved from 1.42074 to 1.41947, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 615us/sample - loss: 1.4151 - val_loss: 1.4195\n",
      "Epoch 47/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 47: val_loss improved from 1.41947 to 1.41678, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 617us/sample - loss: 1.4164 - val_loss: 1.4168\n",
      "Epoch 48/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4141\n",
      "Epoch 48: val_loss improved from 1.41678 to 1.41619, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 1.4141 - val_loss: 1.4162\n",
      "Epoch 49/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4109\n",
      "Epoch 49: val_loss improved from 1.41619 to 1.41563, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 1.4109 - val_loss: 1.4156\n",
      "Epoch 50/50\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4131\n",
      "Epoch 50: val_loss did not improve from 1.41563\n",
      "32323/32323 [==============================] - 20s 614us/sample - loss: 1.4131 - val_loss: 1.4242\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:42:35.619843: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_541_1/lstm_cell_1614/bias/Assign' id:820939 op device:{requested: '', assigned: ''} def:{{{node lstm_541_1/lstm_cell_1614/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_541_1/lstm_cell_1614/bias, lstm_541_1/lstm_cell_1614/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 12:43:18.824397: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_531_1/lstm_cell_1604/kernel/v/Assign' id:824678 op device:{requested: '', assigned: ''} def:{{{node lstm_531_1/lstm_cell_1604/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_531_1/lstm_cell_1604/kernel/v, lstm_531_1/lstm_cell_1604/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 12:44:01.845364: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_74_1/cond/Merge' id:823179 op device:{requested: '', assigned: ''} def:{{{node dropout_74_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_74_1/cond/Identity, dropout_74_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 1080)\n",
      "(1514, 1080)\n",
      "(1644, 1080)\n",
      "(1764, 1080)\n",
      "(1836, 1080)\n",
      "(1699, 1080)\n",
      "(1369, 1080)\n",
      "(1766, 1080)\n",
      "(1631, 1080)\n",
      "(1692, 1080)\n",
      "(1550, 1080)\n",
      "(1920, 1080)\n",
      "(1739, 1080)\n",
      "(1788, 1080)\n",
      "(1812, 1080)\n",
      "(1788, 1080)\n",
      "(1788, 1080)\n",
      "(946, 1080)\n",
      "(1632, 1080)\n",
      "{1: 4.722309992132179, 2: 1.1900036716496198, 4: 3.9826320482559665, 5: 8.020429058484133, 6: 10.0, 8: 4.3934518751639136, 9: 1.0, 10: 5.459715709415159, 11: 2.558755835300288, 12: 3.7795898242853396, 13: 4.946641489640703, 17: 3.5188817204301075, 19: 4.457646997115132, 21: 5.131380015735641, 22: 2.0184799370574353, 25: 3.227377917650144, 26: 3.1209420403881456, 27: 1.0759276160503541, 28: 4.263653815892997}\n",
      "Train on 32323 samples, validate on 3598 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:51:37.090015: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 7.6623\n",
      "Epoch 1: val_loss improved from inf to 1.43201, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 97s 3ms/sample - loss: 7.6623 - val_loss: 1.4320\n",
      "Epoch 2/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.5773\n",
      "Epoch 2: val_loss did not improve from 1.43201\n",
      "32323/32323 [==============================] - 20s 623us/sample - loss: 7.5773 - val_loss: 1.4420\n",
      "Epoch 3/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.5363\n",
      "Epoch 3: val_loss did not improve from 1.43201\n",
      "32323/32323 [==============================] - 20s 618us/sample - loss: 7.5363 - val_loss: 1.4394\n",
      "Epoch 4/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4328\n",
      "Epoch 4: val_loss improved from 1.43201 to 1.43060, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 625us/sample - loss: 7.4328 - val_loss: 1.4306\n",
      "Epoch 5/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4202\n",
      "Epoch 5: val_loss did not improve from 1.43060\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 7.4202 - val_loss: 1.4319\n",
      "Epoch 6/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4358\n",
      "Epoch 6: val_loss improved from 1.43060 to 1.42412, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 627us/sample - loss: 7.4358 - val_loss: 1.4241\n",
      "Epoch 7/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.4125\n",
      "Epoch 7: val_loss did not improve from 1.42412\n",
      "32323/32323 [==============================] - 20s 623us/sample - loss: 7.4125 - val_loss: 1.4349\n",
      "Epoch 8/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3484\n",
      "Epoch 8: val_loss improved from 1.42412 to 1.41573, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 633us/sample - loss: 7.3484 - val_loss: 1.4157\n",
      "Epoch 9/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3733\n",
      "Epoch 9: val_loss improved from 1.41573 to 1.41189, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 627us/sample - loss: 7.3733 - val_loss: 1.4119\n",
      "Epoch 10/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3573\n",
      "Epoch 10: val_loss did not improve from 1.41189\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 7.3573 - val_loss: 1.4119\n",
      "Epoch 11/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3405\n",
      "Epoch 11: val_loss did not improve from 1.41189\n",
      "32323/32323 [==============================] - 20s 621us/sample - loss: 7.3405 - val_loss: 1.4124\n",
      "Epoch 12/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3499\n",
      "Epoch 12: val_loss improved from 1.41189 to 1.41154, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 628us/sample - loss: 7.3499 - val_loss: 1.4115\n",
      "Epoch 13/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3001\n",
      "Epoch 13: val_loss improved from 1.41154 to 1.40864, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 625us/sample - loss: 7.3001 - val_loss: 1.4086\n",
      "Epoch 14/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.3227\n",
      "Epoch 14: val_loss did not improve from 1.40864\n",
      "32323/32323 [==============================] - 20s 620us/sample - loss: 7.3227 - val_loss: 1.4150\n",
      "Epoch 15/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.2973\n",
      "Epoch 15: val_loss did not improve from 1.40864\n",
      "32323/32323 [==============================] - 20s 616us/sample - loss: 7.2973 - val_loss: 1.4177\n",
      "Epoch 16/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.2644\n",
      "Epoch 16: val_loss improved from 1.40864 to 1.40593, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 619us/sample - loss: 7.2644 - val_loss: 1.4059\n",
      "Epoch 17/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.2534\n",
      "Epoch 17: val_loss improved from 1.40593 to 1.40576, saving model to ./checkpoints/unknown_person_few_shot_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 617us/sample - loss: 7.2534 - val_loss: 1.4058\n",
      "Epoch 18/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.2742\n",
      "Epoch 18: val_loss did not improve from 1.40576\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 7.2742 - val_loss: 1.4167\n",
      "Epoch 19/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.2769\n",
      "Epoch 19: val_loss did not improve from 1.40576\n",
      "32323/32323 [==============================] - 20s 615us/sample - loss: 7.2769 - val_loss: 1.4241\n",
      "Epoch 20/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 7.2258\n",
      "Epoch 20: val_loss did not improve from 1.40576\n",
      "32323/32323 [==============================] - 20s 615us/sample - loss: 7.2258 - val_loss: 1.4130\n",
      "WARNING:tensorflow:Layer lstm_518 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_519 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_520 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_521 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_522 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_523 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_524 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_525 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_526 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_527 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_528 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_529 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_530 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_531 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_532 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_533 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_534 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_535 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_536 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_537 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_538 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_539 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_540 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_541 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_542 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_543 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_544 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_545 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_546 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_547 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_548 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_549 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_550 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_551 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_552 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_553 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_554 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 12:59:53.070653: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_531_2/lstm_cell_1641/recurrent_kernel/Assign' id:838726 op device:{requested: '', assigned: ''} def:{{{node lstm_531_2/lstm_cell_1641/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_531_2/lstm_cell_1641/recurrent_kernel, lstm_531_2/lstm_cell_1641/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 13:00:37.231400: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_551_2/lstm_cell_1661/recurrent_kernel/m/Assign' id:843738 op device:{requested: '', assigned: ''} def:{{{node lstm_551_2/lstm_cell_1661/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_551_2/lstm_cell_1661/recurrent_kernel/m, lstm_551_2/lstm_cell_1661/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32323 samples, validate on 3598 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:01:23.985276: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:05:07.712135: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_70_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:05:30.187322: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_89/mul' id:843167 op device:{requested: '', assigned: ''} def:{{{node loss_89/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_89/mul/x, loss_89/dense_59_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41777, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 99s 3ms/sample - loss: 1.4112 - val_loss: 1.4178\n",
      "Epoch 2/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 2: val_loss improved from 1.41777 to 1.41592, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 624us/sample - loss: 1.4096 - val_loss: 1.4159\n",
      "Epoch 3/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4070\n",
      "Epoch 3: val_loss improved from 1.41592 to 1.41203, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 623us/sample - loss: 1.4070 - val_loss: 1.4120\n",
      "Epoch 4/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 4: val_loss did not improve from 1.41203\n",
      "32323/32323 [==============================] - 20s 613us/sample - loss: 1.4051 - val_loss: 1.4123\n",
      "Epoch 5/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4055\n",
      "Epoch 5: val_loss improved from 1.41203 to 1.40911, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4055 - val_loss: 1.4091\n",
      "Epoch 6/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4031\n",
      "Epoch 6: val_loss improved from 1.40911 to 1.40376, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 622us/sample - loss: 1.4031 - val_loss: 1.4038\n",
      "Epoch 7/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4011\n",
      "Epoch 7: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 20s 628us/sample - loss: 1.4011 - val_loss: 1.4093\n",
      "Epoch 8/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.4018\n",
      "Epoch 8: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 23s 706us/sample - loss: 1.4018 - val_loss: 1.4059\n",
      "Epoch 9/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3981\n",
      "Epoch 9: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 23s 705us/sample - loss: 1.3981 - val_loss: 1.4144\n",
      "Epoch 10/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3974\n",
      "Epoch 10: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 22s 696us/sample - loss: 1.3974 - val_loss: 1.4063\n",
      "Epoch 11/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 11: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 22s 670us/sample - loss: 1.3965 - val_loss: 1.4090\n",
      "Epoch 12/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3943\n",
      "Epoch 12: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 22s 675us/sample - loss: 1.3943 - val_loss: 1.4085\n",
      "Epoch 13/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3933\n",
      "Epoch 13: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 22s 696us/sample - loss: 1.3933 - val_loss: 1.4083\n",
      "Epoch 14/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3924\n",
      "Epoch 14: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 20s 614us/sample - loss: 1.3924 - val_loss: 1.4055\n",
      "Epoch 15/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 15: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 20s 614us/sample - loss: 1.3907 - val_loss: 1.4072\n",
      "Epoch 16/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3920\n",
      "Epoch 16: val_loss did not improve from 1.40376\n",
      "32323/32323 [==============================] - 20s 617us/sample - loss: 1.3920 - val_loss: 1.4067\n",
      "Epoch 17/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3922\n",
      "Epoch 17: val_loss improved from 1.40376 to 1.40319, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 625us/sample - loss: 1.3922 - val_loss: 1.4032\n",
      "Epoch 18/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3891\n",
      "Epoch 18: val_loss improved from 1.40319 to 1.40172, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_44.h5\n",
      "32323/32323 [==============================] - 20s 623us/sample - loss: 1.3891 - val_loss: 1.4017\n",
      "Epoch 19/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3882\n",
      "Epoch 19: val_loss did not improve from 1.40172\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.3882 - val_loss: 1.4038\n",
      "Epoch 20/20\n",
      "32323/32323 [==============================] - ETA: 0s - loss: 1.3896\n",
      "Epoch 20: val_loss did not improve from 1.40172\n",
      "32323/32323 [==============================] - 20s 612us/sample - loss: 1.3896 - val_loss: 1.4054\n",
      "36137\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:13:43.197448: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_558/lstm_cell_1668/bias/Assign' id:856172 op device:{requested: '', assigned: ''} def:{{{node lstm_558/lstm_cell_1668/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_558/lstm_cell_1668/bias, lstm_558/lstm_cell_1668/bias/Initializer/concat)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 13:14:07.508610: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_1' id:859266 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 13:14:27.204211: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_15/stack_2' id:859267 op device:{requested: '', assigned: ''} def:{{{node strided_slice_15/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32515, 95)\n",
      "Train on 32515 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:15:10.948986: W tensorflow/c/c_api.cc:304] Operation '{name:'training_90/Adam/lstm_570/lstm_cell_1680/recurrent_kernel/v/Assign' id:872897 op device:{requested: '', assigned: ''} def:{{{node training_90/Adam/lstm_570/lstm_cell_1680/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_90/Adam/lstm_570/lstm_cell_1680/recurrent_kernel/v, training_90/Adam/lstm_570/lstm_cell_1680/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:19:03.743945: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 3.4692"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-24 13:19:26.226040: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_91/mul' id:862107 op device:{requested: '', assigned: ''} def:{{{node loss_91/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_91/mul/x, loss_91/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.99153, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 230s 7ms/sample - loss: 3.4692 - val_loss: 1.9915\n",
      "Epoch 2/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.8150\n",
      "Epoch 2: val_loss improved from 1.99153 to 1.59167, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 609us/sample - loss: 1.8150 - val_loss: 1.5917\n",
      "Epoch 3/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.6041\n",
      "Epoch 3: val_loss improved from 1.59167 to 1.51510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 607us/sample - loss: 1.6041 - val_loss: 1.5151\n",
      "Epoch 4/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5455\n",
      "Epoch 4: val_loss improved from 1.51510 to 1.48044, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 611us/sample - loss: 1.5455 - val_loss: 1.4804\n",
      "Epoch 5/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5221\n",
      "Epoch 5: val_loss improved from 1.48044 to 1.46601, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 613us/sample - loss: 1.5221 - val_loss: 1.4660\n",
      "Epoch 6/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5056\n",
      "Epoch 6: val_loss improved from 1.46601 to 1.45101, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 607us/sample - loss: 1.5056 - val_loss: 1.4510\n",
      "Epoch 7/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4965\n",
      "Epoch 7: val_loss improved from 1.45101 to 1.44182, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 607us/sample - loss: 1.4965 - val_loss: 1.4418\n",
      "Epoch 8/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4957\n",
      "Epoch 8: val_loss did not improve from 1.44182\n",
      "32515/32515 [==============================] - 19s 595us/sample - loss: 1.4957 - val_loss: 1.4426\n",
      "Epoch 9/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4837\n",
      "Epoch 9: val_loss improved from 1.44182 to 1.43558, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 603us/sample - loss: 1.4837 - val_loss: 1.4356\n",
      "Epoch 10/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4879\n",
      "Epoch 10: val_loss did not improve from 1.43558\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.4879 - val_loss: 1.4374\n",
      "Epoch 11/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4977\n",
      "Epoch 11: val_loss did not improve from 1.43558\n",
      "32515/32515 [==============================] - 19s 598us/sample - loss: 1.4977 - val_loss: 1.4420\n",
      "Epoch 12/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4997\n",
      "Epoch 12: val_loss improved from 1.43558 to 1.43236, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 606us/sample - loss: 1.4997 - val_loss: 1.4324\n",
      "Epoch 13/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5418\n",
      "Epoch 13: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 597us/sample - loss: 1.5418 - val_loss: 1.4331\n",
      "Epoch 14/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.6472\n",
      "Epoch 14: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 598us/sample - loss: 1.6472 - val_loss: 1.4657\n",
      "Epoch 15/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5001\n",
      "Epoch 15: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 595us/sample - loss: 1.5001 - val_loss: 1.4430\n",
      "Epoch 16/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.7004\n",
      "Epoch 16: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.7004 - val_loss: 1.4734\n",
      "Epoch 17/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5232\n",
      "Epoch 17: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 597us/sample - loss: 1.5232 - val_loss: 1.4643\n",
      "Epoch 18/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4898\n",
      "Epoch 18: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 598us/sample - loss: 1.4898 - val_loss: 1.4442\n",
      "Epoch 19/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4833\n",
      "Epoch 19: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.4833 - val_loss: 1.4355\n",
      "Epoch 20/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5527\n",
      "Epoch 20: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 20s 602us/sample - loss: 1.5527 - val_loss: 1.4502\n",
      "Epoch 21/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4863\n",
      "Epoch 21: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 20s 600us/sample - loss: 1.4863 - val_loss: 1.4396\n",
      "Epoch 22/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4786\n",
      "Epoch 22: val_loss did not improve from 1.43236\n",
      "32515/32515 [==============================] - 19s 598us/sample - loss: 1.4786 - val_loss: 1.4397\n",
      "Epoch 23/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4707\n",
      "Epoch 23: val_loss improved from 1.43236 to 1.42897, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.4707 - val_loss: 1.4290\n",
      "Epoch 24/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4635\n",
      "Epoch 24: val_loss did not improve from 1.42897\n",
      "32515/32515 [==============================] - 19s 597us/sample - loss: 1.4635 - val_loss: 1.4307\n",
      "Epoch 25/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4579\n",
      "Epoch 25: val_loss improved from 1.42897 to 1.42493, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 607us/sample - loss: 1.4579 - val_loss: 1.4249\n",
      "Epoch 26/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4579\n",
      "Epoch 26: val_loss improved from 1.42493 to 1.42179, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 608us/sample - loss: 1.4579 - val_loss: 1.4218\n",
      "Epoch 27/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4531\n",
      "Epoch 27: val_loss improved from 1.42179 to 1.41574, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 606us/sample - loss: 1.4531 - val_loss: 1.4157\n",
      "Epoch 28/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4531\n",
      "Epoch 28: val_loss did not improve from 1.41574\n",
      "32515/32515 [==============================] - 19s 597us/sample - loss: 1.4531 - val_loss: 1.4211\n",
      "Epoch 29/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4467\n",
      "Epoch 29: val_loss improved from 1.41574 to 1.41092, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 606us/sample - loss: 1.4467 - val_loss: 1.4109\n",
      "Epoch 30/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4424\n",
      "Epoch 30: val_loss did not improve from 1.41092\n",
      "32515/32515 [==============================] - 19s 595us/sample - loss: 1.4424 - val_loss: 1.4130\n",
      "Epoch 31/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4421\n",
      "Epoch 31: val_loss did not improve from 1.41092\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.4421 - val_loss: 1.4118\n",
      "Epoch 32/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4377\n",
      "Epoch 32: val_loss improved from 1.41092 to 1.40982, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 605us/sample - loss: 1.4377 - val_loss: 1.4098\n",
      "Epoch 33/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4355\n",
      "Epoch 33: val_loss improved from 1.40982 to 1.40355, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 21s 660us/sample - loss: 1.4355 - val_loss: 1.4035\n",
      "Epoch 34/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4350\n",
      "Epoch 34: val_loss did not improve from 1.40355\n",
      "32515/32515 [==============================] - 23s 694us/sample - loss: 1.4350 - val_loss: 1.4064\n",
      "Epoch 35/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 35: val_loss did not improve from 1.40355\n",
      "32515/32515 [==============================] - 23s 695us/sample - loss: 1.4305 - val_loss: 1.4066\n",
      "Epoch 36/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4288\n",
      "Epoch 36: val_loss did not improve from 1.40355\n",
      "32515/32515 [==============================] - 23s 696us/sample - loss: 1.4288 - val_loss: 1.4060\n",
      "Epoch 37/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4289\n",
      "Epoch 37: val_loss did not improve from 1.40355\n",
      "32515/32515 [==============================] - 23s 698us/sample - loss: 1.4289 - val_loss: 1.4043\n",
      "Epoch 38/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4262\n",
      "Epoch 38: val_loss improved from 1.40355 to 1.40252, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 1.4262 - val_loss: 1.4025\n",
      "Epoch 39/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4235\n",
      "Epoch 39: val_loss improved from 1.40252 to 1.39906, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 22s 673us/sample - loss: 1.4235 - val_loss: 1.3991\n",
      "Epoch 40/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 40: val_loss did not improve from 1.39906\n",
      "32515/32515 [==============================] - 20s 614us/sample - loss: 1.4220 - val_loss: 1.4097\n",
      "Epoch 41/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4178\n",
      "Epoch 41: val_loss improved from 1.39906 to 1.39840, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 611us/sample - loss: 1.4178 - val_loss: 1.3984\n",
      "Epoch 42/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 42: val_loss improved from 1.39840 to 1.39720, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 611us/sample - loss: 1.4158 - val_loss: 1.3972\n",
      "Epoch 43/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4150\n",
      "Epoch 43: val_loss improved from 1.39720 to 1.39304, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 606us/sample - loss: 1.4150 - val_loss: 1.3930\n",
      "Epoch 44/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4150\n",
      "Epoch 44: val_loss did not improve from 1.39304\n",
      "32515/32515 [==============================] - 20s 600us/sample - loss: 1.4150 - val_loss: 1.3954\n",
      "Epoch 45/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 45: val_loss did not improve from 1.39304\n",
      "32515/32515 [==============================] - 21s 632us/sample - loss: 1.4148 - val_loss: 1.3933\n",
      "Epoch 46/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4139\n",
      "Epoch 46: val_loss did not improve from 1.39304\n",
      "32515/32515 [==============================] - 23s 695us/sample - loss: 1.4139 - val_loss: 1.3961\n",
      "Epoch 47/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4124\n",
      "Epoch 47: val_loss did not improve from 1.39304\n",
      "32515/32515 [==============================] - 23s 697us/sample - loss: 1.4124 - val_loss: 1.3933\n",
      "Epoch 48/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4101\n",
      "Epoch 48: val_loss did not improve from 1.39304\n",
      "32515/32515 [==============================] - 23s 696us/sample - loss: 1.4101 - val_loss: 1.3940\n",
      "Epoch 49/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4095\n",
      "Epoch 49: val_loss improved from 1.39304 to 1.38664, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_45.h5\n",
      "32515/32515 [==============================] - 23s 709us/sample - loss: 1.4095 - val_loss: 1.3866\n",
      "Epoch 50/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4035\n",
      "Epoch 50: val_loss did not improve from 1.38664\n",
      "32515/32515 [==============================] - 22s 683us/sample - loss: 1.4035 - val_loss: 1.3921\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:39:48.038799: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_568_1/lstm_cell_1715/recurrent_kernel/Assign' id:876370 op device:{requested: '', assigned: ''} def:{{{node lstm_568_1/lstm_cell_1715/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_568_1/lstm_cell_1715/recurrent_kernel, lstm_568_1/lstm_cell_1715/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 13:40:34.378451: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_61_1/bias/m/Assign' id:881456 op device:{requested: '', assigned: ''} def:{{{node dense_61_1/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_61_1/bias/m, dense_61_1/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-24 13:41:20.626894: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_79_1/cond/Merge' id:880221 op device:{requested: '', assigned: ''} def:{{{node dropout_79_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_79_1/cond/Identity, dropout_79_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 864)\n",
      "(1514, 864)\n",
      "(1644, 864)\n",
      "(1764, 864)\n",
      "(1836, 864)\n",
      "(1699, 864)\n",
      "(1369, 864)\n",
      "(1766, 864)\n",
      "(1619, 864)\n",
      "(1692, 864)\n",
      "(1550, 864)\n",
      "(1920, 864)\n",
      "(1739, 864)\n",
      "(1788, 864)\n",
      "(1812, 864)\n",
      "(1788, 864)\n",
      "(1788, 864)\n",
      "(946, 864)\n",
      "(1632, 864)\n",
      "{1: 3.8785546558722306, 2: 1.3305344401138213, 4: 3.7428138951813485, 5: 8.325335732706604, 6: 10.0, 8: 3.9998020281895985, 9: 1.2350886588901615, 10: 5.185206964316133, 11: 2.9585942032031456, 12: 3.6547398081628173, 13: 4.518123532939967, 17: 3.3870717794050234, 19: 4.440772992471045, 21: 4.487288872323468, 22: 2.253833517612216, 25: 3.2565082681523028, 26: 2.9204976367574425, 27: 1.0, 28: 4.225087775586093}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2920137/1660627543.py:307: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  w_train[i] = weights_dict[int(p_train[i])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32515 samples, validate on 3622 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:49:17.072279: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9166\n",
      "Epoch 1: val_loss improved from inf to 1.39983, saving model to ./checkpoints/unknown_person_few_shot_p29_45.h5\n",
      "32515/32515 [==============================] - 103s 3ms/sample - loss: 7.9166 - val_loss: 1.3998\n",
      "Epoch 2/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.7341\n",
      "Epoch 2: val_loss did not improve from 1.39983\n",
      "32515/32515 [==============================] - 20s 619us/sample - loss: 7.7341 - val_loss: 1.4055\n",
      "Epoch 3/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.6786\n",
      "Epoch 3: val_loss did not improve from 1.39983\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 7.6786 - val_loss: 1.4019\n",
      "Epoch 4/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.6164\n",
      "Epoch 4: val_loss improved from 1.39983 to 1.39282, saving model to ./checkpoints/unknown_person_few_shot_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 627us/sample - loss: 7.6164 - val_loss: 1.3928\n",
      "Epoch 5/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.6152\n",
      "Epoch 5: val_loss did not improve from 1.39282\n",
      "32515/32515 [==============================] - 20s 619us/sample - loss: 7.6152 - val_loss: 1.3972\n",
      "Epoch 6/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.5491\n",
      "Epoch 6: val_loss did not improve from 1.39282\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 7.5491 - val_loss: 1.3953\n",
      "Epoch 7/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4814\n",
      "Epoch 7: val_loss improved from 1.39282 to 1.39072, saving model to ./checkpoints/unknown_person_few_shot_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 628us/sample - loss: 7.4814 - val_loss: 1.3907\n",
      "Epoch 8/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.5430\n",
      "Epoch 8: val_loss did not improve from 1.39072\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 7.5430 - val_loss: 1.4014\n",
      "Epoch 9/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4646\n",
      "Epoch 9: val_loss did not improve from 1.39072\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 7.4646 - val_loss: 1.3966\n",
      "Epoch 10/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4647\n",
      "Epoch 10: val_loss did not improve from 1.39072\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 7.4647 - val_loss: 1.3985\n",
      "Epoch 11/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4402\n",
      "Epoch 11: val_loss did not improve from 1.39072\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 7.4402 - val_loss: 1.4097\n",
      "Epoch 12/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4338\n",
      "Epoch 12: val_loss improved from 1.39072 to 1.38500, saving model to ./checkpoints/unknown_person_few_shot_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 624us/sample - loss: 7.4338 - val_loss: 1.3850\n",
      "Epoch 13/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4163\n",
      "Epoch 13: val_loss improved from 1.38500 to 1.38078, saving model to ./checkpoints/unknown_person_few_shot_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 625us/sample - loss: 7.4163 - val_loss: 1.3808\n",
      "Epoch 14/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4037\n",
      "Epoch 14: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 7.4037 - val_loss: 1.3900\n",
      "Epoch 15/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.3958\n",
      "Epoch 15: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 7.3958 - val_loss: 1.3868\n",
      "Epoch 16/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.4060\n",
      "Epoch 16: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 615us/sample - loss: 7.4060 - val_loss: 1.3823\n",
      "Epoch 17/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.3844\n",
      "Epoch 17: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 612us/sample - loss: 7.3844 - val_loss: 1.3893\n",
      "Epoch 18/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.3934\n",
      "Epoch 18: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 616us/sample - loss: 7.3934 - val_loss: 1.4009\n",
      "Epoch 19/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.3231\n",
      "Epoch 19: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 611us/sample - loss: 7.3231 - val_loss: 1.3893\n",
      "Epoch 20/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.3554\n",
      "Epoch 20: val_loss did not improve from 1.38078\n",
      "32515/32515 [==============================] - 20s 614us/sample - loss: 7.3554 - val_loss: 1.3884\n",
      "WARNING:tensorflow:Layer lstm_555 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_556 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_557 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_558 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_559 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_560 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_561 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_562 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_563 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_564 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_565 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_566 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_567 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_568 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_569 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_570 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_571 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_572 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_573 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_574 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_575 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_576 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_577 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_578 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_579 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_580 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_581 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_582 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_583 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_584 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_585 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_586 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_587 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_588 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_589 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_590 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_591 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:57:40.717209: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_591_2/lstm_cell_1775/kernel/Assign' id:899430 op device:{requested: '', assigned: ''} def:{{{node lstm_591_2/lstm_cell_1775/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_591_2/lstm_cell_1775/kernel, lstm_591_2/lstm_cell_1775/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 13:58:27.982718: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_582_2/lstm_cell_1766/recurrent_kernel/v/Assign' id:901333 op device:{requested: '', assigned: ''} def:{{{node lstm_582_2/lstm_cell_1766/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_582_2/lstm_cell_1766/recurrent_kernel/v, lstm_582_2/lstm_cell_1766/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32515 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:59:17.771052: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:03:18.071548: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_75_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:03:40.733033: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_95/mul' id:900209 op device:{requested: '', assigned: ''} def:{{{node loss_95/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_95/mul/x, loss_95/dense_63_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38494, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 105s 3ms/sample - loss: 1.4059 - val_loss: 1.3849\n",
      "Epoch 2/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4044\n",
      "Epoch 2: val_loss did not improve from 1.38494\n",
      "32515/32515 [==============================] - 20s 619us/sample - loss: 1.4044 - val_loss: 1.3926\n",
      "Epoch 3/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4006\n",
      "Epoch 3: val_loss improved from 1.38494 to 1.38483, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 624us/sample - loss: 1.4006 - val_loss: 1.3848\n",
      "Epoch 4/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 4: val_loss improved from 1.38483 to 1.38297, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 626us/sample - loss: 1.3996 - val_loss: 1.3830\n",
      "Epoch 5/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3980\n",
      "Epoch 5: val_loss improved from 1.38297 to 1.37902, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 20s 624us/sample - loss: 1.3980 - val_loss: 1.3790\n",
      "Epoch 6/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3993\n",
      "Epoch 6: val_loss did not improve from 1.37902\n",
      "32515/32515 [==============================] - 20s 629us/sample - loss: 1.3993 - val_loss: 1.3824\n",
      "Epoch 7/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3953\n",
      "Epoch 7: val_loss did not improve from 1.37902\n",
      "32515/32515 [==============================] - 23s 713us/sample - loss: 1.3953 - val_loss: 1.3862\n",
      "Epoch 8/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3954\n",
      "Epoch 8: val_loss did not improve from 1.37902\n",
      "32515/32515 [==============================] - 23s 709us/sample - loss: 1.3954 - val_loss: 1.3937\n",
      "Epoch 9/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 9: val_loss did not improve from 1.37902\n",
      "32515/32515 [==============================] - 23s 706us/sample - loss: 1.3939 - val_loss: 1.3795\n",
      "Epoch 10/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3924\n",
      "Epoch 10: val_loss improved from 1.37902 to 1.37541, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 23s 717us/sample - loss: 1.3924 - val_loss: 1.3754\n",
      "Epoch 11/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3915\n",
      "Epoch 11: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 23s 709us/sample - loss: 1.3915 - val_loss: 1.3808\n",
      "Epoch 12/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 12: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 21s 641us/sample - loss: 1.3902 - val_loss: 1.3876\n",
      "Epoch 13/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3873\n",
      "Epoch 13: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 20s 624us/sample - loss: 1.3873 - val_loss: 1.3805\n",
      "Epoch 14/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3864\n",
      "Epoch 14: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 21s 631us/sample - loss: 1.3864 - val_loss: 1.3825\n",
      "Epoch 15/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3864\n",
      "Epoch 15: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 22s 676us/sample - loss: 1.3864 - val_loss: 1.3795\n",
      "Epoch 16/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3846\n",
      "Epoch 16: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 21s 650us/sample - loss: 1.3846 - val_loss: 1.3778\n",
      "Epoch 17/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3856\n",
      "Epoch 17: val_loss did not improve from 1.37541\n",
      "32515/32515 [==============================] - 23s 696us/sample - loss: 1.3856 - val_loss: 1.3802\n",
      "Epoch 18/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3837\n",
      "Epoch 18: val_loss improved from 1.37541 to 1.37240, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 21s 632us/sample - loss: 1.3837 - val_loss: 1.3724\n",
      "Epoch 19/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3820\n",
      "Epoch 19: val_loss improved from 1.37240 to 1.37042, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_45.h5\n",
      "32515/32515 [==============================] - 21s 631us/sample - loss: 1.3820 - val_loss: 1.3704\n",
      "Epoch 20/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3828\n",
      "Epoch 20: val_loss did not improve from 1.37042\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 1.3828 - val_loss: 1.3774\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:12:06.190447: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_598/lstm_cell_1782/kernel/Assign' id:913680 op device:{requested: '', assigned: ''} def:{{{node lstm_598/lstm_cell_1782/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_598/lstm_cell_1782/kernel, lstm_598/lstm_cell_1782/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 14:12:32.320286: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_1' id:916308 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 14:12:53.543925: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_16/stack_2' id:916309 op device:{requested: '', assigned: ''} def:{{{node strided_slice_16/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32515, 95)\n",
      "Train on 32515 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:13:41.776258: W tensorflow/c/c_api.cc:304] Operation '{name:'training_96/Adam/lstm_612/lstm_cell_1796/kernel/m/Assign' id:929366 op device:{requested: '', assigned: ''} def:{{{node training_96/Adam/lstm_612/lstm_cell_1796/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_96/Adam/lstm_612/lstm_cell_1796/kernel/m, training_96/Adam/lstm_612/lstm_cell_1796/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:17:54.415765: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 3.2951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:18:17.126148: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_97/mul' id:919149 op device:{requested: '', assigned: ''} def:{{{node loss_97/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_97/mul/x, loss_97/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.01027, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 258s 8ms/sample - loss: 3.2951 - val_loss: 2.0103\n",
      "Epoch 2/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.8129\n",
      "Epoch 2: val_loss improved from 2.01027 to 1.60351, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 625us/sample - loss: 1.8129 - val_loss: 1.6035\n",
      "Epoch 3/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.6198\n",
      "Epoch 3: val_loss improved from 1.60351 to 1.52563, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 22s 691us/sample - loss: 1.6198 - val_loss: 1.5256\n",
      "Epoch 4/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5507\n",
      "Epoch 4: val_loss improved from 1.52563 to 1.48763, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 21s 648us/sample - loss: 1.5507 - val_loss: 1.4876\n",
      "Epoch 5/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5248\n",
      "Epoch 5: val_loss improved from 1.48763 to 1.47279, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 710us/sample - loss: 1.5248 - val_loss: 1.4728\n",
      "Epoch 6/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5090\n",
      "Epoch 6: val_loss improved from 1.47279 to 1.46510, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 711us/sample - loss: 1.5090 - val_loss: 1.4651\n",
      "Epoch 7/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4984\n",
      "Epoch 7: val_loss improved from 1.46510 to 1.45448, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 709us/sample - loss: 1.4984 - val_loss: 1.4545\n",
      "Epoch 8/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4927\n",
      "Epoch 8: val_loss improved from 1.45448 to 1.44182, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 711us/sample - loss: 1.4927 - val_loss: 1.4418\n",
      "Epoch 9/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4863\n",
      "Epoch 9: val_loss improved from 1.44182 to 1.44055, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 709us/sample - loss: 1.4863 - val_loss: 1.4405\n",
      "Epoch 10/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4851\n",
      "Epoch 10: val_loss improved from 1.44055 to 1.44051, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 710us/sample - loss: 1.4851 - val_loss: 1.4405\n",
      "Epoch 11/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4842\n",
      "Epoch 11: val_loss improved from 1.44051 to 1.43441, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 21s 632us/sample - loss: 1.4842 - val_loss: 1.4344\n",
      "Epoch 12/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4990\n",
      "Epoch 12: val_loss did not improve from 1.43441\n",
      "32515/32515 [==============================] - 20s 616us/sample - loss: 1.4990 - val_loss: 1.4538\n",
      "Epoch 13/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4798\n",
      "Epoch 13: val_loss did not improve from 1.43441\n",
      "32515/32515 [==============================] - 21s 634us/sample - loss: 1.4798 - val_loss: 1.4361\n",
      "Epoch 14/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4891\n",
      "Epoch 14: val_loss did not improve from 1.43441\n",
      "32515/32515 [==============================] - 21s 643us/sample - loss: 1.4891 - val_loss: 1.4420\n",
      "Epoch 15/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5028\n",
      "Epoch 15: val_loss did not improve from 1.43441\n",
      "32515/32515 [==============================] - 23s 696us/sample - loss: 1.5028 - val_loss: 1.4362\n",
      "Epoch 16/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5015\n",
      "Epoch 16: val_loss improved from 1.43441 to 1.43114, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 716us/sample - loss: 1.5015 - val_loss: 1.4311\n",
      "Epoch 17/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4853\n",
      "Epoch 17: val_loss improved from 1.43114 to 1.42822, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 710us/sample - loss: 1.4853 - val_loss: 1.4282\n",
      "Epoch 18/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4768\n",
      "Epoch 18: val_loss did not improve from 1.42822\n",
      "32515/32515 [==============================] - 23s 707us/sample - loss: 1.4768 - val_loss: 1.4308\n",
      "Epoch 19/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4788\n",
      "Epoch 19: val_loss improved from 1.42822 to 1.42282, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 714us/sample - loss: 1.4788 - val_loss: 1.4228\n",
      "Epoch 20/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5101\n",
      "Epoch 20: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 22s 688us/sample - loss: 1.5101 - val_loss: 1.4307\n",
      "Epoch 21/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4836\n",
      "Epoch 21: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 1.4836 - val_loss: 1.4247\n",
      "Epoch 22/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4727\n",
      "Epoch 22: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 20s 613us/sample - loss: 1.4727 - val_loss: 1.4254\n",
      "Epoch 23/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4698\n",
      "Epoch 23: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 20s 613us/sample - loss: 1.4698 - val_loss: 1.4247\n",
      "Epoch 24/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4602\n",
      "Epoch 24: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 20s 614us/sample - loss: 1.4602 - val_loss: 1.4302\n",
      "Epoch 25/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4540\n",
      "Epoch 25: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 1.4540 - val_loss: 1.4243\n",
      "Epoch 26/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4500\n",
      "Epoch 26: val_loss did not improve from 1.42282\n",
      "32515/32515 [==============================] - 20s 622us/sample - loss: 1.4500 - val_loss: 1.4284\n",
      "Epoch 27/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4486\n",
      "Epoch 27: val_loss improved from 1.42282 to 1.41769, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 21s 633us/sample - loss: 1.4486 - val_loss: 1.4177\n",
      "Epoch 28/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4450\n",
      "Epoch 28: val_loss did not improve from 1.41769\n",
      "32515/32515 [==============================] - 20s 619us/sample - loss: 1.4450 - val_loss: 1.4193\n",
      "Epoch 29/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4439\n",
      "Epoch 29: val_loss did not improve from 1.41769\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 1.4439 - val_loss: 1.4196\n",
      "Epoch 30/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4412\n",
      "Epoch 30: val_loss improved from 1.41769 to 1.41112, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 628us/sample - loss: 1.4412 - val_loss: 1.4111\n",
      "Epoch 31/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4386\n",
      "Epoch 31: val_loss improved from 1.41112 to 1.41029, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 626us/sample - loss: 1.4386 - val_loss: 1.4103\n",
      "Epoch 32/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4388\n",
      "Epoch 32: val_loss did not improve from 1.41029\n",
      "32515/32515 [==============================] - 20s 615us/sample - loss: 1.4388 - val_loss: 1.4129\n",
      "Epoch 33/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4331\n",
      "Epoch 33: val_loss did not improve from 1.41029\n",
      "32515/32515 [==============================] - 20s 623us/sample - loss: 1.4331 - val_loss: 1.4180\n",
      "Epoch 34/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4311\n",
      "Epoch 34: val_loss improved from 1.41029 to 1.40700, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 21s 640us/sample - loss: 1.4311 - val_loss: 1.4070\n",
      "Epoch 35/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4318\n",
      "Epoch 35: val_loss did not improve from 1.40700\n",
      "32515/32515 [==============================] - 23s 701us/sample - loss: 1.4318 - val_loss: 1.4077\n",
      "Epoch 36/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4283\n",
      "Epoch 36: val_loss improved from 1.40700 to 1.40365, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 709us/sample - loss: 1.4283 - val_loss: 1.4036\n",
      "Epoch 37/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4273\n",
      "Epoch 37: val_loss improved from 1.40365 to 1.40076, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 711us/sample - loss: 1.4273 - val_loss: 1.4008\n",
      "Epoch 38/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4249\n",
      "Epoch 38: val_loss did not improve from 1.40076\n",
      "32515/32515 [==============================] - 23s 704us/sample - loss: 1.4249 - val_loss: 1.4061\n",
      "Epoch 39/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4227\n",
      "Epoch 39: val_loss did not improve from 1.40076\n",
      "32515/32515 [==============================] - 23s 707us/sample - loss: 1.4227 - val_loss: 1.4018\n",
      "Epoch 40/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 40: val_loss improved from 1.40076 to 1.40008, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 711us/sample - loss: 1.4237 - val_loss: 1.4001\n",
      "Epoch 41/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 41: val_loss improved from 1.40008 to 1.39965, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 712us/sample - loss: 1.4210 - val_loss: 1.3997\n",
      "Epoch 42/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4192\n",
      "Epoch 42: val_loss improved from 1.39965 to 1.39196, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 713us/sample - loss: 1.4192 - val_loss: 1.3920\n",
      "Epoch 43/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4185\n",
      "Epoch 43: val_loss did not improve from 1.39196\n",
      "32515/32515 [==============================] - 23s 702us/sample - loss: 1.4185 - val_loss: 1.4020\n",
      "Epoch 44/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4150\n",
      "Epoch 44: val_loss did not improve from 1.39196\n",
      "32515/32515 [==============================] - 23s 703us/sample - loss: 1.4150 - val_loss: 1.3980\n",
      "Epoch 45/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4140\n",
      "Epoch 45: val_loss improved from 1.39196 to 1.38730, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 712us/sample - loss: 1.4140 - val_loss: 1.3873\n",
      "Epoch 46/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4119\n",
      "Epoch 46: val_loss did not improve from 1.38730\n",
      "32515/32515 [==============================] - 23s 700us/sample - loss: 1.4119 - val_loss: 1.3953\n",
      "Epoch 47/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4126\n",
      "Epoch 47: val_loss did not improve from 1.38730\n",
      "32515/32515 [==============================] - 23s 701us/sample - loss: 1.4126 - val_loss: 1.3960\n",
      "Epoch 48/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4117\n",
      "Epoch 48: val_loss did not improve from 1.38730\n",
      "32515/32515 [==============================] - 23s 708us/sample - loss: 1.4117 - val_loss: 1.3925\n",
      "Epoch 49/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4128\n",
      "Epoch 49: val_loss did not improve from 1.38730\n",
      "32515/32515 [==============================] - 23s 703us/sample - loss: 1.4128 - val_loss: 1.3966\n",
      "Epoch 50/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4078\n",
      "Epoch 50: val_loss did not improve from 1.38730\n",
      "32515/32515 [==============================] - 23s 701us/sample - loss: 1.4078 - val_loss: 1.3929\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:40:25.384772: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_617_1/lstm_cell_1838/kernel/Assign' id:935314 op device:{requested: '', assigned: ''} def:{{{node lstm_617_1/lstm_cell_1838/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_617_1/lstm_cell_1838/kernel, lstm_617_1/lstm_cell_1838/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 14:41:17.899749: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_594_1/lstm_cell_1815/recurrent_kernel/m/Assign' id:937959 op device:{requested: '', assigned: ''} def:{{{node lstm_594_1/lstm_cell_1815/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_594_1/lstm_cell_1815/recurrent_kernel/m, lstm_594_1/lstm_cell_1815/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 14:42:10.300540: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_84_1/cond/Merge' id:937263 op device:{requested: '', assigned: ''} def:{{{node dropout_84_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_84_1/cond/Identity, dropout_84_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 864)\n",
      "(1514, 864)\n",
      "(1644, 864)\n",
      "(1764, 864)\n",
      "(1836, 864)\n",
      "(1699, 864)\n",
      "(1369, 864)\n",
      "(1766, 864)\n",
      "(1619, 864)\n",
      "(1692, 864)\n",
      "(1550, 864)\n",
      "(1920, 864)\n",
      "(1739, 864)\n",
      "(1788, 864)\n",
      "(1812, 864)\n",
      "(1788, 864)\n",
      "(1788, 864)\n",
      "(946, 864)\n",
      "(1632, 864)\n",
      "{1: 4.446936617744557, 2: 1.8621125227842499, 4: 4.07254427827808, 5: 8.639300438965272, 6: 10.0, 8: 4.345371535489308, 9: 1.4830966477434169, 10: 6.0218400202569615, 11: 3.12705831414914, 12: 4.541009716769787, 13: 5.11690470529793, 17: 4.18416632357404, 19: 4.668659503279192, 21: 5.300699908959647, 22: 3.251460801425719, 25: 3.9783416738667796, 26: 3.9447147305611447, 27: 1.0, 28: 5.197938351570397}\n",
      "Train on 32515 samples, validate on 3622 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:50:43.298116: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 8.5681\n",
      "Epoch 1: val_loss improved from inf to 1.40185, saving model to ./checkpoints/unknown_person_few_shot_p29_46.h5\n",
      "32515/32515 [==============================] - 109s 3ms/sample - loss: 8.5681 - val_loss: 1.4019\n",
      "Epoch 2/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.4241\n",
      "Epoch 2: val_loss improved from 1.40185 to 1.39541, saving model to ./checkpoints/unknown_person_few_shot_p29_46.h5\n",
      "32515/32515 [==============================] - 21s 645us/sample - loss: 8.4241 - val_loss: 1.3954\n",
      "Epoch 3/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.3807\n",
      "Epoch 3: val_loss did not improve from 1.39541\n",
      "32515/32515 [==============================] - 21s 648us/sample - loss: 8.3807 - val_loss: 1.4023\n",
      "Epoch 4/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.3404\n",
      "Epoch 4: val_loss improved from 1.39541 to 1.39224, saving model to ./checkpoints/unknown_person_few_shot_p29_46.h5\n",
      "32515/32515 [==============================] - 21s 631us/sample - loss: 8.3404 - val_loss: 1.3922\n",
      "Epoch 5/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.3169\n",
      "Epoch 5: val_loss did not improve from 1.39224\n",
      "32515/32515 [==============================] - 22s 672us/sample - loss: 8.3169 - val_loss: 1.4077\n",
      "Epoch 6/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2837\n",
      "Epoch 6: val_loss did not improve from 1.39224\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 8.2837 - val_loss: 1.4077\n",
      "Epoch 7/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2675\n",
      "Epoch 7: val_loss did not improve from 1.39224\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 8.2675 - val_loss: 1.4089\n",
      "Epoch 8/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2482\n",
      "Epoch 8: val_loss did not improve from 1.39224\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 8.2482 - val_loss: 1.3923\n",
      "Epoch 9/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2577\n",
      "Epoch 9: val_loss improved from 1.39224 to 1.38587, saving model to ./checkpoints/unknown_person_few_shot_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 714us/sample - loss: 8.2577 - val_loss: 1.3859\n",
      "Epoch 10/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2054\n",
      "Epoch 10: val_loss improved from 1.38587 to 1.38175, saving model to ./checkpoints/unknown_person_few_shot_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 714us/sample - loss: 8.2054 - val_loss: 1.3817\n",
      "Epoch 11/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2053\n",
      "Epoch 11: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 8.2053 - val_loss: 1.3952\n",
      "Epoch 12/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1885\n",
      "Epoch 12: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 704us/sample - loss: 8.1885 - val_loss: 1.3916\n",
      "Epoch 13/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1816\n",
      "Epoch 13: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 8.1816 - val_loss: 1.3867\n",
      "Epoch 14/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1894\n",
      "Epoch 14: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 698us/sample - loss: 8.1894 - val_loss: 1.3820\n",
      "Epoch 15/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1590\n",
      "Epoch 15: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 700us/sample - loss: 8.1590 - val_loss: 1.3855\n",
      "Epoch 16/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1357\n",
      "Epoch 16: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 704us/sample - loss: 8.1357 - val_loss: 1.3900\n",
      "Epoch 17/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2137\n",
      "Epoch 17: val_loss did not improve from 1.38175\n",
      "32515/32515 [==============================] - 23s 703us/sample - loss: 8.2137 - val_loss: 1.3850\n",
      "Epoch 18/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1114\n",
      "Epoch 18: val_loss improved from 1.38175 to 1.37898, saving model to ./checkpoints/unknown_person_few_shot_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 713us/sample - loss: 8.1114 - val_loss: 1.3790\n",
      "Epoch 19/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0929\n",
      "Epoch 19: val_loss did not improve from 1.37898\n",
      "32515/32515 [==============================] - 23s 706us/sample - loss: 8.0929 - val_loss: 1.3806\n",
      "Epoch 20/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0851\n",
      "Epoch 20: val_loss did not improve from 1.37898\n",
      "32515/32515 [==============================] - 20s 621us/sample - loss: 8.0851 - val_loss: 1.3829\n",
      "WARNING:tensorflow:Layer lstm_592 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_593 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_594 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_595 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_596 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_597 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_598 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_599 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_600 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_601 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_602 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_603 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_604 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_605 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_606 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_607 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_608 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_609 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_610 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_611 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_612 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_613 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_614 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_615 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_616 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_617 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_618 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_619 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_620 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_621 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_622 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_623 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_624 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_625 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_626 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_627 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_628 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:59:59.497045: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_627_2/lstm_cell_1885/kernel/Assign' id:956312 op device:{requested: '', assigned: ''} def:{{{node lstm_627_2/lstm_cell_1885/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_627_2/lstm_cell_1885/kernel, lstm_627_2/lstm_cell_1885/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 15:00:52.984544: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_621_2/lstm_cell_1879/kernel/v/Assign' id:958400 op device:{requested: '', assigned: ''} def:{{{node lstm_621_2/lstm_cell_1879/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_621_2/lstm_cell_1879/kernel/v, lstm_621_2/lstm_cell_1879/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32515 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:01:48.875014: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:06:07.924700: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_80_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:06:32.505505: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_101/mul' id:957251 op device:{requested: '', assigned: ''} def:{{{node loss_101/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_101/mul/x, loss_101/dense_67_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.40147, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 114s 4ms/sample - loss: 1.4138 - val_loss: 1.4015\n",
      "Epoch 2/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 2: val_loss improved from 1.40147 to 1.38995, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 704us/sample - loss: 1.4093 - val_loss: 1.3899\n",
      "Epoch 3/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4089\n",
      "Epoch 3: val_loss did not improve from 1.38995\n",
      "32515/32515 [==============================] - 23s 696us/sample - loss: 1.4089 - val_loss: 1.3909\n",
      "Epoch 4/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4093\n",
      "Epoch 4: val_loss did not improve from 1.38995\n",
      "32515/32515 [==============================] - 23s 696us/sample - loss: 1.4093 - val_loss: 1.3950\n",
      "Epoch 5/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4056\n",
      "Epoch 5: val_loss improved from 1.38995 to 1.38664, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 704us/sample - loss: 1.4056 - val_loss: 1.3866\n",
      "Epoch 6/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4063\n",
      "Epoch 6: val_loss did not improve from 1.38664\n",
      "32515/32515 [==============================] - 21s 632us/sample - loss: 1.4063 - val_loss: 1.3873\n",
      "Epoch 7/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4050\n",
      "Epoch 7: val_loss improved from 1.38664 to 1.38605, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 621us/sample - loss: 1.4050 - val_loss: 1.3860\n",
      "Epoch 8/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 8: val_loss did not improve from 1.38605\n",
      "32515/32515 [==============================] - 22s 671us/sample - loss: 1.4026 - val_loss: 1.3919\n",
      "Epoch 9/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3984\n",
      "Epoch 9: val_loss improved from 1.38605 to 1.38336, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 23s 701us/sample - loss: 1.3984 - val_loss: 1.3834\n",
      "Epoch 10/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4003\n",
      "Epoch 10: val_loss did not improve from 1.38336\n",
      "32515/32515 [==============================] - 22s 690us/sample - loss: 1.4003 - val_loss: 1.3900\n",
      "Epoch 11/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3970\n",
      "Epoch 11: val_loss improved from 1.38336 to 1.37841, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 614us/sample - loss: 1.3970 - val_loss: 1.3784\n",
      "Epoch 12/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3958\n",
      "Epoch 12: val_loss did not improve from 1.37841\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.3958 - val_loss: 1.3906\n",
      "Epoch 13/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3961\n",
      "Epoch 13: val_loss did not improve from 1.37841\n",
      "32515/32515 [==============================] - 20s 602us/sample - loss: 1.3961 - val_loss: 1.3793\n",
      "Epoch 14/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3917\n",
      "Epoch 14: val_loss did not improve from 1.37841\n",
      "32515/32515 [==============================] - 20s 601us/sample - loss: 1.3917 - val_loss: 1.3855\n",
      "Epoch 15/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3916\n",
      "Epoch 15: val_loss did not improve from 1.37841\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.3916 - val_loss: 1.3810\n",
      "Epoch 16/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 16: val_loss did not improve from 1.37841\n",
      "32515/32515 [==============================] - 19s 598us/sample - loss: 1.3902 - val_loss: 1.3794\n",
      "Epoch 17/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3885\n",
      "Epoch 17: val_loss improved from 1.37841 to 1.37778, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 606us/sample - loss: 1.3885 - val_loss: 1.3778\n",
      "Epoch 18/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3880\n",
      "Epoch 18: val_loss improved from 1.37778 to 1.37663, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 608us/sample - loss: 1.3880 - val_loss: 1.3766\n",
      "Epoch 19/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3895\n",
      "Epoch 19: val_loss did not improve from 1.37663\n",
      "32515/32515 [==============================] - 19s 599us/sample - loss: 1.3895 - val_loss: 1.3811\n",
      "Epoch 20/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3846\n",
      "Epoch 20: val_loss improved from 1.37663 to 1.37603, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_46.h5\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.3846 - val_loss: 1.3760\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:14:57.379244: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_630/lstm_cell_1888/recurrent_kernel/Assign' id:969917 op device:{requested: '', assigned: ''} def:{{{node lstm_630/lstm_cell_1888/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_630/lstm_cell_1888/recurrent_kernel, lstm_630/lstm_cell_1888/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 15:15:26.977465: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_1' id:973350 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 15:15:51.186864: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice_17/stack_2' id:973351 op device:{requested: '', assigned: ''} def:{{{node strided_slice_17/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(32515, 95)\n",
      "Train on 32515 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:16:44.102083: W tensorflow/c/c_api.cc:304] Operation '{name:'training_102/Adam/lstm_636/lstm_cell_1894/bias/m/Assign' id:986223 op device:{requested: '', assigned: ''} def:{{{node training_102/Adam/lstm_636/lstm_cell_1894/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_102/Adam/lstm_636/lstm_cell_1894/bias/m, training_102/Adam/lstm_636/lstm_cell_1894/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:21:14.790199: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 3.4679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:21:37.535511: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_103/mul' id:976191 op device:{requested: '', assigned: ''} def:{{{node loss_103/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_103/mul/x, loss_103/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.92747, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 275s 8ms/sample - loss: 3.4679 - val_loss: 1.9275\n",
      "Epoch 2/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.8139\n",
      "Epoch 2: val_loss improved from 1.92747 to 1.55762, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 1.8139 - val_loss: 1.5576\n",
      "Epoch 3/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5840\n",
      "Epoch 3: val_loss improved from 1.55762 to 1.50482, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 622us/sample - loss: 1.5840 - val_loss: 1.5048\n",
      "Epoch 4/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5406\n",
      "Epoch 4: val_loss improved from 1.50482 to 1.48277, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 626us/sample - loss: 1.5406 - val_loss: 1.4828\n",
      "Epoch 5/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5195\n",
      "Epoch 5: val_loss improved from 1.48277 to 1.47006, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 624us/sample - loss: 1.5195 - val_loss: 1.4701\n",
      "Epoch 6/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5063\n",
      "Epoch 6: val_loss improved from 1.47006 to 1.45688, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 625us/sample - loss: 1.5063 - val_loss: 1.4569\n",
      "Epoch 7/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4948\n",
      "Epoch 7: val_loss improved from 1.45688 to 1.44739, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 626us/sample - loss: 1.4948 - val_loss: 1.4474\n",
      "Epoch 8/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4911\n",
      "Epoch 8: val_loss improved from 1.44739 to 1.44376, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 627us/sample - loss: 1.4911 - val_loss: 1.4438\n",
      "Epoch 9/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5001\n",
      "Epoch 9: val_loss improved from 1.44376 to 1.43903, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 22s 676us/sample - loss: 1.5001 - val_loss: 1.4390\n",
      "Epoch 10/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4953\n",
      "Epoch 10: val_loss did not improve from 1.43903\n",
      "32515/32515 [==============================] - 21s 657us/sample - loss: 1.4953 - val_loss: 1.4435\n",
      "Epoch 11/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4843\n",
      "Epoch 11: val_loss improved from 1.43903 to 1.43712, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 23s 706us/sample - loss: 1.4843 - val_loss: 1.4371\n",
      "Epoch 12/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5339\n",
      "Epoch 12: val_loss did not improve from 1.43712\n",
      "32515/32515 [==============================] - 23s 698us/sample - loss: 1.5339 - val_loss: 1.4380\n",
      "Epoch 13/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4873\n",
      "Epoch 13: val_loss improved from 1.43712 to 1.43585, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 23s 707us/sample - loss: 1.4873 - val_loss: 1.4358\n",
      "Epoch 14/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5198\n",
      "Epoch 14: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 22s 680us/sample - loss: 1.5198 - val_loss: 1.4444\n",
      "Epoch 15/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5770\n",
      "Epoch 15: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.5770 - val_loss: 1.4593\n",
      "Epoch 16/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4897\n",
      "Epoch 16: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 616us/sample - loss: 1.4897 - val_loss: 1.4508\n",
      "Epoch 17/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4800\n",
      "Epoch 17: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 619us/sample - loss: 1.4800 - val_loss: 1.4546\n",
      "Epoch 18/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4883\n",
      "Epoch 18: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 21s 637us/sample - loss: 1.4883 - val_loss: 1.4558\n",
      "Epoch 19/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.6151\n",
      "Epoch 19: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 628us/sample - loss: 1.6151 - val_loss: 1.4744\n",
      "Epoch 20/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5795\n",
      "Epoch 20: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 23s 700us/sample - loss: 1.5795 - val_loss: 1.4776\n",
      "Epoch 21/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5213\n",
      "Epoch 21: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 23s 706us/sample - loss: 1.5213 - val_loss: 1.4546\n",
      "Epoch 22/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5160\n",
      "Epoch 22: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 23s 705us/sample - loss: 1.5160 - val_loss: 1.4560\n",
      "Epoch 23/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5047\n",
      "Epoch 23: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 22s 667us/sample - loss: 1.5047 - val_loss: 1.4501\n",
      "Epoch 24/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.5101\n",
      "Epoch 24: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 1.5101 - val_loss: 1.4488\n",
      "Epoch 25/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4878\n",
      "Epoch 25: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.4878 - val_loss: 1.4428\n",
      "Epoch 26/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4824\n",
      "Epoch 26: val_loss did not improve from 1.43585\n",
      "32515/32515 [==============================] - 20s 614us/sample - loss: 1.4824 - val_loss: 1.4405\n",
      "Epoch 27/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4766\n",
      "Epoch 27: val_loss improved from 1.43585 to 1.43468, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 623us/sample - loss: 1.4766 - val_loss: 1.4347\n",
      "Epoch 28/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4742\n",
      "Epoch 28: val_loss improved from 1.43468 to 1.43407, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 615us/sample - loss: 1.4742 - val_loss: 1.4341\n",
      "Epoch 29/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4673\n",
      "Epoch 29: val_loss did not improve from 1.43407\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.4673 - val_loss: 1.4356\n",
      "Epoch 30/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4623\n",
      "Epoch 30: val_loss improved from 1.43407 to 1.43074, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.4623 - val_loss: 1.4307\n",
      "Epoch 31/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4638\n",
      "Epoch 31: val_loss improved from 1.43074 to 1.42663, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 615us/sample - loss: 1.4638 - val_loss: 1.4266\n",
      "Epoch 32/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4603\n",
      "Epoch 32: val_loss improved from 1.42663 to 1.42329, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 1.4603 - val_loss: 1.4233\n",
      "Epoch 33/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4555\n",
      "Epoch 33: val_loss did not improve from 1.42329\n",
      "32515/32515 [==============================] - 20s 611us/sample - loss: 1.4555 - val_loss: 1.4313\n",
      "Epoch 34/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4530\n",
      "Epoch 34: val_loss did not improve from 1.42329\n",
      "32515/32515 [==============================] - 20s 608us/sample - loss: 1.4530 - val_loss: 1.4255\n",
      "Epoch 35/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4494\n",
      "Epoch 35: val_loss did not improve from 1.42329\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.4494 - val_loss: 1.4235\n",
      "Epoch 36/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4510\n",
      "Epoch 36: val_loss improved from 1.42329 to 1.42053, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.4510 - val_loss: 1.4205\n",
      "Epoch 37/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4465\n",
      "Epoch 37: val_loss did not improve from 1.42053\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.4465 - val_loss: 1.4211\n",
      "Epoch 38/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4461\n",
      "Epoch 38: val_loss did not improve from 1.42053\n",
      "32515/32515 [==============================] - 20s 613us/sample - loss: 1.4461 - val_loss: 1.4282\n",
      "Epoch 39/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4433\n",
      "Epoch 39: val_loss did not improve from 1.42053\n",
      "32515/32515 [==============================] - 20s 609us/sample - loss: 1.4433 - val_loss: 1.4214\n",
      "Epoch 40/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4433\n",
      "Epoch 40: val_loss improved from 1.42053 to 1.41640, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 622us/sample - loss: 1.4433 - val_loss: 1.4164\n",
      "Epoch 41/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4389\n",
      "Epoch 41: val_loss improved from 1.41640 to 1.41626, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 614us/sample - loss: 1.4389 - val_loss: 1.4163\n",
      "Epoch 42/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4365\n",
      "Epoch 42: val_loss did not improve from 1.41626\n",
      "32515/32515 [==============================] - 20s 603us/sample - loss: 1.4365 - val_loss: 1.4181\n",
      "Epoch 43/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4370\n",
      "Epoch 43: val_loss improved from 1.41626 to 1.41368, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.4370 - val_loss: 1.4137\n",
      "Epoch 44/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4369\n",
      "Epoch 44: val_loss improved from 1.41368 to 1.41101, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 1.4369 - val_loss: 1.4110\n",
      "Epoch 45/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4323\n",
      "Epoch 45: val_loss improved from 1.41101 to 1.41025, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 619us/sample - loss: 1.4323 - val_loss: 1.4102\n",
      "Epoch 46/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 46: val_loss did not improve from 1.41025\n",
      "32515/32515 [==============================] - 20s 611us/sample - loss: 1.4305 - val_loss: 1.4113\n",
      "Epoch 47/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4280\n",
      "Epoch 47: val_loss improved from 1.41025 to 1.40618, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 1.4280 - val_loss: 1.4062\n",
      "Epoch 48/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4267\n",
      "Epoch 48: val_loss improved from 1.40618 to 1.40429, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 1.4267 - val_loss: 1.4043\n",
      "Epoch 49/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4277\n",
      "Epoch 49: val_loss improved from 1.40429 to 1.40348, saving model to ./checkpoints/unknown_person_few_shot_baseline_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 620us/sample - loss: 1.4277 - val_loss: 1.4035\n",
      "Epoch 50/50\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4241\n",
      "Epoch 50: val_loss did not improve from 1.40348\n",
      "32515/32515 [==============================] - 20s 612us/sample - loss: 1.4241 - val_loss: 1.4043\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:42:59.120590: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_637_1/lstm_cell_1932/kernel/Assign' id:989634 op device:{requested: '', assigned: ''} def:{{{node lstm_637_1/lstm_cell_1932/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_637_1/lstm_cell_1932/kernel, lstm_637_1/lstm_cell_1932/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 15:43:54.754075: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_660_1/lstm_cell_1955/kernel/m/Assign' id:995431 op device:{requested: '', assigned: ''} def:{{{node lstm_660_1/lstm_cell_1955/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_660_1/lstm_cell_1955/kernel/m, lstm_660_1/lstm_cell_1955/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 15:44:50.276720: W tensorflow/c/c_api.cc:304] Operation '{name:'dropout_89_1/cond/Merge' id:994305 op device:{requested: '', assigned: ''} def:{{{node dropout_89_1/cond/Merge}} = Merge[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](dropout_89_1/cond/Identity, dropout_89_1/cond/dropout/SelectV2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1485, 864)\n",
      "(1514, 864)\n",
      "(1644, 864)\n",
      "(1764, 864)\n",
      "(1836, 864)\n",
      "(1699, 864)\n",
      "(1369, 864)\n",
      "(1766, 864)\n",
      "(1619, 864)\n",
      "(1692, 864)\n",
      "(1550, 864)\n",
      "(1920, 864)\n",
      "(1739, 864)\n",
      "(1788, 864)\n",
      "(1812, 864)\n",
      "(1788, 864)\n",
      "(1788, 864)\n",
      "(946, 864)\n",
      "(1632, 864)\n",
      "{1: 4.724905647478893, 2: 1.055623000086767, 4: 3.6377431118847103, 5: 8.550566693573195, 6: 10.0, 8: 4.231554890634161, 9: 1.0, 10: 5.907408375380263, 11: 2.860638762755404, 12: 3.9847876969676252, 13: 4.945574594627283, 17: 3.5458351059214523, 19: 4.585390017590034, 21: 5.128256640960852, 22: 3.948059706201736, 25: 3.7082420746248643, 26: 3.7906713398136875, 27: 1.2301874429770014, 28: 5.159621485608513}\n",
      "Train on 32515 samples, validate on 3622 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:53:21.985767: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_1/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 8.3414\n",
      "Epoch 1: val_loss improved from inf to 1.41901, saving model to ./checkpoints/unknown_person_few_shot_p29_47.h5\n",
      "32515/32515 [==============================] - 119s 4ms/sample - loss: 8.3414 - val_loss: 1.4190\n",
      "Epoch 2/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2021\n",
      "Epoch 2: val_loss improved from 1.41901 to 1.39975, saving model to ./checkpoints/unknown_person_few_shot_p29_47.h5\n",
      "32515/32515 [==============================] - 23s 715us/sample - loss: 8.2021 - val_loss: 1.3998\n",
      "Epoch 3/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.2265\n",
      "Epoch 3: val_loss did not improve from 1.39975\n",
      "32515/32515 [==============================] - 21s 657us/sample - loss: 8.2265 - val_loss: 1.4151\n",
      "Epoch 4/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1388\n",
      "Epoch 4: val_loss did not improve from 1.39975\n",
      "32515/32515 [==============================] - 21s 640us/sample - loss: 8.1388 - val_loss: 1.4157\n",
      "Epoch 5/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.1122\n",
      "Epoch 5: val_loss did not improve from 1.39975\n",
      "32515/32515 [==============================] - 22s 672us/sample - loss: 8.1122 - val_loss: 1.4235\n",
      "Epoch 6/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0884\n",
      "Epoch 6: val_loss improved from 1.39975 to 1.39211, saving model to ./checkpoints/unknown_person_few_shot_p29_47.h5\n",
      "32515/32515 [==============================] - 22s 670us/sample - loss: 8.0884 - val_loss: 1.3921\n",
      "Epoch 7/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0390\n",
      "Epoch 7: val_loss did not improve from 1.39211\n",
      "32515/32515 [==============================] - 21s 636us/sample - loss: 8.0390 - val_loss: 1.4127\n",
      "Epoch 8/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0322\n",
      "Epoch 8: val_loss did not improve from 1.39211\n",
      "32515/32515 [==============================] - 21s 661us/sample - loss: 8.0322 - val_loss: 1.4024\n",
      "Epoch 9/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0557\n",
      "Epoch 9: val_loss improved from 1.39211 to 1.38967, saving model to ./checkpoints/unknown_person_few_shot_p29_47.h5\n",
      "32515/32515 [==============================] - 21s 636us/sample - loss: 8.0557 - val_loss: 1.3897\n",
      "Epoch 10/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0234\n",
      "Epoch 10: val_loss did not improve from 1.38967\n",
      "32515/32515 [==============================] - 20s 623us/sample - loss: 8.0234 - val_loss: 1.4018\n",
      "Epoch 11/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9857\n",
      "Epoch 11: val_loss did not improve from 1.38967\n",
      "32515/32515 [==============================] - 21s 650us/sample - loss: 7.9857 - val_loss: 1.3974\n",
      "Epoch 12/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9821\n",
      "Epoch 12: val_loss did not improve from 1.38967\n",
      "32515/32515 [==============================] - 22s 670us/sample - loss: 7.9821 - val_loss: 1.4289\n",
      "Epoch 13/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9670\n",
      "Epoch 13: val_loss did not improve from 1.38967\n",
      "32515/32515 [==============================] - 20s 628us/sample - loss: 7.9670 - val_loss: 1.3995\n",
      "Epoch 14/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0024\n",
      "Epoch 14: val_loss did not improve from 1.38967\n",
      "32515/32515 [==============================] - 22s 671us/sample - loss: 8.0024 - val_loss: 1.3964\n",
      "Epoch 15/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 8.0028\n",
      "Epoch 15: val_loss improved from 1.38967 to 1.38829, saving model to ./checkpoints/unknown_person_few_shot_p29_47.h5\n",
      "32515/32515 [==============================] - 23s 697us/sample - loss: 8.0028 - val_loss: 1.3883\n",
      "Epoch 16/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9174\n",
      "Epoch 16: val_loss did not improve from 1.38829\n",
      "32515/32515 [==============================] - 21s 654us/sample - loss: 7.9174 - val_loss: 1.3949\n",
      "Epoch 17/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9306\n",
      "Epoch 17: val_loss did not improve from 1.38829\n",
      "32515/32515 [==============================] - 20s 626us/sample - loss: 7.9306 - val_loss: 1.3997\n",
      "Epoch 18/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9242\n",
      "Epoch 18: val_loss improved from 1.38829 to 1.38479, saving model to ./checkpoints/unknown_person_few_shot_p29_47.h5\n",
      "32515/32515 [==============================] - 21s 643us/sample - loss: 7.9242 - val_loss: 1.3848\n",
      "Epoch 19/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.9033\n",
      "Epoch 19: val_loss did not improve from 1.38479\n",
      "32515/32515 [==============================] - 22s 679us/sample - loss: 7.9033 - val_loss: 1.3983\n",
      "Epoch 20/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 7.8722\n",
      "Epoch 20: val_loss did not improve from 1.38479\n",
      "32515/32515 [==============================] - 23s 694us/sample - loss: 7.8722 - val_loss: 1.3987\n",
      "WARNING:tensorflow:Layer lstm_629 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_630 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_631 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_632 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_633 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_634 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_635 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_636 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_637 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_638 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_639 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_640 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_641 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_642 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_643 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_644 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_645 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_646 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_647 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_648 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_649 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_650 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_651 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_652 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_653 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_654 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_655 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_656 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_657 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_658 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_659 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_660 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_661 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_662 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_663 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_664 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_665 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:02:30.120019: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_645_2/lstm_cell_1977/recurrent_kernel/Assign' id:1010332 op device:{requested: '', assigned: ''} def:{{{node lstm_645_2/lstm_cell_1977/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_645_2/lstm_cell_1977/recurrent_kernel, lstm_645_2/lstm_cell_1977/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-24 16:03:26.848966: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_646_2/lstm_cell_1978/bias/v/Assign' id:1015272 op device:{requested: '', assigned: ''} def:{{{node lstm_646_2/lstm_cell_1978/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_646_2/lstm_cell_1978/bias/v, lstm_646_2/lstm_cell_1978/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32515 samples, validate on 3622 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:04:26.226541: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:09:03.394340: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout_85_2/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:09:28.717335: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_107/mul' id:1014293 op device:{requested: '', assigned: ''} def:{{{node loss_107/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_107/mul/x, loss_107/dense_71_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.41012, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 121s 4ms/sample - loss: 1.4250 - val_loss: 1.4101\n",
      "Epoch 2/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4220\n",
      "Epoch 2: val_loss improved from 1.41012 to 1.39976, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 23s 707us/sample - loss: 1.4220 - val_loss: 1.3998\n",
      "Epoch 3/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4191\n",
      "Epoch 3: val_loss improved from 1.39976 to 1.39839, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 21s 650us/sample - loss: 1.4191 - val_loss: 1.3984\n",
      "Epoch 4/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4208\n",
      "Epoch 4: val_loss improved from 1.39839 to 1.39559, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 21s 658us/sample - loss: 1.4208 - val_loss: 1.3956\n",
      "Epoch 5/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4170\n",
      "Epoch 5: val_loss improved from 1.39559 to 1.39469, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.4170 - val_loss: 1.3947\n",
      "Epoch 6/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4154\n",
      "Epoch 6: val_loss improved from 1.39469 to 1.38972, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 618us/sample - loss: 1.4154 - val_loss: 1.3897\n",
      "Epoch 7/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4155\n",
      "Epoch 7: val_loss did not improve from 1.38972\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.4155 - val_loss: 1.3903\n",
      "Epoch 8/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4068\n",
      "Epoch 8: val_loss did not improve from 1.38972\n",
      "32515/32515 [==============================] - 21s 654us/sample - loss: 1.4068 - val_loss: 1.3972\n",
      "Epoch 9/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4096\n",
      "Epoch 9: val_loss improved from 1.38972 to 1.38961, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 21s 633us/sample - loss: 1.4096 - val_loss: 1.3896\n",
      "Epoch 10/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4109\n",
      "Epoch 10: val_loss improved from 1.38961 to 1.38938, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.4109 - val_loss: 1.3894\n",
      "Epoch 11/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4043\n",
      "Epoch 11: val_loss did not improve from 1.38938\n",
      "32515/32515 [==============================] - 20s 609us/sample - loss: 1.4043 - val_loss: 1.3916\n",
      "Epoch 12/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4056\n",
      "Epoch 12: val_loss did not improve from 1.38938\n",
      "32515/32515 [==============================] - 20s 607us/sample - loss: 1.4056 - val_loss: 1.4062\n",
      "Epoch 13/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.4034\n",
      "Epoch 13: val_loss did not improve from 1.38938\n",
      "32515/32515 [==============================] - 20s 607us/sample - loss: 1.4034 - val_loss: 1.3926\n",
      "Epoch 14/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3992\n",
      "Epoch 14: val_loss did not improve from 1.38938\n",
      "32515/32515 [==============================] - 20s 608us/sample - loss: 1.3992 - val_loss: 1.3968\n",
      "Epoch 15/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3987\n",
      "Epoch 15: val_loss did not improve from 1.38938\n",
      "32515/32515 [==============================] - 20s 608us/sample - loss: 1.3987 - val_loss: 1.3896\n",
      "Epoch 16/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3981\n",
      "Epoch 16: val_loss improved from 1.38938 to 1.38295, saving model to ./checkpoints/unknown_person_few_shot_baseline_2_p29_47.h5\n",
      "32515/32515 [==============================] - 20s 617us/sample - loss: 1.3981 - val_loss: 1.3829\n",
      "Epoch 17/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3987\n",
      "Epoch 17: val_loss did not improve from 1.38295\n",
      "32515/32515 [==============================] - 20s 608us/sample - loss: 1.3987 - val_loss: 1.3851\n",
      "Epoch 18/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3986\n",
      "Epoch 18: val_loss did not improve from 1.38295\n",
      "32515/32515 [==============================] - 21s 658us/sample - loss: 1.3986 - val_loss: 1.3880\n",
      "Epoch 19/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 19: val_loss did not improve from 1.38295\n",
      "32515/32515 [==============================] - 20s 610us/sample - loss: 1.3939 - val_loss: 1.3852\n",
      "Epoch 20/20\n",
      "32515/32515 [==============================] - ETA: 0s - loss: 1.3937\n",
      "Epoch 20: val_loss did not improve from 1.38295\n",
      "32515/32515 [==============================] - 21s 648us/sample - loss: 1.3937 - val_loss: 1.3922\n"
     ]
    }
   ],
   "source": [
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples, split_data_unknown, split_data_few_shot\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "\n",
    "test_person_id = [29]\n",
    "ra_all = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "idx = 30\n",
    "for ra in ra_all:\n",
    "    flag_tr_val_te = split_data_few_shot(test_person_id, walk_nums_all, trace_nums_all, people_nums_all, person_nums, ratio = ra, rand_seed = 42)\n",
    "    ## Data Normalization before training ans testing\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalers = []\n",
    "    X_train_normalized = []\n",
    "    X_val_normalized = []\n",
    "    X_test_normalized = []\n",
    "    train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "    np.random.shuffle(train_idx)\n",
    "    val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "    test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "    \n",
    "    for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature_combine, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "        scaler = StandardScaler()\n",
    "        if len(feature.shape)==2:\n",
    "            X_train_i = feature[train_idx,:]\n",
    "            X_val_i = feature[val_idx,:]\n",
    "            X_test_i = feature[test_idx,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i)\n",
    "            scalers.append(scaler)\n",
    "        else:\n",
    "            X_train_i = feature[train_idx,:,:]\n",
    "            X_val_i = feature[val_idx,:,:]\n",
    "            X_test_i = feature[test_idx,:,:]\n",
    "            X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "            X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "            X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "            scalers.append(scaler)\n",
    "        X_train_normalized.append(X_train_normalized_i)\n",
    "        X_val_normalized.append(X_val_normalized_i)\n",
    "        X_test_normalized.append(X_test_normalized_i)\n",
    "    y_train = gts[train_idx,:]\n",
    "    y_val = gts[val_idx,:]\n",
    "    y_test = gts[test_idx,:]\n",
    "    X_train_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "    for feature in X_train_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_train_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_train_normalized_new.append(feature)\n",
    "    X_train_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_val_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "    for feature in X_val_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_val_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_val_normalized_new.append(feature)\n",
    "    X_val_normalized_new.append(combined_feature)\n",
    "    \n",
    "    X_test_normalized_new = []\n",
    "    combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "    for feature in X_test_normalized:\n",
    "        if len(feature.shape) == 3:\n",
    "            X_test_normalized_new.append(feature)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "        else:\n",
    "            X_test_normalized_new.append(feature)\n",
    "    X_test_normalized_new.append(combined_feature)\n",
    "    \n",
    "    \n",
    "    num_epochs = 50\n",
    "    \n",
    "    \n",
    "    # Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    \n",
    "    \n",
    "    rates = [0.4, 0.5, 0.6]\n",
    "    \n",
    "    for r in rates:\n",
    "        model = individual_model(X_train_normalized)\n",
    "        model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    \n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=20, frequency=1)\n",
    "        model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import tensorflow as tf\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        from tensorflow.keras.models import Model\n",
    "        layers = model.layers\n",
    "        second_last_layer_output = layers[-4].output\n",
    "        feature_extractor_model = Model(inputs=model.input, outputs=second_last_layer_output)\n",
    "        train_features = feature_extractor_model.predict(X_train_normalized_new)\n",
    "        test_features = feature_extractor_model.predict(X_test_normalized_new)\n",
    "        \n",
    "        p_train = people_nums[train_idx,:]\n",
    "        p_val = people_nums[val_idx,:]\n",
    "        p_test = people_nums[test_idx,:]\n",
    "        ## Calculate the distance between test person and training person\n",
    "        def euclidean_distance(a, b):\n",
    "            return np.sqrt(np.sum((a - b) ** 2, axis=1))\n",
    "        \n",
    "        distance_dict = {}\n",
    "        for ii in range(len(person_nums)):\n",
    "            if person_nums[ii] == test_person_id[0]:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                ind = np.where(p_train ==person_nums[ii])[0]\n",
    "                tmp_train_features = train_features[ind, :]\n",
    "                distances = np.array([euclidean_distance(train_sample, test_features) for train_sample in tmp_train_features])\n",
    "                print(distances.shape)\n",
    "                average_distances = np.mean(distances, axis=1)\n",
    "        \n",
    "                # Step 4: Find the overall average distance\n",
    "                overall_average_distance = np.mean(average_distances)\n",
    "                distance_dict[person_nums[ii]] = overall_average_distance\n",
    "        \n",
    "        \n",
    "        def normalize_to_weights(distance_dict):\n",
    "            distances = np.array(list(distance_dict.values()))\n",
    "            # Handle the case where a distance is zero to avoid division by zero\n",
    "            distances = np.clip(distances, a_min=1e-10, a_max=None)\n",
    "            weights = 1 / distances\n",
    "            normalized_weights = weights\n",
    "            # normalized_weights = weights / sum(weights)\n",
    "            # print(sum(weights))\n",
    "            # print(sum(normalized_weights))\n",
    "            # Assign the normalized weights back to the dictionary\n",
    "            normalized_weight_dict = dict(zip(distance_dict.keys(), normalized_weights))\n",
    "            return normalized_weight_dict\n",
    "        def scale_dict_values(my_dict):\n",
    "            scaled_dict = my_dict.copy()\n",
    "            min_val = min(scaled_dict.values())\n",
    "            max_val = max(scaled_dict.values())\n",
    "            \n",
    "            for key in scaled_dict:\n",
    "                scaled_dict[key] = 1 + 9 * (scaled_dict[key] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            return scaled_dict\n",
    "        weights_dict = normalize_to_weights(distance_dict)\n",
    "        weights_dict = scale_dict_values(weights_dict)\n",
    "        print(weights_dict)\n",
    "        \n",
    "        w_train = np.zeros_like(p_train)\n",
    "        for i in range(len(w_train)):\n",
    "            if p_train[i] == test_person_id[0]:\n",
    "                w_train[i] = 50\n",
    "            else:\n",
    "                w_train[i] = weights_dict[int(p_train[i])]\n",
    "        \n",
    "        w_train = np.squeeze(w_train)\n",
    "        \n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,sample_weight= w_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        # for layer in model.layers[-4:]:\n",
    "        #     layer.trainable = False\n",
    "        # model = individual_model.individual_model(X_train_normalized)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        model = tf.keras.models.load_model(model_name)\n",
    "        model_name = './checkpoints/unknown_person_few_shot_baseline_2_p'+str(test_person_id[0])+'_'+str(idx)+'.h5'\n",
    "        idx += 1\n",
    "        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "        pruning_callback = PruningCallback(initial_pruning_factor=r, final_pruning_factor=r, start_epoch=1, end_epoch=20, frequency=1)\n",
    "        \n",
    "        history = model.fit(x=X_train_normalized_new, y=y_train,epochs=20, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508e9a1-9544-41f8-af41-e3d3b02a8d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b59e4-6581-4ea8-994d-a02a6654ab6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
