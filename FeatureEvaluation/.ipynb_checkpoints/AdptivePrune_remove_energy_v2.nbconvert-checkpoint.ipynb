{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4cd1e-14c8-4f76-8133-e8617bb62b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Baseline Method only use simple gait parameter feature, it only includes 2 dense layers\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## We delete people's data with low feedback score and remove people who kicked off the sensors during walking'\n",
    "## So 20 people in total.\n",
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "flag_tr_val_te = split_data(walk_nums_all, trace_nums_all, people_nums_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170353c1-fcb9-4e2b-9909-c3a263bf8bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:54:56.897967Z",
     "iopub.status.busy": "2023-12-05T04:54:56.897814Z",
     "iopub.status.idle": "2023-12-05T04:55:00.792915Z",
     "shell.execute_reply": "2023-12-05T04:55:00.792323Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:54:57.040484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e10b0d-fa00-4007-ad02-296357d1871d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:55:00.795313Z",
     "iopub.status.busy": "2023-12-05T04:55:00.795041Z",
     "iopub.status.idle": "2023-12-05T04:55:00.822271Z",
     "shell.execute_reply": "2023-12-05T04:55:00.821688Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c8fb4a-5f62-4ff5-9d55-a5fd0197b624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:55:00.824410Z",
     "iopub.status.busy": "2023-12-05T04:55:00.824285Z",
     "iopub.status.idle": "2023-12-05T04:55:00.830846Z",
     "shell.execute_reply": "2023-12-05T04:55:00.830369Z"
    }
   },
   "outputs": [],
   "source": [
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7526f3-8fb8-4aca-9d40-c3e551262af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T04:55:00.832726Z",
     "iopub.status.busy": "2023-12-05T04:55:00.832607Z",
     "iopub.status.idle": "2023-12-05T09:42:58.951490Z",
     "shell.execute_reply": "2023-12-05T09:42:58.950902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:55:30.901306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.913170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.913402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.917074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.917264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.917429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.975005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.975209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.975379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:30.975522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-12-04 23:55:30.975831: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:55:31.894021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:31.894258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:31.894428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:31.894631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:31.894801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 23:55:31.894970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-12-04 23:55:31.894998: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-12-04 23:55:31.915795: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-12-04 23:55:32.152252: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_20/lstm_cell_20/recurrent_kernel/Assign' id:3336 op device:{requested: '', assigned: ''} def:{{{node lstm_20/lstm_cell_20/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_20/lstm_cell_20/recurrent_kernel, lstm_20/lstm_cell_20/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:56:02.303103: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-12-04 23:56:02.338723: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(29601, 95)\n",
      "Train on 29601 samples, validate on 3694 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:56:06.374970: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_1/lstm_cell_1/bias/v/Assign' id:15748 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_1/lstm_cell_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_1/lstm_cell_1/bias/v, training/Adam/lstm_1/lstm_cell_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:56:10.081131: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-12-04 23:56:12.534091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-04 23:56:12.541388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29601/29601 [==============================] - ETA: 0s - loss: 2.5805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-12-04 23:56:30.903725: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:5982 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.83795, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 26s 868us/sample - loss: 2.5805 - val_loss: 1.8379\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.7306\n",
      "Epoch 2: val_loss improved from 1.83795 to 1.61061, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.7306 - val_loss: 1.6106\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.6039\n",
      "Epoch 3: val_loss improved from 1.61061 to 1.56223, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.6039 - val_loss: 1.5622\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5507\n",
      "Epoch 4: val_loss improved from 1.56223 to 1.52543, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.5507 - val_loss: 1.5254\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5231\n",
      "Epoch 5: val_loss improved from 1.52543 to 1.50590, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.5231 - val_loss: 1.5059\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5020\n",
      "Epoch 6: val_loss improved from 1.50590 to 1.48648, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.5020 - val_loss: 1.4865\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4898\n",
      "Epoch 7: val_loss improved from 1.48648 to 1.46999, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.4898 - val_loss: 1.4700\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4809\n",
      "Epoch 8: val_loss did not improve from 1.46999\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.4809 - val_loss: 1.4749\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4736\n",
      "Epoch 9: val_loss improved from 1.46999 to 1.46039, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.4736 - val_loss: 1.4604\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4637\n",
      "Epoch 10: val_loss improved from 1.46039 to 1.45217, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.4637 - val_loss: 1.4522\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4596\n",
      "Epoch 11: val_loss improved from 1.45217 to 1.44200, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.4596 - val_loss: 1.4420\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4543\n",
      "Epoch 12: val_loss did not improve from 1.44200\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.4543 - val_loss: 1.4439\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4484\n",
      "Epoch 13: val_loss improved from 1.44200 to 1.43443, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.4484 - val_loss: 1.4344\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4419\n",
      "Epoch 14: val_loss improved from 1.43443 to 1.43129, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.4419 - val_loss: 1.4313\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4375\n",
      "Epoch 15: val_loss improved from 1.43129 to 1.42380, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.4375 - val_loss: 1.4238\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4333\n",
      "Epoch 16: val_loss improved from 1.42380 to 1.42172, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.4333 - val_loss: 1.4217\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4296\n",
      "Epoch 17: val_loss improved from 1.42172 to 1.41872, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.4296 - val_loss: 1.4187\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4238\n",
      "Epoch 18: val_loss improved from 1.41872 to 1.41225, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.4238 - val_loss: 1.4122\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4229\n",
      "Epoch 19: val_loss improved from 1.41225 to 1.41224, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.4229 - val_loss: 1.4122\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4243\n",
      "Epoch 20: val_loss did not improve from 1.41224\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.4243 - val_loss: 1.4193\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4219\n",
      "Epoch 21: val_loss improved from 1.41224 to 1.40715, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.4219 - val_loss: 1.4072\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4135\n",
      "Epoch 22: val_loss improved from 1.40715 to 1.40191, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.4135 - val_loss: 1.4019\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4107\n",
      "Epoch 23: val_loss improved from 1.40191 to 1.40020, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.4107 - val_loss: 1.4002\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4067\n",
      "Epoch 24: val_loss improved from 1.40020 to 1.39789, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.4067 - val_loss: 1.3979\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4048\n",
      "Epoch 25: val_loss did not improve from 1.39789\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.4048 - val_loss: 1.3988\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4017\n",
      "Epoch 26: val_loss improved from 1.39789 to 1.39772, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.4017 - val_loss: 1.3977\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4026\n",
      "Epoch 27: val_loss improved from 1.39772 to 1.39542, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.4026 - val_loss: 1.3954\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4029\n",
      "Epoch 28: val_loss did not improve from 1.39542\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.4029 - val_loss: 1.3967\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3971\n",
      "Epoch 29: val_loss did not improve from 1.39542\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.3971 - val_loss: 1.3966\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 30: val_loss improved from 1.39542 to 1.39044, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.3939 - val_loss: 1.3904\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3941\n",
      "Epoch 31: val_loss did not improve from 1.39044\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.3941 - val_loss: 1.3934\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3927\n",
      "Epoch 32: val_loss did not improve from 1.39044\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.3927 - val_loss: 1.3935\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3902\n",
      "Epoch 33: val_loss improved from 1.39044 to 1.38864, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.3902 - val_loss: 1.3886\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3874\n",
      "Epoch 34: val_loss improved from 1.38864 to 1.38686, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.3874 - val_loss: 1.3869\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3864\n",
      "Epoch 35: val_loss did not improve from 1.38686\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.3864 - val_loss: 1.3873\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3845\n",
      "Epoch 36: val_loss did not improve from 1.38686\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3845 - val_loss: 1.3895\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3863\n",
      "Epoch 37: val_loss improved from 1.38686 to 1.38529, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.3863 - val_loss: 1.3853\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3834\n",
      "Epoch 38: val_loss improved from 1.38529 to 1.38213, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.3834 - val_loss: 1.3821\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3814\n",
      "Epoch 39: val_loss improved from 1.38213 to 1.37510, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3814 - val_loss: 1.3751\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3787\n",
      "Epoch 40: val_loss did not improve from 1.37510\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.3787 - val_loss: 1.3786\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3768\n",
      "Epoch 41: val_loss did not improve from 1.37510\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.3768 - val_loss: 1.3792\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3764\n",
      "Epoch 42: val_loss did not improve from 1.37510\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.3764 - val_loss: 1.3789\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3769\n",
      "Epoch 43: val_loss did not improve from 1.37510\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.3769 - val_loss: 1.3791\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3734\n",
      "Epoch 44: val_loss did not improve from 1.37510\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.3734 - val_loss: 1.3769\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3715\n",
      "Epoch 45: val_loss improved from 1.37510 to 1.37163, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.3715 - val_loss: 1.3716\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3692\n",
      "Epoch 46: val_loss did not improve from 1.37163\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.3692 - val_loss: 1.3747\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3691\n",
      "Epoch 47: val_loss did not improve from 1.37163\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3691 - val_loss: 1.3722\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3684\n",
      "Epoch 48: val_loss improved from 1.37163 to 1.36958, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.3684 - val_loss: 1.3696\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3663\n",
      "Epoch 49: val_loss improved from 1.36958 to 1.36737, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.3663 - val_loss: 1.3674\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3622\n",
      "Epoch 50: val_loss improved from 1.36737 to 1.36464, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3622 - val_loss: 1.3646\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3654\n",
      "Epoch 51: val_loss did not improve from 1.36464\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3654 - val_loss: 1.3724\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3611\n",
      "Epoch 52: val_loss did not improve from 1.36464\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.3611 - val_loss: 1.3679\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3592\n",
      "Epoch 53: val_loss did not improve from 1.36464\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.3592 - val_loss: 1.3729\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3599\n",
      "Epoch 54: val_loss improved from 1.36464 to 1.36357, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.3599 - val_loss: 1.3636\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3566\n",
      "Epoch 55: val_loss did not improve from 1.36357\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3566 - val_loss: 1.3668\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3570\n",
      "Epoch 56: val_loss improved from 1.36357 to 1.36111, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3570 - val_loss: 1.3611\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3564\n",
      "Epoch 57: val_loss did not improve from 1.36111\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.3564 - val_loss: 1.3642\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3508\n",
      "Epoch 58: val_loss did not improve from 1.36111\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.3508 - val_loss: 1.3666\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3530\n",
      "Epoch 59: val_loss improved from 1.36111 to 1.36057, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.3530 - val_loss: 1.3606\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3528\n",
      "Epoch 60: val_loss did not improve from 1.36057\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3528 - val_loss: 1.3628\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3529\n",
      "Epoch 61: val_loss did not improve from 1.36057\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.3529 - val_loss: 1.3623\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3466\n",
      "Epoch 62: val_loss did not improve from 1.36057\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.3466 - val_loss: 1.3635\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3473\n",
      "Epoch 63: val_loss did not improve from 1.36057\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.3473 - val_loss: 1.3630\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3488\n",
      "Epoch 64: val_loss did not improve from 1.36057\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.3488 - val_loss: 1.3625\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3444\n",
      "Epoch 65: val_loss improved from 1.36057 to 1.36050, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.3444 - val_loss: 1.3605\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3431\n",
      "Epoch 66: val_loss improved from 1.36050 to 1.35779, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.3431 - val_loss: 1.3578\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3417\n",
      "Epoch 67: val_loss improved from 1.35779 to 1.35627, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.3417 - val_loss: 1.3563\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3391\n",
      "Epoch 68: val_loss did not improve from 1.35627\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.3391 - val_loss: 1.3660\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3404\n",
      "Epoch 69: val_loss did not improve from 1.35627\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.3404 - val_loss: 1.3565\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3397\n",
      "Epoch 70: val_loss did not improve from 1.35627\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.3397 - val_loss: 1.3587\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3362\n",
      "Epoch 71: val_loss improved from 1.35627 to 1.35621, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.3362 - val_loss: 1.3562\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3354\n",
      "Epoch 72: val_loss did not improve from 1.35621\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.3354 - val_loss: 1.3592\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3335\n",
      "Epoch 73: val_loss did not improve from 1.35621\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.3335 - val_loss: 1.3650\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3328\n",
      "Epoch 74: val_loss improved from 1.35621 to 1.35528, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.3328 - val_loss: 1.3553\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3356\n",
      "Epoch 75: val_loss did not improve from 1.35528\n",
      "29601/29601 [==============================] - 15s 524us/sample - loss: 1.3356 - val_loss: 1.3590\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3339\n",
      "Epoch 76: val_loss did not improve from 1.35528\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.3339 - val_loss: 1.3622\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3306\n",
      "Epoch 77: val_loss did not improve from 1.35528\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.3306 - val_loss: 1.3587\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3275\n",
      "Epoch 78: val_loss improved from 1.35528 to 1.35433, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.3275 - val_loss: 1.3543\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3302\n",
      "Epoch 79: val_loss improved from 1.35433 to 1.35040, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.3302 - val_loss: 1.3504\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3277\n",
      "Epoch 80: val_loss did not improve from 1.35040\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.3277 - val_loss: 1.3549\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3272\n",
      "Epoch 81: val_loss did not improve from 1.35040\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.3272 - val_loss: 1.3522\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3283\n",
      "Epoch 82: val_loss did not improve from 1.35040\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.3283 - val_loss: 1.3541\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3242\n",
      "Epoch 83: val_loss did not improve from 1.35040\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.3242 - val_loss: 1.3506\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3244\n",
      "Epoch 84: val_loss improved from 1.35040 to 1.34971, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3244 - val_loss: 1.3497\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3202\n",
      "Epoch 85: val_loss improved from 1.34971 to 1.34937, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3202 - val_loss: 1.3494\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3221\n",
      "Epoch 86: val_loss did not improve from 1.34937\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.3221 - val_loss: 1.3561\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3180\n",
      "Epoch 87: val_loss improved from 1.34937 to 1.34764, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.3180 - val_loss: 1.3476\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3212\n",
      "Epoch 88: val_loss did not improve from 1.34764\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.3212 - val_loss: 1.3560\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3207\n",
      "Epoch 89: val_loss did not improve from 1.34764\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.3207 - val_loss: 1.3555\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3197\n",
      "Epoch 90: val_loss improved from 1.34764 to 1.34639, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.3197 - val_loss: 1.3464\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3168\n",
      "Epoch 91: val_loss did not improve from 1.34639\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.3168 - val_loss: 1.3477\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3161\n",
      "Epoch 92: val_loss improved from 1.34639 to 1.34528, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3161 - val_loss: 1.3453\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3151\n",
      "Epoch 93: val_loss did not improve from 1.34528\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.3151 - val_loss: 1.3499\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3107\n",
      "Epoch 94: val_loss improved from 1.34528 to 1.34458, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.3107 - val_loss: 1.3446\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3099\n",
      "Epoch 95: val_loss did not improve from 1.34458\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.3099 - val_loss: 1.3457\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3117\n",
      "Epoch 96: val_loss did not improve from 1.34458\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3117 - val_loss: 1.3478\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3104\n",
      "Epoch 97: val_loss did not improve from 1.34458\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.3104 - val_loss: 1.3495\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3106\n",
      "Epoch 98: val_loss improved from 1.34458 to 1.34255, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3106 - val_loss: 1.3426\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3091\n",
      "Epoch 99: val_loss did not improve from 1.34255\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.3091 - val_loss: 1.3490\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3075\n",
      "Epoch 100: val_loss improved from 1.34255 to 1.34252, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_0.h5\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.3075 - val_loss: 1.3425\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3056\n",
      "Epoch 1: val_loss improved from inf to 1.34593, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_1.h5\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.3056 - val_loss: 1.3459\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3118\n",
      "Epoch 2: val_loss did not improve from 1.34593\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.3118 - val_loss: 1.3492\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3074\n",
      "Epoch 3: val_loss did not improve from 1.34593\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3074 - val_loss: 1.3502\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3073\n",
      "Epoch 4: val_loss improved from 1.34593 to 1.33971, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_1.h5\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.3073 - val_loss: 1.3397\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3028\n",
      "Epoch 5: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3028 - val_loss: 1.3494\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3049\n",
      "Epoch 6: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.3049 - val_loss: 1.3446\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2988\n",
      "Epoch 7: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2988 - val_loss: 1.3439\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3006\n",
      "Epoch 8: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.3006 - val_loss: 1.3480\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3031\n",
      "Epoch 9: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.3031 - val_loss: 1.3534\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3033\n",
      "Epoch 10: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.3033 - val_loss: 1.3482\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3038\n",
      "Epoch 11: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.3038 - val_loss: 1.3490\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2999\n",
      "Epoch 12: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2999 - val_loss: 1.3517\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2995\n",
      "Epoch 13: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2995 - val_loss: 1.3537\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3019\n",
      "Epoch 14: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.3019 - val_loss: 1.3583\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2982\n",
      "Epoch 15: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2982 - val_loss: 1.3491\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2956\n",
      "Epoch 16: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2956 - val_loss: 1.3449\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2952\n",
      "Epoch 17: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2952 - val_loss: 1.3449\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2984\n",
      "Epoch 18: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2984 - val_loss: 1.3584\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2969\n",
      "Epoch 19: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2969 - val_loss: 1.3478\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2995\n",
      "Epoch 20: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2995 - val_loss: 1.3471\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2975\n",
      "Epoch 21: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2975 - val_loss: 1.3487\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2977\n",
      "Epoch 22: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2977 - val_loss: 1.3436\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2925\n",
      "Epoch 23: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2925 - val_loss: 1.3432\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2947\n",
      "Epoch 24: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2947 - val_loss: 1.3511\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2949\n",
      "Epoch 25: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2949 - val_loss: 1.3464\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2948\n",
      "Epoch 26: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2948 - val_loss: 1.3442\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2904\n",
      "Epoch 27: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2904 - val_loss: 1.3507\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2921\n",
      "Epoch 28: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2921 - val_loss: 1.3451\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2908\n",
      "Epoch 29: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2908 - val_loss: 1.3419\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2897\n",
      "Epoch 30: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2897 - val_loss: 1.3442\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2864\n",
      "Epoch 31: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2864 - val_loss: 1.3434\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2879\n",
      "Epoch 32: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2879 - val_loss: 1.3481\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2870\n",
      "Epoch 33: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2870 - val_loss: 1.3456\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2908\n",
      "Epoch 34: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2908 - val_loss: 1.3457\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2881\n",
      "Epoch 35: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2881 - val_loss: 1.3461\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2888\n",
      "Epoch 36: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2888 - val_loss: 1.3482\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2857\n",
      "Epoch 37: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2857 - val_loss: 1.3434\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2847\n",
      "Epoch 38: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2847 - val_loss: 1.3414\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2862\n",
      "Epoch 39: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2862 - val_loss: 1.3419\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2848\n",
      "Epoch 40: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2848 - val_loss: 1.3411\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2873\n",
      "Epoch 41: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2873 - val_loss: 1.3404\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2890\n",
      "Epoch 42: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2890 - val_loss: 1.3444\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2839\n",
      "Epoch 43: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2839 - val_loss: 1.3434\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2838\n",
      "Epoch 44: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2838 - val_loss: 1.3412\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2854\n",
      "Epoch 45: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2854 - val_loss: 1.3416\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2830\n",
      "Epoch 46: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2830 - val_loss: 1.3433\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2849\n",
      "Epoch 47: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2849 - val_loss: 1.3441\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2863\n",
      "Epoch 48: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2863 - val_loss: 1.3453\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2818\n",
      "Epoch 49: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2818 - val_loss: 1.3461\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2832\n",
      "Epoch 50: val_loss did not improve from 1.33971\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2832 - val_loss: 1.3458\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2837\n",
      "Epoch 51: val_loss improved from 1.33971 to 1.33809, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_1.h5\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2837 - val_loss: 1.3381\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2843\n",
      "Epoch 52: val_loss did not improve from 1.33809\n",
      "29601/29601 [==============================] - 18s 624us/sample - loss: 1.2843 - val_loss: 1.3420\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2798\n",
      "Epoch 53: val_loss improved from 1.33809 to 1.33756, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_1.h5\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2798 - val_loss: 1.3376\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2784\n",
      "Epoch 54: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2784 - val_loss: 1.3435\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2797\n",
      "Epoch 55: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2797 - val_loss: 1.3410\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2763\n",
      "Epoch 56: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2763 - val_loss: 1.3406\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2773\n",
      "Epoch 57: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2773 - val_loss: 1.3527\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2760\n",
      "Epoch 58: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2760 - val_loss: 1.3400\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2753\n",
      "Epoch 59: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2753 - val_loss: 1.3404\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2710\n",
      "Epoch 60: val_loss did not improve from 1.33756\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2710 - val_loss: 1.3427\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2737\n",
      "Epoch 61: val_loss improved from 1.33756 to 1.33634, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_1.h5\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2737 - val_loss: 1.3363\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2728\n",
      "Epoch 62: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.2728 - val_loss: 1.3433\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2742\n",
      "Epoch 63: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2742 - val_loss: 1.3411\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2700\n",
      "Epoch 64: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2700 - val_loss: 1.3416\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2691\n",
      "Epoch 65: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2691 - val_loss: 1.3400\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2682\n",
      "Epoch 66: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2682 - val_loss: 1.3491\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2681\n",
      "Epoch 67: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2681 - val_loss: 1.3423\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2664\n",
      "Epoch 68: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2664 - val_loss: 1.3403\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2689\n",
      "Epoch 69: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2689 - val_loss: 1.3416\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2665\n",
      "Epoch 70: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2665 - val_loss: 1.3399\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2634\n",
      "Epoch 71: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 15s 524us/sample - loss: 1.2634 - val_loss: 1.3438\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2629\n",
      "Epoch 72: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2629 - val_loss: 1.3364\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2636\n",
      "Epoch 73: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2636 - val_loss: 1.3438\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2641\n",
      "Epoch 74: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2641 - val_loss: 1.3385\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2643\n",
      "Epoch 75: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2643 - val_loss: 1.3396\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2659\n",
      "Epoch 76: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2659 - val_loss: 1.3457\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2629\n",
      "Epoch 77: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2629 - val_loss: 1.3449\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2618\n",
      "Epoch 78: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2618 - val_loss: 1.3402\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2659\n",
      "Epoch 79: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2659 - val_loss: 1.3454\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 80: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2598 - val_loss: 1.3479\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2612\n",
      "Epoch 81: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2612 - val_loss: 1.3493\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2621\n",
      "Epoch 82: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2621 - val_loss: 1.3439\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2588\n",
      "Epoch 83: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2588 - val_loss: 1.3407\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2544\n",
      "Epoch 84: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2544 - val_loss: 1.3380\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2573\n",
      "Epoch 85: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2573 - val_loss: 1.3407\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2575\n",
      "Epoch 86: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2575 - val_loss: 1.3397\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2575\n",
      "Epoch 87: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2575 - val_loss: 1.3486\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2564\n",
      "Epoch 88: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2564 - val_loss: 1.3394\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2553\n",
      "Epoch 89: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2553 - val_loss: 1.3449\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2553\n",
      "Epoch 90: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2553 - val_loss: 1.3445\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2534\n",
      "Epoch 91: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2534 - val_loss: 1.3474\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2570\n",
      "Epoch 92: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2570 - val_loss: 1.3394\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2529\n",
      "Epoch 93: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2529 - val_loss: 1.3415\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2545\n",
      "Epoch 94: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2545 - val_loss: 1.3434\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2541\n",
      "Epoch 95: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.2541 - val_loss: 1.3446\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2513\n",
      "Epoch 96: val_loss did not improve from 1.33634\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2513 - val_loss: 1.3438\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 97: val_loss improved from 1.33634 to 1.33505, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_1.h5\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.2523 - val_loss: 1.3351\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2496\n",
      "Epoch 98: val_loss did not improve from 1.33505\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2496 - val_loss: 1.3381\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 99: val_loss did not improve from 1.33505\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2471 - val_loss: 1.3448\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2509\n",
      "Epoch 100: val_loss did not improve from 1.33505\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2509 - val_loss: 1.3389\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2481\n",
      "Epoch 1: val_loss improved from inf to 1.34067, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_2.h5\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2481 - val_loss: 1.3407\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2495\n",
      "Epoch 2: val_loss improved from 1.34067 to 1.33923, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_2.h5\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2495 - val_loss: 1.3392\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2461\n",
      "Epoch 3: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2461 - val_loss: 1.3414\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2454\n",
      "Epoch 4: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2454 - val_loss: 1.3441\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2479\n",
      "Epoch 5: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2479 - val_loss: 1.3394\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2452\n",
      "Epoch 6: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2452 - val_loss: 1.3466\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2443\n",
      "Epoch 7: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2443 - val_loss: 1.3442\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2465\n",
      "Epoch 8: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2465 - val_loss: 1.3443\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2479\n",
      "Epoch 9: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2479 - val_loss: 1.3476\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2461\n",
      "Epoch 10: val_loss did not improve from 1.33923\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2461 - val_loss: 1.3408\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2480\n",
      "Epoch 11: val_loss improved from 1.33923 to 1.33480, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_2.h5\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2480 - val_loss: 1.3348\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2484\n",
      "Epoch 12: val_loss did not improve from 1.33480\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2484 - val_loss: 1.3406\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2450\n",
      "Epoch 13: val_loss improved from 1.33480 to 1.33393, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_2.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2450 - val_loss: 1.3339\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2450\n",
      "Epoch 14: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2450 - val_loss: 1.3399\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2463\n",
      "Epoch 15: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2463 - val_loss: 1.3374\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2477\n",
      "Epoch 16: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2477 - val_loss: 1.3380\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2491\n",
      "Epoch 17: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2491 - val_loss: 1.3419\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2475\n",
      "Epoch 18: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2475 - val_loss: 1.3443\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2463\n",
      "Epoch 19: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2463 - val_loss: 1.3381\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 20: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2473 - val_loss: 1.3412\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2478\n",
      "Epoch 21: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2478 - val_loss: 1.3389\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2462\n",
      "Epoch 22: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2462 - val_loss: 1.3434\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2483\n",
      "Epoch 23: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2483 - val_loss: 1.3406\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 24: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2486 - val_loss: 1.3398\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2451\n",
      "Epoch 25: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2451 - val_loss: 1.3375\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2530\n",
      "Epoch 26: val_loss did not improve from 1.33393\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2530 - val_loss: 1.3363\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 27: val_loss improved from 1.33393 to 1.33371, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_2.h5\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2471 - val_loss: 1.3337\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2554\n",
      "Epoch 28: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2554 - val_loss: 1.3382\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2510\n",
      "Epoch 29: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2510 - val_loss: 1.3388\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2521\n",
      "Epoch 30: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2521 - val_loss: 1.3408\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2493\n",
      "Epoch 31: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2493 - val_loss: 1.3383\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2512\n",
      "Epoch 32: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2512 - val_loss: 1.3390\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2512\n",
      "Epoch 33: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2512 - val_loss: 1.3398\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2504\n",
      "Epoch 34: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2504 - val_loss: 1.3452\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 35: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2501 - val_loss: 1.3434\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 36: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2523 - val_loss: 1.3367\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2530\n",
      "Epoch 37: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2530 - val_loss: 1.3390\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2525\n",
      "Epoch 38: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2525 - val_loss: 1.3395\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2514\n",
      "Epoch 39: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2514 - val_loss: 1.3483\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2485\n",
      "Epoch 40: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2485 - val_loss: 1.3374\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2504\n",
      "Epoch 41: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2504 - val_loss: 1.3369\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2516\n",
      "Epoch 42: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2516 - val_loss: 1.3393\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2490\n",
      "Epoch 43: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2490 - val_loss: 1.3404\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2489\n",
      "Epoch 44: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2489 - val_loss: 1.3406\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2522\n",
      "Epoch 45: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2522 - val_loss: 1.3368\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2483\n",
      "Epoch 46: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 20s 676us/sample - loss: 1.2483 - val_loss: 1.3349\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2491\n",
      "Epoch 47: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 25s 831us/sample - loss: 1.2491 - val_loss: 1.3432\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2488\n",
      "Epoch 48: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 26s 871us/sample - loss: 1.2488 - val_loss: 1.3343\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2506\n",
      "Epoch 49: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 19s 644us/sample - loss: 1.2506 - val_loss: 1.3403\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2541\n",
      "Epoch 50: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2541 - val_loss: 1.3441\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2532\n",
      "Epoch 51: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2532 - val_loss: 1.3423\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2498\n",
      "Epoch 52: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2498 - val_loss: 1.3451\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2444\n",
      "Epoch 53: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2444 - val_loss: 1.3377\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2454\n",
      "Epoch 54: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2454 - val_loss: 1.3484\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2496\n",
      "Epoch 55: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2496 - val_loss: 1.3413\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 56: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2464 - val_loss: 1.3443\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2426\n",
      "Epoch 57: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2426 - val_loss: 1.3390\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2437\n",
      "Epoch 58: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2437 - val_loss: 1.3429\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2441\n",
      "Epoch 59: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2441 - val_loss: 1.3369\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2422\n",
      "Epoch 60: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2422 - val_loss: 1.3406\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2442\n",
      "Epoch 61: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2442 - val_loss: 1.3367\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2396\n",
      "Epoch 62: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2396 - val_loss: 1.3432\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 63: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2410 - val_loss: 1.3468\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2409\n",
      "Epoch 64: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2409 - val_loss: 1.3411\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2375\n",
      "Epoch 65: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2375 - val_loss: 1.3432\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2364\n",
      "Epoch 66: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2364 - val_loss: 1.3392\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 67: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2363 - val_loss: 1.3411\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2383\n",
      "Epoch 68: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2383 - val_loss: 1.3390\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2337\n",
      "Epoch 69: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2337 - val_loss: 1.3392\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2360\n",
      "Epoch 70: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2360 - val_loss: 1.3392\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 71: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2351 - val_loss: 1.3414\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2307\n",
      "Epoch 72: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2307 - val_loss: 1.3371\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2335\n",
      "Epoch 73: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2335 - val_loss: 1.3397\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 74: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2339 - val_loss: 1.3402\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2320\n",
      "Epoch 75: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2320 - val_loss: 1.3372\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 76: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2302 - val_loss: 1.3394\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 77: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2304 - val_loss: 1.3391\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 78: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2315 - val_loss: 1.3392\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2323\n",
      "Epoch 79: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2323 - val_loss: 1.3355\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2311\n",
      "Epoch 80: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.2311 - val_loss: 1.3382\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2342\n",
      "Epoch 81: val_loss did not improve from 1.33371\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2342 - val_loss: 1.3394\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2290\n",
      "Epoch 82: val_loss improved from 1.33371 to 1.33249, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_2.h5\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2290 - val_loss: 1.3325\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 83: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2287 - val_loss: 1.3381\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 84: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2300 - val_loss: 1.3413\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2280\n",
      "Epoch 85: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2280 - val_loss: 1.3376\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 86: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2254 - val_loss: 1.3383\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2271\n",
      "Epoch 87: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2271 - val_loss: 1.3370\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2298\n",
      "Epoch 88: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2298 - val_loss: 1.3421\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2238\n",
      "Epoch 89: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2238 - val_loss: 1.3461\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2279\n",
      "Epoch 90: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2279 - val_loss: 1.3412\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2290\n",
      "Epoch 91: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2290 - val_loss: 1.3419\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2265\n",
      "Epoch 92: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2265 - val_loss: 1.3427\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 93: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2254 - val_loss: 1.3390\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2281\n",
      "Epoch 94: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2281 - val_loss: 1.3403\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2264\n",
      "Epoch 95: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2264 - val_loss: 1.3457\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2240\n",
      "Epoch 96: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2240 - val_loss: 1.3355\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2249\n",
      "Epoch 97: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2249 - val_loss: 1.3428\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2219\n",
      "Epoch 98: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2219 - val_loss: 1.3396\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2209\n",
      "Epoch 99: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2209 - val_loss: 1.3417\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2227\n",
      "Epoch 100: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2227 - val_loss: 1.3373\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2261\n",
      "Epoch 1: val_loss improved from inf to 1.34661, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2261 - val_loss: 1.3466\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2230\n",
      "Epoch 2: val_loss improved from 1.34661 to 1.34010, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2230 - val_loss: 1.3401\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2175\n",
      "Epoch 3: val_loss did not improve from 1.34010\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2175 - val_loss: 1.3475\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 4: val_loss did not improve from 1.34010\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2194 - val_loss: 1.3423\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 5: val_loss improved from 1.34010 to 1.33933, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2196 - val_loss: 1.3393\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2155\n",
      "Epoch 6: val_loss improved from 1.33933 to 1.33669, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2155 - val_loss: 1.3367\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2167\n",
      "Epoch 7: val_loss did not improve from 1.33669\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2167 - val_loss: 1.3471\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 8: val_loss did not improve from 1.33669\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2197 - val_loss: 1.3396\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 9: val_loss did not improve from 1.33669\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2242 - val_loss: 1.3375\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 10: val_loss did not improve from 1.33669\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2223 - val_loss: 1.3424\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2215\n",
      "Epoch 11: val_loss improved from 1.33669 to 1.33490, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2215 - val_loss: 1.3349\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 12: val_loss did not improve from 1.33490\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2216 - val_loss: 1.3422\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2226\n",
      "Epoch 13: val_loss improved from 1.33490 to 1.33327, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2226 - val_loss: 1.3333\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 14: val_loss improved from 1.33327 to 1.33298, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2287 - val_loss: 1.3330\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2257\n",
      "Epoch 15: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2257 - val_loss: 1.3369\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 16: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2300 - val_loss: 1.3346\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 17: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2255 - val_loss: 1.3458\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2292\n",
      "Epoch 18: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2292 - val_loss: 1.3370\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2303\n",
      "Epoch 19: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2303 - val_loss: 1.3394\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2272\n",
      "Epoch 20: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2272 - val_loss: 1.3353\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 21: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2304 - val_loss: 1.3350\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2327\n",
      "Epoch 22: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2327 - val_loss: 1.3412\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 23: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2266 - val_loss: 1.3369\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 24: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2286 - val_loss: 1.3422\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2277\n",
      "Epoch 25: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2277 - val_loss: 1.3387\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2276\n",
      "Epoch 26: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2276 - val_loss: 1.3424\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 27: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2286 - val_loss: 1.3392\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 28: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2300 - val_loss: 1.3476\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2322\n",
      "Epoch 29: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2322 - val_loss: 1.3383\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 30: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2321 - val_loss: 1.3436\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2485\n",
      "Epoch 31: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2485 - val_loss: 1.3343\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2329\n",
      "Epoch 32: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2329 - val_loss: 1.3363\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 33: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2325 - val_loss: 1.3380\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2352\n",
      "Epoch 34: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2352 - val_loss: 1.3399\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2354\n",
      "Epoch 35: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2354 - val_loss: 1.3372\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2338\n",
      "Epoch 36: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2338 - val_loss: 1.3376\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 37: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2344 - val_loss: 1.3353\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2341\n",
      "Epoch 38: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2341 - val_loss: 1.3383\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2381\n",
      "Epoch 39: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.2381 - val_loss: 1.3391\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2360\n",
      "Epoch 40: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2360 - val_loss: 1.3425\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2357\n",
      "Epoch 41: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2357 - val_loss: 1.3426\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 42: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2365 - val_loss: 1.3416\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 43: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2344 - val_loss: 1.3526\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2328\n",
      "Epoch 44: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2328 - val_loss: 1.3446\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2383\n",
      "Epoch 45: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2383 - val_loss: 1.3465\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2422\n",
      "Epoch 46: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2422 - val_loss: 1.3399\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2664\n",
      "Epoch 47: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2664 - val_loss: 1.3435\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2591\n",
      "Epoch 48: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2591 - val_loss: 1.3466\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2579\n",
      "Epoch 49: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2579 - val_loss: 1.3424\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2546\n",
      "Epoch 50: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2546 - val_loss: 1.3418\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2545\n",
      "Epoch 51: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2545 - val_loss: 1.3486\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 52: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2502 - val_loss: 1.3401\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 53: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2471 - val_loss: 1.3421\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2454\n",
      "Epoch 54: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2454 - val_loss: 1.3429\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 55: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2421 - val_loss: 1.3447\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2441\n",
      "Epoch 56: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2441 - val_loss: 1.3405\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2415\n",
      "Epoch 57: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2415 - val_loss: 1.3434\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2438\n",
      "Epoch 58: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2438 - val_loss: 1.3405\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 59: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2351 - val_loss: 1.3472\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2375\n",
      "Epoch 60: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2375 - val_loss: 1.3451\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2381\n",
      "Epoch 61: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2381 - val_loss: 1.3419\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2357\n",
      "Epoch 62: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2357 - val_loss: 1.3376\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2372\n",
      "Epoch 63: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2372 - val_loss: 1.3381\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2324\n",
      "Epoch 64: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2324 - val_loss: 1.3350\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2342\n",
      "Epoch 65: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2342 - val_loss: 1.3423\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 66: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2284 - val_loss: 1.3364\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 67: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2321 - val_loss: 1.3459\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2320\n",
      "Epoch 68: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2320 - val_loss: 1.3397\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 69: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2286 - val_loss: 1.3407\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2289\n",
      "Epoch 70: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2289 - val_loss: 1.3402\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2314\n",
      "Epoch 71: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2314 - val_loss: 1.3439\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2285\n",
      "Epoch 72: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2285 - val_loss: 1.3414\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 73: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2243 - val_loss: 1.3343\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 74: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2220 - val_loss: 1.3381\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 75: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2255 - val_loss: 1.3405\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 76: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2250 - val_loss: 1.3376\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2235\n",
      "Epoch 77: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2235 - val_loss: 1.3410\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2235\n",
      "Epoch 78: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2235 - val_loss: 1.3348\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2241\n",
      "Epoch 79: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2241 - val_loss: 1.3334\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2205\n",
      "Epoch 80: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2205 - val_loss: 1.3373\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2214\n",
      "Epoch 81: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2214 - val_loss: 1.3389\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 82: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2216 - val_loss: 1.3373\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2215\n",
      "Epoch 83: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2215 - val_loss: 1.3409\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2198\n",
      "Epoch 84: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2198 - val_loss: 1.3389\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2205\n",
      "Epoch 85: val_loss did not improve from 1.33298\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2205 - val_loss: 1.3359\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2201\n",
      "Epoch 86: val_loss improved from 1.33298 to 1.33204, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_3.h5\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2201 - val_loss: 1.3320\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 87: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2200 - val_loss: 1.3358\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 88: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2200 - val_loss: 1.3401\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2155\n",
      "Epoch 89: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2155 - val_loss: 1.3380\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2165\n",
      "Epoch 90: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2165 - val_loss: 1.3404\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 91: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2145 - val_loss: 1.3357\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2163\n",
      "Epoch 92: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2163 - val_loss: 1.3370\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2159\n",
      "Epoch 93: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2159 - val_loss: 1.3419\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2169\n",
      "Epoch 94: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2169 - val_loss: 1.3409\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2160\n",
      "Epoch 95: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2160 - val_loss: 1.3395\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2142\n",
      "Epoch 96: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2142 - val_loss: 1.3399\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2143\n",
      "Epoch 97: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2143 - val_loss: 1.3452\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2126\n",
      "Epoch 98: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2126 - val_loss: 1.3489\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2165\n",
      "Epoch 99: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2165 - val_loss: 1.3367\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2115\n",
      "Epoch 100: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2115 - val_loss: 1.3417\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2149\n",
      "Epoch 1: val_loss improved from inf to 1.33809, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_4.h5\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2149 - val_loss: 1.3381\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2134\n",
      "Epoch 2: val_loss improved from 1.33809 to 1.33807, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_4.h5\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2134 - val_loss: 1.3381\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2140\n",
      "Epoch 3: val_loss did not improve from 1.33807\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2140 - val_loss: 1.3435\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2057\n",
      "Epoch 4: val_loss did not improve from 1.33807\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2057 - val_loss: 1.3445\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2104\n",
      "Epoch 5: val_loss did not improve from 1.33807\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2104 - val_loss: 1.3400\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2075\n",
      "Epoch 6: val_loss did not improve from 1.33807\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2075 - val_loss: 1.3452\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2080\n",
      "Epoch 7: val_loss did not improve from 1.33807\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2080 - val_loss: 1.3457\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2077\n",
      "Epoch 8: val_loss improved from 1.33807 to 1.33768, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_4.h5\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2077 - val_loss: 1.3377\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2099\n",
      "Epoch 9: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2099 - val_loss: 1.3452\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2154\n",
      "Epoch 10: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2154 - val_loss: 1.3439\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2147\n",
      "Epoch 11: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2147 - val_loss: 1.3522\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2132\n",
      "Epoch 12: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2132 - val_loss: 1.3543\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2154\n",
      "Epoch 13: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2154 - val_loss: 1.3528\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 14: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2210 - val_loss: 1.3476\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2188\n",
      "Epoch 15: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2188 - val_loss: 1.3452\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2189\n",
      "Epoch 16: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2189 - val_loss: 1.3479\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 17: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2200 - val_loss: 1.3458\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 18: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2183 - val_loss: 1.3405\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2227\n",
      "Epoch 19: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2227 - val_loss: 1.3423\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2209\n",
      "Epoch 20: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2209 - val_loss: 1.3435\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2195\n",
      "Epoch 21: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2195 - val_loss: 1.3482\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2168\n",
      "Epoch 22: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2168 - val_loss: 1.3471\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2256\n",
      "Epoch 23: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2256 - val_loss: 1.3496\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2252\n",
      "Epoch 24: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2252 - val_loss: 1.3457\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 25: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2250 - val_loss: 1.3457\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2565\n",
      "Epoch 26: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2565 - val_loss: 1.3493\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 27: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2270 - val_loss: 1.3440\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2264\n",
      "Epoch 28: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2264 - val_loss: 1.3476\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2285\n",
      "Epoch 29: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2285 - val_loss: 1.3496\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2298\n",
      "Epoch 30: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2298 - val_loss: 1.3482\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2318\n",
      "Epoch 31: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2318 - val_loss: 1.3431\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2257\n",
      "Epoch 32: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2257 - val_loss: 1.3470\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 33: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2254 - val_loss: 1.3480\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2289\n",
      "Epoch 34: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2289 - val_loss: 1.3452\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2461\n",
      "Epoch 35: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2461 - val_loss: 1.3428\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2303\n",
      "Epoch 36: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2303 - val_loss: 1.3461\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 37: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2325 - val_loss: 1.3443\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2391\n",
      "Epoch 38: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2391 - val_loss: 1.3502\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 39: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2387 - val_loss: 1.3536\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 40: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2368 - val_loss: 1.3477\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2386\n",
      "Epoch 41: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2386 - val_loss: 1.3445\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 42: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2366 - val_loss: 1.3439\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2376\n",
      "Epoch 43: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2376 - val_loss: 1.3450\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2406\n",
      "Epoch 44: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2406 - val_loss: 1.3408\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2536\n",
      "Epoch 45: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2536 - val_loss: 1.3457\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 46: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2471 - val_loss: 1.3455\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2436\n",
      "Epoch 47: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2436 - val_loss: 1.3426\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 48: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2421 - val_loss: 1.3465\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2438\n",
      "Epoch 49: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2438 - val_loss: 1.3402\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 50: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2473 - val_loss: 1.3474\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2528\n",
      "Epoch 51: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2528 - val_loss: 1.3439\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 52: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2473 - val_loss: 1.3429\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2409\n",
      "Epoch 53: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2409 - val_loss: 1.3428\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2405\n",
      "Epoch 54: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2405 - val_loss: 1.3471\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2402\n",
      "Epoch 55: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2402 - val_loss: 1.3455\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 56: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2399 - val_loss: 1.3433\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2342\n",
      "Epoch 57: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2342 - val_loss: 1.3458\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 58: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2363 - val_loss: 1.3443\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2337\n",
      "Epoch 59: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2337 - val_loss: 1.3459\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 60: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2325 - val_loss: 1.3462\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 61: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2325 - val_loss: 1.3438\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 62: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.2287 - val_loss: 1.3483\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 63: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2310 - val_loss: 1.3479\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 64: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2304 - val_loss: 1.3460\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2298\n",
      "Epoch 65: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2298 - val_loss: 1.3445\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 66: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2287 - val_loss: 1.3450\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2232\n",
      "Epoch 67: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2232 - val_loss: 1.3464\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2249\n",
      "Epoch 68: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2249 - val_loss: 1.3438\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 69: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2263 - val_loss: 1.3438\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2259\n",
      "Epoch 70: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2259 - val_loss: 1.3421\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2246\n",
      "Epoch 71: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2246 - val_loss: 1.3424\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2248\n",
      "Epoch 72: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2248 - val_loss: 1.3468\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2228\n",
      "Epoch 73: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2228 - val_loss: 1.3392\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2206\n",
      "Epoch 74: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2206 - val_loss: 1.3428\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2222\n",
      "Epoch 75: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2222 - val_loss: 1.3461\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2205\n",
      "Epoch 76: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2205 - val_loss: 1.3429\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2208\n",
      "Epoch 77: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2208 - val_loss: 1.3415\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2204\n",
      "Epoch 78: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2204 - val_loss: 1.3475\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 79: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2186 - val_loss: 1.3459\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 80: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2196 - val_loss: 1.3478\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2195\n",
      "Epoch 81: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2195 - val_loss: 1.3450\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2204\n",
      "Epoch 82: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2204 - val_loss: 1.3443\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2172\n",
      "Epoch 83: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2172 - val_loss: 1.3447\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2159\n",
      "Epoch 84: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2159 - val_loss: 1.3438\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 85: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2176 - val_loss: 1.3435\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2147\n",
      "Epoch 86: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2147 - val_loss: 1.3474\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2155\n",
      "Epoch 87: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2155 - val_loss: 1.3432\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2179\n",
      "Epoch 88: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2179 - val_loss: 1.3469\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2113\n",
      "Epoch 89: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 23s 767us/sample - loss: 1.2113 - val_loss: 1.3430\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2106\n",
      "Epoch 90: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 858us/sample - loss: 1.2106 - val_loss: 1.3464\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2098\n",
      "Epoch 91: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2098 - val_loss: 1.3522\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2101\n",
      "Epoch 92: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 831us/sample - loss: 1.2101 - val_loss: 1.3476\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2110\n",
      "Epoch 93: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2110 - val_loss: 1.3482\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2119\n",
      "Epoch 94: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2119 - val_loss: 1.3430\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2099\n",
      "Epoch 95: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 26s 881us/sample - loss: 1.2099 - val_loss: 1.3482\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 96: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2145 - val_loss: 1.3442\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2104\n",
      "Epoch 97: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2104 - val_loss: 1.3473\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2100\n",
      "Epoch 98: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2100 - val_loss: 1.3454\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2099\n",
      "Epoch 99: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 839us/sample - loss: 1.2099 - val_loss: 1.3431\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2094\n",
      "Epoch 100: val_loss did not improve from 1.33768\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2094 - val_loss: 1.3465\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2054\n",
      "Epoch 1: val_loss improved from inf to 1.34639, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_5.h5\n",
      "29601/29601 [==============================] - 25s 857us/sample - loss: 1.2054 - val_loss: 1.3464\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2081\n",
      "Epoch 2: val_loss did not improve from 1.34639\n",
      "29601/29601 [==============================] - 25s 838us/sample - loss: 1.2081 - val_loss: 1.3491\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2060\n",
      "Epoch 3: val_loss improved from 1.34639 to 1.34578, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_5.h5\n",
      "29601/29601 [==============================] - 26s 867us/sample - loss: 1.2060 - val_loss: 1.3458\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2074\n",
      "Epoch 4: val_loss did not improve from 1.34578\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2074 - val_loss: 1.3507\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2012\n",
      "Epoch 5: val_loss improved from 1.34578 to 1.34491, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_5.h5\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2012 - val_loss: 1.3449\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2021\n",
      "Epoch 6: val_loss improved from 1.34491 to 1.34486, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_5.h5\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2021 - val_loss: 1.3449\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2020\n",
      "Epoch 7: val_loss improved from 1.34486 to 1.34256, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_5.h5\n",
      "29601/29601 [==============================] - 25s 835us/sample - loss: 1.2020 - val_loss: 1.3426\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2044\n",
      "Epoch 8: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2044 - val_loss: 1.3473\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2121\n",
      "Epoch 9: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2121 - val_loss: 1.3472\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2110\n",
      "Epoch 10: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2110 - val_loss: 1.3478\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2142\n",
      "Epoch 11: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 888us/sample - loss: 1.2142 - val_loss: 1.3469\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2120\n",
      "Epoch 12: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 829us/sample - loss: 1.2120 - val_loss: 1.3457\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2126\n",
      "Epoch 13: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 24s 827us/sample - loss: 1.2126 - val_loss: 1.3535\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2121\n",
      "Epoch 14: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 884us/sample - loss: 1.2121 - val_loss: 1.3430\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2116\n",
      "Epoch 15: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2116 - val_loss: 1.3528\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2115\n",
      "Epoch 16: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2115 - val_loss: 1.3481\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2148\n",
      "Epoch 17: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2148 - val_loss: 1.3480\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2140\n",
      "Epoch 18: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2140 - val_loss: 1.3574\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2131\n",
      "Epoch 19: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2131 - val_loss: 1.3534\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 20: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 833us/sample - loss: 1.2255 - val_loss: 1.3594\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 21: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 832us/sample - loss: 1.2263 - val_loss: 1.3546\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2214\n",
      "Epoch 22: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 867us/sample - loss: 1.2214 - val_loss: 1.3566\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 23: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2262 - val_loss: 1.3525\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2213\n",
      "Epoch 24: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 857us/sample - loss: 1.2213 - val_loss: 1.3575\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2247\n",
      "Epoch 25: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 839us/sample - loss: 1.2247 - val_loss: 1.3498\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2249\n",
      "Epoch 26: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 890us/sample - loss: 1.2249 - val_loss: 1.3502\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2201\n",
      "Epoch 27: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 876us/sample - loss: 1.2201 - val_loss: 1.3539\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2298\n",
      "Epoch 28: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2298 - val_loss: 1.3604\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2241\n",
      "Epoch 29: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 846us/sample - loss: 1.2241 - val_loss: 1.3505\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 30: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 839us/sample - loss: 1.2304 - val_loss: 1.3544\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2357\n",
      "Epoch 31: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2357 - val_loss: 1.3507\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2362\n",
      "Epoch 32: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2362 - val_loss: 1.3522\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2356\n",
      "Epoch 33: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 892us/sample - loss: 1.2356 - val_loss: 1.3541\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2367\n",
      "Epoch 34: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 24s 828us/sample - loss: 1.2367 - val_loss: 1.3588\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2371\n",
      "Epoch 35: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2371 - val_loss: 1.3515\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2364\n",
      "Epoch 36: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2364 - val_loss: 1.3559\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 37: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 836us/sample - loss: 1.2353 - val_loss: 1.3510\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2352\n",
      "Epoch 38: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 847us/sample - loss: 1.2352 - val_loss: 1.3518\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2377\n",
      "Epoch 39: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2377 - val_loss: 1.3483\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2385\n",
      "Epoch 40: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 845us/sample - loss: 1.2385 - val_loss: 1.3480\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 41: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2368 - val_loss: 1.3520\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2378\n",
      "Epoch 42: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 837us/sample - loss: 1.2378 - val_loss: 1.3490\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2390\n",
      "Epoch 43: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 858us/sample - loss: 1.2390 - val_loss: 1.3453\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2401\n",
      "Epoch 44: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2401 - val_loss: 1.3477\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 45: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 829us/sample - loss: 1.2421 - val_loss: 1.3517\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2432\n",
      "Epoch 46: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 24s 825us/sample - loss: 1.2432 - val_loss: 1.3509\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2452\n",
      "Epoch 47: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 838us/sample - loss: 1.2452 - val_loss: 1.3549\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2470\n",
      "Epoch 48: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 839us/sample - loss: 1.2470 - val_loss: 1.3542\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2446\n",
      "Epoch 49: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2446 - val_loss: 1.3499\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 50: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 23s 784us/sample - loss: 1.2466 - val_loss: 1.3499\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2465\n",
      "Epoch 51: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2465 - val_loss: 1.3479\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 52: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2464 - val_loss: 1.3535\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2469\n",
      "Epoch 53: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2469 - val_loss: 1.3482\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2447\n",
      "Epoch 54: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2447 - val_loss: 1.3551\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2411\n",
      "Epoch 55: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2411 - val_loss: 1.3476\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2389\n",
      "Epoch 56: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2389 - val_loss: 1.3540\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2396\n",
      "Epoch 57: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2396 - val_loss: 1.3532\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 58: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2370 - val_loss: 1.3484\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2355\n",
      "Epoch 59: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2355 - val_loss: 1.3467\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2340\n",
      "Epoch 60: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2340 - val_loss: 1.3488\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2343\n",
      "Epoch 61: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2343 - val_loss: 1.3489\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 62: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2326 - val_loss: 1.3464\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 63: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2321 - val_loss: 1.3521\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2319\n",
      "Epoch 64: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2319 - val_loss: 1.3466\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2323\n",
      "Epoch 65: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2323 - val_loss: 1.3538\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 66: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2284 - val_loss: 1.3510\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2267\n",
      "Epoch 67: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2267 - val_loss: 1.3512\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2274\n",
      "Epoch 68: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2274 - val_loss: 1.3590\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 69: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2270 - val_loss: 1.3498\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 70: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2263 - val_loss: 1.3552\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2247\n",
      "Epoch 71: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2247 - val_loss: 1.3477\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 72: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2237 - val_loss: 1.3512\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 73: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2233 - val_loss: 1.3494\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 74: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2237 - val_loss: 1.3509\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2222\n",
      "Epoch 75: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2222 - val_loss: 1.3510\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 76: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2216 - val_loss: 1.3491\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2188\n",
      "Epoch 77: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2188 - val_loss: 1.3442\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2212\n",
      "Epoch 78: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2212 - val_loss: 1.3515\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2182\n",
      "Epoch 79: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2182 - val_loss: 1.3472\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 80: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2197 - val_loss: 1.3552\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2170\n",
      "Epoch 81: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2170 - val_loss: 1.3501\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2173\n",
      "Epoch 82: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2173 - val_loss: 1.3546\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 83: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2186 - val_loss: 1.3538\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2161\n",
      "Epoch 84: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2161 - val_loss: 1.3505\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2164\n",
      "Epoch 85: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2164 - val_loss: 1.3509\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2149\n",
      "Epoch 86: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2149 - val_loss: 1.3567\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2181\n",
      "Epoch 87: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2181 - val_loss: 1.3512\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2205\n",
      "Epoch 88: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2205 - val_loss: 1.3519\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 89: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2162 - val_loss: 1.3502\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2140\n",
      "Epoch 90: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2140 - val_loss: 1.3501\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2150\n",
      "Epoch 91: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2150 - val_loss: 1.3501\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2104\n",
      "Epoch 92: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 15s 508us/sample - loss: 1.2104 - val_loss: 1.3599\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 93: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2145 - val_loss: 1.3487\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2114\n",
      "Epoch 94: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2114 - val_loss: 1.3491\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2127\n",
      "Epoch 95: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2127 - val_loss: 1.3515\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2105\n",
      "Epoch 96: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2105 - val_loss: 1.3529\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2094\n",
      "Epoch 97: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2094 - val_loss: 1.3509\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2106\n",
      "Epoch 98: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2106 - val_loss: 1.3506\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2074\n",
      "Epoch 99: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2074 - val_loss: 1.3553\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2077\n",
      "Epoch 100: val_loss did not improve from 1.34256\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2077 - val_loss: 1.3485\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2083\n",
      "Epoch 1: val_loss improved from inf to 1.34816, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_6.h5\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2083 - val_loss: 1.3482\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2093\n",
      "Epoch 2: val_loss did not improve from 1.34816\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2093 - val_loss: 1.3488\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2092\n",
      "Epoch 3: val_loss improved from 1.34816 to 1.34549, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_6.h5\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2092 - val_loss: 1.3455\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2038\n",
      "Epoch 4: val_loss did not improve from 1.34549\n",
      "29601/29601 [==============================] - 20s 672us/sample - loss: 1.2038 - val_loss: 1.3480\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2014\n",
      "Epoch 5: val_loss did not improve from 1.34549\n",
      "29601/29601 [==============================] - 27s 908us/sample - loss: 1.2014 - val_loss: 1.3495\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2002\n",
      "Epoch 6: val_loss did not improve from 1.34549\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2002 - val_loss: 1.3502\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.1997\n",
      "Epoch 7: val_loss improved from 1.34549 to 1.34056, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_6.h5\n",
      "29601/29601 [==============================] - 20s 682us/sample - loss: 1.1997 - val_loss: 1.3406\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2075\n",
      "Epoch 8: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2075 - val_loss: 1.3466\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2073\n",
      "Epoch 9: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2073 - val_loss: 1.3470\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2100\n",
      "Epoch 10: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2100 - val_loss: 1.3432\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2107\n",
      "Epoch 11: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2107 - val_loss: 1.3492\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2107\n",
      "Epoch 12: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2107 - val_loss: 1.3507\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2106\n",
      "Epoch 13: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2106 - val_loss: 1.3549\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2189\n",
      "Epoch 14: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2189 - val_loss: 1.3478\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2094\n",
      "Epoch 15: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2094 - val_loss: 1.3482\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2181\n",
      "Epoch 16: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2181 - val_loss: 1.3596\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2134\n",
      "Epoch 17: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2134 - val_loss: 1.3517\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2131\n",
      "Epoch 18: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2131 - val_loss: 1.3578\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2218\n",
      "Epoch 19: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 504us/sample - loss: 1.2218 - val_loss: 1.3544\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2213\n",
      "Epoch 20: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2213 - val_loss: 1.3528\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2202\n",
      "Epoch 21: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2202 - val_loss: 1.3545\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 22: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2194 - val_loss: 1.3568\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 23: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2242 - val_loss: 1.3531\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 24: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 615us/sample - loss: 1.2220 - val_loss: 1.3532\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2206\n",
      "Epoch 25: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2206 - val_loss: 1.3501\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2191\n",
      "Epoch 26: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.2191 - val_loss: 1.3490\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 27: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2245 - val_loss: 1.3472\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 28: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2233 - val_loss: 1.3545\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 29: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2266 - val_loss: 1.3523\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2274\n",
      "Epoch 30: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2274 - val_loss: 1.3456\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2256\n",
      "Epoch 31: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2256 - val_loss: 1.3438\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 32: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2250 - val_loss: 1.3482\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2291\n",
      "Epoch 33: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2291 - val_loss: 1.3514\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2274\n",
      "Epoch 34: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2274 - val_loss: 1.3505\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2269\n",
      "Epoch 35: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2269 - val_loss: 1.3514\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2341\n",
      "Epoch 36: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2341 - val_loss: 1.3500\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2396\n",
      "Epoch 37: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2396 - val_loss: 1.3586\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 38: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2361 - val_loss: 1.3567\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2384\n",
      "Epoch 39: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2384 - val_loss: 1.3531\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 40: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2368 - val_loss: 1.3586\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2352\n",
      "Epoch 41: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2352 - val_loss: 1.3494\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2377\n",
      "Epoch 42: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2377 - val_loss: 1.3548\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2386\n",
      "Epoch 43: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2386 - val_loss: 1.3535\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 44: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2366 - val_loss: 1.3533\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2409\n",
      "Epoch 45: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 524us/sample - loss: 1.2409 - val_loss: 1.3533\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2418\n",
      "Epoch 46: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2418 - val_loss: 1.3527\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 47: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2428 - val_loss: 1.3559\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 48: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2466 - val_loss: 1.3560\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 49: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2598 - val_loss: 1.3534\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2600\n",
      "Epoch 50: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2600 - val_loss: 1.3507\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2550\n",
      "Epoch 51: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2550 - val_loss: 1.3541\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2610\n",
      "Epoch 52: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2610 - val_loss: 1.3529\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2578\n",
      "Epoch 53: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2578 - val_loss: 1.3533\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2596\n",
      "Epoch 54: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2596 - val_loss: 1.3509\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2553\n",
      "Epoch 55: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2553 - val_loss: 1.3589\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2492\n",
      "Epoch 56: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2492 - val_loss: 1.3590\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2484\n",
      "Epoch 57: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2484 - val_loss: 1.3550\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2444\n",
      "Epoch 58: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2444 - val_loss: 1.3522\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 59: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2468 - val_loss: 1.3588\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2443\n",
      "Epoch 60: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2443 - val_loss: 1.3554\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2429\n",
      "Epoch 61: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2429 - val_loss: 1.3536\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2402\n",
      "Epoch 62: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2402 - val_loss: 1.3572\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2360\n",
      "Epoch 63: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2360 - val_loss: 1.3498\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2389\n",
      "Epoch 64: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2389 - val_loss: 1.3532\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 65: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2365 - val_loss: 1.3534\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 66: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2366 - val_loss: 1.3537\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 67: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2351 - val_loss: 1.3546\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2294\n",
      "Epoch 68: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2294 - val_loss: 1.3551\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2280\n",
      "Epoch 69: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2280 - val_loss: 1.3538\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 70: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2284 - val_loss: 1.3531\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2285\n",
      "Epoch 71: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2285 - val_loss: 1.3551\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2273\n",
      "Epoch 72: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2273 - val_loss: 1.3575\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 73: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2262 - val_loss: 1.3535\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 74: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2287 - val_loss: 1.3539\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2236\n",
      "Epoch 75: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2236 - val_loss: 1.3521\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2235\n",
      "Epoch 76: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2235 - val_loss: 1.3535\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 77: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2245 - val_loss: 1.3582\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2212\n",
      "Epoch 78: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2212 - val_loss: 1.3536\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2269\n",
      "Epoch 79: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2269 - val_loss: 1.3541\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 80: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2250 - val_loss: 1.3522\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2230\n",
      "Epoch 81: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2230 - val_loss: 1.3500\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2238\n",
      "Epoch 82: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2238 - val_loss: 1.3549\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2215\n",
      "Epoch 83: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2215 - val_loss: 1.3573\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 84: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2220 - val_loss: 1.3542\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 85: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2210 - val_loss: 1.3525\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2207\n",
      "Epoch 86: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2207 - val_loss: 1.3459\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2214\n",
      "Epoch 87: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2214 - val_loss: 1.3576\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 88: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2220 - val_loss: 1.3521\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2199\n",
      "Epoch 89: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2199 - val_loss: 1.3554\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2167\n",
      "Epoch 90: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2167 - val_loss: 1.3563\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2166\n",
      "Epoch 91: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2166 - val_loss: 1.3572\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2184\n",
      "Epoch 92: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2184 - val_loss: 1.3524\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2137\n",
      "Epoch 93: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2137 - val_loss: 1.3529\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2166\n",
      "Epoch 94: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2166 - val_loss: 1.3545\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2137\n",
      "Epoch 95: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2137 - val_loss: 1.3521\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2150\n",
      "Epoch 96: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2150 - val_loss: 1.3511\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2159\n",
      "Epoch 97: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2159 - val_loss: 1.3494\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2117\n",
      "Epoch 98: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2117 - val_loss: 1.3599\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2169\n",
      "Epoch 99: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2169 - val_loss: 1.3546\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2104\n",
      "Epoch 100: val_loss did not improve from 1.34056\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2104 - val_loss: 1.3565\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2114\n",
      "Epoch 1: val_loss improved from inf to 1.35358, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2114 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2107\n",
      "Epoch 2: val_loss did not improve from 1.35358\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2107 - val_loss: 1.3584\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2091\n",
      "Epoch 3: val_loss did not improve from 1.35358\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2091 - val_loss: 1.3557\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2037\n",
      "Epoch 4: val_loss improved from 1.35358 to 1.35277, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2037 - val_loss: 1.3528\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2057\n",
      "Epoch 5: val_loss improved from 1.35277 to 1.35230, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2057 - val_loss: 1.3523\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2026\n",
      "Epoch 6: val_loss improved from 1.35230 to 1.34845, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2026 - val_loss: 1.3485\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2014\n",
      "Epoch 7: val_loss improved from 1.34845 to 1.34843, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2014 - val_loss: 1.3484\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2087\n",
      "Epoch 8: val_loss did not improve from 1.34843\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2087 - val_loss: 1.3565\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2114\n",
      "Epoch 9: val_loss did not improve from 1.34843\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2114 - val_loss: 1.3505\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2192\n",
      "Epoch 10: val_loss did not improve from 1.34843\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2192 - val_loss: 1.3520\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2726\n",
      "Epoch 11: val_loss did not improve from 1.34843\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2726 - val_loss: 1.3590\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 12: val_loss did not improve from 1.34843\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2284 - val_loss: 1.3581\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2188\n",
      "Epoch 13: val_loss improved from 1.34843 to 1.34538, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2188 - val_loss: 1.3454\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2213\n",
      "Epoch 14: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2213 - val_loss: 1.3526\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2193\n",
      "Epoch 15: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2193 - val_loss: 1.3534\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 16: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2263 - val_loss: 1.3528\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 17: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2186 - val_loss: 1.3512\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 18: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2223 - val_loss: 1.3496\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2202\n",
      "Epoch 19: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2202 - val_loss: 1.3577\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2260\n",
      "Epoch 20: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2260 - val_loss: 1.3507\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2211\n",
      "Epoch 21: val_loss did not improve from 1.34538\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2211 - val_loss: 1.3480\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 22: val_loss improved from 1.34538 to 1.34232, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2255 - val_loss: 1.3423\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2217\n",
      "Epoch 23: val_loss did not improve from 1.34232\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2217 - val_loss: 1.3429\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2276\n",
      "Epoch 24: val_loss did not improve from 1.34232\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2276 - val_loss: 1.3488\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 25: val_loss did not improve from 1.34232\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2255 - val_loss: 1.3469\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2348\n",
      "Epoch 26: val_loss did not improve from 1.34232\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2348 - val_loss: 1.3476\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2322\n",
      "Epoch 27: val_loss did not improve from 1.34232\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2322 - val_loss: 1.3499\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 28: val_loss did not improve from 1.34232\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2284 - val_loss: 1.3508\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 29: val_loss improved from 1.34232 to 1.34205, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2305 - val_loss: 1.3420\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 30: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2300 - val_loss: 1.3493\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2356\n",
      "Epoch 31: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2356 - val_loss: 1.3508\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 32: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2305 - val_loss: 1.3491\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2285\n",
      "Epoch 33: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2285 - val_loss: 1.3499\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2281\n",
      "Epoch 34: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2281 - val_loss: 1.3456\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2352\n",
      "Epoch 35: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2352 - val_loss: 1.3507\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2336\n",
      "Epoch 36: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2336 - val_loss: 1.3470\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2349\n",
      "Epoch 37: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2349 - val_loss: 1.3506\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 38: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2408 - val_loss: 1.3479\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2390\n",
      "Epoch 39: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2390 - val_loss: 1.3443\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2379\n",
      "Epoch 40: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2379 - val_loss: 1.3504\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2424\n",
      "Epoch 41: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2424 - val_loss: 1.3557\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2420\n",
      "Epoch 42: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2420 - val_loss: 1.3517\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2452\n",
      "Epoch 43: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2452 - val_loss: 1.3475\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2480\n",
      "Epoch 44: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2480 - val_loss: 1.3589\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2492\n",
      "Epoch 45: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2492 - val_loss: 1.3508\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2532\n",
      "Epoch 46: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2532 - val_loss: 1.3526\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2558\n",
      "Epoch 47: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2558 - val_loss: 1.3468\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2498\n",
      "Epoch 48: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2498 - val_loss: 1.3511\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2563\n",
      "Epoch 49: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2563 - val_loss: 1.3502\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2559\n",
      "Epoch 50: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2559 - val_loss: 1.3475\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2651\n",
      "Epoch 51: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2651 - val_loss: 1.3509\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2577\n",
      "Epoch 52: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2577 - val_loss: 1.3482\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2593\n",
      "Epoch 53: val_loss did not improve from 1.34205\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2593 - val_loss: 1.3464\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2547\n",
      "Epoch 54: val_loss improved from 1.34205 to 1.34163, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2547 - val_loss: 1.3416\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2530\n",
      "Epoch 55: val_loss improved from 1.34163 to 1.34017, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2530 - val_loss: 1.3402\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2490\n",
      "Epoch 56: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2490 - val_loss: 1.3451\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2488\n",
      "Epoch 57: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2488 - val_loss: 1.3487\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2487\n",
      "Epoch 58: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2487 - val_loss: 1.3430\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2455\n",
      "Epoch 59: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2455 - val_loss: 1.3446\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2453\n",
      "Epoch 60: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2453 - val_loss: 1.3450\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2424\n",
      "Epoch 61: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2424 - val_loss: 1.3470\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 62: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2408 - val_loss: 1.3429\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2380\n",
      "Epoch 63: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2380 - val_loss: 1.3478\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2389\n",
      "Epoch 64: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2389 - val_loss: 1.3405\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2386\n",
      "Epoch 65: val_loss did not improve from 1.34017\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2386 - val_loss: 1.3418\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2359\n",
      "Epoch 66: val_loss improved from 1.34017 to 1.33914, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2359 - val_loss: 1.3391\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2364\n",
      "Epoch 67: val_loss did not improve from 1.33914\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2364 - val_loss: 1.3478\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2375\n",
      "Epoch 68: val_loss improved from 1.33914 to 1.33884, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2375 - val_loss: 1.3388\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2333\n",
      "Epoch 69: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2333 - val_loss: 1.3421\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 70: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2315 - val_loss: 1.3394\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 71: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2339 - val_loss: 1.3490\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 72: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2305 - val_loss: 1.3409\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 73: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2321 - val_loss: 1.3423\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2280\n",
      "Epoch 74: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2280 - val_loss: 1.3534\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 75: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2287 - val_loss: 1.3428\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2291\n",
      "Epoch 76: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2291 - val_loss: 1.3403\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 77: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2250 - val_loss: 1.3444\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 78: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2262 - val_loss: 1.3416\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 79: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2262 - val_loss: 1.3409\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2260\n",
      "Epoch 80: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2260 - val_loss: 1.3422\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 81: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 508us/sample - loss: 1.2242 - val_loss: 1.3449\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 82: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2270 - val_loss: 1.3418\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 83: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2262 - val_loss: 1.3434\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 84: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2254 - val_loss: 1.3413\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2218\n",
      "Epoch 85: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2218 - val_loss: 1.3416\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 86: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2220 - val_loss: 1.3415\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 87: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2223 - val_loss: 1.3408\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2231\n",
      "Epoch 88: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2231 - val_loss: 1.3425\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 89: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2255 - val_loss: 1.3404\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2179\n",
      "Epoch 90: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2179 - val_loss: 1.3483\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 91: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2194 - val_loss: 1.3444\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2231\n",
      "Epoch 92: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2231 - val_loss: 1.3471\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2207\n",
      "Epoch 93: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2207 - val_loss: 1.3409\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2198\n",
      "Epoch 94: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2198 - val_loss: 1.3482\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 95: val_loss did not improve from 1.33884\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2197 - val_loss: 1.3463\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2185\n",
      "Epoch 96: val_loss improved from 1.33884 to 1.33878, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2185 - val_loss: 1.3388\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2120\n",
      "Epoch 97: val_loss did not improve from 1.33878\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2120 - val_loss: 1.3426\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2142\n",
      "Epoch 98: val_loss improved from 1.33878 to 1.33744, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_7.h5\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2142 - val_loss: 1.3374\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2147\n",
      "Epoch 99: val_loss did not improve from 1.33744\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2147 - val_loss: 1.3408\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 100: val_loss did not improve from 1.33744\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2196 - val_loss: 1.3411\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2130\n",
      "Epoch 1: val_loss improved from inf to 1.33892, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_8.h5\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2130 - val_loss: 1.3389\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2137\n",
      "Epoch 2: val_loss did not improve from 1.33892\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2137 - val_loss: 1.3395\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2103\n",
      "Epoch 3: val_loss did not improve from 1.33892\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2103 - val_loss: 1.3472\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2104\n",
      "Epoch 4: val_loss did not improve from 1.33892\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2104 - val_loss: 1.3416\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2093\n",
      "Epoch 5: val_loss did not improve from 1.33892\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2093 - val_loss: 1.3493\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2062\n",
      "Epoch 6: val_loss did not improve from 1.33892\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2062 - val_loss: 1.3399\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2034\n",
      "Epoch 7: val_loss did not improve from 1.33892\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2034 - val_loss: 1.3421\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2061\n",
      "Epoch 8: val_loss improved from 1.33892 to 1.33810, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_8.h5\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2061 - val_loss: 1.3381\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2034\n",
      "Epoch 9: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2034 - val_loss: 1.3435\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2064\n",
      "Epoch 10: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2064 - val_loss: 1.3427\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2058\n",
      "Epoch 11: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2058 - val_loss: 1.3436\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2073\n",
      "Epoch 12: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2073 - val_loss: 1.3406\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2128\n",
      "Epoch 13: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2128 - val_loss: 1.3415\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2151\n",
      "Epoch 14: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2151 - val_loss: 1.3420\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2139\n",
      "Epoch 15: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2139 - val_loss: 1.3448\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2121\n",
      "Epoch 16: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2121 - val_loss: 1.3419\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 17: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2145 - val_loss: 1.3390\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2122\n",
      "Epoch 18: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2122 - val_loss: 1.3445\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 19: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2145 - val_loss: 1.3496\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2207\n",
      "Epoch 20: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2207 - val_loss: 1.3454\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2180\n",
      "Epoch 21: val_loss did not improve from 1.33810\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2180 - val_loss: 1.3410\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2165\n",
      "Epoch 22: val_loss improved from 1.33810 to 1.33294, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_8.h5\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2165 - val_loss: 1.3329\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2141\n",
      "Epoch 23: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2141 - val_loss: 1.3400\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2177\n",
      "Epoch 24: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2177 - val_loss: 1.3406\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 25: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2223 - val_loss: 1.3428\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2187\n",
      "Epoch 26: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2187 - val_loss: 1.3379\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2181\n",
      "Epoch 27: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2181 - val_loss: 1.3413\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 28: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2197 - val_loss: 1.3420\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 29: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2210 - val_loss: 1.3334\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2246\n",
      "Epoch 30: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2246 - val_loss: 1.3426\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 31: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.2302 - val_loss: 1.3439\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2289\n",
      "Epoch 32: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2289 - val_loss: 1.3379\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 33: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2262 - val_loss: 1.3414\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2388\n",
      "Epoch 34: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 505us/sample - loss: 1.2388 - val_loss: 1.3443\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 35: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2339 - val_loss: 1.3418\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2391\n",
      "Epoch 36: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2391 - val_loss: 1.3383\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 37: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2366 - val_loss: 1.3370\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2372\n",
      "Epoch 38: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2372 - val_loss: 1.3456\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2367\n",
      "Epoch 39: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2367 - val_loss: 1.3406\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2393\n",
      "Epoch 40: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2393 - val_loss: 1.3447\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2465\n",
      "Epoch 41: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2465 - val_loss: 1.3385\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2378\n",
      "Epoch 42: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2378 - val_loss: 1.3395\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2437\n",
      "Epoch 43: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2437 - val_loss: 1.3400\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2445\n",
      "Epoch 44: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2445 - val_loss: 1.3332\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 45: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.2464 - val_loss: 1.3438\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2476\n",
      "Epoch 46: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2476 - val_loss: 1.3355\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2596\n",
      "Epoch 47: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2596 - val_loss: 1.3405\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2564\n",
      "Epoch 48: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2564 - val_loss: 1.3373\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2750\n",
      "Epoch 49: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2750 - val_loss: 1.3420\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2890\n",
      "Epoch 50: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2890 - val_loss: 1.3440\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2802\n",
      "Epoch 51: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2802 - val_loss: 1.3389\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3492\n",
      "Epoch 52: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.3492 - val_loss: 1.3535\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3129\n",
      "Epoch 53: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.3129 - val_loss: 1.3531\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2821\n",
      "Epoch 54: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2821 - val_loss: 1.3456\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2713\n",
      "Epoch 55: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2713 - val_loss: 1.3548\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2674\n",
      "Epoch 56: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2674 - val_loss: 1.3431\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2683\n",
      "Epoch 57: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2683 - val_loss: 1.3478\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2623\n",
      "Epoch 58: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2623 - val_loss: 1.3376\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2592\n",
      "Epoch 59: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2592 - val_loss: 1.3432\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2597\n",
      "Epoch 60: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2597 - val_loss: 1.3475\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2599\n",
      "Epoch 61: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2599 - val_loss: 1.3457\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2550\n",
      "Epoch 62: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2550 - val_loss: 1.3373\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2540\n",
      "Epoch 63: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2540 - val_loss: 1.3372\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2527\n",
      "Epoch 64: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2527 - val_loss: 1.3358\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2518\n",
      "Epoch 65: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2518 - val_loss: 1.3430\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2491\n",
      "Epoch 66: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 505us/sample - loss: 1.2491 - val_loss: 1.3370\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2489\n",
      "Epoch 67: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 508us/sample - loss: 1.2489 - val_loss: 1.3405\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2461\n",
      "Epoch 68: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2461 - val_loss: 1.3355\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2449\n",
      "Epoch 69: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2449 - val_loss: 1.3424\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2462\n",
      "Epoch 70: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2462 - val_loss: 1.3390\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 71: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2428 - val_loss: 1.3398\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2457\n",
      "Epoch 72: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2457 - val_loss: 1.3404\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2437\n",
      "Epoch 73: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2437 - val_loss: 1.3387\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2416\n",
      "Epoch 74: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2416 - val_loss: 1.3399\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 75: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2410 - val_loss: 1.3359\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2378\n",
      "Epoch 76: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2378 - val_loss: 1.3412\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2398\n",
      "Epoch 77: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2398 - val_loss: 1.3379\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2398\n",
      "Epoch 78: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2398 - val_loss: 1.3367\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2393\n",
      "Epoch 79: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2393 - val_loss: 1.3337\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2347\n",
      "Epoch 80: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2347 - val_loss: 1.3394\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2348\n",
      "Epoch 81: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2348 - val_loss: 1.3380\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2354\n",
      "Epoch 82: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2354 - val_loss: 1.3343\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2340\n",
      "Epoch 83: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2340 - val_loss: 1.3362\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2337\n",
      "Epoch 84: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2337 - val_loss: 1.3443\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 85: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2321 - val_loss: 1.3451\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2328\n",
      "Epoch 86: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2328 - val_loss: 1.3414\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 87: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2339 - val_loss: 1.3470\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2308\n",
      "Epoch 88: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2308 - val_loss: 1.3369\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 89: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2353 - val_loss: 1.3398\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2319\n",
      "Epoch 90: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2319 - val_loss: 1.3415\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 91: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2287 - val_loss: 1.3443\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 92: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2270 - val_loss: 1.3392\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 93: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2286 - val_loss: 1.3430\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2288\n",
      "Epoch 94: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2288 - val_loss: 1.3418\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 95: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2284 - val_loss: 1.3401\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2269\n",
      "Epoch 96: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2269 - val_loss: 1.3459\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2320\n",
      "Epoch 97: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2320 - val_loss: 1.3395\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2281\n",
      "Epoch 98: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2281 - val_loss: 1.3487\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2231\n",
      "Epoch 99: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2231 - val_loss: 1.3470\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2288\n",
      "Epoch 100: val_loss did not improve from 1.33294\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2288 - val_loss: 1.3463\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2275\n",
      "Epoch 1: val_loss improved from inf to 1.33989, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_9.h5\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2275 - val_loss: 1.3399\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2225\n",
      "Epoch 2: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2225 - val_loss: 1.3478\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2205\n",
      "Epoch 3: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2205 - val_loss: 1.3475\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2146\n",
      "Epoch 4: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2146 - val_loss: 1.3420\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2119\n",
      "Epoch 5: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 15s 499us/sample - loss: 1.2119 - val_loss: 1.3442\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2094\n",
      "Epoch 6: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 15s 508us/sample - loss: 1.2094 - val_loss: 1.3415\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2087\n",
      "Epoch 7: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 15s 501us/sample - loss: 1.2087 - val_loss: 1.3414\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2125\n",
      "Epoch 8: val_loss did not improve from 1.33989\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2125 - val_loss: 1.3407\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2120\n",
      "Epoch 9: val_loss improved from 1.33989 to 1.33948, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_9.h5\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2120 - val_loss: 1.3395\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2167\n",
      "Epoch 10: val_loss improved from 1.33948 to 1.33401, saving model to ./checkpoints/Feature_extraction_remove_energy_v2_9.h5\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2167 - val_loss: 1.3340\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2173\n",
      "Epoch 11: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2173 - val_loss: 1.3417\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2150\n",
      "Epoch 12: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2150 - val_loss: 1.3462\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2138\n",
      "Epoch 13: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2138 - val_loss: 1.3430\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2206\n",
      "Epoch 14: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2206 - val_loss: 1.3419\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2173\n",
      "Epoch 15: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2173 - val_loss: 1.3365\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2219\n",
      "Epoch 16: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2219 - val_loss: 1.3385\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2202\n",
      "Epoch 17: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2202 - val_loss: 1.3466\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2211\n",
      "Epoch 18: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2211 - val_loss: 1.3478\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 19: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2183 - val_loss: 1.3420\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 20: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2266 - val_loss: 1.3388\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2229\n",
      "Epoch 21: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2229 - val_loss: 1.3476\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 22: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2233 - val_loss: 1.3417\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2232\n",
      "Epoch 23: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2232 - val_loss: 1.3431\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2258\n",
      "Epoch 24: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2258 - val_loss: 1.3466\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2239\n",
      "Epoch 25: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2239 - val_loss: 1.3450\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2490\n",
      "Epoch 26: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2490 - val_loss: 1.3448\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 27: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2394 - val_loss: 1.3401\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2341\n",
      "Epoch 28: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2341 - val_loss: 1.3440\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2348\n",
      "Epoch 29: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2348 - val_loss: 1.3424\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2382\n",
      "Epoch 30: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2382 - val_loss: 1.3412\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2442\n",
      "Epoch 31: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2442 - val_loss: 1.3474\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2404\n",
      "Epoch 32: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2404 - val_loss: 1.3448\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2469\n",
      "Epoch 33: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2469 - val_loss: 1.3449\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2535\n",
      "Epoch 34: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2535 - val_loss: 1.3500\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2489\n",
      "Epoch 35: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2489 - val_loss: 1.3429\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2496\n",
      "Epoch 36: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2496 - val_loss: 1.3428\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2493\n",
      "Epoch 37: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2493 - val_loss: 1.3453\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2513\n",
      "Epoch 38: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2513 - val_loss: 1.3466\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 39: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2468 - val_loss: 1.3469\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2531\n",
      "Epoch 40: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2531 - val_loss: 1.3433\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2595\n",
      "Epoch 41: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2595 - val_loss: 1.3418\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2612\n",
      "Epoch 42: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2612 - val_loss: 1.3444\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2633\n",
      "Epoch 43: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2633 - val_loss: 1.3458\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2612\n",
      "Epoch 44: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2612 - val_loss: 1.3487\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2689\n",
      "Epoch 45: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2689 - val_loss: 1.3470\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2792\n",
      "Epoch 46: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2792 - val_loss: 1.3474\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2746\n",
      "Epoch 47: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2746 - val_loss: 1.3466\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2737\n",
      "Epoch 48: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2737 - val_loss: 1.3434\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2753\n",
      "Epoch 49: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2753 - val_loss: 1.3491\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2809\n",
      "Epoch 50: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2809 - val_loss: 1.3506\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2829\n",
      "Epoch 51: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2829 - val_loss: 1.3453\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2815\n",
      "Epoch 52: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2815 - val_loss: 1.3461\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2815\n",
      "Epoch 53: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2815 - val_loss: 1.3503\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2816\n",
      "Epoch 54: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2816 - val_loss: 1.3548\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2837\n",
      "Epoch 55: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2837 - val_loss: 1.3498\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2800\n",
      "Epoch 56: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 497us/sample - loss: 1.2800 - val_loss: 1.3467\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2792\n",
      "Epoch 57: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2792 - val_loss: 1.3479\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2754\n",
      "Epoch 58: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2754 - val_loss: 1.3463\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2758\n",
      "Epoch 59: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2758 - val_loss: 1.3467\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2774\n",
      "Epoch 60: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2774 - val_loss: 1.3546\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2764\n",
      "Epoch 61: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2764 - val_loss: 1.3484\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2730\n",
      "Epoch 62: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2730 - val_loss: 1.3432\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2737\n",
      "Epoch 63: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2737 - val_loss: 1.3536\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2700\n",
      "Epoch 64: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2700 - val_loss: 1.3488\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2692\n",
      "Epoch 65: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2692 - val_loss: 1.3508\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2699\n",
      "Epoch 66: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2699 - val_loss: 1.3496\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2683\n",
      "Epoch 67: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2683 - val_loss: 1.3485\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2697\n",
      "Epoch 68: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2697 - val_loss: 1.3515\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2645\n",
      "Epoch 69: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2645 - val_loss: 1.3450\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2642\n",
      "Epoch 70: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2642 - val_loss: 1.3525\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2681\n",
      "Epoch 71: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2681 - val_loss: 1.3487\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2683\n",
      "Epoch 72: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2683 - val_loss: 1.3511\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2637\n",
      "Epoch 73: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2637 - val_loss: 1.3491\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2657\n",
      "Epoch 74: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2657 - val_loss: 1.3500\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2614\n",
      "Epoch 75: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2614 - val_loss: 1.3551\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2603\n",
      "Epoch 76: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2603 - val_loss: 1.3589\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2597\n",
      "Epoch 77: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2597 - val_loss: 1.3533\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2575\n",
      "Epoch 78: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2575 - val_loss: 1.3526\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2606\n",
      "Epoch 79: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2606 - val_loss: 1.3564\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2617\n",
      "Epoch 80: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2617 - val_loss: 1.3581\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2606\n",
      "Epoch 81: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 504us/sample - loss: 1.2606 - val_loss: 1.3517\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2563\n",
      "Epoch 82: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2563 - val_loss: 1.3479\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2564\n",
      "Epoch 83: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2564 - val_loss: 1.3472\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2553\n",
      "Epoch 84: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2553 - val_loss: 1.3538\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2594\n",
      "Epoch 85: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2594 - val_loss: 1.3496\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2543\n",
      "Epoch 86: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2543 - val_loss: 1.3484\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2543\n",
      "Epoch 87: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2543 - val_loss: 1.3471\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2518\n",
      "Epoch 88: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2518 - val_loss: 1.3463\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2519\n",
      "Epoch 89: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2519 - val_loss: 1.3525\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2529\n",
      "Epoch 90: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2529 - val_loss: 1.3533\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2510\n",
      "Epoch 91: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2510 - val_loss: 1.3558\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 92: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2523 - val_loss: 1.3476\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 93: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2464 - val_loss: 1.3495\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2496\n",
      "Epoch 94: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2496 - val_loss: 1.3544\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2520\n",
      "Epoch 95: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2520 - val_loss: 1.3455\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2477\n",
      "Epoch 96: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2477 - val_loss: 1.3477\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 97: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 505us/sample - loss: 1.2486 - val_loss: 1.3453\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2484\n",
      "Epoch 98: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2484 - val_loss: 1.3458\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2479\n",
      "Epoch 99: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2479 - val_loss: 1.3526\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2511\n",
      "Epoch 100: val_loss did not improve from 1.33401\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2511 - val_loss: 1.3488\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "model = individual_model(X_train_normalized)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "num_epochs = 100\n",
    "rates = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "idx = 0\n",
    "for r in rates:\n",
    "# Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    model_name = './checkpoints/Feature_extraction_remove_energy_v2_'+str(idx)+'.h5'\n",
    "    idx = idx+1\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=50, frequency=1)\n",
    "    model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
