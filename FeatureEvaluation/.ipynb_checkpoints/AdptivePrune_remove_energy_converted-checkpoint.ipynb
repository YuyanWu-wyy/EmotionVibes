{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e4cd1e-14c8-4f76-8133-e8617bb62b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T16:29:15.579802Z",
     "iopub.status.busy": "2023-11-07T16:29:15.579661Z",
     "iopub.status.idle": "2023-11-07T16:30:10.020802Z",
     "shell.execute_reply": "2023-11-07T16:30:10.020205Z"
    }
   },
   "outputs": [],
   "source": [
    "## The Baseline Method only use simple gait parameter feature, it only includes 2 dense layers\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## We delete people's data with low feedback score and remove people who kicked off the sensors during walking'\n",
    "## So 20 people in total.\n",
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "flag_tr_val_te = split_data(walk_nums_all, trace_nums_all, people_nums_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170353c1-fcb9-4e2b-9909-c3a263bf8bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T16:30:10.023083Z",
     "iopub.status.busy": "2023-11-07T16:30:10.022912Z",
     "iopub.status.idle": "2023-11-07T16:30:13.837794Z",
     "shell.execute_reply": "2023-11-07T16:30:13.837172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 11:30:10.163328: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e10b0d-fa00-4007-ad02-296357d1871d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T16:30:13.840184Z",
     "iopub.status.busy": "2023-11-07T16:30:13.839932Z",
     "iopub.status.idle": "2023-11-07T16:30:13.866880Z",
     "shell.execute_reply": "2023-11-07T16:30:13.866269Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c8fb4a-5f62-4ff5-9d55-a5fd0197b624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T16:30:13.869006Z",
     "iopub.status.busy": "2023-11-07T16:30:13.868874Z",
     "iopub.status.idle": "2023-11-07T16:30:13.875317Z",
     "shell.execute_reply": "2023-11-07T16:30:13.874844Z"
    }
   },
   "outputs": [],
   "source": [
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7526f3-8fb8-4aca-9d40-c3e551262af6",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-07T16:30:13.877188Z",
     "iopub.status.busy": "2023-11-07T16:30:13.877042Z",
     "iopub.status.idle": "2023-11-07T21:07:49.986889Z",
     "shell.execute_reply": "2023-11-07T21:07:49.986293Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 11:30:43.948185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:43.959786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:43.960023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:43.963713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:43.963903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:43.964067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.045152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.045351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.045518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.045658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-07 11:30:44.046016: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 11:30:44.986987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.987218: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.987388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.987598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.987773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 11:30:44.987910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-07 11:30:44.987938: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-07 11:30:45.008972: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-07 11:30:45.221163: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_19/lstm_cell_19/kernel/Assign' id:3151 op device:{requested: '', assigned: ''} def:{{{node lstm_19/lstm_cell_19/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_19/lstm_cell_19/kernel, lstm_19/lstm_cell_19/kernel/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-07 11:30:45.353864: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-07 11:30:45.386753: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(29601, 95)\n",
      "Train on 29601 samples, validate on 3694 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 11:30:49.440904: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_1/lstm_cell_1/recurrent_kernel/m/Assign' id:15145 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_1/lstm_cell_1/recurrent_kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_1/lstm_cell_1/recurrent_kernel/m, training/Adam/lstm_1/lstm_cell_1/recurrent_kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 11:30:52.782924: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-07 11:30:54.700282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-07 11:30:54.717901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29601/29601 [==============================] - ETA: 0s - loss: 3.2652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-07 11:31:12.957182: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:5982 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.06326, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 25s 838us/sample - loss: 3.2652 - val_loss: 2.0633\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.8575\n",
      "Epoch 2: val_loss improved from 2.06326 to 1.64033, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.8575 - val_loss: 1.6403\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.6121\n",
      "Epoch 3: val_loss improved from 1.64033 to 1.55114, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.6121 - val_loss: 1.5511\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5475\n",
      "Epoch 4: val_loss improved from 1.55114 to 1.51226, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 618us/sample - loss: 1.5475 - val_loss: 1.5123\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5160\n",
      "Epoch 5: val_loss improved from 1.51226 to 1.49310, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.5160 - val_loss: 1.4931\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5006\n",
      "Epoch 6: val_loss improved from 1.49310 to 1.48160, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.5006 - val_loss: 1.4816\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4915\n",
      "Epoch 7: val_loss improved from 1.48160 to 1.47357, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.4915 - val_loss: 1.4736\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4829\n",
      "Epoch 8: val_loss improved from 1.47357 to 1.46080, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.4829 - val_loss: 1.4608\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4753\n",
      "Epoch 9: val_loss improved from 1.46080 to 1.45523, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.4753 - val_loss: 1.4552\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4694\n",
      "Epoch 10: val_loss improved from 1.45523 to 1.45483, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.4694 - val_loss: 1.4548\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4629\n",
      "Epoch 11: val_loss improved from 1.45483 to 1.44084, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.4629 - val_loss: 1.4408\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4612\n",
      "Epoch 12: val_loss improved from 1.44084 to 1.43647, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.4612 - val_loss: 1.4365\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4525\n",
      "Epoch 13: val_loss improved from 1.43647 to 1.43634, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.4525 - val_loss: 1.4363\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4488\n",
      "Epoch 14: val_loss improved from 1.43634 to 1.42553, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.4488 - val_loss: 1.4255\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4434\n",
      "Epoch 15: val_loss did not improve from 1.42553\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.4434 - val_loss: 1.4299\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4393\n",
      "Epoch 16: val_loss improved from 1.42553 to 1.42034, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.4393 - val_loss: 1.4203\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4354\n",
      "Epoch 17: val_loss improved from 1.42034 to 1.41540, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.4354 - val_loss: 1.4154\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4336\n",
      "Epoch 18: val_loss improved from 1.41540 to 1.41276, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.4336 - val_loss: 1.4128\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4284\n",
      "Epoch 19: val_loss improved from 1.41276 to 1.40998, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.4284 - val_loss: 1.4100\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4270\n",
      "Epoch 20: val_loss did not improve from 1.40998\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.4270 - val_loss: 1.4110\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4251\n",
      "Epoch 21: val_loss improved from 1.40998 to 1.40079, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.4251 - val_loss: 1.4008\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4211\n",
      "Epoch 22: val_loss did not improve from 1.40079\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.4211 - val_loss: 1.4094\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4177\n",
      "Epoch 23: val_loss did not improve from 1.40079\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.4177 - val_loss: 1.4040\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4139\n",
      "Epoch 24: val_loss did not improve from 1.40079\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.4139 - val_loss: 1.4015\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4148\n",
      "Epoch 25: val_loss improved from 1.40079 to 1.39786, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.4148 - val_loss: 1.3979\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4087\n",
      "Epoch 26: val_loss did not improve from 1.39786\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.4087 - val_loss: 1.3992\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4108\n",
      "Epoch 27: val_loss improved from 1.39786 to 1.39642, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.4108 - val_loss: 1.3964\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4060\n",
      "Epoch 28: val_loss did not improve from 1.39642\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.4060 - val_loss: 1.4063\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4041\n",
      "Epoch 29: val_loss did not improve from 1.39642\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.4041 - val_loss: 1.4039\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4051\n",
      "Epoch 30: val_loss improved from 1.39642 to 1.39503, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.4051 - val_loss: 1.3950\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3996\n",
      "Epoch 31: val_loss improved from 1.39503 to 1.39094, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 619us/sample - loss: 1.3996 - val_loss: 1.3909\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3965\n",
      "Epoch 32: val_loss did not improve from 1.39094\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3965 - val_loss: 1.3917\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3956\n",
      "Epoch 33: val_loss did not improve from 1.39094\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.3956 - val_loss: 1.3974\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3960\n",
      "Epoch 34: val_loss improved from 1.39094 to 1.38911, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.3960 - val_loss: 1.3891\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3916\n",
      "Epoch 35: val_loss improved from 1.38911 to 1.38245, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 616us/sample - loss: 1.3916 - val_loss: 1.3824\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3914\n",
      "Epoch 36: val_loss improved from 1.38245 to 1.38159, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.3914 - val_loss: 1.3816\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3894\n",
      "Epoch 37: val_loss did not improve from 1.38159\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.3894 - val_loss: 1.3869\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3907\n",
      "Epoch 38: val_loss did not improve from 1.38159\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.3907 - val_loss: 1.3818\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3886\n",
      "Epoch 39: val_loss did not improve from 1.38159\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.3886 - val_loss: 1.3828\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3844\n",
      "Epoch 40: val_loss improved from 1.38159 to 1.38102, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.3844 - val_loss: 1.3810\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3831\n",
      "Epoch 41: val_loss improved from 1.38102 to 1.37442, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.3831 - val_loss: 1.3744\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3825\n",
      "Epoch 42: val_loss did not improve from 1.37442\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.3825 - val_loss: 1.3782\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3830\n",
      "Epoch 43: val_loss did not improve from 1.37442\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.3830 - val_loss: 1.3783\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3781\n",
      "Epoch 44: val_loss did not improve from 1.37442\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.3781 - val_loss: 1.3745\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3772\n",
      "Epoch 45: val_loss did not improve from 1.37442\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.3772 - val_loss: 1.3795\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3752\n",
      "Epoch 46: val_loss improved from 1.37442 to 1.37436, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3752 - val_loss: 1.3744\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3754\n",
      "Epoch 47: val_loss improved from 1.37436 to 1.37229, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3754 - val_loss: 1.3723\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3728\n",
      "Epoch 48: val_loss did not improve from 1.37229\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3728 - val_loss: 1.3737\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3734\n",
      "Epoch 49: val_loss improved from 1.37229 to 1.37206, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.3734 - val_loss: 1.3721\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3719\n",
      "Epoch 50: val_loss improved from 1.37206 to 1.36908, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3719 - val_loss: 1.3691\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3729\n",
      "Epoch 51: val_loss improved from 1.36908 to 1.36453, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.3729 - val_loss: 1.3645\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3665\n",
      "Epoch 52: val_loss did not improve from 1.36453\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.3665 - val_loss: 1.3650\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3644\n",
      "Epoch 53: val_loss improved from 1.36453 to 1.36374, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.3644 - val_loss: 1.3637\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3659\n",
      "Epoch 54: val_loss improved from 1.36374 to 1.36315, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3659 - val_loss: 1.3631\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3617\n",
      "Epoch 55: val_loss did not improve from 1.36315\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.3617 - val_loss: 1.3663\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3635\n",
      "Epoch 56: val_loss did not improve from 1.36315\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.3635 - val_loss: 1.3657\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3608\n",
      "Epoch 57: val_loss did not improve from 1.36315\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.3608 - val_loss: 1.3636\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3604\n",
      "Epoch 58: val_loss improved from 1.36315 to 1.36054, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.3604 - val_loss: 1.3605\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3589\n",
      "Epoch 59: val_loss improved from 1.36054 to 1.35844, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.3589 - val_loss: 1.3584\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3558\n",
      "Epoch 60: val_loss improved from 1.35844 to 1.35785, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3558 - val_loss: 1.3579\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3578\n",
      "Epoch 61: val_loss improved from 1.35785 to 1.35664, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3578 - val_loss: 1.3566\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3539\n",
      "Epoch 62: val_loss improved from 1.35664 to 1.35617, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3539 - val_loss: 1.3562\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3530\n",
      "Epoch 63: val_loss did not improve from 1.35617\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3530 - val_loss: 1.3564\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3520\n",
      "Epoch 64: val_loss improved from 1.35617 to 1.35424, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.3520 - val_loss: 1.3542\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3506\n",
      "Epoch 65: val_loss did not improve from 1.35424\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3506 - val_loss: 1.3574\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3496\n",
      "Epoch 66: val_loss did not improve from 1.35424\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.3496 - val_loss: 1.3576\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3452\n",
      "Epoch 67: val_loss did not improve from 1.35424\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.3452 - val_loss: 1.3562\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3502\n",
      "Epoch 68: val_loss improved from 1.35424 to 1.35001, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.3502 - val_loss: 1.3500\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3444\n",
      "Epoch 69: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3444 - val_loss: 1.3534\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3497\n",
      "Epoch 70: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.3497 - val_loss: 1.3525\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3462\n",
      "Epoch 71: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.3462 - val_loss: 1.3601\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3446\n",
      "Epoch 72: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.3446 - val_loss: 1.3549\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3437\n",
      "Epoch 73: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.3437 - val_loss: 1.3538\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3424\n",
      "Epoch 74: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.3424 - val_loss: 1.3551\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3414\n",
      "Epoch 75: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.3414 - val_loss: 1.3507\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3430\n",
      "Epoch 76: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.3430 - val_loss: 1.3552\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3396\n",
      "Epoch 77: val_loss did not improve from 1.35001\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.3396 - val_loss: 1.3533\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3380\n",
      "Epoch 78: val_loss improved from 1.35001 to 1.34641, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.3380 - val_loss: 1.3464\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3375\n",
      "Epoch 79: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.3375 - val_loss: 1.3539\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3371\n",
      "Epoch 80: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.3371 - val_loss: 1.3571\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3341\n",
      "Epoch 81: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.3341 - val_loss: 1.3481\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3350\n",
      "Epoch 82: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.3350 - val_loss: 1.3488\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3325\n",
      "Epoch 83: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3325 - val_loss: 1.3465\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3295\n",
      "Epoch 84: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.3295 - val_loss: 1.3510\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3308\n",
      "Epoch 85: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.3308 - val_loss: 1.3490\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3283\n",
      "Epoch 86: val_loss did not improve from 1.34641\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.3283 - val_loss: 1.3514\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3301\n",
      "Epoch 87: val_loss improved from 1.34641 to 1.34228, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.3301 - val_loss: 1.3423\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3263\n",
      "Epoch 88: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.3263 - val_loss: 1.3487\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3265\n",
      "Epoch 89: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3265 - val_loss: 1.3476\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3276\n",
      "Epoch 90: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3276 - val_loss: 1.3431\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3236\n",
      "Epoch 91: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3236 - val_loss: 1.3464\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3252\n",
      "Epoch 92: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.3252 - val_loss: 1.3436\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3228\n",
      "Epoch 93: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3228 - val_loss: 1.3467\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3200\n",
      "Epoch 94: val_loss did not improve from 1.34228\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3200 - val_loss: 1.3485\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3219\n",
      "Epoch 95: val_loss improved from 1.34228 to 1.34214, saving model to ./checkpoints/Feature_extraction_remove_energy_0.h5\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.3219 - val_loss: 1.3421\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3195\n",
      "Epoch 96: val_loss did not improve from 1.34214\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.3195 - val_loss: 1.3528\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3181\n",
      "Epoch 97: val_loss did not improve from 1.34214\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.3181 - val_loss: 1.3485\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3185\n",
      "Epoch 98: val_loss did not improve from 1.34214\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3185 - val_loss: 1.3478\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3190\n",
      "Epoch 99: val_loss did not improve from 1.34214\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.3190 - val_loss: 1.3447\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3178\n",
      "Epoch 100: val_loss did not improve from 1.34214\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.3178 - val_loss: 1.3428\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3137\n",
      "Epoch 1: val_loss improved from inf to 1.34791, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.3137 - val_loss: 1.3479\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3181\n",
      "Epoch 2: val_loss did not improve from 1.34791\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.3181 - val_loss: 1.3483\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3176\n",
      "Epoch 3: val_loss did not improve from 1.34791\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3176 - val_loss: 1.3480\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3121\n",
      "Epoch 4: val_loss improved from 1.34791 to 1.34412, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.3121 - val_loss: 1.3441\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3120\n",
      "Epoch 5: val_loss did not improve from 1.34412\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3120 - val_loss: 1.3455\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3096\n",
      "Epoch 6: val_loss improved from 1.34412 to 1.34298, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.3096 - val_loss: 1.3430\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3092\n",
      "Epoch 7: val_loss improved from 1.34298 to 1.33655, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.3092 - val_loss: 1.3365\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3079\n",
      "Epoch 8: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.3079 - val_loss: 1.3409\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3081\n",
      "Epoch 9: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.3081 - val_loss: 1.3462\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3111\n",
      "Epoch 10: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.3111 - val_loss: 1.3466\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3101\n",
      "Epoch 11: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3101 - val_loss: 1.3487\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3068\n",
      "Epoch 12: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3068 - val_loss: 1.3541\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3061\n",
      "Epoch 13: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3061 - val_loss: 1.3458\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3056\n",
      "Epoch 14: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.3056 - val_loss: 1.3465\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3064\n",
      "Epoch 15: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.3064 - val_loss: 1.3496\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3083\n",
      "Epoch 16: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3083 - val_loss: 1.3542\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3044\n",
      "Epoch 17: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.3044 - val_loss: 1.3490\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3071\n",
      "Epoch 18: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3071 - val_loss: 1.3524\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3095\n",
      "Epoch 19: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.3095 - val_loss: 1.3471\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3066\n",
      "Epoch 20: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.3066 - val_loss: 1.3436\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3052\n",
      "Epoch 21: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.3052 - val_loss: 1.3416\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3003\n",
      "Epoch 22: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.3003 - val_loss: 1.3459\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3044\n",
      "Epoch 23: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.3044 - val_loss: 1.3427\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3022\n",
      "Epoch 24: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.3022 - val_loss: 1.3464\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3022\n",
      "Epoch 25: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.3022 - val_loss: 1.3417\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3017\n",
      "Epoch 26: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.3017 - val_loss: 1.3465\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3035\n",
      "Epoch 27: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3035 - val_loss: 1.3488\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3010\n",
      "Epoch 28: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.3010 - val_loss: 1.3494\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3031\n",
      "Epoch 29: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3031 - val_loss: 1.3429\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2982\n",
      "Epoch 30: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2982 - val_loss: 1.3427\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3014\n",
      "Epoch 31: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3014 - val_loss: 1.3443\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2997\n",
      "Epoch 32: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2997 - val_loss: 1.3462\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2991\n",
      "Epoch 33: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2991 - val_loss: 1.3525\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2962\n",
      "Epoch 34: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2962 - val_loss: 1.3425\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2970\n",
      "Epoch 35: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2970 - val_loss: 1.3444\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2950\n",
      "Epoch 36: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2950 - val_loss: 1.3399\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3000\n",
      "Epoch 37: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3000 - val_loss: 1.3479\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2958\n",
      "Epoch 38: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2958 - val_loss: 1.3373\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2936\n",
      "Epoch 39: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2936 - val_loss: 1.3455\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2935\n",
      "Epoch 40: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2935 - val_loss: 1.3501\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2932\n",
      "Epoch 41: val_loss did not improve from 1.33655\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2932 - val_loss: 1.3432\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2933\n",
      "Epoch 42: val_loss improved from 1.33655 to 1.33595, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2933 - val_loss: 1.3360\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2918\n",
      "Epoch 43: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2918 - val_loss: 1.3384\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2950\n",
      "Epoch 44: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2950 - val_loss: 1.3388\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2889\n",
      "Epoch 45: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2889 - val_loss: 1.3432\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2924\n",
      "Epoch 46: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2924 - val_loss: 1.3437\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2897\n",
      "Epoch 47: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2897 - val_loss: 1.3383\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2926\n",
      "Epoch 48: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2926 - val_loss: 1.3413\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2901\n",
      "Epoch 49: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2901 - val_loss: 1.3387\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2901\n",
      "Epoch 50: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2901 - val_loss: 1.3380\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2904\n",
      "Epoch 51: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2904 - val_loss: 1.3427\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2869\n",
      "Epoch 52: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2869 - val_loss: 1.3420\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2882\n",
      "Epoch 53: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2882 - val_loss: 1.3394\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2872\n",
      "Epoch 54: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2872 - val_loss: 1.3393\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2858\n",
      "Epoch 55: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2858 - val_loss: 1.3392\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2846\n",
      "Epoch 56: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2846 - val_loss: 1.3432\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2822\n",
      "Epoch 57: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2822 - val_loss: 1.3489\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2857\n",
      "Epoch 58: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2857 - val_loss: 1.3422\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2824\n",
      "Epoch 59: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2824 - val_loss: 1.3440\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2819\n",
      "Epoch 60: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2819 - val_loss: 1.3417\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2834\n",
      "Epoch 61: val_loss did not improve from 1.33595\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2834 - val_loss: 1.3385\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2771\n",
      "Epoch 62: val_loss improved from 1.33595 to 1.33366, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2771 - val_loss: 1.3337\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2809\n",
      "Epoch 63: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2809 - val_loss: 1.3375\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2793\n",
      "Epoch 64: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2793 - val_loss: 1.3389\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2783\n",
      "Epoch 65: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2783 - val_loss: 1.3352\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2786\n",
      "Epoch 66: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2786 - val_loss: 1.3476\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2767\n",
      "Epoch 67: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2767 - val_loss: 1.3362\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2762\n",
      "Epoch 68: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2762 - val_loss: 1.3377\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2737\n",
      "Epoch 69: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2737 - val_loss: 1.3399\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2753\n",
      "Epoch 70: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2753 - val_loss: 1.3404\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2790\n",
      "Epoch 71: val_loss did not improve from 1.33366\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2790 - val_loss: 1.3351\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2734\n",
      "Epoch 72: val_loss improved from 1.33366 to 1.33204, saving model to ./checkpoints/Feature_extraction_remove_energy_1.h5\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2734 - val_loss: 1.3320\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2773\n",
      "Epoch 73: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2773 - val_loss: 1.3439\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2721\n",
      "Epoch 74: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2721 - val_loss: 1.3349\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2738\n",
      "Epoch 75: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2738 - val_loss: 1.3364\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2729\n",
      "Epoch 76: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2729 - val_loss: 1.3422\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2747\n",
      "Epoch 77: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2747 - val_loss: 1.3386\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2719\n",
      "Epoch 78: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2719 - val_loss: 1.3406\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2688\n",
      "Epoch 79: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2688 - val_loss: 1.3437\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2720\n",
      "Epoch 80: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2720 - val_loss: 1.3370\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2706\n",
      "Epoch 81: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2706 - val_loss: 1.3441\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2694\n",
      "Epoch 82: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2694 - val_loss: 1.3356\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2654\n",
      "Epoch 83: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2654 - val_loss: 1.3359\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2669\n",
      "Epoch 84: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2669 - val_loss: 1.3397\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2687\n",
      "Epoch 85: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2687 - val_loss: 1.3473\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2661\n",
      "Epoch 86: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2661 - val_loss: 1.3361\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2675\n",
      "Epoch 87: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2675 - val_loss: 1.3342\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2625\n",
      "Epoch 88: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2625 - val_loss: 1.3426\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2634\n",
      "Epoch 89: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2634 - val_loss: 1.3394\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2625\n",
      "Epoch 90: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.2625 - val_loss: 1.3410\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2655\n",
      "Epoch 91: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2655 - val_loss: 1.3381\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2658\n",
      "Epoch 92: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2658 - val_loss: 1.3343\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2618\n",
      "Epoch 93: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2618 - val_loss: 1.3419\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2639\n",
      "Epoch 94: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2639 - val_loss: 1.3393\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2621\n",
      "Epoch 95: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2621 - val_loss: 1.3397\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2610\n",
      "Epoch 96: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2610 - val_loss: 1.3373\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2619\n",
      "Epoch 97: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2619 - val_loss: 1.3403\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2589\n",
      "Epoch 98: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2589 - val_loss: 1.3399\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 99: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2607 - val_loss: 1.3434\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2606\n",
      "Epoch 100: val_loss did not improve from 1.33204\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2606 - val_loss: 1.3349\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2603\n",
      "Epoch 1: val_loss improved from inf to 1.34600, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 18s 617us/sample - loss: 1.2603 - val_loss: 1.3460\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2576\n",
      "Epoch 2: val_loss improved from 1.34600 to 1.34025, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2576 - val_loss: 1.3403\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2617\n",
      "Epoch 3: val_loss did not improve from 1.34025\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2617 - val_loss: 1.3425\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2556\n",
      "Epoch 4: val_loss did not improve from 1.34025\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2556 - val_loss: 1.3452\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2563\n",
      "Epoch 5: val_loss did not improve from 1.34025\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2563 - val_loss: 1.3422\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2537\n",
      "Epoch 6: val_loss did not improve from 1.34025\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2537 - val_loss: 1.3495\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2527\n",
      "Epoch 7: val_loss improved from 1.34025 to 1.33757, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2527 - val_loss: 1.3376\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2547\n",
      "Epoch 8: val_loss did not improve from 1.33757\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2547 - val_loss: 1.3387\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2582\n",
      "Epoch 9: val_loss did not improve from 1.33757\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2582 - val_loss: 1.3481\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2568\n",
      "Epoch 10: val_loss did not improve from 1.33757\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2568 - val_loss: 1.3405\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2585\n",
      "Epoch 11: val_loss improved from 1.33757 to 1.33502, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2585 - val_loss: 1.3350\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2578\n",
      "Epoch 12: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2578 - val_loss: 1.3365\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2549\n",
      "Epoch 13: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2549 - val_loss: 1.3403\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2695\n",
      "Epoch 14: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2695 - val_loss: 1.3385\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2613\n",
      "Epoch 15: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2613 - val_loss: 1.3386\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2610\n",
      "Epoch 16: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2610 - val_loss: 1.3452\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2595\n",
      "Epoch 17: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2595 - val_loss: 1.3435\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2625\n",
      "Epoch 18: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2625 - val_loss: 1.3418\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2639\n",
      "Epoch 19: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2639 - val_loss: 1.3435\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2717\n",
      "Epoch 20: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2717 - val_loss: 1.3370\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2640\n",
      "Epoch 21: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2640 - val_loss: 1.3401\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2617\n",
      "Epoch 22: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2617 - val_loss: 1.3442\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2652\n",
      "Epoch 23: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2652 - val_loss: 1.3410\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2611\n",
      "Epoch 24: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2611 - val_loss: 1.3410\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2696\n",
      "Epoch 25: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2696 - val_loss: 1.3387\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2622\n",
      "Epoch 26: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2622 - val_loss: 1.3391\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2635\n",
      "Epoch 27: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2635 - val_loss: 1.3410\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2627\n",
      "Epoch 28: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2627 - val_loss: 1.3385\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2593\n",
      "Epoch 29: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2593 - val_loss: 1.3380\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2750\n",
      "Epoch 30: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2750 - val_loss: 1.3446\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2648\n",
      "Epoch 31: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.2648 - val_loss: 1.3429\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2637\n",
      "Epoch 32: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2637 - val_loss: 1.3381\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2603\n",
      "Epoch 33: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.2603 - val_loss: 1.3393\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2610\n",
      "Epoch 34: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2610 - val_loss: 1.3454\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 35: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2607 - val_loss: 1.3467\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 36: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2607 - val_loss: 1.3385\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2599\n",
      "Epoch 37: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2599 - val_loss: 1.3393\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2576\n",
      "Epoch 38: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2576 - val_loss: 1.3394\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2572\n",
      "Epoch 39: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2572 - val_loss: 1.3439\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2716\n",
      "Epoch 40: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2716 - val_loss: 1.3418\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2593\n",
      "Epoch 41: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2593 - val_loss: 1.3352\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2612\n",
      "Epoch 42: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2612 - val_loss: 1.3395\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2605\n",
      "Epoch 43: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2605 - val_loss: 1.3387\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2602\n",
      "Epoch 44: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2602 - val_loss: 1.3361\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2606\n",
      "Epoch 45: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2606 - val_loss: 1.3387\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2608\n",
      "Epoch 46: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2608 - val_loss: 1.3352\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2597\n",
      "Epoch 47: val_loss did not improve from 1.33502\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2597 - val_loss: 1.3378\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2639\n",
      "Epoch 48: val_loss improved from 1.33502 to 1.33157, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2639 - val_loss: 1.3316\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2660\n",
      "Epoch 49: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2660 - val_loss: 1.3323\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3106\n",
      "Epoch 50: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.3106 - val_loss: 1.3373\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2687\n",
      "Epoch 51: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2687 - val_loss: 1.3331\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2640\n",
      "Epoch 52: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2640 - val_loss: 1.3356\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2618\n",
      "Epoch 53: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2618 - val_loss: 1.3446\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2604\n",
      "Epoch 54: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2604 - val_loss: 1.3471\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2595\n",
      "Epoch 55: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2595 - val_loss: 1.3399\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2552\n",
      "Epoch 56: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2552 - val_loss: 1.3421\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2577\n",
      "Epoch 57: val_loss did not improve from 1.33157\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2577 - val_loss: 1.3317\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2560\n",
      "Epoch 58: val_loss improved from 1.33157 to 1.33073, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2560 - val_loss: 1.3307\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2531\n",
      "Epoch 59: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2531 - val_loss: 1.3319\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2572\n",
      "Epoch 60: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2572 - val_loss: 1.3352\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2554\n",
      "Epoch 61: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2554 - val_loss: 1.3341\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2516\n",
      "Epoch 62: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2516 - val_loss: 1.3354\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2529\n",
      "Epoch 63: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2529 - val_loss: 1.3386\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2541\n",
      "Epoch 64: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2541 - val_loss: 1.3333\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2478\n",
      "Epoch 65: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2478 - val_loss: 1.3391\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2480\n",
      "Epoch 66: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2480 - val_loss: 1.3357\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2497\n",
      "Epoch 67: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2497 - val_loss: 1.3348\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 68: val_loss did not improve from 1.33073\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2486 - val_loss: 1.3317\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 69: val_loss improved from 1.33073 to 1.33018, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2471 - val_loss: 1.3302\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2481\n",
      "Epoch 70: val_loss did not improve from 1.33018\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2481 - val_loss: 1.3313\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 71: val_loss did not improve from 1.33018\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2464 - val_loss: 1.3358\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2427\n",
      "Epoch 72: val_loss did not improve from 1.33018\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2427 - val_loss: 1.3364\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 73: val_loss did not improve from 1.33018\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2464 - val_loss: 1.3342\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2451\n",
      "Epoch 74: val_loss did not improve from 1.33018\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2451 - val_loss: 1.3343\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2441\n",
      "Epoch 75: val_loss did not improve from 1.33018\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2441 - val_loss: 1.3333\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2460\n",
      "Epoch 76: val_loss improved from 1.33018 to 1.32955, saving model to ./checkpoints/Feature_extraction_remove_energy_2.h5\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2460 - val_loss: 1.3295\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2463\n",
      "Epoch 77: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2463 - val_loss: 1.3356\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2412\n",
      "Epoch 78: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2412 - val_loss: 1.3350\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2430\n",
      "Epoch 79: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2430 - val_loss: 1.3362\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2420\n",
      "Epoch 80: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2420 - val_loss: 1.3361\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 81: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2413 - val_loss: 1.3433\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2373\n",
      "Epoch 82: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2373 - val_loss: 1.3313\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2416\n",
      "Epoch 83: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2416 - val_loss: 1.3344\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 84: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2399 - val_loss: 1.3421\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2385\n",
      "Epoch 85: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2385 - val_loss: 1.3356\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 86: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2387 - val_loss: 1.3366\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 87: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2410 - val_loss: 1.3314\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 88: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2399 - val_loss: 1.3336\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 89: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2370 - val_loss: 1.3358\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2404\n",
      "Epoch 90: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2404 - val_loss: 1.3361\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2373\n",
      "Epoch 91: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2373 - val_loss: 1.3348\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 92: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2361 - val_loss: 1.3347\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2379\n",
      "Epoch 93: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2379 - val_loss: 1.3465\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2388\n",
      "Epoch 94: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2388 - val_loss: 1.3385\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2372\n",
      "Epoch 95: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2372 - val_loss: 1.3364\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 96: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2325 - val_loss: 1.3308\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2332\n",
      "Epoch 97: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2332 - val_loss: 1.3354\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2334\n",
      "Epoch 98: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2334 - val_loss: 1.3351\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2320\n",
      "Epoch 99: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2320 - val_loss: 1.3410\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 100: val_loss did not improve from 1.32955\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2310 - val_loss: 1.3330\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2341\n",
      "Epoch 1: val_loss improved from inf to 1.34506, saving model to ./checkpoints/Feature_extraction_remove_energy_3.h5\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2341 - val_loss: 1.3451\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2329\n",
      "Epoch 2: val_loss improved from 1.34506 to 1.33249, saving model to ./checkpoints/Feature_extraction_remove_energy_3.h5\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2329 - val_loss: 1.3325\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 3: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2306 - val_loss: 1.3368\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 4: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2310 - val_loss: 1.3336\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2294\n",
      "Epoch 5: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2294 - val_loss: 1.3403\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2273\n",
      "Epoch 6: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2273 - val_loss: 1.3332\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2333\n",
      "Epoch 7: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2333 - val_loss: 1.3362\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2307\n",
      "Epoch 8: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2307 - val_loss: 1.3406\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2335\n",
      "Epoch 9: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2335 - val_loss: 1.3379\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 10: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2365 - val_loss: 1.3396\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2335\n",
      "Epoch 11: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2335 - val_loss: 1.3374\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2294\n",
      "Epoch 12: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2294 - val_loss: 1.3382\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 13: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2325 - val_loss: 1.3380\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2342\n",
      "Epoch 14: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2342 - val_loss: 1.3332\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 15: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2304 - val_loss: 1.3405\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 16: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2315 - val_loss: 1.3375\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2334\n",
      "Epoch 17: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2334 - val_loss: 1.3420\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 18: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2301 - val_loss: 1.3367\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2327\n",
      "Epoch 19: val_loss did not improve from 1.33249\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2327 - val_loss: 1.3366\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2362\n",
      "Epoch 20: val_loss improved from 1.33249 to 1.33214, saving model to ./checkpoints/Feature_extraction_remove_energy_3.h5\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2362 - val_loss: 1.3321\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 21: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2410 - val_loss: 1.3327\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 22: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2351 - val_loss: 1.3347\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2385\n",
      "Epoch 23: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2385 - val_loss: 1.3377\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2381\n",
      "Epoch 24: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2381 - val_loss: 1.3358\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2544\n",
      "Epoch 25: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2544 - val_loss: 1.3387\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2438\n",
      "Epoch 26: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2438 - val_loss: 1.3376\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2448\n",
      "Epoch 27: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2448 - val_loss: 1.3365\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2420\n",
      "Epoch 28: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2420 - val_loss: 1.3384\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2420\n",
      "Epoch 29: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2420 - val_loss: 1.3336\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2422\n",
      "Epoch 30: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2422 - val_loss: 1.3396\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2625\n",
      "Epoch 31: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2625 - val_loss: 1.3402\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2474\n",
      "Epoch 32: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2474 - val_loss: 1.3384\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 33: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2471 - val_loss: 1.3351\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2459\n",
      "Epoch 34: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2459 - val_loss: 1.3417\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2484\n",
      "Epoch 35: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2484 - val_loss: 1.3370\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2506\n",
      "Epoch 36: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2506 - val_loss: 1.3365\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2478\n",
      "Epoch 37: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2478 - val_loss: 1.3364\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2472\n",
      "Epoch 38: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2472 - val_loss: 1.3330\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2519\n",
      "Epoch 39: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2519 - val_loss: 1.3352\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2474\n",
      "Epoch 40: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2474 - val_loss: 1.3369\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 41: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2486 - val_loss: 1.3409\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2514\n",
      "Epoch 42: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2514 - val_loss: 1.3389\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2507\n",
      "Epoch 43: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2507 - val_loss: 1.3414\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 44: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2486 - val_loss: 1.3398\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 45: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2523 - val_loss: 1.3462\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2475\n",
      "Epoch 46: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2475 - val_loss: 1.3363\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2539\n",
      "Epoch 47: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2539 - val_loss: 1.3429\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2536\n",
      "Epoch 48: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2536 - val_loss: 1.3408\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2528\n",
      "Epoch 49: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2528 - val_loss: 1.3327\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2654\n",
      "Epoch 50: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2654 - val_loss: 1.3431\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2576\n",
      "Epoch 51: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2576 - val_loss: 1.3406\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2509\n",
      "Epoch 52: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2509 - val_loss: 1.3345\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2511\n",
      "Epoch 53: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2511 - val_loss: 1.3373\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 54: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2468 - val_loss: 1.3396\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2444\n",
      "Epoch 55: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2444 - val_loss: 1.3413\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2418\n",
      "Epoch 56: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2418 - val_loss: 1.3399\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 57: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2428 - val_loss: 1.3328\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 58: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2464 - val_loss: 1.3384\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2420\n",
      "Epoch 59: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2420 - val_loss: 1.3369\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2427\n",
      "Epoch 60: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2427 - val_loss: 1.3357\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2389\n",
      "Epoch 61: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2389 - val_loss: 1.3362\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2398\n",
      "Epoch 62: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2398 - val_loss: 1.3336\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2355\n",
      "Epoch 63: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2355 - val_loss: 1.3394\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 64: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2368 - val_loss: 1.3345\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2395\n",
      "Epoch 65: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2395 - val_loss: 1.3407\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2356\n",
      "Epoch 66: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2356 - val_loss: 1.3361\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2396\n",
      "Epoch 67: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2396 - val_loss: 1.3389\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 68: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2351 - val_loss: 1.3357\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2378\n",
      "Epoch 69: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2378 - val_loss: 1.3413\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2384\n",
      "Epoch 70: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2384 - val_loss: 1.3392\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2328\n",
      "Epoch 71: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2328 - val_loss: 1.3378\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2329\n",
      "Epoch 72: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2329 - val_loss: 1.3402\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2299\n",
      "Epoch 73: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2299 - val_loss: 1.3329\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 74: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2339 - val_loss: 1.3389\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 75: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2306 - val_loss: 1.3421\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 76: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2301 - val_loss: 1.3367\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 77: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2302 - val_loss: 1.3412\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 78: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2301 - val_loss: 1.3378\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 79: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2306 - val_loss: 1.3334\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 80: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2302 - val_loss: 1.3365\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 81: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2266 - val_loss: 1.3358\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 82: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2263 - val_loss: 1.3347\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 83: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2286 - val_loss: 1.3330\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 84: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2233 - val_loss: 1.3361\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2219\n",
      "Epoch 85: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2219 - val_loss: 1.3383\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2235\n",
      "Epoch 86: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2235 - val_loss: 1.3344\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 87: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2223 - val_loss: 1.3341\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2218\n",
      "Epoch 88: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2218 - val_loss: 1.3397\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2273\n",
      "Epoch 89: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2273 - val_loss: 1.3366\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 90: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2254 - val_loss: 1.3346\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 91: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2237 - val_loss: 1.3427\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 92: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2255 - val_loss: 1.3409\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 93: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2210 - val_loss: 1.3361\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 94: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2197 - val_loss: 1.3435\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2224\n",
      "Epoch 95: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2224 - val_loss: 1.3388\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2199\n",
      "Epoch 96: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2199 - val_loss: 1.3326\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2247\n",
      "Epoch 97: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2247 - val_loss: 1.3372\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 98: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2220 - val_loss: 1.3362\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2209\n",
      "Epoch 99: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2209 - val_loss: 1.3380\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2190\n",
      "Epoch 100: val_loss did not improve from 1.33214\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2190 - val_loss: 1.3351\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2175\n",
      "Epoch 1: val_loss improved from inf to 1.33581, saving model to ./checkpoints/Feature_extraction_remove_energy_4.h5\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2175 - val_loss: 1.3358\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2166\n",
      "Epoch 2: val_loss did not improve from 1.33581\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2166 - val_loss: 1.3361\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2185\n",
      "Epoch 3: val_loss did not improve from 1.33581\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2185 - val_loss: 1.3368\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2170\n",
      "Epoch 4: val_loss did not improve from 1.33581\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.2170 - val_loss: 1.3409\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2135\n",
      "Epoch 5: val_loss did not improve from 1.33581\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.2135 - val_loss: 1.3363\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 6: val_loss improved from 1.33581 to 1.33506, saving model to ./checkpoints/Feature_extraction_remove_energy_4.h5\n",
      "29601/29601 [==============================] - 18s 616us/sample - loss: 1.2162 - val_loss: 1.3351\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2160\n",
      "Epoch 7: val_loss improved from 1.33506 to 1.33043, saving model to ./checkpoints/Feature_extraction_remove_energy_4.h5\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2160 - val_loss: 1.3304\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2156\n",
      "Epoch 8: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2156 - val_loss: 1.3345\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2240\n",
      "Epoch 9: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2240 - val_loss: 1.3380\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2236\n",
      "Epoch 10: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2236 - val_loss: 1.3334\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2246\n",
      "Epoch 11: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2246 - val_loss: 1.3401\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 12: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2200 - val_loss: 1.3422\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2281\n",
      "Epoch 13: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2281 - val_loss: 1.3483\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 14: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2233 - val_loss: 1.3455\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2257\n",
      "Epoch 15: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2257 - val_loss: 1.3380\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2307\n",
      "Epoch 16: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2307 - val_loss: 1.3392\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 17: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2262 - val_loss: 1.3379\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 18: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.2263 - val_loss: 1.3405\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2288\n",
      "Epoch 19: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2288 - val_loss: 1.3308\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2252\n",
      "Epoch 20: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2252 - val_loss: 1.3341\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2311\n",
      "Epoch 21: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2311 - val_loss: 1.3366\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2283\n",
      "Epoch 22: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2283 - val_loss: 1.3356\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2398\n",
      "Epoch 23: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2398 - val_loss: 1.3326\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 24: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2305 - val_loss: 1.3391\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 25: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2301 - val_loss: 1.3393\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 26: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2408 - val_loss: 1.3397\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2299\n",
      "Epoch 27: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2299 - val_loss: 1.3414\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2341\n",
      "Epoch 28: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2341 - val_loss: 1.3432\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 29: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2353 - val_loss: 1.3395\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2378\n",
      "Epoch 30: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2378 - val_loss: 1.3420\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 31: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2351 - val_loss: 1.3398\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 32: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2344 - val_loss: 1.3458\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 33: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2370 - val_loss: 1.3428\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2414\n",
      "Epoch 34: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2414 - val_loss: 1.3378\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2390\n",
      "Epoch 35: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2390 - val_loss: 1.3365\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2443\n",
      "Epoch 36: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2443 - val_loss: 1.3414\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2446\n",
      "Epoch 37: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2446 - val_loss: 1.3418\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2430\n",
      "Epoch 38: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2430 - val_loss: 1.3362\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2435\n",
      "Epoch 39: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2435 - val_loss: 1.3375\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2433\n",
      "Epoch 40: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2433 - val_loss: 1.3337\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 41: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2408 - val_loss: 1.3353\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2384\n",
      "Epoch 42: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2384 - val_loss: 1.3376\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 43: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2413 - val_loss: 1.3317\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2472\n",
      "Epoch 44: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2472 - val_loss: 1.3388\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2418\n",
      "Epoch 45: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2418 - val_loss: 1.3381\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2402\n",
      "Epoch 46: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2402 - val_loss: 1.3395\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2499\n",
      "Epoch 47: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2499 - val_loss: 1.3377\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2481\n",
      "Epoch 48: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2481 - val_loss: 1.3422\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2491\n",
      "Epoch 49: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2491 - val_loss: 1.3353\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2469\n",
      "Epoch 50: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2469 - val_loss: 1.3371\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 51: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2502 - val_loss: 1.3367\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2537\n",
      "Epoch 52: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2537 - val_loss: 1.3362\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2447\n",
      "Epoch 53: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2447 - val_loss: 1.3338\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2439\n",
      "Epoch 54: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2439 - val_loss: 1.3388\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2444\n",
      "Epoch 55: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2444 - val_loss: 1.3341\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2383\n",
      "Epoch 56: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2383 - val_loss: 1.3362\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2405\n",
      "Epoch 57: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2405 - val_loss: 1.3367\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2411\n",
      "Epoch 58: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2411 - val_loss: 1.3400\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2415\n",
      "Epoch 59: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2415 - val_loss: 1.3362\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2360\n",
      "Epoch 60: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2360 - val_loss: 1.3362\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2337\n",
      "Epoch 61: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2337 - val_loss: 1.3371\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 62: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2353 - val_loss: 1.3343\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2335\n",
      "Epoch 63: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2335 - val_loss: 1.3341\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 64: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2370 - val_loss: 1.3343\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2374\n",
      "Epoch 65: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2374 - val_loss: 1.3322\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2320\n",
      "Epoch 66: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2320 - val_loss: 1.3347\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2307\n",
      "Epoch 67: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2307 - val_loss: 1.3395\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 68: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2284 - val_loss: 1.3374\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2324\n",
      "Epoch 69: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2324 - val_loss: 1.3384\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 70: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2301 - val_loss: 1.3307\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2324\n",
      "Epoch 71: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2324 - val_loss: 1.3323\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 72: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2301 - val_loss: 1.3316\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 73: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2266 - val_loss: 1.3332\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 74: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2287 - val_loss: 1.3338\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2268\n",
      "Epoch 75: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2268 - val_loss: 1.3411\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2283\n",
      "Epoch 76: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2283 - val_loss: 1.3322\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 77: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2220 - val_loss: 1.3374\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2240\n",
      "Epoch 78: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2240 - val_loss: 1.3394\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2217\n",
      "Epoch 79: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2217 - val_loss: 1.3391\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2259\n",
      "Epoch 80: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2259 - val_loss: 1.3364\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2207\n",
      "Epoch 81: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2207 - val_loss: 1.3364\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2212\n",
      "Epoch 82: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2212 - val_loss: 1.3372\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 83: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2253 - val_loss: 1.3333\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 84: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2210 - val_loss: 1.3313\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2213\n",
      "Epoch 85: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2213 - val_loss: 1.3329\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 86: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2194 - val_loss: 1.3357\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 87: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2196 - val_loss: 1.3358\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2187\n",
      "Epoch 88: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2187 - val_loss: 1.3368\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 89: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.2223 - val_loss: 1.3366\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2208\n",
      "Epoch 90: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2208 - val_loss: 1.3364\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 91: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2183 - val_loss: 1.3368\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2152\n",
      "Epoch 92: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2152 - val_loss: 1.3371\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 93: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2176 - val_loss: 1.3376\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2171\n",
      "Epoch 94: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2171 - val_loss: 1.3348\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2179\n",
      "Epoch 95: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2179 - val_loss: 1.3371\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2170\n",
      "Epoch 96: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2170 - val_loss: 1.3373\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2180\n",
      "Epoch 97: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2180 - val_loss: 1.3420\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2143\n",
      "Epoch 98: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2143 - val_loss: 1.3440\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2132\n",
      "Epoch 99: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2132 - val_loss: 1.3339\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2115\n",
      "Epoch 100: val_loss did not improve from 1.33043\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2115 - val_loss: 1.3348\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2154\n",
      "Epoch 1: val_loss improved from inf to 1.33167, saving model to ./checkpoints/Feature_extraction_remove_energy_5.h5\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2154 - val_loss: 1.3317\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2139\n",
      "Epoch 2: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2139 - val_loss: 1.3338\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2121\n",
      "Epoch 3: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2121 - val_loss: 1.3324\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2089\n",
      "Epoch 4: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2089 - val_loss: 1.3396\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2090\n",
      "Epoch 5: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2090 - val_loss: 1.3381\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2104\n",
      "Epoch 6: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2104 - val_loss: 1.3335\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2076\n",
      "Epoch 7: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2076 - val_loss: 1.3340\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2113\n",
      "Epoch 8: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2113 - val_loss: 1.3383\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2109\n",
      "Epoch 9: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2109 - val_loss: 1.3371\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2121\n",
      "Epoch 10: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2121 - val_loss: 1.3350\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2181\n",
      "Epoch 11: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2181 - val_loss: 1.3441\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 12: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2220 - val_loss: 1.3438\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2222\n",
      "Epoch 13: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2222 - val_loss: 1.3512\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2185\n",
      "Epoch 14: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2185 - val_loss: 1.3384\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 15: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2210 - val_loss: 1.3496\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2191\n",
      "Epoch 16: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2191 - val_loss: 1.3376\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2187\n",
      "Epoch 17: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2187 - val_loss: 1.3392\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2214\n",
      "Epoch 18: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2214 - val_loss: 1.3393\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2215\n",
      "Epoch 19: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2215 - val_loss: 1.3375\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 20: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2243 - val_loss: 1.3469\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2340\n",
      "Epoch 21: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2340 - val_loss: 1.3417\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2276\n",
      "Epoch 22: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2276 - val_loss: 1.3427\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2278\n",
      "Epoch 23: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2278 - val_loss: 1.3411\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2265\n",
      "Epoch 24: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2265 - val_loss: 1.3408\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2281\n",
      "Epoch 25: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2281 - val_loss: 1.3359\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2274\n",
      "Epoch 26: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2274 - val_loss: 1.3426\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 27: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.2315 - val_loss: 1.3402\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2322\n",
      "Epoch 28: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2322 - val_loss: 1.3377\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2355\n",
      "Epoch 29: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2355 - val_loss: 1.3409\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2295\n",
      "Epoch 30: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2295 - val_loss: 1.3397\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2271\n",
      "Epoch 31: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2271 - val_loss: 1.3428\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2314\n",
      "Epoch 32: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2314 - val_loss: 1.3430\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2374\n",
      "Epoch 33: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2374 - val_loss: 1.3442\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2376\n",
      "Epoch 34: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2376 - val_loss: 1.3475\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2376\n",
      "Epoch 35: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2376 - val_loss: 1.3433\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2409\n",
      "Epoch 36: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2409 - val_loss: 1.3446\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2388\n",
      "Epoch 37: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2388 - val_loss: 1.3436\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2373\n",
      "Epoch 38: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2373 - val_loss: 1.3465\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2463\n",
      "Epoch 39: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2463 - val_loss: 1.3412\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2405\n",
      "Epoch 40: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2405 - val_loss: 1.3341\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2447\n",
      "Epoch 41: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.2447 - val_loss: 1.3379\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 42: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2501 - val_loss: 1.3377\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2520\n",
      "Epoch 43: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2520 - val_loss: 1.3415\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2496\n",
      "Epoch 44: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2496 - val_loss: 1.3433\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 45: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2486 - val_loss: 1.3448\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2500\n",
      "Epoch 46: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2500 - val_loss: 1.3444\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2566\n",
      "Epoch 47: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2566 - val_loss: 1.3422\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2603\n",
      "Epoch 48: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2603 - val_loss: 1.3394\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2538\n",
      "Epoch 49: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2538 - val_loss: 1.3464\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2689\n",
      "Epoch 50: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2689 - val_loss: 1.3455\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2652\n",
      "Epoch 51: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2652 - val_loss: 1.3438\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2700\n",
      "Epoch 52: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2700 - val_loss: 1.3424\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2702\n",
      "Epoch 53: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2702 - val_loss: 1.3480\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2678\n",
      "Epoch 54: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2678 - val_loss: 1.3486\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2639\n",
      "Epoch 55: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2639 - val_loss: 1.3500\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2601\n",
      "Epoch 56: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2601 - val_loss: 1.3408\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2561\n",
      "Epoch 57: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2561 - val_loss: 1.3452\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2567\n",
      "Epoch 58: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2567 - val_loss: 1.3452\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2517\n",
      "Epoch 59: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2517 - val_loss: 1.3462\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2509\n",
      "Epoch 60: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2509 - val_loss: 1.3420\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2516\n",
      "Epoch 61: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2516 - val_loss: 1.3419\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2500\n",
      "Epoch 62: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2500 - val_loss: 1.3393\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2485\n",
      "Epoch 63: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2485 - val_loss: 1.3436\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 64: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2473 - val_loss: 1.3433\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2450\n",
      "Epoch 65: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2450 - val_loss: 1.3485\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2446\n",
      "Epoch 66: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2446 - val_loss: 1.3447\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2474\n",
      "Epoch 67: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 603us/sample - loss: 1.2474 - val_loss: 1.3428\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 68: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2428 - val_loss: 1.3434\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2404\n",
      "Epoch 69: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2404 - val_loss: 1.3408\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 70: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2408 - val_loss: 1.3440\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 71: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2421 - val_loss: 1.3428\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 72: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2365 - val_loss: 1.3406\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2381\n",
      "Epoch 73: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.2381 - val_loss: 1.3362\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 74: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2387 - val_loss: 1.3436\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2346\n",
      "Epoch 75: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2346 - val_loss: 1.3436\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 76: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2339 - val_loss: 1.3437\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 77: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2363 - val_loss: 1.3454\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2337\n",
      "Epoch 78: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2337 - val_loss: 1.3432\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2309\n",
      "Epoch 79: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 611us/sample - loss: 1.2309 - val_loss: 1.3421\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2319\n",
      "Epoch 80: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2319 - val_loss: 1.3452\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2330\n",
      "Epoch 81: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2330 - val_loss: 1.3470\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2340\n",
      "Epoch 82: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2340 - val_loss: 1.3446\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 83: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2300 - val_loss: 1.3437\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 84: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2351 - val_loss: 1.3399\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 85: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2296 - val_loss: 1.3403\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2317\n",
      "Epoch 86: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2317 - val_loss: 1.3457\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2258\n",
      "Epoch 87: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2258 - val_loss: 1.3446\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 88: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2284 - val_loss: 1.3401\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 89: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2263 - val_loss: 1.3375\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2271\n",
      "Epoch 90: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2271 - val_loss: 1.3370\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 91: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2266 - val_loss: 1.3375\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 92: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2284 - val_loss: 1.3443\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2256\n",
      "Epoch 93: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2256 - val_loss: 1.3390\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2279\n",
      "Epoch 94: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2279 - val_loss: 1.3375\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 95: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2243 - val_loss: 1.3404\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 96: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2250 - val_loss: 1.3380\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 97: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2220 - val_loss: 1.3441\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 98: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2233 - val_loss: 1.3413\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2202\n",
      "Epoch 99: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2202 - val_loss: 1.3388\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 100: val_loss did not improve from 1.33167\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2253 - val_loss: 1.3359\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2198\n",
      "Epoch 1: val_loss improved from inf to 1.34177, saving model to ./checkpoints/Feature_extraction_remove_energy_6.h5\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2198 - val_loss: 1.3418\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2156\n",
      "Epoch 2: val_loss improved from 1.34177 to 1.33958, saving model to ./checkpoints/Feature_extraction_remove_energy_6.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2156 - val_loss: 1.3396\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 3: val_loss improved from 1.33958 to 1.33784, saving model to ./checkpoints/Feature_extraction_remove_energy_6.h5\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2216 - val_loss: 1.3378\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2156\n",
      "Epoch 4: val_loss did not improve from 1.33784\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2156 - val_loss: 1.3403\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 5: val_loss did not improve from 1.33784\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2183 - val_loss: 1.3387\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2102\n",
      "Epoch 6: val_loss did not improve from 1.33784\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2102 - val_loss: 1.3429\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2102\n",
      "Epoch 7: val_loss improved from 1.33784 to 1.33783, saving model to ./checkpoints/Feature_extraction_remove_energy_6.h5\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2102 - val_loss: 1.3378\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2175\n",
      "Epoch 8: val_loss did not improve from 1.33783\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2175 - val_loss: 1.3414\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2172\n",
      "Epoch 9: val_loss did not improve from 1.33783\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2172 - val_loss: 1.3392\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2167\n",
      "Epoch 10: val_loss improved from 1.33783 to 1.33189, saving model to ./checkpoints/Feature_extraction_remove_energy_6.h5\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2167 - val_loss: 1.3319\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2188\n",
      "Epoch 11: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2188 - val_loss: 1.3434\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2182\n",
      "Epoch 12: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2182 - val_loss: 1.3409\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2246\n",
      "Epoch 13: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2246 - val_loss: 1.3386\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2217\n",
      "Epoch 14: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2217 - val_loss: 1.3376\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2228\n",
      "Epoch 15: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2228 - val_loss: 1.3397\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2225\n",
      "Epoch 16: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2225 - val_loss: 1.3382\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 17: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2262 - val_loss: 1.3373\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2239\n",
      "Epoch 18: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2239 - val_loss: 1.3409\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2292\n",
      "Epoch 19: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2292 - val_loss: 1.3400\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2277\n",
      "Epoch 20: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2277 - val_loss: 1.3465\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2240\n",
      "Epoch 21: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2240 - val_loss: 1.3434\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2258\n",
      "Epoch 22: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2258 - val_loss: 1.3460\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 23: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2287 - val_loss: 1.3558\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 24: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2306 - val_loss: 1.3427\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2257\n",
      "Epoch 25: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2257 - val_loss: 1.3445\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2392\n",
      "Epoch 26: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2392 - val_loss: 1.3371\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2442\n",
      "Epoch 27: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2442 - val_loss: 1.3447\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2434\n",
      "Epoch 28: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2434 - val_loss: 1.3592\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 29: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2399 - val_loss: 1.3430\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 30: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2399 - val_loss: 1.3382\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2379\n",
      "Epoch 31: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2379 - val_loss: 1.3433\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2556\n",
      "Epoch 32: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2556 - val_loss: 1.3437\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2424\n",
      "Epoch 33: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2424 - val_loss: 1.3461\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2437\n",
      "Epoch 34: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2437 - val_loss: 1.3405\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2455\n",
      "Epoch 35: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2455 - val_loss: 1.3381\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2443\n",
      "Epoch 36: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2443 - val_loss: 1.3338\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2427\n",
      "Epoch 37: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2427 - val_loss: 1.3358\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2442\n",
      "Epoch 38: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2442 - val_loss: 1.3389\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2450\n",
      "Epoch 39: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2450 - val_loss: 1.3380\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2459\n",
      "Epoch 40: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2459 - val_loss: 1.3504\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2459\n",
      "Epoch 41: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2459 - val_loss: 1.3392\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2521\n",
      "Epoch 42: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2521 - val_loss: 1.3387\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2478\n",
      "Epoch 43: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2478 - val_loss: 1.3387\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2500\n",
      "Epoch 44: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2500 - val_loss: 1.3430\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2540\n",
      "Epoch 45: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 508us/sample - loss: 1.2540 - val_loss: 1.3484\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2582\n",
      "Epoch 46: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2582 - val_loss: 1.3455\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2591\n",
      "Epoch 47: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2591 - val_loss: 1.3434\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2855\n",
      "Epoch 48: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 568us/sample - loss: 1.2855 - val_loss: 1.3488\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2729\n",
      "Epoch 49: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2729 - val_loss: 1.3449\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2675\n",
      "Epoch 50: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2675 - val_loss: 1.3430\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2731\n",
      "Epoch 51: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2731 - val_loss: 1.3521\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2688\n",
      "Epoch 52: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 557us/sample - loss: 1.2688 - val_loss: 1.3497\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2661\n",
      "Epoch 53: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2661 - val_loss: 1.3501\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2623\n",
      "Epoch 54: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2623 - val_loss: 1.3455\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2593\n",
      "Epoch 55: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2593 - val_loss: 1.3487\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2554\n",
      "Epoch 56: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2554 - val_loss: 1.3442\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2581\n",
      "Epoch 57: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2581 - val_loss: 1.3475\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2546\n",
      "Epoch 58: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2546 - val_loss: 1.3421\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 59: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2502 - val_loss: 1.3434\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 60: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2501 - val_loss: 1.3460\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2480\n",
      "Epoch 61: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2480 - val_loss: 1.3390\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2458\n",
      "Epoch 62: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2458 - val_loss: 1.3496\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2474\n",
      "Epoch 63: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2474 - val_loss: 1.3394\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2790\n",
      "Epoch 64: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2790 - val_loss: 1.3359\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2544\n",
      "Epoch 65: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2544 - val_loss: 1.3428\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 66: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2466 - val_loss: 1.3414\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 67: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2471 - val_loss: 1.3521\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2456\n",
      "Epoch 68: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2456 - val_loss: 1.3436\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 69: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2413 - val_loss: 1.3503\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2444\n",
      "Epoch 70: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2444 - val_loss: 1.3429\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 71: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2413 - val_loss: 1.3417\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2382\n",
      "Epoch 72: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2382 - val_loss: 1.3452\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2396\n",
      "Epoch 73: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2396 - val_loss: 1.3527\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 74: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2363 - val_loss: 1.3452\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2369\n",
      "Epoch 75: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2369 - val_loss: 1.3427\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 76: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2366 - val_loss: 1.3441\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 77: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2366 - val_loss: 1.3426\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 78: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2326 - val_loss: 1.3549\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2330\n",
      "Epoch 79: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2330 - val_loss: 1.3426\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2318\n",
      "Epoch 80: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2318 - val_loss: 1.3405\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2327\n",
      "Epoch 81: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2327 - val_loss: 1.3365\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 82: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2361 - val_loss: 1.3469\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 83: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2302 - val_loss: 1.3418\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2333\n",
      "Epoch 84: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2333 - val_loss: 1.3403\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2307\n",
      "Epoch 85: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2307 - val_loss: 1.3424\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2324\n",
      "Epoch 86: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2324 - val_loss: 1.3415\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 87: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2326 - val_loss: 1.3386\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 88: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2245 - val_loss: 1.3459\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2292\n",
      "Epoch 89: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2292 - val_loss: 1.3447\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2277\n",
      "Epoch 90: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2277 - val_loss: 1.3425\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2256\n",
      "Epoch 91: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2256 - val_loss: 1.3465\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2262\n",
      "Epoch 92: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2262 - val_loss: 1.3468\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2276\n",
      "Epoch 93: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2276 - val_loss: 1.3422\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2225\n",
      "Epoch 94: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2225 - val_loss: 1.3462\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2275\n",
      "Epoch 95: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2275 - val_loss: 1.3470\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2248\n",
      "Epoch 96: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2248 - val_loss: 1.3433\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2268\n",
      "Epoch 97: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2268 - val_loss: 1.3441\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 98: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2242 - val_loss: 1.3465\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 99: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2243 - val_loss: 1.3410\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 100: val_loss did not improve from 1.33189\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2220 - val_loss: 1.3463\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2211\n",
      "Epoch 1: val_loss improved from inf to 1.34495, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2211 - val_loss: 1.3449\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 2: val_loss improved from 1.34495 to 1.34064, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2233 - val_loss: 1.3406\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 3: val_loss did not improve from 1.34064\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2176 - val_loss: 1.3413\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2215\n",
      "Epoch 4: val_loss improved from 1.34064 to 1.33837, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2215 - val_loss: 1.3384\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2160\n",
      "Epoch 5: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2160 - val_loss: 1.3394\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2165\n",
      "Epoch 6: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2165 - val_loss: 1.3449\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2122\n",
      "Epoch 7: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2122 - val_loss: 1.3414\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2182\n",
      "Epoch 8: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2182 - val_loss: 1.3399\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 9: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2176 - val_loss: 1.3485\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2185\n",
      "Epoch 10: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2185 - val_loss: 1.3453\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 11: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2197 - val_loss: 1.3448\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 12: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2186 - val_loss: 1.3450\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2238\n",
      "Epoch 13: val_loss did not improve from 1.33837\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2238 - val_loss: 1.3403\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 14: val_loss improved from 1.33837 to 1.33554, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2321 - val_loss: 1.3355\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2269\n",
      "Epoch 15: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2269 - val_loss: 1.3419\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2232\n",
      "Epoch 16: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2232 - val_loss: 1.3420\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2275\n",
      "Epoch 17: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2275 - val_loss: 1.3403\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2209\n",
      "Epoch 18: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2209 - val_loss: 1.3415\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2256\n",
      "Epoch 19: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2256 - val_loss: 1.3394\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 20: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2242 - val_loss: 1.3360\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2289\n",
      "Epoch 21: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2289 - val_loss: 1.3394\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 22: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2263 - val_loss: 1.3385\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2282\n",
      "Epoch 23: val_loss improved from 1.33554 to 1.33452, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2282 - val_loss: 1.3345\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2272\n",
      "Epoch 24: val_loss improved from 1.33452 to 1.33401, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2272 - val_loss: 1.3340\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 25: val_loss improved from 1.33401 to 1.33182, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2326 - val_loss: 1.3318\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2319\n",
      "Epoch 26: val_loss improved from 1.33182 to 1.32882, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2319 - val_loss: 1.3288\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 27: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2344 - val_loss: 1.3395\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 28: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2304 - val_loss: 1.3326\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 29: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2310 - val_loss: 1.3326\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2374\n",
      "Epoch 30: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2374 - val_loss: 1.3355\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 31: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2286 - val_loss: 1.3391\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2323\n",
      "Epoch 32: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2323 - val_loss: 1.3370\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2312\n",
      "Epoch 33: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2312 - val_loss: 1.3351\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2343\n",
      "Epoch 34: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2343 - val_loss: 1.3336\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2331\n",
      "Epoch 35: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2331 - val_loss: 1.3335\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2336\n",
      "Epoch 36: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2336 - val_loss: 1.3322\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2393\n",
      "Epoch 37: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2393 - val_loss: 1.3325\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2404\n",
      "Epoch 38: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2404 - val_loss: 1.3313\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2384\n",
      "Epoch 39: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2384 - val_loss: 1.3305\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 40: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2387 - val_loss: 1.3375\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2498\n",
      "Epoch 41: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2498 - val_loss: 1.3382\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2434\n",
      "Epoch 42: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2434 - val_loss: 1.3331\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2439\n",
      "Epoch 43: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2439 - val_loss: 1.3327\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 44: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2466 - val_loss: 1.3416\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2518\n",
      "Epoch 45: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2518 - val_loss: 1.3354\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2515\n",
      "Epoch 46: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2515 - val_loss: 1.3345\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2495\n",
      "Epoch 47: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2495 - val_loss: 1.3335\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2552\n",
      "Epoch 48: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2552 - val_loss: 1.3336\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2520\n",
      "Epoch 49: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2520 - val_loss: 1.3379\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2604\n",
      "Epoch 50: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2604 - val_loss: 1.3306\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2879\n",
      "Epoch 51: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2879 - val_loss: 1.3377\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2812\n",
      "Epoch 52: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2812 - val_loss: 1.3353\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2703\n",
      "Epoch 53: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2703 - val_loss: 1.3377\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2667\n",
      "Epoch 54: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2667 - val_loss: 1.3305\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2622\n",
      "Epoch 55: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2622 - val_loss: 1.3340\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2596\n",
      "Epoch 56: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2596 - val_loss: 1.3325\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2549\n",
      "Epoch 57: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2549 - val_loss: 1.3371\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2514\n",
      "Epoch 58: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2514 - val_loss: 1.3315\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2494\n",
      "Epoch 59: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2494 - val_loss: 1.3405\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2527\n",
      "Epoch 60: val_loss did not improve from 1.32882\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2527 - val_loss: 1.3333\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2484\n",
      "Epoch 61: val_loss improved from 1.32882 to 1.32679, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2484 - val_loss: 1.3268\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2487\n",
      "Epoch 62: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2487 - val_loss: 1.3292\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2464\n",
      "Epoch 63: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 15s 505us/sample - loss: 1.2464 - val_loss: 1.3301\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 64: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2471 - val_loss: 1.3300\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2418\n",
      "Epoch 65: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2418 - val_loss: 1.3384\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2380\n",
      "Epoch 66: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2380 - val_loss: 1.3312\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2441\n",
      "Epoch 67: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2441 - val_loss: 1.3327\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 68: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2399 - val_loss: 1.3290\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2397\n",
      "Epoch 69: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 600us/sample - loss: 1.2397 - val_loss: 1.3280\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2379\n",
      "Epoch 70: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2379 - val_loss: 1.3297\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2348\n",
      "Epoch 71: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2348 - val_loss: 1.3295\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2382\n",
      "Epoch 72: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2382 - val_loss: 1.3298\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2367\n",
      "Epoch 73: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2367 - val_loss: 1.3329\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2328\n",
      "Epoch 74: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2328 - val_loss: 1.3327\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2354\n",
      "Epoch 75: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2354 - val_loss: 1.3339\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 76: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2365 - val_loss: 1.3287\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2367\n",
      "Epoch 77: val_loss did not improve from 1.32679\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2367 - val_loss: 1.3321\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2314\n",
      "Epoch 78: val_loss improved from 1.32679 to 1.32616, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2314 - val_loss: 1.3262\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2313\n",
      "Epoch 79: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2313 - val_loss: 1.3287\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 80: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2370 - val_loss: 1.3350\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2323\n",
      "Epoch 81: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2323 - val_loss: 1.3376\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2283\n",
      "Epoch 82: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2283 - val_loss: 1.3312\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2314\n",
      "Epoch 83: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2314 - val_loss: 1.3366\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2303\n",
      "Epoch 84: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2303 - val_loss: 1.3340\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2268\n",
      "Epoch 85: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2268 - val_loss: 1.3342\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2265\n",
      "Epoch 86: val_loss did not improve from 1.32616\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2265 - val_loss: 1.3319\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2278\n",
      "Epoch 87: val_loss improved from 1.32616 to 1.32529, saving model to ./checkpoints/Feature_extraction_remove_energy_7.h5\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2278 - val_loss: 1.3253\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 88: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2270 - val_loss: 1.3324\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2318\n",
      "Epoch 89: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2318 - val_loss: 1.3271\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 90: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2254 - val_loss: 1.3315\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2249\n",
      "Epoch 91: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2249 - val_loss: 1.3318\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2226\n",
      "Epoch 92: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2226 - val_loss: 1.3294\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 93: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2242 - val_loss: 1.3340\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 94: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2253 - val_loss: 1.3331\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2227\n",
      "Epoch 95: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2227 - val_loss: 1.3295\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2232\n",
      "Epoch 96: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2232 - val_loss: 1.3313\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 97: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.2245 - val_loss: 1.3388\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 98: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2223 - val_loss: 1.3305\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2208\n",
      "Epoch 99: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2208 - val_loss: 1.3318\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2222\n",
      "Epoch 100: val_loss did not improve from 1.32529\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2222 - val_loss: 1.3329\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2222\n",
      "Epoch 1: val_loss improved from inf to 1.33554, saving model to ./checkpoints/Feature_extraction_remove_energy_8.h5\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2222 - val_loss: 1.3355\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2169\n",
      "Epoch 2: val_loss did not improve from 1.33554\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2169 - val_loss: 1.3367\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2154\n",
      "Epoch 3: val_loss improved from 1.33554 to 1.33443, saving model to ./checkpoints/Feature_extraction_remove_energy_8.h5\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2154 - val_loss: 1.3344\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2158\n",
      "Epoch 4: val_loss improved from 1.33443 to 1.33126, saving model to ./checkpoints/Feature_extraction_remove_energy_8.h5\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2158 - val_loss: 1.3313\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2095\n",
      "Epoch 5: val_loss did not improve from 1.33126\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2095 - val_loss: 1.3340\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2048\n",
      "Epoch 6: val_loss improved from 1.33126 to 1.32924, saving model to ./checkpoints/Feature_extraction_remove_energy_8.h5\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2048 - val_loss: 1.3292\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2080\n",
      "Epoch 7: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2080 - val_loss: 1.3331\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2096\n",
      "Epoch 8: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2096 - val_loss: 1.3301\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2101\n",
      "Epoch 9: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2101 - val_loss: 1.3332\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2095\n",
      "Epoch 10: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2095 - val_loss: 1.3345\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2129\n",
      "Epoch 11: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2129 - val_loss: 1.3312\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2148\n",
      "Epoch 12: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2148 - val_loss: 1.3355\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 13: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2194 - val_loss: 1.3339\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2139\n",
      "Epoch 14: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2139 - val_loss: 1.3357\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 15: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2145 - val_loss: 1.3438\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 16: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2176 - val_loss: 1.3335\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2173\n",
      "Epoch 17: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2173 - val_loss: 1.3333\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2182\n",
      "Epoch 18: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2182 - val_loss: 1.3372\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 19: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2473 - val_loss: 1.3481\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 20: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2302 - val_loss: 1.3392\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2323\n",
      "Epoch 21: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2323 - val_loss: 1.3349\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 22: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2321 - val_loss: 1.3385\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2274\n",
      "Epoch 23: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2274 - val_loss: 1.3394\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2317\n",
      "Epoch 24: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2317 - val_loss: 1.3417\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2330\n",
      "Epoch 25: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2330 - val_loss: 1.3354\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2346\n",
      "Epoch 26: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2346 - val_loss: 1.3376\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2331\n",
      "Epoch 27: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2331 - val_loss: 1.3383\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2405\n",
      "Epoch 28: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2405 - val_loss: 1.3371\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2505\n",
      "Epoch 29: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.2505 - val_loss: 1.3397\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2383\n",
      "Epoch 30: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2383 - val_loss: 1.3359\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2415\n",
      "Epoch 31: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 508us/sample - loss: 1.2415 - val_loss: 1.3343\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 32: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2408 - val_loss: 1.3359\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2476\n",
      "Epoch 33: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2476 - val_loss: 1.3407\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 34: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2468 - val_loss: 1.3349\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2462\n",
      "Epoch 35: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2462 - val_loss: 1.3332\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2483\n",
      "Epoch 36: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2483 - val_loss: 1.3410\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2560\n",
      "Epoch 37: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2560 - val_loss: 1.3423\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2570\n",
      "Epoch 38: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2570 - val_loss: 1.3502\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2521\n",
      "Epoch 39: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2521 - val_loss: 1.3386\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2532\n",
      "Epoch 40: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2532 - val_loss: 1.3472\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2528\n",
      "Epoch 41: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2528 - val_loss: 1.3433\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2561\n",
      "Epoch 42: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2561 - val_loss: 1.3441\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2601\n",
      "Epoch 43: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2601 - val_loss: 1.3370\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2662\n",
      "Epoch 44: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2662 - val_loss: 1.3392\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2661\n",
      "Epoch 45: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2661 - val_loss: 1.3484\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2624\n",
      "Epoch 46: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2624 - val_loss: 1.3438\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2690\n",
      "Epoch 47: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2690 - val_loss: 1.3520\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2706\n",
      "Epoch 48: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2706 - val_loss: 1.3464\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2727\n",
      "Epoch 49: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2727 - val_loss: 1.3474\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2906\n",
      "Epoch 50: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2906 - val_loss: 1.3538\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2818\n",
      "Epoch 51: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2818 - val_loss: 1.3536\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2800\n",
      "Epoch 52: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2800 - val_loss: 1.3441\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2757\n",
      "Epoch 53: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2757 - val_loss: 1.3518\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2757\n",
      "Epoch 54: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2757 - val_loss: 1.3528\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2755\n",
      "Epoch 55: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.2755 - val_loss: 1.3552\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2724\n",
      "Epoch 56: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2724 - val_loss: 1.3470\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2696\n",
      "Epoch 57: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2696 - val_loss: 1.3468\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2734\n",
      "Epoch 58: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2734 - val_loss: 1.3426\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2681\n",
      "Epoch 59: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2681 - val_loss: 1.3409\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2671\n",
      "Epoch 60: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 575us/sample - loss: 1.2671 - val_loss: 1.3413\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2643\n",
      "Epoch 61: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2643 - val_loss: 1.3406\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2630\n",
      "Epoch 62: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2630 - val_loss: 1.3406\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2649\n",
      "Epoch 63: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2649 - val_loss: 1.3448\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2632\n",
      "Epoch 64: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 506us/sample - loss: 1.2632 - val_loss: 1.3418\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 65: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2598 - val_loss: 1.3540\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 66: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2607 - val_loss: 1.3421\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2587\n",
      "Epoch 67: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2587 - val_loss: 1.3458\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2562\n",
      "Epoch 68: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2562 - val_loss: 1.3447\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2589\n",
      "Epoch 69: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2589 - val_loss: 1.3498\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2535\n",
      "Epoch 70: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2535 - val_loss: 1.3476\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2522\n",
      "Epoch 71: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2522 - val_loss: 1.3443\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2539\n",
      "Epoch 72: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2539 - val_loss: 1.3480\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2510\n",
      "Epoch 73: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2510 - val_loss: 1.3450\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2498\n",
      "Epoch 74: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2498 - val_loss: 1.3459\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2535\n",
      "Epoch 75: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2535 - val_loss: 1.3440\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2522\n",
      "Epoch 76: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2522 - val_loss: 1.3511\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2503\n",
      "Epoch 77: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2503 - val_loss: 1.3484\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2520\n",
      "Epoch 78: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2520 - val_loss: 1.3493\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2461\n",
      "Epoch 79: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2461 - val_loss: 1.3388\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2469\n",
      "Epoch 80: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2469 - val_loss: 1.3427\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 81: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2502 - val_loss: 1.3531\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2445\n",
      "Epoch 82: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2445 - val_loss: 1.3482\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2504\n",
      "Epoch 83: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2504 - val_loss: 1.3384\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2457\n",
      "Epoch 84: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2457 - val_loss: 1.3491\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2442\n",
      "Epoch 85: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2442 - val_loss: 1.3442\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 86: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2408 - val_loss: 1.3548\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2391\n",
      "Epoch 87: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2391 - val_loss: 1.3520\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2451\n",
      "Epoch 88: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2451 - val_loss: 1.3420\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2426\n",
      "Epoch 89: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2426 - val_loss: 1.3486\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2409\n",
      "Epoch 90: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2409 - val_loss: 1.3420\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2419\n",
      "Epoch 91: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2419 - val_loss: 1.3533\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2416\n",
      "Epoch 92: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2416 - val_loss: 1.3463\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2403\n",
      "Epoch 93: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2403 - val_loss: 1.3490\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2418\n",
      "Epoch 94: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2418 - val_loss: 1.3425\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 95: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2394 - val_loss: 1.3486\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2431\n",
      "Epoch 96: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2431 - val_loss: 1.3418\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2362\n",
      "Epoch 97: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2362 - val_loss: 1.3496\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 98: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2399 - val_loss: 1.3477\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2374\n",
      "Epoch 99: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2374 - val_loss: 1.3473\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2350\n",
      "Epoch 100: val_loss did not improve from 1.32924\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2350 - val_loss: 1.3424\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2341\n",
      "Epoch 1: val_loss improved from inf to 1.34491, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2341 - val_loss: 1.3449\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2380\n",
      "Epoch 2: val_loss did not improve from 1.34491\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2380 - val_loss: 1.3481\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2290\n",
      "Epoch 3: val_loss improved from 1.34491 to 1.34440, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2290 - val_loss: 1.3444\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2277\n",
      "Epoch 4: val_loss improved from 1.34440 to 1.34285, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2277 - val_loss: 1.3428\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 5: val_loss improved from 1.34285 to 1.33967, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2253 - val_loss: 1.3397\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2238\n",
      "Epoch 6: val_loss improved from 1.33967 to 1.33963, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2238 - val_loss: 1.3396\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 7: val_loss did not improve from 1.33963\n",
      "29601/29601 [==============================] - 17s 563us/sample - loss: 1.2196 - val_loss: 1.3397\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 8: val_loss did not improve from 1.33963\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2237 - val_loss: 1.3431\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2259\n",
      "Epoch 9: val_loss did not improve from 1.33963\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2259 - val_loss: 1.3426\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2219\n",
      "Epoch 10: val_loss did not improve from 1.33963\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2219 - val_loss: 1.3397\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2203\n",
      "Epoch 11: val_loss improved from 1.33963 to 1.33843, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2203 - val_loss: 1.3384\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2178\n",
      "Epoch 12: val_loss improved from 1.33843 to 1.33588, saving model to ./checkpoints/Feature_extraction_remove_energy_9.h5\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2178 - val_loss: 1.3359\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 13: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2243 - val_loss: 1.3452\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2231\n",
      "Epoch 14: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2231 - val_loss: 1.3398\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 15: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2223 - val_loss: 1.3418\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2211\n",
      "Epoch 16: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 507us/sample - loss: 1.2211 - val_loss: 1.3477\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 17: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2306 - val_loss: 1.3496\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2282\n",
      "Epoch 18: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 509us/sample - loss: 1.2282 - val_loss: 1.3421\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 19: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2310 - val_loss: 1.3441\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2284\n",
      "Epoch 20: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2284 - val_loss: 1.3434\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2328\n",
      "Epoch 21: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2328 - val_loss: 1.3500\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 22: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2363 - val_loss: 1.3430\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 23: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2361 - val_loss: 1.3387\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2375\n",
      "Epoch 24: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2375 - val_loss: 1.3404\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2371\n",
      "Epoch 25: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2371 - val_loss: 1.3377\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2314\n",
      "Epoch 26: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.2314 - val_loss: 1.3386\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2329\n",
      "Epoch 27: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2329 - val_loss: 1.3428\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 28: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2358 - val_loss: 1.3360\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2362\n",
      "Epoch 29: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2362 - val_loss: 1.3389\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2417\n",
      "Epoch 30: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2417 - val_loss: 1.3458\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 31: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2421 - val_loss: 1.3432\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2460\n",
      "Epoch 32: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2460 - val_loss: 1.3478\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2530\n",
      "Epoch 33: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2530 - val_loss: 1.3466\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2547\n",
      "Epoch 34: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2547 - val_loss: 1.3483\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2528\n",
      "Epoch 35: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2528 - val_loss: 1.3390\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 36: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2523 - val_loss: 1.3412\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2547\n",
      "Epoch 37: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.2547 - val_loss: 1.3406\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2528\n",
      "Epoch 38: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2528 - val_loss: 1.3417\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2580\n",
      "Epoch 39: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 513us/sample - loss: 1.2580 - val_loss: 1.3403\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 40: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2598 - val_loss: 1.3388\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2584\n",
      "Epoch 41: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2584 - val_loss: 1.3419\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2609\n",
      "Epoch 42: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2609 - val_loss: 1.3476\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2835\n",
      "Epoch 43: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2835 - val_loss: 1.3477\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3023\n",
      "Epoch 44: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 598us/sample - loss: 1.3023 - val_loss: 1.3434\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2752\n",
      "Epoch 45: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2752 - val_loss: 1.3405\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2853\n",
      "Epoch 46: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2853 - val_loss: 1.3493\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2882\n",
      "Epoch 47: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2882 - val_loss: 1.3438\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2905\n",
      "Epoch 48: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2905 - val_loss: 1.3459\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2935\n",
      "Epoch 49: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2935 - val_loss: 1.3540\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2990\n",
      "Epoch 50: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 524us/sample - loss: 1.2990 - val_loss: 1.3543\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3028\n",
      "Epoch 51: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.3028 - val_loss: 1.3539\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3192\n",
      "Epoch 52: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.3192 - val_loss: 1.3468\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3063\n",
      "Epoch 53: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.3063 - val_loss: 1.3532\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3018\n",
      "Epoch 54: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.3018 - val_loss: 1.3547\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3037\n",
      "Epoch 55: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.3037 - val_loss: 1.3565\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2999\n",
      "Epoch 56: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.2999 - val_loss: 1.3551\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2960\n",
      "Epoch 57: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 520us/sample - loss: 1.2960 - val_loss: 1.3501\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2961\n",
      "Epoch 58: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2961 - val_loss: 1.3516\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2970\n",
      "Epoch 59: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2970 - val_loss: 1.3490\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2968\n",
      "Epoch 60: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 511us/sample - loss: 1.2968 - val_loss: 1.3528\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2920\n",
      "Epoch 61: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 580us/sample - loss: 1.2920 - val_loss: 1.3512\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2891\n",
      "Epoch 62: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2891 - val_loss: 1.3459\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2897\n",
      "Epoch 63: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2897 - val_loss: 1.3508\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2890\n",
      "Epoch 64: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2890 - val_loss: 1.3520\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2864\n",
      "Epoch 65: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2864 - val_loss: 1.3519\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2847\n",
      "Epoch 66: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2847 - val_loss: 1.3534\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2858\n",
      "Epoch 67: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2858 - val_loss: 1.3522\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2801\n",
      "Epoch 68: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2801 - val_loss: 1.3531\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2805\n",
      "Epoch 69: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2805 - val_loss: 1.3528\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2765\n",
      "Epoch 70: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2765 - val_loss: 1.3529\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2761\n",
      "Epoch 71: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2761 - val_loss: 1.3442\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2782\n",
      "Epoch 72: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2782 - val_loss: 1.3469\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2800\n",
      "Epoch 73: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2800 - val_loss: 1.3500\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2763\n",
      "Epoch 74: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2763 - val_loss: 1.3506\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2760\n",
      "Epoch 75: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 510us/sample - loss: 1.2760 - val_loss: 1.3541\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2756\n",
      "Epoch 76: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 581us/sample - loss: 1.2756 - val_loss: 1.3508\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2769\n",
      "Epoch 77: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2769 - val_loss: 1.3513\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2750\n",
      "Epoch 78: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2750 - val_loss: 1.3509\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2708\n",
      "Epoch 79: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2708 - val_loss: 1.3509\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2729\n",
      "Epoch 80: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2729 - val_loss: 1.3516\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2722\n",
      "Epoch 81: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2722 - val_loss: 1.3508\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2673\n",
      "Epoch 82: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2673 - val_loss: 1.3531\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2679\n",
      "Epoch 83: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2679 - val_loss: 1.3502\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2712\n",
      "Epoch 84: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2712 - val_loss: 1.3466\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2666\n",
      "Epoch 85: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 512us/sample - loss: 1.2666 - val_loss: 1.3480\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2696\n",
      "Epoch 86: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 503us/sample - loss: 1.2696 - val_loss: 1.3510\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2672\n",
      "Epoch 87: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 501us/sample - loss: 1.2672 - val_loss: 1.3496\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2652\n",
      "Epoch 88: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 501us/sample - loss: 1.2652 - val_loss: 1.3489\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2647\n",
      "Epoch 89: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2647 - val_loss: 1.3462\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2629\n",
      "Epoch 90: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 502us/sample - loss: 1.2629 - val_loss: 1.3523\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2637\n",
      "Epoch 91: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2637 - val_loss: 1.3519\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2631\n",
      "Epoch 92: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2631 - val_loss: 1.3475\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2624\n",
      "Epoch 93: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2624 - val_loss: 1.3489\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2605\n",
      "Epoch 94: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2605 - val_loss: 1.3509\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2581\n",
      "Epoch 95: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2581 - val_loss: 1.3447\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2584\n",
      "Epoch 96: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2584 - val_loss: 1.3498\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2608\n",
      "Epoch 97: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2608 - val_loss: 1.3457\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2555\n",
      "Epoch 98: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2555 - val_loss: 1.3465\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2558\n",
      "Epoch 99: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2558 - val_loss: 1.3495\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2613\n",
      "Epoch 100: val_loss did not improve from 1.33588\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2613 - val_loss: 1.3566\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "model = individual_model(X_train_normalized)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "num_epochs = 100\n",
    "rates = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "idx = 0\n",
    "for r in rates:\n",
    "# Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    model_name = './checkpoints/Feature_extraction_remove_energy_'+str(idx)+'.h5'\n",
    "    idx = idx+1\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=50, frequency=1)\n",
    "    model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
