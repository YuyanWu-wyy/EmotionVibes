{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4cd1e-14c8-4f76-8133-e8617bb62b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Baseline Method only use simple gait parameter feature, it only includes 2 dense layers\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## We delete people's data with low feedback score and remove people who kicked off the sensors during walking'\n",
    "## So 20 people in total.\n",
    "person_nums = [1,2,4,5,6,8,9,10,11,12,13,17,19,21,22,25,26,27,28,29]\n",
    "\n",
    "from feature_emotion import feature_extract, split_data, label_unique_tuples\n",
    "gts, sensor_nums, walk_nums, trace_nums, people_nums, spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, auto_corrs, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features = feature_extract(person_nums)\n",
    "\n",
    "walk_nums_all = np.squeeze(walk_nums)\n",
    "trace_nums_all = np.squeeze(trace_nums)\n",
    "people_nums_all = np.squeeze(people_nums)\n",
    "\n",
    "## 0: train, 1: validation 2: test\n",
    "flag_tr_val_te = split_data(walk_nums_all, trace_nums_all, people_nums_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170353c1-fcb9-4e2b-9909-c3a263bf8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Normalization before training ans testing\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalers = []\n",
    "X_train_normalized = []\n",
    "X_val_normalized = []\n",
    "X_test_normalized = []\n",
    "train_idx = np.where(flag_tr_val_te ==0)[0]\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = np.where(flag_tr_val_te ==1)[0]\n",
    "test_idx = np.where(flag_tr_val_te ==2)[0]\n",
    "\n",
    "for i, feature in enumerate([spe_centr, delta_spe_centr, spe_crest, delta_spe_crest, spe_decrease, delta_spe_decrease, spe_entropy, delta_spe_entropy, spe_flatness, delta_spe_flatness, spe_flux, delta_spe_flux, spe_kurtosis, delta_spe_kurtosis, spe_skewness, delta_spe_skewness, spe_rfp, delta_spe_rfp, spe_slope, delta_spe_slope, spe_spread, delta_spe_spread, wlk_fre, wlk_fres_trace, cwt_figs_all, cwt_sum_all_0, cwt_sum_all_1, cwt_sum_all_2, cwt_sum_all_3, high_fre_compos, pitchs, low_fre_compos, real_hils, imag_hils, dur_time_1_alls, dur_time_2_alls, jitters, shimmers, jitter_rap, hrs, feature, slope, zcrs, fft_features, energy_alls, log_energy_alls, smoothe_energy_alls, legendres, double_support_time, pdps_new, lpcs, ceps_features]):\n",
    "    scaler = StandardScaler()\n",
    "    if len(feature.shape)==2:\n",
    "        X_train_i = feature[train_idx,:]\n",
    "        X_val_i = feature[val_idx,:]\n",
    "        X_test_i = feature[test_idx,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i)\n",
    "        scalers.append(scaler)\n",
    "    else:\n",
    "        X_train_i = feature[train_idx,:,:]\n",
    "        X_val_i = feature[val_idx,:,:]\n",
    "        X_test_i = feature[test_idx,:,:]\n",
    "        X_train_normalized_i = scaler.fit_transform(X_train_i.reshape(X_train_i.shape[0], -1)).reshape(X_train_i.shape)\n",
    "        X_val_normalized_i = scaler.transform(X_val_i.reshape(X_val_i.shape[0], -1)).reshape(X_val_i.shape)\n",
    "        X_test_normalized_i = scaler.transform(X_test_i.reshape(X_test_i.shape[0], -1)).reshape(X_test_i.shape)\n",
    "        scalers.append(scaler)\n",
    "    X_train_normalized.append(X_train_normalized_i)\n",
    "    X_val_normalized.append(X_val_normalized_i)\n",
    "    X_test_normalized.append(X_test_normalized_i)\n",
    "y_train = gts[train_idx,:]\n",
    "y_val = gts[val_idx,:]\n",
    "y_test = gts[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e10b0d-fa00-4007-ad02-296357d1871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_new = []\n",
    "combined_feature = np.empty((len(X_train_normalized[0]),0))\n",
    "for feature in X_train_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_train_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_train_normalized_new.append(feature)\n",
    "X_train_normalized_new.append(combined_feature)\n",
    "\n",
    "X_val_normalized_new = []\n",
    "combined_feature = np.empty((len(X_val_normalized[0]),0))\n",
    "for feature in X_val_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_val_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_val_normalized_new.append(feature)\n",
    "X_val_normalized_new.append(combined_feature)\n",
    "\n",
    "X_test_normalized_new = []\n",
    "combined_feature = np.empty((len(X_test_normalized[0]),0))\n",
    "for feature in X_test_normalized:\n",
    "    if len(feature.shape) == 3:\n",
    "        X_test_normalized_new.append(feature)\n",
    "    elif feature.shape[1] <20:\n",
    "        combined_feature = np.hstack((combined_feature, feature))\n",
    "    else:\n",
    "        X_test_normalized_new.append(feature)\n",
    "X_test_normalized_new.append(combined_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8fb4a-5f62-4ff5-9d55-a5fd0197b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the baseline model for emotion recognition with dropout layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, SimpleRNN, LSTM, Conv2D, Flatten, MaxPooling2D, GRU, AveragePooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def individual_model(features_list):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    combined_feature = np.empty((len(features_list[0]),0))\n",
    "    for i, feature in enumerate(features_list):\n",
    "        \n",
    "        if len(feature.shape) == 3:\n",
    "            input_i = Input(shape=(feature.shape[1], feature.shape[2]))\n",
    "            input_layers.append(input_i)\n",
    "\n",
    "            hidden_i = input_i[:,:,:,None]\n",
    "            hidden_i = Conv2D(32, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(16, 3, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((3, 3))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(8, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Conv2D(4, 1, activation='relu')(hidden_i)\n",
    "            hidden_i = AveragePooling2D((2, 2))(hidden_i)\n",
    "            hidden_i = Dropout(0.5)(hidden_i)\n",
    "            hidden_i = Flatten()(hidden_i)\n",
    "\n",
    "            hidden_layers.append(hidden_i)\n",
    "        elif feature.shape[1] <20:\n",
    "            combined_feature = np.hstack((combined_feature, feature))\n",
    "            \n",
    "        else:  # For series features\n",
    "            input_i = Input(shape=(feature.shape[1],))\n",
    "            input_layers.append(input_i)\n",
    "            hidden_i = Lambda(lambda x: x[:, :, None])(input_i)  # Add a new dimension\n",
    "            hidden_i = LSTM(4)(hidden_i)\n",
    "            hidden_layers.append(hidden_i)\n",
    "    input_i = Input(shape=(combined_feature.shape[1],))\n",
    "    input_layers.append(input_i)\n",
    "    dense_num = np.max((1, int(combined_feature.shape[1]/2)))\n",
    "    hidden_i = Dense(dense_num, activation='relu')(input_i)\n",
    "    hidden_layers.append(hidden_i)\n",
    "    print(combined_feature.shape)\n",
    "    concat_layer = concatenate(hidden_layers)\n",
    "    h = Dropout(0.2)(concat_layer)\n",
    "    h = Dense(64, activation='relu')(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    output_layer = Dense(2)(h)\n",
    "    model = Model(inputs=input_layers, outputs=output_layer)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34842e6a-c939-4681-a48f-aacc87132d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d5403e-e59a-4ea2-9e43-48df515280e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T04:29:29.641318Z",
     "iopub.status.busy": "2023-11-07T04:29:29.641193Z",
     "iopub.status.idle": "2023-11-07T10:33:25.398870Z",
     "shell.execute_reply": "2023-11-07T10:33:25.397782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 23:29:59.723788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.735285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.744168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.747757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.747950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.748117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.816054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.816257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.816424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:29:59.816566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-06 23:29:59.816815: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 23:30:00.730335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:30:00.730580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:30:00.730763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:30:00.730970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:30:00.731140: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-06 23:30:00.731277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46608 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2023-11-06 23:30:00.731309: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-06 23:30:00.752193: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-06 23:30:00.965764: W tensorflow/c/c_api.cc:304] Operation '{name:'lstm_20/lstm_cell_20/recurrent_kernel/Assign' id:3336 op device:{requested: '', assigned: ''} def:{{{node lstm_20/lstm_cell_20/recurrent_kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](lstm_20/lstm_cell_20/recurrent_kernel, lstm_20/lstm_cell_20/recurrent_kernel/Initializer/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-06 23:30:01.097644: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_1' id:3634 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_1}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 0 0 0...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-06 23:30:01.130424: W tensorflow/c/c_api.cc:304] Operation '{name:'strided_slice/stack_2' id:3635 op device:{requested: '', assigned: ''} def:{{{node strided_slice/stack_2}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [4] values: 1 1 1...>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(29601, 95)\n",
      "Train on 29601 samples, validate on 3694 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 23:30:05.358733: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/lstm_35/lstm_cell_35/recurrent_kernel/v/Assign' id:17129 op device:{requested: '', assigned: ''} def:{{{node training/Adam/lstm_35/lstm_cell_35/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/lstm_35/lstm_cell_35/recurrent_kernel/v, training/Adam/lstm_35/lstm_cell_35/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 23:30:08.982512: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indropout/cond/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-06 23:30:11.048140: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-11-06 23:30:11.264536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29601/29601 [==============================] - ETA: 0s - loss: 3.1843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-11-06 23:30:27.943081: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/mul' id:6312 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_3_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.99366, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 24s 797us/sample - loss: 3.1843 - val_loss: 1.9937\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.8070\n",
      "Epoch 2: val_loss improved from 1.99366 to 1.63071, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.8070 - val_loss: 1.6307\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.6081\n",
      "Epoch 3: val_loss improved from 1.63071 to 1.56161, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.6081 - val_loss: 1.5616\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5539\n",
      "Epoch 4: val_loss improved from 1.56161 to 1.52382, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.5539 - val_loss: 1.5238\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5252\n",
      "Epoch 5: val_loss improved from 1.52382 to 1.49883, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.5252 - val_loss: 1.4988\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.5069\n",
      "Epoch 6: val_loss improved from 1.49883 to 1.48902, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.5069 - val_loss: 1.4890\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4936\n",
      "Epoch 7: val_loss improved from 1.48902 to 1.47096, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.4936 - val_loss: 1.4710\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4859\n",
      "Epoch 8: val_loss improved from 1.47096 to 1.47033, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.4859 - val_loss: 1.4703\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4773\n",
      "Epoch 9: val_loss improved from 1.47033 to 1.45977, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.4773 - val_loss: 1.4598\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4712\n",
      "Epoch 10: val_loss improved from 1.45977 to 1.45023, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.4712 - val_loss: 1.4502\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4664\n",
      "Epoch 11: val_loss improved from 1.45023 to 1.44490, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.4664 - val_loss: 1.4449\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4617\n",
      "Epoch 12: val_loss improved from 1.44490 to 1.44204, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.4617 - val_loss: 1.4420\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4563\n",
      "Epoch 13: val_loss improved from 1.44204 to 1.43956, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.4563 - val_loss: 1.4396\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4515\n",
      "Epoch 14: val_loss improved from 1.43956 to 1.43732, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.4515 - val_loss: 1.4373\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4494\n",
      "Epoch 15: val_loss did not improve from 1.43732\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.4494 - val_loss: 1.4446\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4432\n",
      "Epoch 16: val_loss improved from 1.43732 to 1.43158, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.4432 - val_loss: 1.4316\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4388\n",
      "Epoch 17: val_loss improved from 1.43158 to 1.43101, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.4388 - val_loss: 1.4310\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4362\n",
      "Epoch 18: val_loss improved from 1.43101 to 1.42677, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.4362 - val_loss: 1.4268\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4326\n",
      "Epoch 19: val_loss improved from 1.42677 to 1.41807, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.4326 - val_loss: 1.4181\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4305\n",
      "Epoch 20: val_loss did not improve from 1.41807\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.4305 - val_loss: 1.4278\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4279\n",
      "Epoch 21: val_loss improved from 1.41807 to 1.41492, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.4279 - val_loss: 1.4149\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4269\n",
      "Epoch 22: val_loss did not improve from 1.41492\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.4269 - val_loss: 1.4184\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4210\n",
      "Epoch 23: val_loss did not improve from 1.41492\n",
      "29601/29601 [==============================] - 19s 637us/sample - loss: 1.4210 - val_loss: 1.4165\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4205\n",
      "Epoch 24: val_loss improved from 1.41492 to 1.40956, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 634us/sample - loss: 1.4205 - val_loss: 1.4096\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4161\n",
      "Epoch 25: val_loss improved from 1.40956 to 1.40924, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 631us/sample - loss: 1.4161 - val_loss: 1.4092\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4145\n",
      "Epoch 26: val_loss did not improve from 1.40924\n",
      "29601/29601 [==============================] - 19s 627us/sample - loss: 1.4145 - val_loss: 1.4093\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4158\n",
      "Epoch 27: val_loss improved from 1.40924 to 1.40488, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 635us/sample - loss: 1.4158 - val_loss: 1.4049\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4119\n",
      "Epoch 28: val_loss did not improve from 1.40488\n",
      "29601/29601 [==============================] - 19s 630us/sample - loss: 1.4119 - val_loss: 1.4072\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4109\n",
      "Epoch 29: val_loss improved from 1.40488 to 1.40315, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 630us/sample - loss: 1.4109 - val_loss: 1.4031\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4066\n",
      "Epoch 30: val_loss did not improve from 1.40315\n",
      "29601/29601 [==============================] - 19s 626us/sample - loss: 1.4066 - val_loss: 1.4058\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4056\n",
      "Epoch 31: val_loss improved from 1.40315 to 1.40285, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 636us/sample - loss: 1.4056 - val_loss: 1.4028\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4044\n",
      "Epoch 32: val_loss improved from 1.40285 to 1.39827, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.4044 - val_loss: 1.3983\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4015\n",
      "Epoch 33: val_loss did not improve from 1.39827\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.4015 - val_loss: 1.3985\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3998\n",
      "Epoch 34: val_loss improved from 1.39827 to 1.39560, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.3998 - val_loss: 1.3956\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.4010\n",
      "Epoch 35: val_loss did not improve from 1.39560\n",
      "29601/29601 [==============================] - 18s 620us/sample - loss: 1.4010 - val_loss: 1.3970\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3955\n",
      "Epoch 36: val_loss improved from 1.39560 to 1.39505, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 630us/sample - loss: 1.3955 - val_loss: 1.3951\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3968\n",
      "Epoch 37: val_loss did not improve from 1.39505\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.3968 - val_loss: 1.3988\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3962\n",
      "Epoch 38: val_loss improved from 1.39505 to 1.39376, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.3962 - val_loss: 1.3938\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3939\n",
      "Epoch 39: val_loss improved from 1.39376 to 1.39076, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 636us/sample - loss: 1.3939 - val_loss: 1.3908\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3920\n",
      "Epoch 40: val_loss did not improve from 1.39076\n",
      "29601/29601 [==============================] - 19s 633us/sample - loss: 1.3920 - val_loss: 1.3933\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3895\n",
      "Epoch 41: val_loss improved from 1.39076 to 1.38990, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.3895 - val_loss: 1.3899\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3863\n",
      "Epoch 42: val_loss improved from 1.38990 to 1.38834, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.3863 - val_loss: 1.3883\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3843\n",
      "Epoch 43: val_loss improved from 1.38834 to 1.38801, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.3843 - val_loss: 1.3880\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3820\n",
      "Epoch 44: val_loss improved from 1.38801 to 1.38764, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.3820 - val_loss: 1.3876\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3816\n",
      "Epoch 45: val_loss did not improve from 1.38764\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.3816 - val_loss: 1.3916\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3813\n",
      "Epoch 46: val_loss improved from 1.38764 to 1.38684, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.3813 - val_loss: 1.3868\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3796\n",
      "Epoch 47: val_loss improved from 1.38684 to 1.37963, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 634us/sample - loss: 1.3796 - val_loss: 1.3796\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3757\n",
      "Epoch 48: val_loss did not improve from 1.37963\n",
      "29601/29601 [==============================] - 19s 626us/sample - loss: 1.3757 - val_loss: 1.3830\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3800\n",
      "Epoch 49: val_loss improved from 1.37963 to 1.37889, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.3800 - val_loss: 1.3789\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3735\n",
      "Epoch 50: val_loss improved from 1.37889 to 1.37858, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3735 - val_loss: 1.3786\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3746\n",
      "Epoch 51: val_loss did not improve from 1.37858\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.3746 - val_loss: 1.3802\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3732\n",
      "Epoch 52: val_loss did not improve from 1.37858\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.3732 - val_loss: 1.3809\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3729\n",
      "Epoch 53: val_loss improved from 1.37858 to 1.37570, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 18s 619us/sample - loss: 1.3729 - val_loss: 1.3757\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3675\n",
      "Epoch 54: val_loss did not improve from 1.37570\n",
      "29601/29601 [==============================] - 19s 626us/sample - loss: 1.3675 - val_loss: 1.3777\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3663\n",
      "Epoch 55: val_loss did not improve from 1.37570\n",
      "29601/29601 [==============================] - 18s 623us/sample - loss: 1.3663 - val_loss: 1.3769\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3660\n",
      "Epoch 56: val_loss did not improve from 1.37570\n",
      "29601/29601 [==============================] - 18s 622us/sample - loss: 1.3660 - val_loss: 1.3765\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3677\n",
      "Epoch 57: val_loss did not improve from 1.37570\n",
      "29601/29601 [==============================] - 18s 623us/sample - loss: 1.3677 - val_loss: 1.3794\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3628\n",
      "Epoch 58: val_loss did not improve from 1.37570\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.3628 - val_loss: 1.3763\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3656\n",
      "Epoch 59: val_loss improved from 1.37570 to 1.37429, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.3656 - val_loss: 1.3743\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3614\n",
      "Epoch 60: val_loss improved from 1.37429 to 1.37062, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.3614 - val_loss: 1.3706\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3592\n",
      "Epoch 61: val_loss did not improve from 1.37062\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.3592 - val_loss: 1.3752\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3619\n",
      "Epoch 62: val_loss did not improve from 1.37062\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.3619 - val_loss: 1.3744\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3579\n",
      "Epoch 63: val_loss did not improve from 1.37062\n",
      "29601/29601 [==============================] - 18s 625us/sample - loss: 1.3579 - val_loss: 1.3757\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3583\n",
      "Epoch 64: val_loss did not improve from 1.37062\n",
      "29601/29601 [==============================] - 19s 625us/sample - loss: 1.3583 - val_loss: 1.3750\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3536\n",
      "Epoch 65: val_loss did not improve from 1.37062\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.3536 - val_loss: 1.3755\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3521\n",
      "Epoch 66: val_loss did not improve from 1.37062\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.3521 - val_loss: 1.3756\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3510\n",
      "Epoch 67: val_loss improved from 1.37062 to 1.36793, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.3510 - val_loss: 1.3679\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3531\n",
      "Epoch 68: val_loss did not improve from 1.36793\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.3531 - val_loss: 1.3750\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3510\n",
      "Epoch 69: val_loss did not improve from 1.36793\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.3510 - val_loss: 1.3735\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3515\n",
      "Epoch 70: val_loss did not improve from 1.36793\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.3515 - val_loss: 1.3719\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3499\n",
      "Epoch 71: val_loss did not improve from 1.36793\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.3499 - val_loss: 1.3682\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3465\n",
      "Epoch 72: val_loss did not improve from 1.36793\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.3465 - val_loss: 1.3748\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3458\n",
      "Epoch 73: val_loss improved from 1.36793 to 1.36564, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 626us/sample - loss: 1.3458 - val_loss: 1.3656\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3437\n",
      "Epoch 74: val_loss did not improve from 1.36564\n",
      "29601/29601 [==============================] - 18s 620us/sample - loss: 1.3437 - val_loss: 1.3706\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3443\n",
      "Epoch 75: val_loss improved from 1.36564 to 1.36451, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 19s 627us/sample - loss: 1.3443 - val_loss: 1.3645\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3485\n",
      "Epoch 76: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 19s 626us/sample - loss: 1.3485 - val_loss: 1.3753\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3437\n",
      "Epoch 77: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3437 - val_loss: 1.3675\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3421\n",
      "Epoch 78: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 17s 579us/sample - loss: 1.3421 - val_loss: 1.3658\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3398\n",
      "Epoch 79: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 18s 618us/sample - loss: 1.3398 - val_loss: 1.3666\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3395\n",
      "Epoch 80: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 16s 553us/sample - loss: 1.3395 - val_loss: 1.3719\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3371\n",
      "Epoch 81: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.3371 - val_loss: 1.3651\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3381\n",
      "Epoch 82: val_loss did not improve from 1.36451\n",
      "29601/29601 [==============================] - 18s 618us/sample - loss: 1.3381 - val_loss: 1.3675\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3365\n",
      "Epoch 83: val_loss improved from 1.36451 to 1.36295, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 18s 616us/sample - loss: 1.3365 - val_loss: 1.3630\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3367\n",
      "Epoch 84: val_loss did not improve from 1.36295\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.3367 - val_loss: 1.3660\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3369\n",
      "Epoch 85: val_loss did not improve from 1.36295\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.3369 - val_loss: 1.3640\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3344\n",
      "Epoch 86: val_loss did not improve from 1.36295\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3344 - val_loss: 1.3716\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3349\n",
      "Epoch 87: val_loss did not improve from 1.36295\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3349 - val_loss: 1.3630\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3341\n",
      "Epoch 88: val_loss did not improve from 1.36295\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.3341 - val_loss: 1.3630\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3315\n",
      "Epoch 89: val_loss did not improve from 1.36295\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.3315 - val_loss: 1.3630\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3297\n",
      "Epoch 90: val_loss improved from 1.36295 to 1.36254, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.3297 - val_loss: 1.3625\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3268\n",
      "Epoch 91: val_loss did not improve from 1.36254\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.3268 - val_loss: 1.3649\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3285\n",
      "Epoch 92: val_loss improved from 1.36254 to 1.36147, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.3285 - val_loss: 1.3615\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3269\n",
      "Epoch 93: val_loss did not improve from 1.36147\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.3269 - val_loss: 1.3641\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3249\n",
      "Epoch 94: val_loss did not improve from 1.36147\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.3249 - val_loss: 1.3695\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3266\n",
      "Epoch 95: val_loss did not improve from 1.36147\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.3266 - val_loss: 1.3639\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3246\n",
      "Epoch 96: val_loss did not improve from 1.36147\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.3246 - val_loss: 1.3643\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3259\n",
      "Epoch 97: val_loss improved from 1.36147 to 1.35680, saving model to ./checkpoints/Feature_extraction_remove_autocorr_0.h5\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.3259 - val_loss: 1.3568\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3221\n",
      "Epoch 98: val_loss did not improve from 1.35680\n",
      "29601/29601 [==============================] - 16s 557us/sample - loss: 1.3221 - val_loss: 1.3605\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3217\n",
      "Epoch 99: val_loss did not improve from 1.35680\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.3217 - val_loss: 1.3612\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3209\n",
      "Epoch 100: val_loss did not improve from 1.35680\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.3209 - val_loss: 1.3618\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3199\n",
      "Epoch 1: val_loss improved from inf to 1.36008, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 18s 617us/sample - loss: 1.3199 - val_loss: 1.3601\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3221\n",
      "Epoch 2: val_loss did not improve from 1.36008\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.3221 - val_loss: 1.3648\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3199\n",
      "Epoch 3: val_loss improved from 1.36008 to 1.35956, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.3199 - val_loss: 1.3596\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3158\n",
      "Epoch 4: val_loss did not improve from 1.35956\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.3158 - val_loss: 1.3644\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3167\n",
      "Epoch 5: val_loss did not improve from 1.35956\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.3167 - val_loss: 1.3602\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3180\n",
      "Epoch 6: val_loss improved from 1.35956 to 1.35889, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.3180 - val_loss: 1.3589\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3137\n",
      "Epoch 7: val_loss improved from 1.35889 to 1.35777, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.3137 - val_loss: 1.3578\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3153\n",
      "Epoch 8: val_loss did not improve from 1.35777\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.3153 - val_loss: 1.3597\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3117\n",
      "Epoch 9: val_loss did not improve from 1.35777\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.3117 - val_loss: 1.3663\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3127\n",
      "Epoch 10: val_loss did not improve from 1.35777\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.3127 - val_loss: 1.3632\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3142\n",
      "Epoch 11: val_loss did not improve from 1.35777\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3142 - val_loss: 1.3665\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3095\n",
      "Epoch 12: val_loss did not improve from 1.35777\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3095 - val_loss: 1.3647\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3131\n",
      "Epoch 13: val_loss did not improve from 1.35777\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.3131 - val_loss: 1.3633\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3132\n",
      "Epoch 14: val_loss improved from 1.35777 to 1.35639, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 19s 640us/sample - loss: 1.3132 - val_loss: 1.3564\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3114\n",
      "Epoch 15: val_loss did not improve from 1.35639\n",
      "29601/29601 [==============================] - 19s 637us/sample - loss: 1.3114 - val_loss: 1.3576\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3111\n",
      "Epoch 16: val_loss did not improve from 1.35639\n",
      "29601/29601 [==============================] - 19s 639us/sample - loss: 1.3111 - val_loss: 1.3580\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3099\n",
      "Epoch 17: val_loss did not improve from 1.35639\n",
      "29601/29601 [==============================] - 19s 642us/sample - loss: 1.3099 - val_loss: 1.3610\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3432\n",
      "Epoch 18: val_loss did not improve from 1.35639\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.3432 - val_loss: 1.3630\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3107\n",
      "Epoch 19: val_loss did not improve from 1.35639\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.3107 - val_loss: 1.3608\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3068\n",
      "Epoch 20: val_loss did not improve from 1.35639\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3068 - val_loss: 1.3631\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3082\n",
      "Epoch 21: val_loss improved from 1.35639 to 1.35573, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.3082 - val_loss: 1.3557\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3091\n",
      "Epoch 22: val_loss did not improve from 1.35573\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.3091 - val_loss: 1.3623\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3044\n",
      "Epoch 23: val_loss did not improve from 1.35573\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3044 - val_loss: 1.3565\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3094\n",
      "Epoch 24: val_loss did not improve from 1.35573\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.3094 - val_loss: 1.3639\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3075\n",
      "Epoch 25: val_loss improved from 1.35573 to 1.35539, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.3075 - val_loss: 1.3554\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3046\n",
      "Epoch 26: val_loss did not improve from 1.35539\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.3046 - val_loss: 1.3568\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3047\n",
      "Epoch 27: val_loss did not improve from 1.35539\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.3047 - val_loss: 1.3628\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3042\n",
      "Epoch 28: val_loss did not improve from 1.35539\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.3042 - val_loss: 1.3616\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3076\n",
      "Epoch 29: val_loss did not improve from 1.35539\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3076 - val_loss: 1.3560\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3036\n",
      "Epoch 30: val_loss improved from 1.35539 to 1.35252, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.3036 - val_loss: 1.3525\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3010\n",
      "Epoch 31: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.3010 - val_loss: 1.3545\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3025\n",
      "Epoch 32: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.3025 - val_loss: 1.3593\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3037\n",
      "Epoch 33: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.3037 - val_loss: 1.3586\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3025\n",
      "Epoch 34: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.3025 - val_loss: 1.3576\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3006\n",
      "Epoch 35: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.3006 - val_loss: 1.3572\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3002\n",
      "Epoch 36: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.3002 - val_loss: 1.3592\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3007\n",
      "Epoch 37: val_loss did not improve from 1.35252\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.3007 - val_loss: 1.3589\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3019\n",
      "Epoch 38: val_loss improved from 1.35252 to 1.35037, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.3019 - val_loss: 1.3504\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3000\n",
      "Epoch 39: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.3000 - val_loss: 1.3520\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2968\n",
      "Epoch 40: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 17s 578us/sample - loss: 1.2968 - val_loss: 1.3557\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2988\n",
      "Epoch 41: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 17s 571us/sample - loss: 1.2988 - val_loss: 1.3530\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3253\n",
      "Epoch 42: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.3253 - val_loss: 1.3590\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2999\n",
      "Epoch 43: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2999 - val_loss: 1.3555\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3023\n",
      "Epoch 44: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.3023 - val_loss: 1.3535\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2989\n",
      "Epoch 45: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2989 - val_loss: 1.3533\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2956\n",
      "Epoch 46: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2956 - val_loss: 1.3592\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2964\n",
      "Epoch 47: val_loss did not improve from 1.35037\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2964 - val_loss: 1.3534\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2942\n",
      "Epoch 48: val_loss improved from 1.35037 to 1.34878, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2942 - val_loss: 1.3488\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2965\n",
      "Epoch 49: val_loss did not improve from 1.34878\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2965 - val_loss: 1.3557\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3648\n",
      "Epoch 50: val_loss did not improve from 1.34878\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.3648 - val_loss: 1.3699\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3009\n",
      "Epoch 51: val_loss did not improve from 1.34878\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.3009 - val_loss: 1.3561\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2984\n",
      "Epoch 52: val_loss did not improve from 1.34878\n",
      "29601/29601 [==============================] - 17s 573us/sample - loss: 1.2984 - val_loss: 1.3516\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2929\n",
      "Epoch 53: val_loss did not improve from 1.34878\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2929 - val_loss: 1.3497\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2933\n",
      "Epoch 54: val_loss did not improve from 1.34878\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2933 - val_loss: 1.3570\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2919\n",
      "Epoch 55: val_loss improved from 1.34878 to 1.34633, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 19s 629us/sample - loss: 1.2919 - val_loss: 1.3463\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2917\n",
      "Epoch 56: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2917 - val_loss: 1.3505\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2875\n",
      "Epoch 57: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2875 - val_loss: 1.3572\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2894\n",
      "Epoch 58: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2894 - val_loss: 1.3504\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2884\n",
      "Epoch 59: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2884 - val_loss: 1.3553\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2856\n",
      "Epoch 60: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2856 - val_loss: 1.3544\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2871\n",
      "Epoch 61: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2871 - val_loss: 1.3557\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2859\n",
      "Epoch 62: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 18s 620us/sample - loss: 1.2859 - val_loss: 1.3512\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2825\n",
      "Epoch 63: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.2825 - val_loss: 1.3491\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2841\n",
      "Epoch 64: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2841 - val_loss: 1.3499\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2838\n",
      "Epoch 65: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.2838 - val_loss: 1.3484\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2792\n",
      "Epoch 66: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2792 - val_loss: 1.3562\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2793\n",
      "Epoch 67: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2793 - val_loss: 1.3528\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2799\n",
      "Epoch 68: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2799 - val_loss: 1.3513\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2808\n",
      "Epoch 69: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2808 - val_loss: 1.3525\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2813\n",
      "Epoch 70: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2813 - val_loss: 1.3512\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2795\n",
      "Epoch 71: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2795 - val_loss: 1.3509\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2748\n",
      "Epoch 72: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2748 - val_loss: 1.3487\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2724\n",
      "Epoch 73: val_loss did not improve from 1.34633\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2724 - val_loss: 1.3502\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2745\n",
      "Epoch 74: val_loss improved from 1.34633 to 1.34587, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 18s 618us/sample - loss: 1.2745 - val_loss: 1.3459\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2757\n",
      "Epoch 75: val_loss did not improve from 1.34587\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2757 - val_loss: 1.3511\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2745\n",
      "Epoch 76: val_loss did not improve from 1.34587\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2745 - val_loss: 1.3524\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2741\n",
      "Epoch 77: val_loss did not improve from 1.34587\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2741 - val_loss: 1.3518\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2753\n",
      "Epoch 78: val_loss did not improve from 1.34587\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2753 - val_loss: 1.3461\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2717\n",
      "Epoch 79: val_loss did not improve from 1.34587\n",
      "29601/29601 [==============================] - 16s 544us/sample - loss: 1.2717 - val_loss: 1.3523\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2714\n",
      "Epoch 80: val_loss improved from 1.34587 to 1.34585, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2714 - val_loss: 1.3459\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2691\n",
      "Epoch 81: val_loss did not improve from 1.34585\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2691 - val_loss: 1.3532\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2678\n",
      "Epoch 82: val_loss did not improve from 1.34585\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2678 - val_loss: 1.3482\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2687\n",
      "Epoch 83: val_loss did not improve from 1.34585\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2687 - val_loss: 1.3471\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2719\n",
      "Epoch 84: val_loss improved from 1.34585 to 1.34198, saving model to ./checkpoints/Feature_extraction_remove_autocorr_1.h5\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2719 - val_loss: 1.3420\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2719\n",
      "Epoch 85: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2719 - val_loss: 1.3440\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2688\n",
      "Epoch 86: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2688 - val_loss: 1.3456\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2672\n",
      "Epoch 87: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 18s 616us/sample - loss: 1.2672 - val_loss: 1.3515\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2662\n",
      "Epoch 88: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2662 - val_loss: 1.3517\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2709\n",
      "Epoch 89: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2709 - val_loss: 1.3503\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2664\n",
      "Epoch 90: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2664 - val_loss: 1.3506\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2656\n",
      "Epoch 91: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2656 - val_loss: 1.3578\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2657\n",
      "Epoch 92: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2657 - val_loss: 1.3448\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2679\n",
      "Epoch 93: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2679 - val_loss: 1.3452\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2645\n",
      "Epoch 94: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2645 - val_loss: 1.3557\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2640\n",
      "Epoch 95: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2640 - val_loss: 1.3525\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2641\n",
      "Epoch 96: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2641 - val_loss: 1.3547\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2651\n",
      "Epoch 97: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2651 - val_loss: 1.3476\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2630\n",
      "Epoch 98: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2630 - val_loss: 1.3523\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2637\n",
      "Epoch 99: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2637 - val_loss: 1.3463\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2633\n",
      "Epoch 100: val_loss did not improve from 1.34198\n",
      "29601/29601 [==============================] - 16s 547us/sample - loss: 1.2633 - val_loss: 1.3463\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2608\n",
      "Epoch 1: val_loss improved from inf to 1.34969, saving model to ./checkpoints/Feature_extraction_remove_autocorr_2.h5\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2608 - val_loss: 1.3497\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2589\n",
      "Epoch 2: val_loss improved from 1.34969 to 1.34691, saving model to ./checkpoints/Feature_extraction_remove_autocorr_2.h5\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2589 - val_loss: 1.3469\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2595\n",
      "Epoch 3: val_loss did not improve from 1.34691\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2595 - val_loss: 1.3504\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2580\n",
      "Epoch 4: val_loss did not improve from 1.34691\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2580 - val_loss: 1.3492\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2587\n",
      "Epoch 5: val_loss did not improve from 1.34691\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2587 - val_loss: 1.3476\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2573\n",
      "Epoch 6: val_loss did not improve from 1.34691\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2573 - val_loss: 1.3527\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2555\n",
      "Epoch 7: val_loss improved from 1.34691 to 1.34513, saving model to ./checkpoints/Feature_extraction_remove_autocorr_2.h5\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2555 - val_loss: 1.3451\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2576\n",
      "Epoch 8: val_loss did not improve from 1.34513\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2576 - val_loss: 1.3463\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2573\n",
      "Epoch 9: val_loss did not improve from 1.34513\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2573 - val_loss: 1.3560\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 10: val_loss did not improve from 1.34513\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2598 - val_loss: 1.3504\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2578\n",
      "Epoch 11: val_loss did not improve from 1.34513\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2578 - val_loss: 1.3477\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2591\n",
      "Epoch 12: val_loss did not improve from 1.34513\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2591 - val_loss: 1.3490\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2557\n",
      "Epoch 13: val_loss improved from 1.34513 to 1.34469, saving model to ./checkpoints/Feature_extraction_remove_autocorr_2.h5\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2557 - val_loss: 1.3447\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2552\n",
      "Epoch 14: val_loss did not improve from 1.34469\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2552 - val_loss: 1.3487\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2621\n",
      "Epoch 15: val_loss improved from 1.34469 to 1.34222, saving model to ./checkpoints/Feature_extraction_remove_autocorr_2.h5\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2621 - val_loss: 1.3422\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2621\n",
      "Epoch 16: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2621 - val_loss: 1.3517\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2592\n",
      "Epoch 17: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2592 - val_loss: 1.3573\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 18: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2598 - val_loss: 1.3486\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2576\n",
      "Epoch 19: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2576 - val_loss: 1.3530\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2548\n",
      "Epoch 20: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2548 - val_loss: 1.3448\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2585\n",
      "Epoch 21: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 540us/sample - loss: 1.2585 - val_loss: 1.3504\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2583\n",
      "Epoch 22: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2583 - val_loss: 1.3517\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2543\n",
      "Epoch 23: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2543 - val_loss: 1.3487\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2587\n",
      "Epoch 24: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2587 - val_loss: 1.3499\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2908\n",
      "Epoch 25: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 17s 584us/sample - loss: 1.2908 - val_loss: 1.3473\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2645\n",
      "Epoch 26: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2645 - val_loss: 1.3462\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2610\n",
      "Epoch 27: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2610 - val_loss: 1.3447\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2641\n",
      "Epoch 28: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2641 - val_loss: 1.3458\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2599\n",
      "Epoch 29: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2599 - val_loss: 1.3499\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2680\n",
      "Epoch 30: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2680 - val_loss: 1.3502\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2662\n",
      "Epoch 31: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2662 - val_loss: 1.3531\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2625\n",
      "Epoch 32: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2625 - val_loss: 1.3482\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2577\n",
      "Epoch 33: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 17s 564us/sample - loss: 1.2577 - val_loss: 1.3426\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2600\n",
      "Epoch 34: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2600 - val_loss: 1.3462\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2796\n",
      "Epoch 35: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2796 - val_loss: 1.3496\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2660\n",
      "Epoch 36: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2660 - val_loss: 1.3449\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2661\n",
      "Epoch 37: val_loss did not improve from 1.34222\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2661 - val_loss: 1.3510\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2660\n",
      "Epoch 38: val_loss improved from 1.34222 to 1.34129, saving model to ./checkpoints/Feature_extraction_remove_autocorr_2.h5\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2660 - val_loss: 1.3413\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2644\n",
      "Epoch 39: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2644 - val_loss: 1.3449\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2695\n",
      "Epoch 40: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2695 - val_loss: 1.3508\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2674\n",
      "Epoch 41: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2674 - val_loss: 1.3463\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2651\n",
      "Epoch 42: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2651 - val_loss: 1.3531\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2638\n",
      "Epoch 43: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2638 - val_loss: 1.3509\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2650\n",
      "Epoch 44: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2650 - val_loss: 1.3475\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2640\n",
      "Epoch 45: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2640 - val_loss: 1.3510\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2656\n",
      "Epoch 46: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2656 - val_loss: 1.3517\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2654\n",
      "Epoch 47: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2654 - val_loss: 1.3605\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2672\n",
      "Epoch 48: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2672 - val_loss: 1.3545\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2674\n",
      "Epoch 49: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2674 - val_loss: 1.3480\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2717\n",
      "Epoch 50: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 541us/sample - loss: 1.2717 - val_loss: 1.3484\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2667\n",
      "Epoch 51: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2667 - val_loss: 1.3503\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2673\n",
      "Epoch 52: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2673 - val_loss: 1.3480\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2631\n",
      "Epoch 53: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2631 - val_loss: 1.3492\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2637\n",
      "Epoch 54: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2637 - val_loss: 1.3523\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2644\n",
      "Epoch 55: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2644 - val_loss: 1.3446\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2604\n",
      "Epoch 56: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2604 - val_loss: 1.3571\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2587\n",
      "Epoch 57: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2587 - val_loss: 1.3447\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2598\n",
      "Epoch 58: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2598 - val_loss: 1.3464\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2585\n",
      "Epoch 59: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2585 - val_loss: 1.3458\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2587\n",
      "Epoch 60: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2587 - val_loss: 1.3451\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2533\n",
      "Epoch 61: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2533 - val_loss: 1.3423\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2560\n",
      "Epoch 62: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2560 - val_loss: 1.3517\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2540\n",
      "Epoch 63: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2540 - val_loss: 1.3512\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2529\n",
      "Epoch 64: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2529 - val_loss: 1.3440\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2525\n",
      "Epoch 65: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 612us/sample - loss: 1.2525 - val_loss: 1.3497\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2516\n",
      "Epoch 66: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2516 - val_loss: 1.3480\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2527\n",
      "Epoch 67: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2527 - val_loss: 1.3519\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2511\n",
      "Epoch 68: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2511 - val_loss: 1.3515\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2455\n",
      "Epoch 69: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2455 - val_loss: 1.3538\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2517\n",
      "Epoch 70: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2517 - val_loss: 1.3500\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2497\n",
      "Epoch 71: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2497 - val_loss: 1.3480\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 72: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2473 - val_loss: 1.3477\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2453\n",
      "Epoch 73: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2453 - val_loss: 1.3490\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2458\n",
      "Epoch 74: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 624us/sample - loss: 1.2458 - val_loss: 1.3468\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2463\n",
      "Epoch 75: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 586us/sample - loss: 1.2463 - val_loss: 1.3481\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2439\n",
      "Epoch 76: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2439 - val_loss: 1.3503\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2418\n",
      "Epoch 77: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2418 - val_loss: 1.3505\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2431\n",
      "Epoch 78: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2431 - val_loss: 1.3480\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2416\n",
      "Epoch 79: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2416 - val_loss: 1.3508\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 80: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2387 - val_loss: 1.3541\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 81: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 517us/sample - loss: 1.2410 - val_loss: 1.3496\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2408\n",
      "Epoch 82: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2408 - val_loss: 1.3457\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2431\n",
      "Epoch 83: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 515us/sample - loss: 1.2431 - val_loss: 1.3457\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2415\n",
      "Epoch 84: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 514us/sample - loss: 1.2415 - val_loss: 1.3496\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2405\n",
      "Epoch 85: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 521us/sample - loss: 1.2405 - val_loss: 1.3448\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2390\n",
      "Epoch 86: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 551us/sample - loss: 1.2390 - val_loss: 1.3459\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2395\n",
      "Epoch 87: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2395 - val_loss: 1.3465\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2382\n",
      "Epoch 88: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2382 - val_loss: 1.3467\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 89: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 587us/sample - loss: 1.2370 - val_loss: 1.3469\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2379\n",
      "Epoch 90: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.2379 - val_loss: 1.3496\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2380\n",
      "Epoch 91: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 592us/sample - loss: 1.2380 - val_loss: 1.3517\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 92: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2358 - val_loss: 1.3552\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2342\n",
      "Epoch 93: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2342 - val_loss: 1.3524\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2343\n",
      "Epoch 94: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 550us/sample - loss: 1.2343 - val_loss: 1.3500\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2329\n",
      "Epoch 95: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2329 - val_loss: 1.3522\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2355\n",
      "Epoch 96: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 17s 572us/sample - loss: 1.2355 - val_loss: 1.3495\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 97: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2326 - val_loss: 1.3552\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 98: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2326 - val_loss: 1.3479\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 99: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 526us/sample - loss: 1.2315 - val_loss: 1.3501\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 100: val_loss did not improve from 1.34129\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2310 - val_loss: 1.3529\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 1: val_loss improved from inf to 1.36632, saving model to ./checkpoints/Feature_extraction_remove_autocorr_3.h5\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2300 - val_loss: 1.3663\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 2: val_loss improved from 1.36632 to 1.34849, saving model to ./checkpoints/Feature_extraction_remove_autocorr_3.h5\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2306 - val_loss: 1.3485\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2309\n",
      "Epoch 3: val_loss did not improve from 1.34849\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2309 - val_loss: 1.3517\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 4: val_loss did not improve from 1.34849\n",
      "29601/29601 [==============================] - 16s 524us/sample - loss: 1.2339 - val_loss: 1.3492\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2269\n",
      "Epoch 5: val_loss did not improve from 1.34849\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2269 - val_loss: 1.3530\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2255\n",
      "Epoch 6: val_loss improved from 1.34849 to 1.34732, saving model to ./checkpoints/Feature_extraction_remove_autocorr_3.h5\n",
      "29601/29601 [==============================] - 16s 556us/sample - loss: 1.2255 - val_loss: 1.3473\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2274\n",
      "Epoch 7: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2274 - val_loss: 1.3524\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2291\n",
      "Epoch 8: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2291 - val_loss: 1.3548\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 9: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2300 - val_loss: 1.3495\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2372\n",
      "Epoch 10: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2372 - val_loss: 1.3543\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 11: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2300 - val_loss: 1.3496\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2308\n",
      "Epoch 12: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2308 - val_loss: 1.3518\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 13: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2358 - val_loss: 1.3578\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 14: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2344 - val_loss: 1.3479\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2332\n",
      "Epoch 15: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2332 - val_loss: 1.3590\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2376\n",
      "Epoch 16: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2376 - val_loss: 1.3580\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2383\n",
      "Epoch 17: val_loss did not improve from 1.34732\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2383 - val_loss: 1.3555\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2385\n",
      "Epoch 18: val_loss improved from 1.34732 to 1.33907, saving model to ./checkpoints/Feature_extraction_remove_autocorr_3.h5\n",
      "29601/29601 [==============================] - 17s 588us/sample - loss: 1.2385 - val_loss: 1.3391\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 19: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 534us/sample - loss: 1.2351 - val_loss: 1.3477\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 20: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 532us/sample - loss: 1.2365 - val_loss: 1.3432\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2346\n",
      "Epoch 21: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2346 - val_loss: 1.3486\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2339\n",
      "Epoch 22: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 538us/sample - loss: 1.2339 - val_loss: 1.3499\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 23: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 567us/sample - loss: 1.2361 - val_loss: 1.3528\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 24: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2363 - val_loss: 1.3549\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2367\n",
      "Epoch 25: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 595us/sample - loss: 1.2367 - val_loss: 1.3507\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 26: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2366 - val_loss: 1.3521\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2397\n",
      "Epoch 27: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2397 - val_loss: 1.3543\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2377\n",
      "Epoch 28: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2377 - val_loss: 1.3532\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2371\n",
      "Epoch 29: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 615us/sample - loss: 1.2371 - val_loss: 1.3486\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2376\n",
      "Epoch 30: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 624us/sample - loss: 1.2376 - val_loss: 1.3611\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2499\n",
      "Epoch 31: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 19s 639us/sample - loss: 1.2499 - val_loss: 1.3539\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2406\n",
      "Epoch 32: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2406 - val_loss: 1.3525\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2442\n",
      "Epoch 33: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2442 - val_loss: 1.3507\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2426\n",
      "Epoch 34: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2426 - val_loss: 1.3499\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2460\n",
      "Epoch 35: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 552us/sample - loss: 1.2460 - val_loss: 1.3521\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2437\n",
      "Epoch 36: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2437 - val_loss: 1.3473\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2429\n",
      "Epoch 37: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2429 - val_loss: 1.3503\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2398\n",
      "Epoch 38: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 583us/sample - loss: 1.2398 - val_loss: 1.3521\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2403\n",
      "Epoch 39: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2403 - val_loss: 1.3460\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2435\n",
      "Epoch 40: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2435 - val_loss: 1.3518\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2486\n",
      "Epoch 41: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2486 - val_loss: 1.3544\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2445\n",
      "Epoch 42: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 562us/sample - loss: 1.2445 - val_loss: 1.3523\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2436\n",
      "Epoch 43: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2436 - val_loss: 1.3579\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 44: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 616us/sample - loss: 1.2502 - val_loss: 1.3451\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 45: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 596us/sample - loss: 1.2428 - val_loss: 1.3525\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2454\n",
      "Epoch 46: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 570us/sample - loss: 1.2454 - val_loss: 1.3485\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2435\n",
      "Epoch 47: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 608us/sample - loss: 1.2435 - val_loss: 1.3496\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2518\n",
      "Epoch 48: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2518 - val_loss: 1.3435\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2483\n",
      "Epoch 49: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2483 - val_loss: 1.3442\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 50: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 531us/sample - loss: 1.2466 - val_loss: 1.3472\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2467\n",
      "Epoch 51: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 561us/sample - loss: 1.2467 - val_loss: 1.3554\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2492\n",
      "Epoch 52: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2492 - val_loss: 1.3406\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2450\n",
      "Epoch 53: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2450 - val_loss: 1.3492\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 54: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 585us/sample - loss: 1.2428 - val_loss: 1.3543\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2422\n",
      "Epoch 55: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 546us/sample - loss: 1.2422 - val_loss: 1.3544\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2407\n",
      "Epoch 56: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2407 - val_loss: 1.3580\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2399\n",
      "Epoch 57: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2399 - val_loss: 1.3526\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2375\n",
      "Epoch 58: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 548us/sample - loss: 1.2375 - val_loss: 1.3521\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2362\n",
      "Epoch 59: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2362 - val_loss: 1.3542\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2357\n",
      "Epoch 60: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 19s 633us/sample - loss: 1.2357 - val_loss: 1.3540\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 61: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 19s 645us/sample - loss: 1.2358 - val_loss: 1.3524\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2382\n",
      "Epoch 62: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2382 - val_loss: 1.3524\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 63: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2353 - val_loss: 1.3525\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2332\n",
      "Epoch 64: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 20s 666us/sample - loss: 1.2332 - val_loss: 1.3477\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2334\n",
      "Epoch 65: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 593us/sample - loss: 1.2334 - val_loss: 1.3474\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2303\n",
      "Epoch 66: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2303 - val_loss: 1.3529\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2307\n",
      "Epoch 67: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2307 - val_loss: 1.3540\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 68: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2302 - val_loss: 1.3578\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 69: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2296 - val_loss: 1.3572\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2311\n",
      "Epoch 70: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 543us/sample - loss: 1.2311 - val_loss: 1.3507\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2275\n",
      "Epoch 71: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 597us/sample - loss: 1.2275 - val_loss: 1.3516\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 72: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 620us/sample - loss: 1.2305 - val_loss: 1.3602\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2297\n",
      "Epoch 73: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 19s 633us/sample - loss: 1.2297 - val_loss: 1.3498\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2263\n",
      "Epoch 74: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 614us/sample - loss: 1.2263 - val_loss: 1.3536\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2277\n",
      "Epoch 75: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.2277 - val_loss: 1.3566\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2289\n",
      "Epoch 76: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2289 - val_loss: 1.3500\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 77: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2266 - val_loss: 1.3553\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2244\n",
      "Epoch 78: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2244 - val_loss: 1.3554\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 79: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2253 - val_loss: 1.3506\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2251\n",
      "Epoch 80: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2251 - val_loss: 1.3577\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2229\n",
      "Epoch 81: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 594us/sample - loss: 1.2229 - val_loss: 1.3558\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2234\n",
      "Epoch 82: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2234 - val_loss: 1.3493\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2202\n",
      "Epoch 83: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2202 - val_loss: 1.3517\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2232\n",
      "Epoch 84: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 15s 522us/sample - loss: 1.2232 - val_loss: 1.3585\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 85: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2250 - val_loss: 1.3517\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2209\n",
      "Epoch 86: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 15s 518us/sample - loss: 1.2209 - val_loss: 1.3499\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2218\n",
      "Epoch 87: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2218 - val_loss: 1.3507\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 88: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2237 - val_loss: 1.3539\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2211\n",
      "Epoch 89: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 577us/sample - loss: 1.2211 - val_loss: 1.3543\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 90: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2197 - val_loss: 1.3516\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2161\n",
      "Epoch 91: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 610us/sample - loss: 1.2161 - val_loss: 1.3552\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 92: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 576us/sample - loss: 1.2176 - val_loss: 1.3522\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2179\n",
      "Epoch 93: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 607us/sample - loss: 1.2179 - val_loss: 1.3549\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2167\n",
      "Epoch 94: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2167 - val_loss: 1.3558\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2158\n",
      "Epoch 95: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2158 - val_loss: 1.3547\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2159\n",
      "Epoch 96: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 537us/sample - loss: 1.2159 - val_loss: 1.3524\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2190\n",
      "Epoch 97: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2190 - val_loss: 1.3590\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2160\n",
      "Epoch 98: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2160 - val_loss: 1.3692\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 99: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 17s 569us/sample - loss: 1.2162 - val_loss: 1.3575\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2151\n",
      "Epoch 100: val_loss did not improve from 1.33907\n",
      "29601/29601 [==============================] - 16s 545us/sample - loss: 1.2151 - val_loss: 1.3541\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2146\n",
      "Epoch 1: val_loss improved from inf to 1.35019, saving model to ./checkpoints/Feature_extraction_remove_autocorr_4.h5\n",
      "29601/29601 [==============================] - 18s 601us/sample - loss: 1.2146 - val_loss: 1.3502\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2163\n",
      "Epoch 2: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 18s 602us/sample - loss: 1.2163 - val_loss: 1.3543\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2141\n",
      "Epoch 3: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2141 - val_loss: 1.3547\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2109\n",
      "Epoch 4: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2109 - val_loss: 1.3520\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2069\n",
      "Epoch 5: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 23s 772us/sample - loss: 1.2069 - val_loss: 1.3568\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2082\n",
      "Epoch 6: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 25s 830us/sample - loss: 1.2082 - val_loss: 1.3585\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2100\n",
      "Epoch 7: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 24s 800us/sample - loss: 1.2100 - val_loss: 1.3541\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2130\n",
      "Epoch 8: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 536us/sample - loss: 1.2130 - val_loss: 1.3528\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2124\n",
      "Epoch 9: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2124 - val_loss: 1.3576\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2155\n",
      "Epoch 10: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 530us/sample - loss: 1.2155 - val_loss: 1.3531\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2158\n",
      "Epoch 11: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2158 - val_loss: 1.3559\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 12: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.2200 - val_loss: 1.3550\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2170\n",
      "Epoch 13: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 17s 591us/sample - loss: 1.2170 - val_loss: 1.3558\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2164\n",
      "Epoch 14: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2164 - val_loss: 1.3518\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2184\n",
      "Epoch 15: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 539us/sample - loss: 1.2184 - val_loss: 1.3593\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2193\n",
      "Epoch 16: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 554us/sample - loss: 1.2193 - val_loss: 1.3538\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2187\n",
      "Epoch 17: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2187 - val_loss: 1.3577\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 18: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2210 - val_loss: 1.3564\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2149\n",
      "Epoch 19: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2149 - val_loss: 1.3536\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2195\n",
      "Epoch 20: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2195 - val_loss: 1.3591\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2205\n",
      "Epoch 21: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 18s 604us/sample - loss: 1.2205 - val_loss: 1.3603\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 22: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2197 - val_loss: 1.3624\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 23: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 525us/sample - loss: 1.2216 - val_loss: 1.3547\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2201\n",
      "Epoch 24: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 16s 555us/sample - loss: 1.2201 - val_loss: 1.3531\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2224\n",
      "Epoch 25: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 17s 590us/sample - loss: 1.2224 - val_loss: 1.3542\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2248\n",
      "Epoch 26: val_loss did not improve from 1.35019\n",
      "29601/29601 [==============================] - 18s 609us/sample - loss: 1.2248 - val_loss: 1.3513\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2279\n",
      "Epoch 27: val_loss improved from 1.35019 to 1.34986, saving model to ./checkpoints/Feature_extraction_remove_autocorr_4.h5\n",
      "29601/29601 [==============================] - 18s 599us/sample - loss: 1.2279 - val_loss: 1.3499\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 28: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 582us/sample - loss: 1.2242 - val_loss: 1.3547\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2253\n",
      "Epoch 29: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2253 - val_loss: 1.3541\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 30: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 15s 523us/sample - loss: 1.2243 - val_loss: 1.3533\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2277\n",
      "Epoch 31: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 15s 516us/sample - loss: 1.2277 - val_loss: 1.3590\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2298\n",
      "Epoch 32: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 15s 519us/sample - loss: 1.2298 - val_loss: 1.3583\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2299\n",
      "Epoch 33: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2299 - val_loss: 1.3590\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 34: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 560us/sample - loss: 1.2315 - val_loss: 1.3564\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 35: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 18s 591us/sample - loss: 1.2326 - val_loss: 1.3548\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2288\n",
      "Epoch 36: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 535us/sample - loss: 1.2288 - val_loss: 1.3607\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2267\n",
      "Epoch 37: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 574us/sample - loss: 1.2267 - val_loss: 1.3578\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2382\n",
      "Epoch 38: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 18s 606us/sample - loss: 1.2382 - val_loss: 1.3602\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 39: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 566us/sample - loss: 1.2368 - val_loss: 1.3628\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 40: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 18s 605us/sample - loss: 1.2358 - val_loss: 1.3531\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2483\n",
      "Epoch 41: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 559us/sample - loss: 1.2483 - val_loss: 1.3572\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 42: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 18s 618us/sample - loss: 1.2421 - val_loss: 1.3625\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2480\n",
      "Epoch 43: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 18s 619us/sample - loss: 1.2480 - val_loss: 1.3586\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2491\n",
      "Epoch 44: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 558us/sample - loss: 1.2491 - val_loss: 1.3534\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 45: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 565us/sample - loss: 1.2501 - val_loss: 1.3578\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2522\n",
      "Epoch 46: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 18s 613us/sample - loss: 1.2522 - val_loss: 1.3548\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2623\n",
      "Epoch 47: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 17s 589us/sample - loss: 1.2623 - val_loss: 1.3541\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2541\n",
      "Epoch 48: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 542us/sample - loss: 1.2541 - val_loss: 1.3618\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2554\n",
      "Epoch 49: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 549us/sample - loss: 1.2554 - val_loss: 1.3587\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.3072\n",
      "Epoch 50: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 528us/sample - loss: 1.3072 - val_loss: 1.3562\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2654\n",
      "Epoch 51: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 529us/sample - loss: 1.2654 - val_loss: 1.3566\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 52: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 533us/sample - loss: 1.2607 - val_loss: 1.3583\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2571\n",
      "Epoch 53: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 16s 527us/sample - loss: 1.2571 - val_loss: 1.3663\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 54: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 21s 702us/sample - loss: 1.2523 - val_loss: 1.3583\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2469\n",
      "Epoch 55: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2469 - val_loss: 1.3591\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 56: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 25s 833us/sample - loss: 1.2471 - val_loss: 1.3603\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2419\n",
      "Epoch 57: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2419 - val_loss: 1.3651\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2427\n",
      "Epoch 58: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 27s 905us/sample - loss: 1.2427 - val_loss: 1.3584\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2431\n",
      "Epoch 59: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2431 - val_loss: 1.3599\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2405\n",
      "Epoch 60: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 26s 879us/sample - loss: 1.2405 - val_loss: 1.3616\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2416\n",
      "Epoch 61: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 25s 837us/sample - loss: 1.2416 - val_loss: 1.3610\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 62: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 23s 786us/sample - loss: 1.2387 - val_loss: 1.3599\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 63: val_loss did not improve from 1.34986\n",
      "29601/29601 [==============================] - 25s 833us/sample - loss: 1.2410 - val_loss: 1.3502\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 64: val_loss improved from 1.34986 to 1.34891, saving model to ./checkpoints/Feature_extraction_remove_autocorr_4.h5\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2361 - val_loss: 1.3489\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 65: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 877us/sample - loss: 1.2368 - val_loss: 1.3502\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 66: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2344 - val_loss: 1.3524\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2349\n",
      "Epoch 67: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 24s 808us/sample - loss: 1.2349 - val_loss: 1.3540\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2359\n",
      "Epoch 68: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2359 - val_loss: 1.3552\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2324\n",
      "Epoch 69: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2324 - val_loss: 1.3572\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2328\n",
      "Epoch 70: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 847us/sample - loss: 1.2328 - val_loss: 1.3499\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 71: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 879us/sample - loss: 1.2321 - val_loss: 1.3559\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2290\n",
      "Epoch 72: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 831us/sample - loss: 1.2290 - val_loss: 1.3562\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2278\n",
      "Epoch 73: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 24s 798us/sample - loss: 1.2278 - val_loss: 1.3533\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2281\n",
      "Epoch 74: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 829us/sample - loss: 1.2281 - val_loss: 1.3537\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 75: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 833us/sample - loss: 1.2296 - val_loss: 1.3507\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 76: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 838us/sample - loss: 1.2242 - val_loss: 1.3514\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2247\n",
      "Epoch 77: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2247 - val_loss: 1.3536\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2269\n",
      "Epoch 78: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2269 - val_loss: 1.3536\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2267\n",
      "Epoch 79: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2267 - val_loss: 1.3530\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 80: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2300 - val_loss: 1.3501\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2259\n",
      "Epoch 81: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 26s 882us/sample - loss: 1.2259 - val_loss: 1.3516\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2248\n",
      "Epoch 82: val_loss did not improve from 1.34891\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2248 - val_loss: 1.3504\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2241\n",
      "Epoch 83: val_loss improved from 1.34891 to 1.34371, saving model to ./checkpoints/Feature_extraction_remove_autocorr_4.h5\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2241 - val_loss: 1.3437\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2250\n",
      "Epoch 84: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2250 - val_loss: 1.3481\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2221\n",
      "Epoch 85: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 883us/sample - loss: 1.2221 - val_loss: 1.3501\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 86: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 28s 948us/sample - loss: 1.2183 - val_loss: 1.3492\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2249\n",
      "Epoch 87: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 29s 984us/sample - loss: 1.2249 - val_loss: 1.3498\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2222\n",
      "Epoch 88: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 881us/sample - loss: 1.2222 - val_loss: 1.3479\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2167\n",
      "Epoch 89: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2167 - val_loss: 1.3523\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 90: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2183 - val_loss: 1.3595\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2191\n",
      "Epoch 91: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 844us/sample - loss: 1.2191 - val_loss: 1.3623\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 92: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 877us/sample - loss: 1.2186 - val_loss: 1.3530\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2169\n",
      "Epoch 93: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 890us/sample - loss: 1.2169 - val_loss: 1.3493\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2157\n",
      "Epoch 94: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2157 - val_loss: 1.3507\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2148\n",
      "Epoch 95: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 874us/sample - loss: 1.2148 - val_loss: 1.3523\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 96: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2176 - val_loss: 1.3524\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2142\n",
      "Epoch 97: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2142 - val_loss: 1.3566\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2144\n",
      "Epoch 98: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2144 - val_loss: 1.3551\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2137\n",
      "Epoch 99: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 26s 874us/sample - loss: 1.2137 - val_loss: 1.3479\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2125\n",
      "Epoch 100: val_loss did not improve from 1.34371\n",
      "29601/29601 [==============================] - 24s 809us/sample - loss: 1.2125 - val_loss: 1.3531\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2170\n",
      "Epoch 1: val_loss improved from inf to 1.35792, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 25s 834us/sample - loss: 1.2170 - val_loss: 1.3579\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 2: val_loss improved from 1.35792 to 1.35594, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 23s 779us/sample - loss: 1.2176 - val_loss: 1.3559\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2144\n",
      "Epoch 3: val_loss improved from 1.35594 to 1.35410, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 26s 886us/sample - loss: 1.2144 - val_loss: 1.3541\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2112\n",
      "Epoch 4: val_loss improved from 1.35410 to 1.35345, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 27s 920us/sample - loss: 1.2112 - val_loss: 1.3535\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2090\n",
      "Epoch 5: val_loss improved from 1.35345 to 1.34685, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 23s 790us/sample - loss: 1.2090 - val_loss: 1.3469\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2082\n",
      "Epoch 6: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2082 - val_loss: 1.3498\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2061\n",
      "Epoch 7: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2061 - val_loss: 1.3479\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2106\n",
      "Epoch 8: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 888us/sample - loss: 1.2106 - val_loss: 1.3527\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2153\n",
      "Epoch 9: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 894us/sample - loss: 1.2153 - val_loss: 1.3569\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2107\n",
      "Epoch 10: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 24s 819us/sample - loss: 1.2107 - val_loss: 1.3496\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2124\n",
      "Epoch 11: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 873us/sample - loss: 1.2124 - val_loss: 1.3526\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2141\n",
      "Epoch 12: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2141 - val_loss: 1.3487\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2158\n",
      "Epoch 13: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 25s 846us/sample - loss: 1.2158 - val_loss: 1.3563\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2147\n",
      "Epoch 14: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2147 - val_loss: 1.3542\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2166\n",
      "Epoch 15: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2166 - val_loss: 1.3529\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 16: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2186 - val_loss: 1.3522\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2213\n",
      "Epoch 17: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2213 - val_loss: 1.3498\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2191\n",
      "Epoch 18: val_loss did not improve from 1.34685\n",
      "29601/29601 [==============================] - 26s 876us/sample - loss: 1.2191 - val_loss: 1.3586\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2207\n",
      "Epoch 19: val_loss improved from 1.34685 to 1.34624, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 26s 867us/sample - loss: 1.2207 - val_loss: 1.3462\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 20: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 23s 771us/sample - loss: 1.2200 - val_loss: 1.3494\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2249\n",
      "Epoch 21: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 24s 802us/sample - loss: 1.2249 - val_loss: 1.3543\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2259\n",
      "Epoch 22: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2259 - val_loss: 1.3498\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2235\n",
      "Epoch 23: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2235 - val_loss: 1.3526\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2229\n",
      "Epoch 24: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 24s 802us/sample - loss: 1.2229 - val_loss: 1.3517\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 25: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 27s 905us/sample - loss: 1.2306 - val_loss: 1.3508\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2265\n",
      "Epoch 26: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2265 - val_loss: 1.3480\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2346\n",
      "Epoch 27: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 27s 900us/sample - loss: 1.2346 - val_loss: 1.3484\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2349\n",
      "Epoch 28: val_loss did not improve from 1.34624\n",
      "29601/29601 [==============================] - 26s 881us/sample - loss: 1.2349 - val_loss: 1.3488\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2329\n",
      "Epoch 29: val_loss improved from 1.34624 to 1.34578, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2329 - val_loss: 1.3458\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2322\n",
      "Epoch 30: val_loss improved from 1.34578 to 1.34390, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2322 - val_loss: 1.3439\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2383\n",
      "Epoch 31: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 25s 844us/sample - loss: 1.2383 - val_loss: 1.3507\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2349\n",
      "Epoch 32: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 25s 838us/sample - loss: 1.2349 - val_loss: 1.3441\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2544\n",
      "Epoch 33: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2544 - val_loss: 1.3487\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2425\n",
      "Epoch 34: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2425 - val_loss: 1.3516\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 35: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 25s 836us/sample - loss: 1.2394 - val_loss: 1.3488\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2411\n",
      "Epoch 36: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 26s 876us/sample - loss: 1.2411 - val_loss: 1.3469\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2429\n",
      "Epoch 37: val_loss did not improve from 1.34390\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2429 - val_loss: 1.3450\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2427\n",
      "Epoch 38: val_loss improved from 1.34390 to 1.34267, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 26s 895us/sample - loss: 1.2427 - val_loss: 1.3427\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2434\n",
      "Epoch 39: val_loss improved from 1.34267 to 1.33992, saving model to ./checkpoints/Feature_extraction_remove_autocorr_5.h5\n",
      "29601/29601 [==============================] - 27s 907us/sample - loss: 1.2434 - val_loss: 1.3399\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2487\n",
      "Epoch 40: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 838us/sample - loss: 1.2487 - val_loss: 1.3462\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2461\n",
      "Epoch 41: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 877us/sample - loss: 1.2461 - val_loss: 1.3501\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 42: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 889us/sample - loss: 1.2468 - val_loss: 1.3500\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2517\n",
      "Epoch 43: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 894us/sample - loss: 1.2517 - val_loss: 1.3474\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2577\n",
      "Epoch 44: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2577 - val_loss: 1.3468\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2703\n",
      "Epoch 45: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 884us/sample - loss: 1.2703 - val_loss: 1.3572\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2646\n",
      "Epoch 46: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 24s 800us/sample - loss: 1.2646 - val_loss: 1.3469\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2619\n",
      "Epoch 47: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 907us/sample - loss: 1.2619 - val_loss: 1.3512\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2675\n",
      "Epoch 48: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2675 - val_loss: 1.3504\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2642\n",
      "Epoch 49: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 905us/sample - loss: 1.2642 - val_loss: 1.3489\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2628\n",
      "Epoch 50: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2628 - val_loss: 1.3450\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2676\n",
      "Epoch 51: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 898us/sample - loss: 1.2676 - val_loss: 1.3514\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2679\n",
      "Epoch 52: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 905us/sample - loss: 1.2679 - val_loss: 1.3468\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2622\n",
      "Epoch 53: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 24s 822us/sample - loss: 1.2622 - val_loss: 1.3502\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2581\n",
      "Epoch 54: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 835us/sample - loss: 1.2581 - val_loss: 1.3548\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2557\n",
      "Epoch 55: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2557 - val_loss: 1.3519\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2538\n",
      "Epoch 56: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2538 - val_loss: 1.3496\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2512\n",
      "Epoch 57: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 887us/sample - loss: 1.2512 - val_loss: 1.3513\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 58: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 834us/sample - loss: 1.2523 - val_loss: 1.3471\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 59: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 24s 815us/sample - loss: 1.2501 - val_loss: 1.3469\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2487\n",
      "Epoch 60: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 829us/sample - loss: 1.2487 - val_loss: 1.3495\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2472\n",
      "Epoch 61: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 832us/sample - loss: 1.2472 - val_loss: 1.3495\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 62: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 872us/sample - loss: 1.2471 - val_loss: 1.3503\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2451\n",
      "Epoch 63: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2451 - val_loss: 1.3527\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2430\n",
      "Epoch 64: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2430 - val_loss: 1.3537\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 65: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2421 - val_loss: 1.3517\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 66: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2413 - val_loss: 1.3493\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 67: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2413 - val_loss: 1.3534\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 68: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 904us/sample - loss: 1.2387 - val_loss: 1.3538\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 69: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 897us/sample - loss: 1.2366 - val_loss: 1.3575\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2396\n",
      "Epoch 70: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 898us/sample - loss: 1.2396 - val_loss: 1.3526\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 71: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2358 - val_loss: 1.3525\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2357\n",
      "Epoch 72: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 868us/sample - loss: 1.2357 - val_loss: 1.3542\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2359\n",
      "Epoch 73: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2359 - val_loss: 1.3490\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2317\n",
      "Epoch 74: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 830us/sample - loss: 1.2317 - val_loss: 1.3450\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2322\n",
      "Epoch 75: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 870us/sample - loss: 1.2322 - val_loss: 1.3505\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 76: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 899us/sample - loss: 1.2306 - val_loss: 1.3484\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2310\n",
      "Epoch 77: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2310 - val_loss: 1.3541\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2313\n",
      "Epoch 78: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 877us/sample - loss: 1.2313 - val_loss: 1.3528\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2319\n",
      "Epoch 79: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 857us/sample - loss: 1.2319 - val_loss: 1.3486\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2299\n",
      "Epoch 80: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2299 - val_loss: 1.3509\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2309\n",
      "Epoch 81: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2309 - val_loss: 1.3488\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2271\n",
      "Epoch 82: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 840us/sample - loss: 1.2271 - val_loss: 1.3530\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2291\n",
      "Epoch 83: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2291 - val_loss: 1.3524\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2300\n",
      "Epoch 84: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 24s 828us/sample - loss: 1.2300 - val_loss: 1.3496\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2290\n",
      "Epoch 85: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2290 - val_loss: 1.3494\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2280\n",
      "Epoch 86: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 24s 815us/sample - loss: 1.2280 - val_loss: 1.3531\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2268\n",
      "Epoch 87: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2268 - val_loss: 1.3499\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 88: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 907us/sample - loss: 1.2242 - val_loss: 1.3484\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2224\n",
      "Epoch 89: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 895us/sample - loss: 1.2224 - val_loss: 1.3519\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 90: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 23s 790us/sample - loss: 1.2237 - val_loss: 1.3550\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 91: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 895us/sample - loss: 1.2237 - val_loss: 1.3487\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2224\n",
      "Epoch 92: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 29s 968us/sample - loss: 1.2224 - val_loss: 1.3529\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2265\n",
      "Epoch 93: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 874us/sample - loss: 1.2265 - val_loss: 1.3531\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2236\n",
      "Epoch 94: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2236 - val_loss: 1.3447\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2231\n",
      "Epoch 95: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 896us/sample - loss: 1.2231 - val_loss: 1.3560\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 96: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 26s 866us/sample - loss: 1.2216 - val_loss: 1.3525\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2204\n",
      "Epoch 97: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2204 - val_loss: 1.3511\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2213\n",
      "Epoch 98: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 27s 896us/sample - loss: 1.2213 - val_loss: 1.3502\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2183\n",
      "Epoch 99: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2183 - val_loss: 1.3495\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2168\n",
      "Epoch 100: val_loss did not improve from 1.33992\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2168 - val_loss: 1.3501\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 1: val_loss improved from inf to 1.34921, saving model to ./checkpoints/Feature_extraction_remove_autocorr_6.h5\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2196 - val_loss: 1.3492\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 2: val_loss did not improve from 1.34921\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2176 - val_loss: 1.3516\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2163\n",
      "Epoch 3: val_loss did not improve from 1.34921\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2163 - val_loss: 1.3527\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2150\n",
      "Epoch 4: val_loss improved from 1.34921 to 1.34482, saving model to ./checkpoints/Feature_extraction_remove_autocorr_6.h5\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2150 - val_loss: 1.3448\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2142\n",
      "Epoch 5: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2142 - val_loss: 1.3534\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2100\n",
      "Epoch 6: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2100 - val_loss: 1.3526\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2085\n",
      "Epoch 7: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2085 - val_loss: 1.3490\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2122\n",
      "Epoch 8: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 26s 873us/sample - loss: 1.2122 - val_loss: 1.3469\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2168\n",
      "Epoch 9: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2168 - val_loss: 1.3581\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2144\n",
      "Epoch 10: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2144 - val_loss: 1.3461\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2178\n",
      "Epoch 11: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 25s 846us/sample - loss: 1.2178 - val_loss: 1.3542\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 12: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2162 - val_loss: 1.3497\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2139\n",
      "Epoch 13: val_loss did not improve from 1.34482\n",
      "29601/29601 [==============================] - 23s 777us/sample - loss: 1.2139 - val_loss: 1.3506\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2225\n",
      "Epoch 14: val_loss improved from 1.34482 to 1.34387, saving model to ./checkpoints/Feature_extraction_remove_autocorr_6.h5\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2225 - val_loss: 1.3439\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2266\n",
      "Epoch 15: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2266 - val_loss: 1.3468\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2206\n",
      "Epoch 16: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 27s 913us/sample - loss: 1.2206 - val_loss: 1.3460\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2164\n",
      "Epoch 17: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 23s 792us/sample - loss: 1.2164 - val_loss: 1.3519\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2446\n",
      "Epoch 18: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2446 - val_loss: 1.3479\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2260\n",
      "Epoch 19: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2260 - val_loss: 1.3470\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2272\n",
      "Epoch 20: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 24s 810us/sample - loss: 1.2272 - val_loss: 1.3537\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 21: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 26s 866us/sample - loss: 1.2296 - val_loss: 1.3528\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 22: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 25s 840us/sample - loss: 1.2301 - val_loss: 1.3519\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2312\n",
      "Epoch 23: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 26s 871us/sample - loss: 1.2312 - val_loss: 1.3543\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2308\n",
      "Epoch 24: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2308 - val_loss: 1.3506\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2299\n",
      "Epoch 25: val_loss did not improve from 1.34387\n",
      "29601/29601 [==============================] - 26s 884us/sample - loss: 1.2299 - val_loss: 1.3449\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 26: val_loss improved from 1.34387 to 1.33903, saving model to ./checkpoints/Feature_extraction_remove_autocorr_6.h5\n",
      "29601/29601 [==============================] - 25s 847us/sample - loss: 1.2306 - val_loss: 1.3390\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2384\n",
      "Epoch 27: val_loss improved from 1.33903 to 1.33898, saving model to ./checkpoints/Feature_extraction_remove_autocorr_6.h5\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2384 - val_loss: 1.3390\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2363\n",
      "Epoch 28: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 896us/sample - loss: 1.2363 - val_loss: 1.3543\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2338\n",
      "Epoch 29: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 795us/sample - loss: 1.2338 - val_loss: 1.3475\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 30: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2296 - val_loss: 1.3415\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2327\n",
      "Epoch 31: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2327 - val_loss: 1.3429\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 32: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 866us/sample - loss: 1.2306 - val_loss: 1.3463\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 33: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2394 - val_loss: 1.3486\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2360\n",
      "Epoch 34: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 834us/sample - loss: 1.2360 - val_loss: 1.3518\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2362\n",
      "Epoch 35: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 887us/sample - loss: 1.2362 - val_loss: 1.3490\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 36: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 845us/sample - loss: 1.2353 - val_loss: 1.3462\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2393\n",
      "Epoch 37: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2393 - val_loss: 1.3417\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2425\n",
      "Epoch 38: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 826us/sample - loss: 1.2425 - val_loss: 1.3472\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2400\n",
      "Epoch 39: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2400 - val_loss: 1.3481\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2460\n",
      "Epoch 40: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 872us/sample - loss: 1.2460 - val_loss: 1.3529\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2456\n",
      "Epoch 41: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 897us/sample - loss: 1.2456 - val_loss: 1.3484\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2509\n",
      "Epoch 42: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 886us/sample - loss: 1.2509 - val_loss: 1.3469\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2498\n",
      "Epoch 43: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 868us/sample - loss: 1.2498 - val_loss: 1.3457\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2510\n",
      "Epoch 44: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2510 - val_loss: 1.3482\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2534\n",
      "Epoch 45: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2534 - val_loss: 1.3572\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2574\n",
      "Epoch 46: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 823us/sample - loss: 1.2574 - val_loss: 1.3577\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2576\n",
      "Epoch 47: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2576 - val_loss: 1.3497\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2585\n",
      "Epoch 48: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 849us/sample - loss: 1.2585 - val_loss: 1.3528\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2603\n",
      "Epoch 49: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 928us/sample - loss: 1.2603 - val_loss: 1.3437\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2626\n",
      "Epoch 50: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 897us/sample - loss: 1.2626 - val_loss: 1.3468\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2648\n",
      "Epoch 51: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 897us/sample - loss: 1.2648 - val_loss: 1.3551\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2661\n",
      "Epoch 52: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 874us/sample - loss: 1.2661 - val_loss: 1.3622\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2619\n",
      "Epoch 53: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 28s 941us/sample - loss: 1.2619 - val_loss: 1.3494\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2580\n",
      "Epoch 54: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2580 - val_loss: 1.3539\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2561\n",
      "Epoch 55: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 858us/sample - loss: 1.2561 - val_loss: 1.3518\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2540\n",
      "Epoch 56: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2540 - val_loss: 1.3494\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2530\n",
      "Epoch 57: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 28s 942us/sample - loss: 1.2530 - val_loss: 1.3450\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2497\n",
      "Epoch 58: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2497 - val_loss: 1.3432\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 59: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 907us/sample - loss: 1.2501 - val_loss: 1.3488\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2477\n",
      "Epoch 60: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 877us/sample - loss: 1.2477 - val_loss: 1.3478\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2425\n",
      "Epoch 61: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2425 - val_loss: 1.3476\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2462\n",
      "Epoch 62: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 898us/sample - loss: 1.2462 - val_loss: 1.3530\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2452\n",
      "Epoch 63: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 816us/sample - loss: 1.2452 - val_loss: 1.3471\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2404\n",
      "Epoch 64: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 895us/sample - loss: 1.2404 - val_loss: 1.3442\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2430\n",
      "Epoch 65: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 885us/sample - loss: 1.2430 - val_loss: 1.3451\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2415\n",
      "Epoch 66: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2415 - val_loss: 1.3478\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2400\n",
      "Epoch 67: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2400 - val_loss: 1.3570\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 68: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2394 - val_loss: 1.3546\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2381\n",
      "Epoch 69: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 844us/sample - loss: 1.2381 - val_loss: 1.3504\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2373\n",
      "Epoch 70: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2373 - val_loss: 1.3542\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2358\n",
      "Epoch 71: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 914us/sample - loss: 1.2358 - val_loss: 1.3455\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2346\n",
      "Epoch 72: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 876us/sample - loss: 1.2346 - val_loss: 1.3442\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2325\n",
      "Epoch 73: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2325 - val_loss: 1.3538\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2370\n",
      "Epoch 74: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 873us/sample - loss: 1.2370 - val_loss: 1.3515\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2345\n",
      "Epoch 75: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 885us/sample - loss: 1.2345 - val_loss: 1.3484\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2312\n",
      "Epoch 76: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2312 - val_loss: 1.3476\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2353\n",
      "Epoch 77: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2353 - val_loss: 1.3489\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2301\n",
      "Epoch 78: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 874us/sample - loss: 1.2301 - val_loss: 1.3518\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2308\n",
      "Epoch 79: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 881us/sample - loss: 1.2308 - val_loss: 1.3486\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2333\n",
      "Epoch 80: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 896us/sample - loss: 1.2333 - val_loss: 1.3486\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2306\n",
      "Epoch 81: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 888us/sample - loss: 1.2306 - val_loss: 1.3431\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 82: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2305 - val_loss: 1.3493\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2316\n",
      "Epoch 83: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2316 - val_loss: 1.3497\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2268\n",
      "Epoch 84: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 802us/sample - loss: 1.2268 - val_loss: 1.3461\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2248\n",
      "Epoch 85: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 858us/sample - loss: 1.2248 - val_loss: 1.3527\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2294\n",
      "Epoch 86: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2294 - val_loss: 1.3495\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2302\n",
      "Epoch 87: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 857us/sample - loss: 1.2302 - val_loss: 1.3489\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2234\n",
      "Epoch 88: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 817us/sample - loss: 1.2234 - val_loss: 1.3558\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2251\n",
      "Epoch 89: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 895us/sample - loss: 1.2251 - val_loss: 1.3525\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2224\n",
      "Epoch 90: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 805us/sample - loss: 1.2224 - val_loss: 1.3476\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 91: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 24s 809us/sample - loss: 1.2245 - val_loss: 1.3483\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 92: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 894us/sample - loss: 1.2197 - val_loss: 1.3447\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 93: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2216 - val_loss: 1.3515\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2234\n",
      "Epoch 94: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2234 - val_loss: 1.3488\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 95: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2197 - val_loss: 1.3471\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2226\n",
      "Epoch 96: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 27s 909us/sample - loss: 1.2226 - val_loss: 1.3468\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2211\n",
      "Epoch 97: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 872us/sample - loss: 1.2211 - val_loss: 1.3471\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2182\n",
      "Epoch 98: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 878us/sample - loss: 1.2182 - val_loss: 1.3521\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2176\n",
      "Epoch 99: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 25s 857us/sample - loss: 1.2176 - val_loss: 1.3450\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2187\n",
      "Epoch 100: val_loss did not improve from 1.33898\n",
      "29601/29601 [==============================] - 26s 878us/sample - loss: 1.2187 - val_loss: 1.3631\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2182\n",
      "Epoch 1: val_loss improved from inf to 1.34709, saving model to ./checkpoints/Feature_extraction_remove_autocorr_7.h5\n",
      "29601/29601 [==============================] - 26s 890us/sample - loss: 1.2182 - val_loss: 1.3471\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2158\n",
      "Epoch 2: val_loss did not improve from 1.34709\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2158 - val_loss: 1.3517\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 3: val_loss did not improve from 1.34709\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2162 - val_loss: 1.3506\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2126\n",
      "Epoch 4: val_loss improved from 1.34709 to 1.34695, saving model to ./checkpoints/Feature_extraction_remove_autocorr_7.h5\n",
      "29601/29601 [==============================] - 26s 888us/sample - loss: 1.2126 - val_loss: 1.3469\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2154\n",
      "Epoch 5: val_loss did not improve from 1.34695\n",
      "29601/29601 [==============================] - 27s 906us/sample - loss: 1.2154 - val_loss: 1.3524\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2114\n",
      "Epoch 6: val_loss improved from 1.34695 to 1.34243, saving model to ./checkpoints/Feature_extraction_remove_autocorr_7.h5\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2114 - val_loss: 1.3424\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2131\n",
      "Epoch 7: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 23s 785us/sample - loss: 1.2131 - val_loss: 1.3467\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2080\n",
      "Epoch 8: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 845us/sample - loss: 1.2080 - val_loss: 1.3495\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2140\n",
      "Epoch 9: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 871us/sample - loss: 1.2140 - val_loss: 1.3442\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2149\n",
      "Epoch 10: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2149 - val_loss: 1.3470\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2145\n",
      "Epoch 11: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 24s 803us/sample - loss: 1.2145 - val_loss: 1.3482\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2080\n",
      "Epoch 12: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 879us/sample - loss: 1.2080 - val_loss: 1.3495\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2083\n",
      "Epoch 13: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 24s 813us/sample - loss: 1.2083 - val_loss: 1.3490\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2151\n",
      "Epoch 14: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 831us/sample - loss: 1.2151 - val_loss: 1.3478\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2174\n",
      "Epoch 15: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2174 - val_loss: 1.3507\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2193\n",
      "Epoch 16: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 866us/sample - loss: 1.2193 - val_loss: 1.3524\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2164\n",
      "Epoch 17: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2164 - val_loss: 1.3493\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2151\n",
      "Epoch 18: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 883us/sample - loss: 1.2151 - val_loss: 1.3450\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2195\n",
      "Epoch 19: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 27s 904us/sample - loss: 1.2195 - val_loss: 1.3453\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2191\n",
      "Epoch 20: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2191 - val_loss: 1.3548\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 21: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2245 - val_loss: 1.3523\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2225\n",
      "Epoch 22: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 845us/sample - loss: 1.2225 - val_loss: 1.3499\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2218\n",
      "Epoch 23: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 27s 903us/sample - loss: 1.2218 - val_loss: 1.3426\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2246\n",
      "Epoch 24: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 24s 817us/sample - loss: 1.2246 - val_loss: 1.3499\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2273\n",
      "Epoch 25: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2273 - val_loss: 1.3521\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2259\n",
      "Epoch 26: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2259 - val_loss: 1.3455\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2287\n",
      "Epoch 27: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 844us/sample - loss: 1.2287 - val_loss: 1.3537\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 28: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 23s 771us/sample - loss: 1.2344 - val_loss: 1.3542\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2305\n",
      "Epoch 29: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2305 - val_loss: 1.3466\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2319\n",
      "Epoch 30: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 844us/sample - loss: 1.2319 - val_loss: 1.3511\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2343\n",
      "Epoch 31: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 889us/sample - loss: 1.2343 - val_loss: 1.3507\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 32: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 894us/sample - loss: 1.2365 - val_loss: 1.3520\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2456\n",
      "Epoch 33: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2456 - val_loss: 1.3504\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 34: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2466 - val_loss: 1.3556\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 35: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 23s 794us/sample - loss: 1.2473 - val_loss: 1.3492\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2489\n",
      "Epoch 36: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 24s 812us/sample - loss: 1.2489 - val_loss: 1.3509\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2508\n",
      "Epoch 37: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2508 - val_loss: 1.3431\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2470\n",
      "Epoch 38: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 842us/sample - loss: 1.2470 - val_loss: 1.3477\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2593\n",
      "Epoch 39: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 871us/sample - loss: 1.2593 - val_loss: 1.3536\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 40: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2502 - val_loss: 1.3541\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2590\n",
      "Epoch 41: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2590 - val_loss: 1.3590\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2588\n",
      "Epoch 42: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 834us/sample - loss: 1.2588 - val_loss: 1.3544\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2608\n",
      "Epoch 43: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2608 - val_loss: 1.3547\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2539\n",
      "Epoch 44: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 876us/sample - loss: 1.2539 - val_loss: 1.3559\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2582\n",
      "Epoch 45: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 844us/sample - loss: 1.2582 - val_loss: 1.3529\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2595\n",
      "Epoch 46: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 24s 826us/sample - loss: 1.2595 - val_loss: 1.3493\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2557\n",
      "Epoch 47: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 895us/sample - loss: 1.2557 - val_loss: 1.3515\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2606\n",
      "Epoch 48: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2606 - val_loss: 1.3593\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2677\n",
      "Epoch 49: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2677 - val_loss: 1.3572\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2612\n",
      "Epoch 50: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2612 - val_loss: 1.3524\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2682\n",
      "Epoch 51: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 883us/sample - loss: 1.2682 - val_loss: 1.3500\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2705\n",
      "Epoch 52: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2705 - val_loss: 1.3480\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2677\n",
      "Epoch 53: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2677 - val_loss: 1.3474\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2660\n",
      "Epoch 54: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 829us/sample - loss: 1.2660 - val_loss: 1.3430\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 55: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 879us/sample - loss: 1.2607 - val_loss: 1.3433\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2627\n",
      "Epoch 56: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 873us/sample - loss: 1.2627 - val_loss: 1.3568\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2571\n",
      "Epoch 57: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 24s 820us/sample - loss: 1.2571 - val_loss: 1.3644\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2550\n",
      "Epoch 58: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 878us/sample - loss: 1.2550 - val_loss: 1.3526\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2535\n",
      "Epoch 59: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 888us/sample - loss: 1.2535 - val_loss: 1.3532\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2526\n",
      "Epoch 60: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 868us/sample - loss: 1.2526 - val_loss: 1.3493\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2502\n",
      "Epoch 61: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2502 - val_loss: 1.3452\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2506\n",
      "Epoch 62: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 25s 834us/sample - loss: 1.2506 - val_loss: 1.3428\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2494\n",
      "Epoch 63: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2494 - val_loss: 1.3468\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2466\n",
      "Epoch 64: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 26s 871us/sample - loss: 1.2466 - val_loss: 1.3518\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2443\n",
      "Epoch 65: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 27s 913us/sample - loss: 1.2443 - val_loss: 1.3513\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2458\n",
      "Epoch 66: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 27s 922us/sample - loss: 1.2458 - val_loss: 1.3437\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2450\n",
      "Epoch 67: val_loss did not improve from 1.34243\n",
      "29601/29601 [==============================] - 28s 931us/sample - loss: 1.2450 - val_loss: 1.3513\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2433\n",
      "Epoch 68: val_loss improved from 1.34243 to 1.34183, saving model to ./checkpoints/Feature_extraction_remove_autocorr_7.h5\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2433 - val_loss: 1.3418\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2426\n",
      "Epoch 69: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 28s 931us/sample - loss: 1.2426 - val_loss: 1.3452\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2398\n",
      "Epoch 70: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 907us/sample - loss: 1.2398 - val_loss: 1.3444\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2416\n",
      "Epoch 71: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 913us/sample - loss: 1.2416 - val_loss: 1.3466\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 72: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 916us/sample - loss: 1.2394 - val_loss: 1.3491\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2361\n",
      "Epoch 73: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 928us/sample - loss: 1.2361 - val_loss: 1.3446\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2372\n",
      "Epoch 74: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 919us/sample - loss: 1.2372 - val_loss: 1.3483\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2368\n",
      "Epoch 75: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 921us/sample - loss: 1.2368 - val_loss: 1.3494\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 76: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 925us/sample - loss: 1.2387 - val_loss: 1.3464\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2391\n",
      "Epoch 77: val_loss did not improve from 1.34183\n",
      "29601/29601 [==============================] - 27s 926us/sample - loss: 1.2391 - val_loss: 1.3471\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2387\n",
      "Epoch 78: val_loss improved from 1.34183 to 1.33885, saving model to ./checkpoints/Feature_extraction_remove_autocorr_7.h5\n",
      "29601/29601 [==============================] - 26s 881us/sample - loss: 1.2387 - val_loss: 1.3389\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2346\n",
      "Epoch 79: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 26s 877us/sample - loss: 1.2346 - val_loss: 1.3465\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2366\n",
      "Epoch 80: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 923us/sample - loss: 1.2366 - val_loss: 1.3458\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2342\n",
      "Epoch 81: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2342 - val_loss: 1.3466\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 82: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2351 - val_loss: 1.3411\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2344\n",
      "Epoch 83: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2344 - val_loss: 1.3439\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2295\n",
      "Epoch 84: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 843us/sample - loss: 1.2295 - val_loss: 1.3470\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 85: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2296 - val_loss: 1.3481\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2321\n",
      "Epoch 86: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2321 - val_loss: 1.3459\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2272\n",
      "Epoch 87: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2272 - val_loss: 1.3439\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2256\n",
      "Epoch 88: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2256 - val_loss: 1.3470\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2275\n",
      "Epoch 89: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2275 - val_loss: 1.3412\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2238\n",
      "Epoch 90: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2238 - val_loss: 1.3521\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2275\n",
      "Epoch 91: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2275 - val_loss: 1.3467\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2220\n",
      "Epoch 92: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 900us/sample - loss: 1.2220 - val_loss: 1.3440\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2240\n",
      "Epoch 93: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 26s 883us/sample - loss: 1.2240 - val_loss: 1.3496\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2285\n",
      "Epoch 94: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 26s 889us/sample - loss: 1.2285 - val_loss: 1.3474\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2233\n",
      "Epoch 95: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2233 - val_loss: 1.3472\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2264\n",
      "Epoch 96: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 923us/sample - loss: 1.2264 - val_loss: 1.3479\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2232\n",
      "Epoch 97: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 26s 874us/sample - loss: 1.2232 - val_loss: 1.3505\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2227\n",
      "Epoch 98: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 28s 947us/sample - loss: 1.2227 - val_loss: 1.3472\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2237\n",
      "Epoch 99: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 921us/sample - loss: 1.2237 - val_loss: 1.3440\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2200\n",
      "Epoch 100: val_loss did not improve from 1.33885\n",
      "29601/29601 [==============================] - 27s 911us/sample - loss: 1.2200 - val_loss: 1.3572\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 1: val_loss improved from inf to 1.35145, saving model to ./checkpoints/Feature_extraction_remove_autocorr_8.h5\n",
      "29601/29601 [==============================] - 28s 935us/sample - loss: 1.2194 - val_loss: 1.3515\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2223\n",
      "Epoch 2: val_loss improved from 1.35145 to 1.34706, saving model to ./checkpoints/Feature_extraction_remove_autocorr_8.h5\n",
      "29601/29601 [==============================] - 27s 918us/sample - loss: 1.2223 - val_loss: 1.3471\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2188\n",
      "Epoch 3: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 27s 897us/sample - loss: 1.2188 - val_loss: 1.3522\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2163\n",
      "Epoch 4: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 27s 896us/sample - loss: 1.2163 - val_loss: 1.3478\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2116\n",
      "Epoch 5: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 25s 846us/sample - loss: 1.2116 - val_loss: 1.3484\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2129\n",
      "Epoch 6: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 25s 830us/sample - loss: 1.2129 - val_loss: 1.3489\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2099\n",
      "Epoch 7: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 27s 911us/sample - loss: 1.2099 - val_loss: 1.3500\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2107\n",
      "Epoch 8: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 27s 911us/sample - loss: 1.2107 - val_loss: 1.3516\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 9: val_loss did not improve from 1.34706\n",
      "29601/29601 [==============================] - 27s 906us/sample - loss: 1.2162 - val_loss: 1.3476\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2107\n",
      "Epoch 10: val_loss improved from 1.34706 to 1.34591, saving model to ./checkpoints/Feature_extraction_remove_autocorr_8.h5\n",
      "29601/29601 [==============================] - 27s 909us/sample - loss: 1.2107 - val_loss: 1.3459\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2085\n",
      "Epoch 11: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 906us/sample - loss: 1.2085 - val_loss: 1.3521\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2169\n",
      "Epoch 12: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 909us/sample - loss: 1.2169 - val_loss: 1.3533\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2120\n",
      "Epoch 13: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 918us/sample - loss: 1.2120 - val_loss: 1.3475\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 14: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 914us/sample - loss: 1.2194 - val_loss: 1.3592\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2225\n",
      "Epoch 15: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 26s 885us/sample - loss: 1.2225 - val_loss: 1.3533\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2194\n",
      "Epoch 16: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 901us/sample - loss: 1.2194 - val_loss: 1.3475\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2162\n",
      "Epoch 17: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 909us/sample - loss: 1.2162 - val_loss: 1.3532\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 18: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 921us/sample - loss: 1.2216 - val_loss: 1.3575\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2202\n",
      "Epoch 19: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2202 - val_loss: 1.3538\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2170\n",
      "Epoch 20: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 907us/sample - loss: 1.2170 - val_loss: 1.3587\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2221\n",
      "Epoch 21: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 914us/sample - loss: 1.2221 - val_loss: 1.3559\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2206\n",
      "Epoch 22: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 917us/sample - loss: 1.2206 - val_loss: 1.3486\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2264\n",
      "Epoch 23: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 905us/sample - loss: 1.2264 - val_loss: 1.3574\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2240\n",
      "Epoch 24: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 902us/sample - loss: 1.2240 - val_loss: 1.3515\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 25: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 899us/sample - loss: 1.2270 - val_loss: 1.3609\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2234\n",
      "Epoch 26: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2234 - val_loss: 1.3560\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2326\n",
      "Epoch 27: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2326 - val_loss: 1.3534\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2291\n",
      "Epoch 28: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2291 - val_loss: 1.3524\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2349\n",
      "Epoch 29: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 917us/sample - loss: 1.2349 - val_loss: 1.3524\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2400\n",
      "Epoch 30: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 26s 894us/sample - loss: 1.2400 - val_loss: 1.3480\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2460\n",
      "Epoch 31: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 923us/sample - loss: 1.2460 - val_loss: 1.3559\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2445\n",
      "Epoch 32: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 917us/sample - loss: 1.2445 - val_loss: 1.3518\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2348\n",
      "Epoch 33: val_loss did not improve from 1.34591\n",
      "29601/29601 [==============================] - 27s 918us/sample - loss: 1.2348 - val_loss: 1.3468\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2351\n",
      "Epoch 34: val_loss improved from 1.34591 to 1.34587, saving model to ./checkpoints/Feature_extraction_remove_autocorr_8.h5\n",
      "29601/29601 [==============================] - 27s 918us/sample - loss: 1.2351 - val_loss: 1.3459\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2337\n",
      "Epoch 35: val_loss improved from 1.34587 to 1.34497, saving model to ./checkpoints/Feature_extraction_remove_autocorr_8.h5\n",
      "29601/29601 [==============================] - 27s 918us/sample - loss: 1.2337 - val_loss: 1.3450\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2394\n",
      "Epoch 36: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 905us/sample - loss: 1.2394 - val_loss: 1.3487\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2449\n",
      "Epoch 37: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 899us/sample - loss: 1.2449 - val_loss: 1.3455\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2438\n",
      "Epoch 38: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 945us/sample - loss: 1.2438 - val_loss: 1.3540\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2413\n",
      "Epoch 39: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 911us/sample - loss: 1.2413 - val_loss: 1.3587\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2430\n",
      "Epoch 40: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2430 - val_loss: 1.3595\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2480\n",
      "Epoch 41: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 904us/sample - loss: 1.2480 - val_loss: 1.3557\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2522\n",
      "Epoch 42: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2522 - val_loss: 1.3525\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2594\n",
      "Epoch 43: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 938us/sample - loss: 1.2594 - val_loss: 1.3491\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2601\n",
      "Epoch 44: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 924us/sample - loss: 1.2601 - val_loss: 1.3502\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2634\n",
      "Epoch 45: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 930us/sample - loss: 1.2634 - val_loss: 1.3553\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2648\n",
      "Epoch 46: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 923us/sample - loss: 1.2648 - val_loss: 1.3549\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2845\n",
      "Epoch 47: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 947us/sample - loss: 1.2845 - val_loss: 1.3590\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2840\n",
      "Epoch 48: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 940us/sample - loss: 1.2840 - val_loss: 1.3635\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2845\n",
      "Epoch 49: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2845 - val_loss: 1.3623\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2862\n",
      "Epoch 50: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 916us/sample - loss: 1.2862 - val_loss: 1.3638\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2859\n",
      "Epoch 51: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 871us/sample - loss: 1.2859 - val_loss: 1.3553\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2875\n",
      "Epoch 52: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 890us/sample - loss: 1.2875 - val_loss: 1.3602\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2873\n",
      "Epoch 53: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 927us/sample - loss: 1.2873 - val_loss: 1.3561\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2840\n",
      "Epoch 54: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 884us/sample - loss: 1.2840 - val_loss: 1.3621\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2810\n",
      "Epoch 55: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 898us/sample - loss: 1.2810 - val_loss: 1.3704\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2806\n",
      "Epoch 56: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 886us/sample - loss: 1.2806 - val_loss: 1.3553\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2796\n",
      "Epoch 57: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2796 - val_loss: 1.3568\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2773\n",
      "Epoch 58: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2773 - val_loss: 1.3513\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2733\n",
      "Epoch 59: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 936us/sample - loss: 1.2733 - val_loss: 1.3507\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2721\n",
      "Epoch 60: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 931us/sample - loss: 1.2721 - val_loss: 1.3555\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2727\n",
      "Epoch 61: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 928us/sample - loss: 1.2727 - val_loss: 1.3539\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2675\n",
      "Epoch 62: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 934us/sample - loss: 1.2675 - val_loss: 1.3574\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2714\n",
      "Epoch 63: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 945us/sample - loss: 1.2714 - val_loss: 1.3545\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2669\n",
      "Epoch 64: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 932us/sample - loss: 1.2669 - val_loss: 1.3583\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2656\n",
      "Epoch 65: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 30s 1ms/sample - loss: 1.2656 - val_loss: 1.3632\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2651\n",
      "Epoch 66: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 948us/sample - loss: 1.2651 - val_loss: 1.3646\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2622\n",
      "Epoch 67: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 955us/sample - loss: 1.2622 - val_loss: 1.3640\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2624\n",
      "Epoch 68: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 926us/sample - loss: 1.2624 - val_loss: 1.3666\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2585\n",
      "Epoch 69: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2585 - val_loss: 1.3671\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2599\n",
      "Epoch 70: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 926us/sample - loss: 1.2599 - val_loss: 1.3657\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2624\n",
      "Epoch 71: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 904us/sample - loss: 1.2624 - val_loss: 1.3574\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2611\n",
      "Epoch 72: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 910us/sample - loss: 1.2611 - val_loss: 1.3649\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2588\n",
      "Epoch 73: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 915us/sample - loss: 1.2588 - val_loss: 1.3594\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2556\n",
      "Epoch 74: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 935us/sample - loss: 1.2556 - val_loss: 1.3604\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2582\n",
      "Epoch 75: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 925us/sample - loss: 1.2582 - val_loss: 1.3653\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2555\n",
      "Epoch 76: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 912us/sample - loss: 1.2555 - val_loss: 1.3656\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2561\n",
      "Epoch 77: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 921us/sample - loss: 1.2561 - val_loss: 1.3573\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2535\n",
      "Epoch 78: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 941us/sample - loss: 1.2535 - val_loss: 1.3568\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2529\n",
      "Epoch 79: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 928us/sample - loss: 1.2529 - val_loss: 1.3565\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2542\n",
      "Epoch 80: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 917us/sample - loss: 1.2542 - val_loss: 1.3542\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2531\n",
      "Epoch 81: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 27s 908us/sample - loss: 1.2531 - val_loss: 1.3563\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2504\n",
      "Epoch 82: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2504 - val_loss: 1.3541\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2503\n",
      "Epoch 83: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 24s 801us/sample - loss: 1.2503 - val_loss: 1.3556\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2501\n",
      "Epoch 84: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 841us/sample - loss: 1.2501 - val_loss: 1.3569\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2485\n",
      "Epoch 85: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 846us/sample - loss: 1.2485 - val_loss: 1.3594\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2476\n",
      "Epoch 86: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 836us/sample - loss: 1.2476 - val_loss: 1.3568\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2445\n",
      "Epoch 87: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2445 - val_loss: 1.3675\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2477\n",
      "Epoch 88: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2477 - val_loss: 1.3580\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 89: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 870us/sample - loss: 1.2468 - val_loss: 1.3584\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2459\n",
      "Epoch 90: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2459 - val_loss: 1.3618\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2473\n",
      "Epoch 91: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 881us/sample - loss: 1.2473 - val_loss: 1.3584\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2475\n",
      "Epoch 92: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 28s 951us/sample - loss: 1.2475 - val_loss: 1.3558\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2421\n",
      "Epoch 93: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 24s 798us/sample - loss: 1.2421 - val_loss: 1.3637\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2425\n",
      "Epoch 94: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 24s 805us/sample - loss: 1.2425 - val_loss: 1.3560\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2428\n",
      "Epoch 95: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 24s 825us/sample - loss: 1.2428 - val_loss: 1.3571\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2446\n",
      "Epoch 96: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 24s 819us/sample - loss: 1.2446 - val_loss: 1.3606\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2440\n",
      "Epoch 97: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2440 - val_loss: 1.3570\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2401\n",
      "Epoch 98: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 24s 826us/sample - loss: 1.2401 - val_loss: 1.3622\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2400\n",
      "Epoch 99: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 870us/sample - loss: 1.2400 - val_loss: 1.3648\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2390\n",
      "Epoch 100: val_loss did not improve from 1.34497\n",
      "29601/29601 [==============================] - 26s 872us/sample - loss: 1.2390 - val_loss: 1.3634\n",
      "Train on 29601 samples, validate on 3694 samples\n",
      "Epoch 1/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2397\n",
      "Epoch 1: val_loss improved from inf to 1.35687, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 28s 933us/sample - loss: 1.2397 - val_loss: 1.3569\n",
      "Epoch 2/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2360\n",
      "Epoch 2: val_loss did not improve from 1.35687\n",
      "29601/29601 [==============================] - 26s 870us/sample - loss: 1.2360 - val_loss: 1.3662\n",
      "Epoch 3/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2315\n",
      "Epoch 3: val_loss did not improve from 1.35687\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2315 - val_loss: 1.3679\n",
      "Epoch 4/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2282\n",
      "Epoch 4: val_loss improved from 1.35687 to 1.35563, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2282 - val_loss: 1.3556\n",
      "Epoch 5/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2254\n",
      "Epoch 5: val_loss did not improve from 1.35563\n",
      "29601/29601 [==============================] - 26s 893us/sample - loss: 1.2254 - val_loss: 1.3608\n",
      "Epoch 6/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2242\n",
      "Epoch 6: val_loss improved from 1.35563 to 1.35419, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 27s 912us/sample - loss: 1.2242 - val_loss: 1.3542\n",
      "Epoch 7/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2204\n",
      "Epoch 7: val_loss did not improve from 1.35419\n",
      "29601/29601 [==============================] - 27s 908us/sample - loss: 1.2204 - val_loss: 1.3612\n",
      "Epoch 8/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2246\n",
      "Epoch 8: val_loss did not improve from 1.35419\n",
      "29601/29601 [==============================] - 27s 911us/sample - loss: 1.2246 - val_loss: 1.3600\n",
      "Epoch 9/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2196\n",
      "Epoch 9: val_loss did not improve from 1.35419\n",
      "29601/29601 [==============================] - 27s 911us/sample - loss: 1.2196 - val_loss: 1.3640\n",
      "Epoch 10/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2204\n",
      "Epoch 10: val_loss did not improve from 1.35419\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2204 - val_loss: 1.3612\n",
      "Epoch 11/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2208\n",
      "Epoch 11: val_loss did not improve from 1.35419\n",
      "29601/29601 [==============================] - 26s 866us/sample - loss: 1.2208 - val_loss: 1.3587\n",
      "Epoch 12/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2216\n",
      "Epoch 12: val_loss improved from 1.35419 to 1.35298, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 27s 897us/sample - loss: 1.2216 - val_loss: 1.3530\n",
      "Epoch 13/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2243\n",
      "Epoch 13: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 839us/sample - loss: 1.2243 - val_loss: 1.3675\n",
      "Epoch 14/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2212\n",
      "Epoch 14: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 857us/sample - loss: 1.2212 - val_loss: 1.3601\n",
      "Epoch 15/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2168\n",
      "Epoch 15: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 837us/sample - loss: 1.2168 - val_loss: 1.3625\n",
      "Epoch 16/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2217\n",
      "Epoch 16: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2217 - val_loss: 1.3630\n",
      "Epoch 17/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2231\n",
      "Epoch 17: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 846us/sample - loss: 1.2231 - val_loss: 1.3667\n",
      "Epoch 18/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2210\n",
      "Epoch 18: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2210 - val_loss: 1.3595\n",
      "Epoch 19/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2229\n",
      "Epoch 19: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 26s 870us/sample - loss: 1.2229 - val_loss: 1.3605\n",
      "Epoch 20/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2245\n",
      "Epoch 20: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2245 - val_loss: 1.3586\n",
      "Epoch 21/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2230\n",
      "Epoch 21: val_loss did not improve from 1.35298\n",
      "29601/29601 [==============================] - 24s 823us/sample - loss: 1.2230 - val_loss: 1.3541\n",
      "Epoch 22/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2288\n",
      "Epoch 22: val_loss improved from 1.35298 to 1.35131, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2288 - val_loss: 1.3513\n",
      "Epoch 23/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2271\n",
      "Epoch 23: val_loss did not improve from 1.35131\n",
      "29601/29601 [==============================] - 26s 891us/sample - loss: 1.2271 - val_loss: 1.3579\n",
      "Epoch 24/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2270\n",
      "Epoch 24: val_loss did not improve from 1.35131\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2270 - val_loss: 1.3539\n",
      "Epoch 25/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2272\n",
      "Epoch 25: val_loss did not improve from 1.35131\n",
      "29601/29601 [==============================] - 25s 830us/sample - loss: 1.2272 - val_loss: 1.3519\n",
      "Epoch 26/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 26: val_loss did not improve from 1.35131\n",
      "29601/29601 [==============================] - 25s 830us/sample - loss: 1.2286 - val_loss: 1.3607\n",
      "Epoch 27/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2285\n",
      "Epoch 27: val_loss did not improve from 1.35131\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2285 - val_loss: 1.3528\n",
      "Epoch 28/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2296\n",
      "Epoch 28: val_loss did not improve from 1.35131\n",
      "29601/29601 [==============================] - 25s 859us/sample - loss: 1.2296 - val_loss: 1.3533\n",
      "Epoch 29/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2271\n",
      "Epoch 29: val_loss improved from 1.35131 to 1.34527, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 26s 869us/sample - loss: 1.2271 - val_loss: 1.3453\n",
      "Epoch 30/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2312\n",
      "Epoch 30: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2312 - val_loss: 1.3510\n",
      "Epoch 31/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2356\n",
      "Epoch 31: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2356 - val_loss: 1.3558\n",
      "Epoch 32/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2304\n",
      "Epoch 32: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2304 - val_loss: 1.3538\n",
      "Epoch 33/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2324\n",
      "Epoch 33: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2324 - val_loss: 1.3595\n",
      "Epoch 34/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2338\n",
      "Epoch 34: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2338 - val_loss: 1.3527\n",
      "Epoch 35/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2365\n",
      "Epoch 35: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 26s 867us/sample - loss: 1.2365 - val_loss: 1.3551\n",
      "Epoch 36/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2331\n",
      "Epoch 36: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2331 - val_loss: 1.3595\n",
      "Epoch 37/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2367\n",
      "Epoch 37: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2367 - val_loss: 1.3583\n",
      "Epoch 38/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2392\n",
      "Epoch 38: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2392 - val_loss: 1.3530\n",
      "Epoch 39/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2410\n",
      "Epoch 39: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2410 - val_loss: 1.3498\n",
      "Epoch 40/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2478\n",
      "Epoch 40: val_loss did not improve from 1.34527\n",
      "29601/29601 [==============================] - 26s 870us/sample - loss: 1.2478 - val_loss: 1.3494\n",
      "Epoch 41/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2495\n",
      "Epoch 41: val_loss improved from 1.34527 to 1.34496, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2495 - val_loss: 1.3450\n",
      "Epoch 42/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2500\n",
      "Epoch 42: val_loss improved from 1.34496 to 1.34375, saving model to ./checkpoints/Feature_extraction_remove_autocorr_9.h5\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2500 - val_loss: 1.3438\n",
      "Epoch 43/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2512\n",
      "Epoch 43: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2512 - val_loss: 1.3500\n",
      "Epoch 44/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2585\n",
      "Epoch 44: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 903us/sample - loss: 1.2585 - val_loss: 1.3478\n",
      "Epoch 45/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2547\n",
      "Epoch 45: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2547 - val_loss: 1.3497\n",
      "Epoch 46/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2568\n",
      "Epoch 46: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 860us/sample - loss: 1.2568 - val_loss: 1.3514\n",
      "Epoch 47/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2596\n",
      "Epoch 47: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 875us/sample - loss: 1.2596 - val_loss: 1.3483\n",
      "Epoch 48/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2635\n",
      "Epoch 48: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 830us/sample - loss: 1.2635 - val_loss: 1.3510\n",
      "Epoch 49/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2665\n",
      "Epoch 49: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 845us/sample - loss: 1.2665 - val_loss: 1.3488\n",
      "Epoch 50/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2742\n",
      "Epoch 50: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 856us/sample - loss: 1.2742 - val_loss: 1.3512\n",
      "Epoch 51/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2757\n",
      "Epoch 51: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 899us/sample - loss: 1.2757 - val_loss: 1.3480\n",
      "Epoch 52/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2754\n",
      "Epoch 52: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2754 - val_loss: 1.3465\n",
      "Epoch 53/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2820\n",
      "Epoch 53: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 886us/sample - loss: 1.2820 - val_loss: 1.3484\n",
      "Epoch 54/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2780\n",
      "Epoch 54: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2780 - val_loss: 1.3540\n",
      "Epoch 55/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2774\n",
      "Epoch 55: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 862us/sample - loss: 1.2774 - val_loss: 1.3523\n",
      "Epoch 56/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2745\n",
      "Epoch 56: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 851us/sample - loss: 1.2745 - val_loss: 1.3572\n",
      "Epoch 57/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2795\n",
      "Epoch 57: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 855us/sample - loss: 1.2795 - val_loss: 1.3477\n",
      "Epoch 58/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2736\n",
      "Epoch 58: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 850us/sample - loss: 1.2736 - val_loss: 1.3548\n",
      "Epoch 59/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2772\n",
      "Epoch 59: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 852us/sample - loss: 1.2772 - val_loss: 1.3530\n",
      "Epoch 60/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2758\n",
      "Epoch 60: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 858us/sample - loss: 1.2758 - val_loss: 1.3547\n",
      "Epoch 61/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2795\n",
      "Epoch 61: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2795 - val_loss: 1.3529\n",
      "Epoch 62/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2730\n",
      "Epoch 62: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 853us/sample - loss: 1.2730 - val_loss: 1.3501\n",
      "Epoch 63/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2704\n",
      "Epoch 63: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 848us/sample - loss: 1.2704 - val_loss: 1.3530\n",
      "Epoch 64/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2692\n",
      "Epoch 64: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2692 - val_loss: 1.3534\n",
      "Epoch 65/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2713\n",
      "Epoch 65: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 854us/sample - loss: 1.2713 - val_loss: 1.3568\n",
      "Epoch 66/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2663\n",
      "Epoch 66: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 864us/sample - loss: 1.2663 - val_loss: 1.3526\n",
      "Epoch 67/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2644\n",
      "Epoch 67: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2644 - val_loss: 1.3579\n",
      "Epoch 68/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2653\n",
      "Epoch 68: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 863us/sample - loss: 1.2653 - val_loss: 1.3554\n",
      "Epoch 69/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2639\n",
      "Epoch 69: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 26s 865us/sample - loss: 1.2639 - val_loss: 1.3541\n",
      "Epoch 70/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2618\n",
      "Epoch 70: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 861us/sample - loss: 1.2618 - val_loss: 1.3566\n",
      "Epoch 71/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2606\n",
      "Epoch 71: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 25s 840us/sample - loss: 1.2606 - val_loss: 1.3521\n",
      "Epoch 72/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2640\n",
      "Epoch 72: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 955us/sample - loss: 1.2640 - val_loss: 1.3448\n",
      "Epoch 73/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2619\n",
      "Epoch 73: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 926us/sample - loss: 1.2619 - val_loss: 1.3525\n",
      "Epoch 74/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2626\n",
      "Epoch 74: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 932us/sample - loss: 1.2626 - val_loss: 1.3500\n",
      "Epoch 75/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2578\n",
      "Epoch 75: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 932us/sample - loss: 1.2578 - val_loss: 1.3580\n",
      "Epoch 76/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2607\n",
      "Epoch 76: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 931us/sample - loss: 1.2607 - val_loss: 1.3567\n",
      "Epoch 77/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2578\n",
      "Epoch 77: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 929us/sample - loss: 1.2578 - val_loss: 1.3539\n",
      "Epoch 78/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2586\n",
      "Epoch 78: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 944us/sample - loss: 1.2586 - val_loss: 1.3567\n",
      "Epoch 79/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2582\n",
      "Epoch 79: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 920us/sample - loss: 1.2582 - val_loss: 1.3506\n",
      "Epoch 80/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2582\n",
      "Epoch 80: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 937us/sample - loss: 1.2582 - val_loss: 1.3535\n",
      "Epoch 81/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2616\n",
      "Epoch 81: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 936us/sample - loss: 1.2616 - val_loss: 1.3533\n",
      "Epoch 82/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2591\n",
      "Epoch 82: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 938us/sample - loss: 1.2591 - val_loss: 1.3527\n",
      "Epoch 83/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2571\n",
      "Epoch 83: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 918us/sample - loss: 1.2571 - val_loss: 1.3492\n",
      "Epoch 84/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2551\n",
      "Epoch 84: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 916us/sample - loss: 1.2551 - val_loss: 1.3451\n",
      "Epoch 85/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2541\n",
      "Epoch 85: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 950us/sample - loss: 1.2541 - val_loss: 1.3476\n",
      "Epoch 86/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2523\n",
      "Epoch 86: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 921us/sample - loss: 1.2523 - val_loss: 1.3532\n",
      "Epoch 87/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2469\n",
      "Epoch 87: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 929us/sample - loss: 1.2469 - val_loss: 1.3504\n",
      "Epoch 88/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2539\n",
      "Epoch 88: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 926us/sample - loss: 1.2539 - val_loss: 1.3602\n",
      "Epoch 89/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2529\n",
      "Epoch 89: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 939us/sample - loss: 1.2529 - val_loss: 1.3523\n",
      "Epoch 90/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2540\n",
      "Epoch 90: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 933us/sample - loss: 1.2540 - val_loss: 1.3537\n",
      "Epoch 91/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2490\n",
      "Epoch 91: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 29s 977us/sample - loss: 1.2490 - val_loss: 1.3500\n",
      "Epoch 92/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2449\n",
      "Epoch 92: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 934us/sample - loss: 1.2449 - val_loss: 1.3440\n",
      "Epoch 93/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2522\n",
      "Epoch 93: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 928us/sample - loss: 1.2522 - val_loss: 1.3547\n",
      "Epoch 94/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2530\n",
      "Epoch 94: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 931us/sample - loss: 1.2530 - val_loss: 1.3553\n",
      "Epoch 95/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2471\n",
      "Epoch 95: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 923us/sample - loss: 1.2471 - val_loss: 1.3502\n",
      "Epoch 96/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2479\n",
      "Epoch 96: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 939us/sample - loss: 1.2479 - val_loss: 1.3526\n",
      "Epoch 97/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2487\n",
      "Epoch 97: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 961us/sample - loss: 1.2487 - val_loss: 1.3525\n",
      "Epoch 98/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2470\n",
      "Epoch 98: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 925us/sample - loss: 1.2470 - val_loss: 1.3545\n",
      "Epoch 99/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2492\n",
      "Epoch 99: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 27s 928us/sample - loss: 1.2492 - val_loss: 1.3517\n",
      "Epoch 100/100\n",
      "29601/29601 [==============================] - ETA: 0s - loss: 1.2448\n",
      "Epoch 100: val_loss did not improve from 1.34375\n",
      "29601/29601 [==============================] - 28s 940us/sample - loss: 1.2448 - val_loss: 1.3543\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class PruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_pruning_factor=0.1, final_pruning_factor=0.5, start_epoch=0, end_epoch=None, frequency=1):\n",
    "        super(PruningCallback, self).__init__()\n",
    "        self.initial_pruning_factor = initial_pruning_factor\n",
    "        self.final_pruning_factor = final_pruning_factor\n",
    "        self.start_epoch = start_epoch\n",
    "        self.end_epoch = end_epoch if end_epoch is not None else np.inf\n",
    "        self.frequency = frequency\n",
    "        self.pruned_weights = {}\n",
    "        self.layer_importance = {}\n",
    "\n",
    "    def get_pruning_factor(self, epoch):\n",
    "        if epoch < self.start_epoch:\n",
    "            return 0\n",
    "        if epoch > self.end_epoch:\n",
    "            return self.final_pruning_factor\n",
    "        return self.initial_pruning_factor + (self.final_pruning_factor - self.initial_pruning_factor) * (epoch - self.start_epoch) / (self.end_epoch - self.start_epoch)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        total_weight_magnitude = 0\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'get_weights'):\n",
    "                weights = layer.get_weights()\n",
    "                layer_norm = sum(np.linalg.norm(w) for w in weights)\n",
    "                total_weight_magnitude += layer_norm\n",
    "                self.layer_importance[layer.name] = layer_norm\n",
    "    \n",
    "        # Normalize the layer importance values so they sum up to 1\n",
    "        for layer_name in self.layer_importance:\n",
    "            self.layer_importance[layer_name] /= total_weight_magnitude\n",
    "    # def on_train_begin(self, logs=None):\n",
    "    #     total_weight_magnitude = sum([np.linalg.norm(layer.get_weights()) for layer in self.model.layers if hasattr(layer, 'get_weights')])\n",
    "    #     for layer in self.model.layers:\n",
    "    #         if hasattr(layer, 'get_weights'):\n",
    "    #             self.layer_importance[layer.name] = np.linalg.norm(layer.get_weights()) / total_weight_magnitude\n",
    "\n",
    "    def get_layer_pruning_factor(self, layer_name, global_pruning_factor):\n",
    "        if layer_name in self.layer_importance:\n",
    "            importance = self.layer_importance[layer_name]\n",
    "            adjusted_pruning_factor = global_pruning_factor * (1 - importance)\n",
    "            return min(adjusted_pruning_factor, 1)  # Ensure the pruning factor is not greater than 1\n",
    "        return global_pruning_factor\n",
    "    def prune_weights(self, layer, global_pruning_factor):\n",
    "        \n",
    "        weights = layer.get_weights()\n",
    "        layer_name = layer.name\n",
    "        pruning_factor = self.get_layer_pruning_factor(layer_name, global_pruning_factor)\n",
    "\n",
    "        if layer_name not in self.pruned_weights:\n",
    "            self.pruned_weights[layer_name] = [np.zeros_like(w, dtype=bool) for w in weights]\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            weight = weights[i]\n",
    "            # print(weight.shape)\n",
    "            # print(weight.size)\n",
    "            if weight.ndim > 1:  # Only prune dense or convolutional layers\n",
    "                unpruned_weights = np.logical_not(self.pruned_weights[layer_name][i])\n",
    "                num_unpruned = np.sum(unpruned_weights)\n",
    "                num_pruning = min(num_unpruned, int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i]))\n",
    "                num_pruning = int(weight.size * pruning_factor) - np.sum(self.pruned_weights[layer_name][i])\n",
    "                if num_pruning > 0:\n",
    "                    unpruned_flat_indices = np.flatnonzero(unpruned_weights)\n",
    "                    abs_unpruned_weights = np.abs(weight[unpruned_weights])\n",
    "                    pruning_flat_indices = np.argpartition(abs_unpruned_weights, num_pruning)[:num_pruning]\n",
    "                    \n",
    "                    indices = np.unravel_index(pruning_flat_indices, weight.shape)\n",
    "                    self.pruned_weights[layer_name][i][indices] = True\n",
    "\n",
    "                weights[i] = weights[i]*(~self.pruned_weights[layer_name][i])\n",
    "                \n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch - self.start_epoch) % self.frequency != 0:\n",
    "            return\n",
    "\n",
    "        pruning_factor = self.get_pruning_factor(epoch)\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "                self.prune_weights(layer, pruning_factor)\n",
    "model = individual_model(X_train_normalized)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "num_epochs = 100\n",
    "rates = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "idx = 0\n",
    "for r in rates:\n",
    "# Gradually prune weights in dense and convolutional layers from 10% to 50% over the course of training, starting from epoch 0.\n",
    "    model_name = './checkpoints/Feature_extraction_remove_autocorr_'+str(idx)+'.h5'\n",
    "    idx = idx+1\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    pruning_callback = PruningCallback(initial_pruning_factor=0.01, final_pruning_factor=r, start_epoch=5, end_epoch=50, frequency=1)\n",
    "    model.fit(X_train_normalized_new, y_train, epochs=num_epochs, batch_size=1024, validation_data=(X_val_normalized_new, y_val), callbacks=[pruning_callback, checkpoint])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
